<doc id="18154" url="https://en.wikipedia.org/wiki?curid=18154" title="Propositional calculus">
Propositional calculus

Propositional calculus is a branch of logic. It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic. It deals with propositions (which can be true or false) and argument flow. Compound propositions are formed by connecting propositions by logical connectives. The propositions without logical connectives are called atomic propositions.

Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. However, all the machinery of propositional logic is included in first-order logic and higher-order logics. In this sense, propositional logic is the foundation of first-order logic and higher-order logic.

Logical connectives are found in natural languages. In English for example, some examples are "and" (conjunction), "or" (disjunction), "not" (negation) and "if" (but only when used to denote material conditional).

The following is an example of a very simple inference within the scope of propositional logic:

Both premises and the conclusion are propositions. The premises are taken for granted and then with the application of modus ponens (an inference rule) the conclusion follows.

As propositional logic is not concerned with the structure of propositions beyond the point where they can't be decomposed any more by logical connectives, this inference can be restated replacing those "atomic" statements with statement letters, which are interpreted as variables representing statements:

The same can be stated succinctly in the following way:

When is interpreted as "It's raining" and as "it's cloudy" the above symbolic expressions can be seen to exactly correspond with the original expression in natural language. Not only that, but they will also correspond with any other inference of this "form", which will be valid on the same basis that this inference is.

Propositional logic may be studied through a formal system in which formulas of a formal language may be interpreted to represent propositions. A system of inference rules and axioms allows certain formulas to be derived. These derived formulas are called theorems and may be interpreted to be true propositions. A constructed sequence of such formulas is known as a "derivation" or "proof" and the last formula of the sequence is the theorem. The derivation may be interpreted as proof of the proposition represented by the theorem.

When a formal system is used to represent formal logic, only statement letters are represented directly. The natural language propositions that arise when they're interpreted are outside the scope of the system, and the relation between the formal system and its interpretation is likewise outside the formal system itself.

In classical truth-functional propositional logic, formulas are interpreted as having precisely one of two possible truth values, the truth value of "true" or the truth value of "false". The principle of bivalence and the law of excluded middle are upheld. Truth-functional propositional logic defined as such and systems isomorphic to it are considered to be zeroth-order logic. However, alternative propositional logics are possible. See Other logical calculi below.

Although propositional logic (which is interchangeable with propositional calculus) had been hinted by earlier philosophers, it was developed into a formal logic (Stoic logic) by Chrysippus in the 3rd century BC and expanded by his successor Stoics. The logic was focused on propositions. This advancement was different from the traditional syllogistic logic which was focused on terms. However, later in antiquity, the propositional logic developed by the Stoics was no longer understood . Consequently, the system was essentially reinvented by Peter Abelard in the 12th century.

Propositional logic was eventually refined using symbolic logic. The 17th/18th-century mathematician Gottfried Leibniz has been credited with being the founder of symbolic logic for his work with the calculus ratiocinator. Although his work was the first of its kind, it was unknown to the larger logical community. Consequently, many of the advances achieved by Leibniz were recreated by logicians like George Boole and Augustus De Morgan completely independent of Leibniz.

Just as propositional logic can be considered an advancement from the earlier syllogistic logic, Gottlob Frege's predicate logic was an advancement from the earlier propositional logic. One author describes predicate logic as combining "the distinctive features of syllogistic logic and propositional logic." Consequently, predicate logic ushered in a new era in logic's history; however, advances in propositional logic were still made after Frege, including Natural Deduction, Truth-Trees and Truth-Tables. Natural deduction was invented by Gerhard Gentzen and Jan Łukasiewicz. Truth-Trees were invented by Evert Willem Beth. The invention of truth-tables, however, is of uncertain attribution.

Within works by Frege and Bertrand Russell, are ideas influential to the invention of truth tables. The actual tabular structure (being formatted as a table), itself, is generally credited to either Ludwig Wittgenstein or Emil Post (or both, independently). Besides Frege and Russell, others credited with having ideas preceding truth-tables include Philo, Boole, Charles Sanders Peirce, and Ernst Schröder. Others credited with the tabular structure include Jan Łukasiewicz, Ernst Schröder, Alfred North Whitehead, William Stanley Jevons, John Venn, and Clarence Irving Lewis. Ultimately, some have concluded, like John Shosky, that "It is far from clear that any one person should be given the title of 'inventor' of truth-tables.".

In general terms, a calculus is a formal system that consists of a set of syntactic expressions ("well-formed formulas"), a distinguished subset of these expressions (axioms), plus a set of formal rules that define a specific binary relation, intended to be interpreted as logical equivalence, on the space of expressions.

When the formal system is intended to be a logical system, the expressions are meant to be interpreted as statements, and the rules, known to be "inference rules", are typically intended to be truth-preserving. In this setting, the rules (which may include axioms) can then be used to derive ("infer") formulas representing true statements from given formulas representing true statements.

The set of axioms may be empty, a nonempty finite set, or a countably infinite set (see axiom schema). A formal grammar recursively defines the expressions and well-formed formulas of the language. In addition a semantics may be given which defines truth and valuations (or interpretations).

The language of a propositional calculus consists of

A "well-formed formula" is any atomic formula, or any formula that can be built up from atomic formulas by means of operator symbols according to the rules of the grammar.

Mathematicians sometimes distinguish between propositional constants, propositional variables, and schemata. Propositional constants represent some particular proposition, while propositional variables range over the set of all atomic propositions. Schemata, however, range over all propositions. It is common to represent propositional constants by , , and , propositional variables by , , and , and schematic letters are often Greek letters, most often , , and .

The following outlines a standard propositional calculus. Many different formulations exist which are all more or less equivalent but differ in the details of:

Any given proposition may be represented with a letter called a 'propositional constant', analogous to representing a number by a letter in mathematics, for instance, . All propositions require exactly one of two truth-values: true or false. For example, let be the proposition that it is raining outside. This will be true () if it is raining outside and false otherwise ().


It is extremely helpful to look at the truth tables for these different operators, as well as the method of analytic tableaux.

Propositional logic is closed under truth-functional connectives. That is to say, for any proposition , is also a proposition. Likewise, for any propositions and , is a proposition, and similarly for disjunction, conditional, and biconditional. This implies that, for instance, is a proposition, and so it can be conjoined with another proposition. In order to represent this, we need to use parentheses to indicate which proposition is conjoined with which. For instance, is not a well-formed formula, because we do not know if we are conjoining with or if we are conjoining with . Thus we must write either to represent the former, or to represent the latter. By evaluating the truth conditions, we see that both expressions have the same truth conditions (will be true in the same cases), and moreover that any proposition formed by arbitrary conjunctions will have the same truth conditions, regardless of the location of the parentheses. This means that conjunction is associative, however, one should not assume that parentheses never serve a purpose. For instance, the sentence does not have the same truth conditions of , so they are different sentences distinguished only by the parentheses. One can verify this by the truth-table method referenced above.

Note: For any arbitrary number of propositional constants, we can form a finite number of cases which list their possible truth-values. A simple way to generate this is by truth-tables, in which one writes , , ..., , for any list of propositional constants—that is to say, any list of propositional constants with entries. Below this list, one writes rows, and below one fills in the first half of the rows with true (or T) and the second half with false (or F). Below one fills in one-quarter of the rows with T, then one-quarter with F, then one-quarter with T and the last quarter with F. The next column alternates between true and false for each eighth of the rows, then sixteenths, and so on, until the last propositional constant varies between T and F for each row. This will give a complete listing of cases or truth-value assignments possible for those propositional constants.

The propositional calculus then defines an "argument" to be a list of propositions. A valid argument is a list of propositions, the last of which follows from—or is implied by—the rest. All other arguments are invalid. The simplest valid argument is modus ponens, one instance of which is the following list of propositions:

This is a list of three propositions, each line is a proposition, and the last follows from the rest. The first two lines are called premises, and the last line the conclusion. We say that any proposition follows from any set of propositions formula_6, if must be true whenever every member of the set formula_6 is true. In the argument above, for any and , whenever and are true, necessarily is true. Notice that, when is true, we cannot consider cases 3 and 4 (from the truth table). When is true, we cannot consider case 2. This leaves only case 1, in which is also true. Thus is implied by the premises.

This generalizes schematically. Thus, where and may be any propositions at all,

Other argument forms are convenient, but not necessary. Given a complete set of axioms (see below for one such set), modus ponens is sufficient to prove all other argument forms in propositional logic, thus they may be considered to be a derivative. Note, this is not true of the extension of propositional logic to other logics like first-order logic. First-order logic requires at least one additional rule of inference in order to obtain completeness.

The significance of argument in formal logic is that one may obtain new truths from established truths. In the first example above, given the two premises, the truth of is not yet known or stated. After the argument is made, is deduced. In this way, we define a deduction system to be a set of all propositions that may be deduced from another set of propositions. For instance, given the set of propositions formula_9, we can define a deduction system, , which is the set of all propositions which follow from . Reiteration is always assumed, so formula_10. Also, from the first element of , last element, as well as modus ponens, is a consequence, and so formula_11. Because we have not included sufficiently complete axioms, though, nothing else may be deduced. Thus, even though most deduction systems studied in propositional logic are able to deduce formula_12, this one is too weak to prove such a proposition.

A propositional calculus is a formal system formula_13, where:



The "language" of formula_15, also known as its set of "formulas", "well-formed formulas", is inductively defined by the following rules:


Repeated applications of these rules permits the construction of complex formulas. For example:


Let formula_37, where formula_14, formula_39, formula_25, formula_26 are defined as follows:





Let formula_58, where formula_14, formula_39, formula_25, formula_26 are defined as follows:


In the following example of a propositional calculus, the transformation rules are intended to be interpreted as the inference rules of a so-called "natural deduction system". The particular system presented here has no initial points, which means that its interpretation for logical applications derives its theorems from an empty axiom set.


Our propositional calculus has eleven inference rules. These rules allow us to derive other true formulas given a set of formulas that are assumed to be true. The first ten simply state that we can infer certain well-formed formulas from other well-formed formulas. The last rule however uses hypothetical reasoning in the sense that in the premise of the rule we temporarily assume an (unproven) hypothesis to be part of the set of inferred formulas to see if we can infer a certain other formula. Since the first ten rules don't do this they are usually described as "non-hypothetical" rules, and the last one as a "hypothetical" rule.

In describing the transformation rules, we may introduce a metalanguage symbol formula_70. It is basically a convenient shorthand for saying "infer that". The format is formula_71, in which is a (possibly empty) set of formulas called premises, and is a formula called conclusion. The transformation rule formula_71 means that if every proposition in is a theorem (or has the same truth value as the axioms), then is also a theorem. Note that considering the following rule Conjunction introduction, we will know whenever has more than one formula, we can always safely reduce it into one formula using conjunction. So for short, from that time on we may represent as one formula instead of a set. Another omission for convenience is when is an empty set, in which case may not appear.


One of the main uses of a propositional calculus, when interpreted for logical applications, is to determine relations of logical equivalence between propositional formulas. These relationships are determined by means of the available transformation rules, sequences of which are called "derivations" or "proofs".

In the discussion to follow, a proof is presented as a sequence of numbered lines, with each line consisting of a single formula followed by a "reason" or "justification" for introducing that formula. Each premise of the argument, that is, an assumption introduced as an hypothesis of the argument, is listed at the beginning of the sequence and is marked as a "premise" in lieu of other justification. The conclusion is listed on the last line. A proof is complete if every line follows from the previous ones by the correct application of a transformation rule. (For a contrasting approach, see proof-trees).


Interpret formula_110 as "Assuming , infer ". Read formula_111 as "Assuming nothing, infer that implies ", or "It is a tautology that implies ", or "It is always true that implies ".

The crucial properties of this set of rules are that they are "sound" and "complete". Informally this means that the rules are correct and that no other rules are required. These claims can be made more formal as follows.

We define a "truth assignment" as a function that maps propositional variables to true or false. Informally such a truth assignment can be understood as the description of a possible state of affairs (or possible world) where certain statements are true and others are not. The semantics of formulas can then be formalized by defining for which "state of affairs" they are considered to be true, which is what is done by the following definition.

We define when such a truth assignment satisfies a certain well-formed formula with the following rules:

With this definition we can now formalize what it means for a formula to be implied by a certain set of formulas. Informally this is true if in all worlds that are possible given the set of formulas the formula also holds. This leads to the following formal definition: We say that a set of well-formed formulas "semantically entails" (or "implies") a certain well-formed formula if all truth assignments that satisfy all the formulas in also satisfy .

Finally we define "syntactical entailment" such that is syntactically entailed by if and only if we can derive it with the inference rules that were presented above in a finite number of steps. This allows us to formulate exactly what it means for the set of inference rules to be sound and complete:

Soundness: If the set of well-formed formulas syntactically entails the well-formed formula then semantically entails .

Completeness: If the set of well-formed formulas semantically entails the well-formed formula then syntactically entails .

For the above set of rules this is indeed the case.

Notational conventions: Let be a variable ranging over sets of sentences. Let and range over sentences. For " syntactically entails " we write " proves ". For " semantically entails " we write " implies ".

We want to show: (if proves , then implies ).

We note that " proves " has an inductive definition, and that gives us the immediate resources for demonstrating claims of the form "If proves , then ...". So our proof proceeds by induction.
Notice that Basis Step II can be omitted for natural deduction systems because they have no axioms. When used, Step II involves showing that each of the axioms is a (semantic) logical truth.

The Basis steps demonstrate that the simplest provable sentences from are also implied by , for any . (The proof is simple, since the semantic fact that a set implies any of its members, is also trivial.) The Inductive step will systematically cover all the further sentences that might be provable—by considering each case where we might reach a logical conclusion using an inference rule—and shows that if a new sentence is provable, it is also logically implied. (For example, we might have a rule telling us that from "" we can derive " or ". In III.a We assume that if is provable it is implied. We also know that if is provable then " or " is provable. We have to show that then " or " too is implied. We do so by appeal to the semantic definition and the assumption we just made. is provable from , we assume. So it is also implied by . So any semantic valuation making all of true makes true. But any valuation making true makes " or " true, by the defined semantics for "or". So any valuation which makes all of true makes " or " true. So " or " is implied.) Generally, the Inductive step will consist of a lengthy but simple case-by-case analysis of all the rules of inference, showing that each "preserves" semantic implication.

By the definition of provability, there are no sentences provable other than by being a member of , an axiom, or following by a rule; so if all of those are semantically implied, the deduction calculus is sound.

We adopt the same notational conventions as above.

We want to show: If implies , then proves . We proceed by contraposition: We show instead that if does not prove then does not imply . If we show that there is a model where does not hold despite being true, then obviously does not imply . The idea is to build such a model out of our very assumption that does not prove .

QED

If a formula is a tautology, then there is a truth table for it which shows that each valuation yields the value true for the formula. Consider such a valuation. By mathematical induction on the length of the subformulas, show that the truth or falsity of the subformula follows from the truth or falsity (as appropriate for the valuation) of each propositional variable in the subformula. Then combine the lines of the truth table together two at a time by using "( is true implies ) implies (( is false implies ) implies )". Keep repeating this until all dependencies on propositional variables have been eliminated. The result is that we have proved the given tautology. Since every tautology is provable, the logic is complete.

An interpretation of a truth-functional propositional calculus formula_112 is an assignment to each propositional symbol of formula_112 of one or the other (but not both) of the truth values truth (T) and falsity (F), and an assignment to the connective symbols of formula_112 of their usual truth-functional meanings. An interpretation of a truth-functional propositional calculus may also be expressed in terms of truth tables.

For formula_115 distinct propositional symbols there are formula_116 distinct possible interpretations. For any particular symbol formula_117, for example, there are formula_118 possible interpretations:
For the pair formula_117, formula_122 there are formula_123 possible interpretations:

Since formula_112 has formula_129, that is, denumerably many propositional symbols, there are formula_130, and therefore uncountably many distinct possible interpretations of formula_112.

If and are formulas of formula_112 and formula_133 is an interpretation of formula_112 then:


Some consequences of these definitions:


It is possible to define another version of propositional calculus, which defines most of the syntax of the logical operators by means of axioms, and which uses only one inference rule.

Let , , and stand for well-formed formulas. (The well-formed formulas themselves would not contain any Greek letters, but only capital Roman letters, connective operators, and parentheses.) Then the axioms are as follows:


The inference rule is modus ponens:

Let a demonstration be represented by a sequence, with hypotheses to the left of the turnstile and the conclusion to the right of the turnstile. Then the deduction theorem can be stated as follows:

This deduction theorem (DT) is not itself formulated with propositional calculus: it is not a theorem of propositional calculus, but a theorem about propositional calculus. In this sense, it is a meta-theorem, comparable to theorems about the soundness or completeness of propositional calculus.

On the other hand, DT is so useful for simplifying the syntactical proof process that it can be considered and used as another inference rule, accompanying modus ponens. In this sense, DT corresponds to the natural conditional proof inference rule which is part of the first version of propositional calculus introduced in this article.

The converse of DT is also valid:
in fact, the validity of the converse of DT is almost trivial compared to that of DT:

The converse of DT has powerful implications: it can be used to convert an axiom into an inference rule. For example, the axiom AND-1,
can be transformed by means of the converse of the deduction theorem into the inference rule
which is conjunction elimination, one of the ten inference rules used in the first version (in this article) of the propositional calculus.

The following is an example of a (syntactical) demonstration, involving only axioms and :

Prove: formula_167 (Reflexivity of implication).

Proof:

The preceding alternative calculus is an example of a Hilbert-style deduction system. In the case of propositional systems the axioms are terms built with logical connectives and the only inference rule is modus ponens. Equational logic as standardly used informally in high school algebra is a different kind of calculus from Hilbert systems. Its theorems are equations and its inference rules express the properties of equality, namely that it is a congruence on terms that admits substitution.

Classical propositional calculus as described above is equivalent to Boolean algebra, while intuitionistic propositional calculus is equivalent to Heyting algebra. The equivalence is shown by translation in each direction of the theorems of the respective systems. Theorems formula_176 of classical or intuitionistic propositional calculus are translated as equations formula_177 of Boolean or Heyting algebra respectively. Conversely theorems formula_178 of Boolean or Heyting algebra are translated as theorems formula_179 of classical or intuitionistic calculus respectively, for which formula_180 is a standard abbreviation. In the case of Boolean algebra formula_178 can also be translated as formula_182, but this translation is incorrect intuitionistically.

In both Boolean and Heyting algebra, inequality formula_183 can be used in place of equality. The equality formula_178 is expressible as a pair of inequalities formula_183 and formula_186. Conversely the inequality formula_183 is expressible as the equality formula_188, or as formula_189. The significance of inequality for Hilbert-style systems is that it corresponds to the latter's deduction or entailment symbol formula_70. An entailment

is translated in the inequality version of the algebraic framework as

Conversely the algebraic inequality formula_183 is translated as the entailment

The difference between implication formula_195 and inequality or entailment formula_183 or formula_194 is that the former is internal to the logic while the latter is external. Internal implication between two terms is another term of the same kind. Entailment as external implication between two terms expresses a metatruth outside the language of the logic, and is considered part of the metalanguage. Even when the logic under study is intuitionistic, entailment is ordinarily understood classically as two-valued: either the left side entails, or is less-or-equal to, the right side, or it is not.

Similar but more complex translations to and from algebraic logics are possible for natural deduction systems as described above and for the sequent calculus. The entailments of the latter can be interpreted as two-valued, but a more insightful interpretation is as a set, the elements of which can be understood as abstract proofs organized as the morphisms of a category. In this interpretation the cut rule of the sequent calculus corresponds to composition in the category. Boolean and Heyting algebras enter this picture as special categories having at most one morphism per homset, i.e., one proof per entailment, corresponding to the idea that existence of proofs is all that matters: any proof will do and there is no point in distinguishing them.

It is possible to generalize the definition of a formal language from a set of finite sequences over a finite basis to include many other sets of mathematical structures, so long as they are built up by finitary means from finite materials. What's more, many of these families of formal structures are especially well-suited for use in logic.

For example, there are many families of graphs that are close enough analogues of formal languages that the concept of a calculus is quite easily and naturally extended to them. Indeed, many species of graphs arise as "parse graphs" in the syntactic analysis of the corresponding families of text structures. The exigencies of practical computation on formal languages frequently demand that text strings be converted into pointer structure renditions of parse graphs, simply as a matter of checking whether strings are well-formed formulas or not. Once this is done, there are many advantages to be gained from developing the graphical analogue of the calculus on strings. The mapping from strings to parse graphs is called "parsing" and the inverse mapping from parse graphs to strings is achieved by an operation that is called "traversing" the graph.

Propositional calculus is about the simplest kind of logical calculus in current use. It can be extended in several ways. (Aristotelian "syllogistic" calculus, which is largely supplanted in modern logic, is in "some" ways simpler – but in other ways more complex – than propositional calculus.) The most immediate way to develop a more complex logical calculus is to introduce rules that are sensitive to more fine-grained details of the sentences being used.

First-order logic (a.k.a. first-order predicate logic) results when the "atomic sentences" of propositional logic are broken up into terms, variables, predicates, and quantifiers, all keeping the rules of propositional logic with some new ones introduced. (For example, from "All dogs are mammals" we may infer "If Rover is a dog then Rover is a mammal".) With the tools of first-order logic it is possible to formulate a number of theories, either with explicit axioms or by rules of inference, that can themselves be treated as logical calculi. Arithmetic is the best known of these; others include set theory and mereology. Second-order logic and other higher-order logics are formal extensions of first-order logic. Thus, it makes sense to refer to propositional logic as ""zeroth-order logic"", when comparing it with these logics.

Modal logic also offers a variety of inferences that cannot be captured in propositional calculus. For example, from "Necessarily " we may infer that . From we may infer "It is possible that ". The translation between modal logics and algebraic logics concerns classical and intuitionistic logics but with the introduction of a unary operator on Boolean or Heyting algebras, different from the Boolean operations, interpreting the possibility modality, and in the case of Heyting algebra a second operator interpreting necessity (for Boolean algebra this is redundant since necessity is the De Morgan dual of possibility). The first operator preserves 0 and disjunction while the second preserves 1 and conjunction.

Many-valued logics are those allowing sentences to have values other than "true" and "false". (For example, "neither" and "both" are standard "extra values"; "continuum logic" allows each sentence to have any of an infinite number of "degrees of truth" between "true" and "false".) These logics often require calculational devices quite distinct from propositional calculus. When the values form a Boolean algebra (which may have more than two or even infinitely many values), many-valued logic reduces to classical logic; many-valued logics are therefore only of independent interest when the values form an algebra that is not Boolean.

Finding solutions to propositional logic formulas is an NP-complete problem. However, practical methods exist (e.g., DPLL algorithm, 1962; Chaff algorithm, 2001) that are very fast for many useful cases. Recent work has extended the SAT solver algorithms to work with propositions containing arithmetic expressions; these are the SMT solvers.





</doc>
<doc id="18155" url="https://en.wikipedia.org/wiki?curid=18155" title="Lazy evaluation">
Lazy evaluation

In programming language theory, lazy evaluation, or call-by-need is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing). The sharing can reduce the running time of certain functions by an exponential factor over other non-strict evaluation strategies, such as call-by-name. 

However, for lengthy operations, it would be more appropriate to perform before any time-sensitive operations, such as handling user inputs in a video game.

The benefits of lazy evaluation include: 

Lazy evaluation is often combined with memoization, as described in Jon Bentley's "Writing Efficient Programs". After a function's value is computed for that parameter or set of parameters, the result is stored in a lookup table that is indexed by the values of those parameters; the next time the function is called, the table is consulted to determine whether the result for that combination of parameter values is already available. If so, the stored result is simply returned. If not, the function is evaluated and another entry is added to the lookup table for reuse.

Lazy evaluation can lead to reduction in memory footprint, since values are created when needed. However, lazy evaluation is difficult to combine with imperative features such as exception handling and input/output, because the order of operations becomes indeterminate. Lazy evaluation can introduce memory leaks.

The opposite of lazy evaluation is eager evaluation, sometimes known as strict evaluation. Eager evaluation is the evaluation strategy employed in most programming languages.

Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth. For programming languages, it was independently introduced by Peter Henderson and James H. Morris and by Daniel P. Friedman and David S. Wise.

Delayed evaluation is used particularly in functional programming languages. When using delayed evaluation, an expression is not evaluated as soon as it gets bound to a variable, but when the evaluator is forced to produce the expression's value. That is, a statement such as codice_1 (i.e. the assignment of the result of an expression to a variable) clearly calls for the expression to be evaluated and the result placed in codice_2, but what actually is in codice_2 is irrelevant until there is a need for its value via a reference to codice_2 in some later expression whose evaluation could itself be deferred, though eventually the rapidly growing tree of dependencies would be pruned to produce some symbol rather than another for the outside world to see.

Delayed evaluation has the advantage of being able to create calculable infinite lists without infinite loops or size matters interfering in computation. For example, one could create a function that creates an infinite list (often called a "stream") of Fibonacci numbers. The calculation of the "n"-th Fibonacci number would be merely the extraction of that element from the infinite list, forcing the evaluation of only the first n members of the list.

For example, in the Haskell programming language, the list of all Fibonacci numbers can be written as:

In Haskell syntax, "codice_5" prepends an element to a list, codice_6 returns a list without its first element, and codice_7 uses a specified function (in this case addition) to combine corresponding elements of two lists to produce a third.

Provided the programmer is careful, only the values that are required to produce a particular result are evaluated. However, certain calculations may result in the program attempting to evaluate an infinite number of elements; for example, requesting the length of the list or trying to sum the elements of the list with a fold operation would result in the program either failing to terminate or running out of memory.

In almost all common "eager" languages, "if" statements evaluate in a lazy fashion.
evaluates (a), then if and only if (a) evaluates to true does it evaluate (b), otherwise it evaluates (c). That is, either (b) or (c) will not be evaluated. Conversely, in an eager language the expected behavior is that
will still evaluate (e) when computing the value of f(d, e) even though (e) is unused in function f. However, user-defined control structures depend on exact syntax, so for example
(i) and (j) would both be evaluated in an eager language. While in a lazy language,
(i) or (j) would be evaluated, but never both.

Lazy evaluation allows control structures to be defined normally, and not as primitives or compile-time techniques. If (i) or (j) have side effects or introduce run time errors, the subtle differences between (l) and (l') can be complex. It is usually possible to introduce user-defined lazy control structures in eager languages as functions, though they may depart from the language's syntax for eager evaluation: Often the involved code bodies (like (i) and (j)) need to be wrapped in a function value, so that they are executed only when called.

Short-circuit evaluation of Boolean control structures is sometimes called "lazy".

Many languages offer the notion of "infinite data-structures". These allow definitions of data to be given in terms of infinite ranges, or unending recursion, but the actual values are only computed when needed. Take for example this trivial program in Haskell:

In the function numberFromInfiniteList, the value of infinity is an infinite range, but until an actual value (or more specifically, a specific value at a certain index) is needed, the list is not evaluated, and even then it is only evaluated as needed (that is, until the desired index.)

A compound expression might be in the form "EasilyComputed or LotsOfWork" so that if the easy part gives true a lot of work could be avoided. For instance, suppose a large number N is to be checked to determine if it is a prime number and a function IsPrime(N) is available, but alas, it can require a lot of computation to evaluate. Perhaps "N=2 or [Mod(N,2)≠0 and IsPrime(N)]" will help if there are to be many evaluations with arbitrary values for N.

A compound expression might be in the form "SafeToTry and Expression" whereby if "SafeToTry" is false there should be no attempt at evaluating the "Expression" lest a run-time error be signalled, such as divide-by-zero or index-out-of-bounds, etc. For instance, the following pseudocode locates the last non-zero element of an array:
Should all elements of the array be zero, the loop will work down to L = 0, and in this case the loop must be terminated without attempting to reference element zero of the array, which does not exist.

In computer windowing systems, the painting of information to the screen is driven by "expose events" which drive the display code at the last possible moment. By doing this, windowing systems avoid computing unnecessary display content updates.

Another example of laziness in modern computer systems is copy-on-write page allocation or demand paging, where memory is allocated only when a value stored in that memory is changed.

Laziness can be useful for high performance scenarios. An example is the Unix mmap function, which provides "demand driven" loading of pages from disk, so that only those pages actually touched are loaded into memory, and unneeded memory is not allocated.

MATLAB implements "copy on edit", where arrays which are copied have their actual memory storage replicated only when their content is changed, possibly leading to an "out of memory" error when updating an element afterwards instead of during the copy operation.

Some programming languages delay evaluation of expressions by default, and some others provide functions or special syntax to delay evaluation. In Miranda and Haskell, evaluation of function arguments is delayed by default. In many other languages, evaluation can be delayed by explicitly suspending the computation using special syntax (as with Scheme's "codice_8" and "codice_9" and OCaml's "codice_10" and "codice_11") or, more generally, by wrapping the expression in a thunk. The object representing such an explicitly delayed evaluation is called a "lazy future." Raku uses lazy evaluation of lists, so one can assign infinite lists to variables and use them as arguments to functions, but unlike Haskell and Miranda, Raku does not use lazy evaluation of arithmetic operators and functions by default.

In lazy programming languages such as Haskell, although the default is to evaluate expressions only when they are demanded, it is possible in some cases to make code more eager—or conversely, to make it more lazy again after it has been made more eager. This can be done by explicitly coding something which forces evaluation (which may make the code more eager) or avoiding such code (which may make the code more lazy). "Strict" evaluation usually implies eagerness, but they are technically different concepts.

However, there is an optimisation implemented in some compilers called strictness analysis, which, in some cases, allows the compiler to infer that a value will always be used. In such cases, this may render the programmer's choice of whether to force that particular value or not, irrelevant, because strictness analysis will force strict evaluation.

In Haskell, marking constructor fields strict means that their values will always be demanded immediately. The codice_12 function can also be used to demand a value immediately and then pass it on, which is useful if a constructor field should generally be lazy. However, neither of these techniques implements "recursive" strictness—for that, a function called codice_13 was invented.

Also, pattern matching in Haskell 98 is strict by default, so the codice_14 qualifier has to be used to make it lazy.

In Python 2.x the codice_15 function computes a list of integers. The entire list is stored in memory when the first assignment statement is evaluated, so this is an example of eager or immediate evaluation:
In Python 3.x the codice_15 function returns a special range object which computes elements of the list on demand. Elements of the range object are only generated when they are needed (e.g., when codice_17 is evaluated in the following example), so this is an example of lazy or deferred evaluation:

In Python 2.x is possible to use a function called codice_18 which returns an object that generates the numbers in the range on demand. The advantage of codice_19 is that generated object will always take the same amount of memory.

From version 2.2 forward, Python manifests lazy evaluation by implementing iterators (lazy sequences) unlike tuple or list sequences. For instance (Python 2):

In the .NET Framework it is possible to do lazy evaluation using the class System.Lazy<T>. The class can be easily exploited in F# using the lazy keyword, while the force method will force the evaluation. There are also specialized collections like Microsoft.FSharp.Collections.Seq that provide built-in support for lazy evaluation. 

let fibonacci = Seq.unfold (fun (x, y) -> Some(x, (y, x + y))) (0I,1I)
fibonacci |> Seq.nth 1000

In C# and VB.NET, the class System.Lazy<T> is directly used. 

public int Sum()

Or with a more practical example: 

// recursive calculation of the n'th fibonacci number
public int Fib(int n)

public void Main()

Another way is to use the yield keyword: 

// eager evaluation 
public IEnumerable<int> Fibonacci(int x)

// lazy evaluation 
public IEnumerable<int> LazyFibonacci(int x)





</doc>
<doc id="18156" url="https://en.wikipedia.org/wiki?curid=18156" title="Lemuridae">
Lemuridae

Lemuridae is a family of strepsirrhine primates native to Madagascar, and the Comoros Islands. They are represented by the Lemuriformes in Madagascar with one of the highest concentration of the lemurs. One of five families commonly known as lemurs. These animals were once thought to be the evolutionary predecessors of monkeys and apes, but this is no longer considered correct.

Lemurids are medium-sized arboreal primates, ranging from 32 to 56 cm in length, excluding the tail, and weighing from 0.7 to 5 kg. They have long, bushy tails and soft, woolly fur of varying coloration. The hindlegs are slightly longer than the forelegs, although not enough to hamper fully quadrupedal movement (unlike the sportive lemurs). Most species are highly agile, and regularly leap several metres between trees. They have a good sense of smell and binocular vision. Unlike most other lemurs, all but one species of lemurid (the ring-tailed lemur) lack a tapetum lucidum, a reflective layer in the eye that improves night vision. Historically among mammals, activity cycles are either strictly diurnal or nocturnal, however, these can widely vary across species. Lemur activity has in general evolved from nocturnal to diurnal. Some lemurs are also cathemeral, an activity pattern where an animal is neither strictly diurnal nor nocturnal.

Lemurids are herbivorous, eating fruit, leaves, and, in some cases, nectar. For the most part, they have the dental formula: . A lemur’s diet is one that is not restricted since their diet consists of frugivory, granivory, folivory, insectivory, omnivory, and gumnivory foods. Some Subfossil records have contributed to the knowledge of the currently extant lemurs from the Holocene by showing the changes in their dental records in habitats near human activity. This demonstrates that lemur species such as the lemur "catta" and the common brown lemur were forced to switch their primary diet to a group of secondary food sources.

With most lemurids, the mother gives birth to one or two young after a gestation period of between 120 and 140 days, depending on species. The ruffed lemur species are the only lemurids that have true litters, consisting of anywhere from two to six offspring. They are generally sociable animals, living in groups of up to thirty individuals in some species. In some cases, such as the ring-tailed lemur, the groups are long-lasting, with distinct dominance hierarchies, while in others, such as the common brown lemur, the membership of the groups varies from day to day, and seems to have no clear social structure.

Some of the lemur traits include low basal metabolic rate, highly seasonal breeders, adaptations to unpredictable climate and female dominance. Female dominance amongst lemurs is when the females are sexually monomorphic and have priority access to food. Lemurs live in groups of 11 to 17 animals, where females tend to stay within their natal groups and the males migrate. Male lemurs are competitive to win their mates which causes instability among the other organisms. Lemurs are able to mark their territory by using scents from local areas.

A number of lemur species are considered threatened; two species are critically endangered, one species is endangered, and five species are rated as vulnerable.

The highly seasonal dry deciduous forest of Madagascar alternates between dry and wet seasons, making it uniquely suitable for lemurs. Lemur species diversity increases as the number of tree species in an area increase and is also higher in forests that have been disturbed over undisturbed areas. Evidence from the Subfossil records show that many of the now extinct lemurs actually lived in much drier climates than the currently extant lemurs.

The family Lemuridae contains 21 extant species in five genera.

FAMILY LEMURIDAE

This family was once broken into two subfamilies, Hapalemurinae (bamboo lemurs and the greater bamboo lemur) and Lemurinae (the rest of the family), but molecular evidence and the similarity of the scent glands have since placed the ring-tailed lemur with the bamboo lemurs and the greater bamboo lemur.

Lemur species in the genus "Eulemur" are known to interbreed, despite having dramatically different chromosome numbers. Red-fronted (2N=60) and collared (2N=50–52) brown lemurs were found to hybridize at Berenty Reserve, Madagascar.



</doc>
<doc id="18157" url="https://en.wikipedia.org/wiki?curid=18157" title="Lucent">
Lucent

Lucent Technologies, Inc., was an American multinational telecommunications equipment company headquartered in Murray Hill, New Jersey, in the United States. It was established on September 30, 1996, through the divestiture of the former AT&T Technologies business unit of AT&T Corporation, which included Western Electric and Bell Labs.

Lucent was merged with Alcatel SA of France on December 1, 2006, forming Alcatel-Lucent. Alcatel-Lucent was absorbed by Nokia in January 2016.

Lucent means "they shine" in Latin. The name was applied in 1996 at the time of the split from AT&T.

The name was widely criticised, as the logo was to be, both internally and externally. Corporate communications and business cards included the strapline 'Bell Labs Innovations' in a bid to retain the prestige of the internationally famous research lab, within a new business under an as-yet unknown name.

This same linguistic root also gives Lucifer, "the light bearer" (from lux, 'light', and ferre, 'to bear'), who is also a character in Dante's epic poem "Inferno". Shortly after the Lucent renaming in 1996, Lucent's Plan 9 project released a development of their work as the Inferno OS in 1997. This extended the 'Lucifer' and Dante references as a series of punning names for the components of Inferno - Dis, Limbo, Charon and Styx (9P Protocol). When the rights to Inferno were sold in 2000, the company Vita Nuova Holdings was formed to represent them. This continues the Dante theme, although moving away from his "Divine Comedy" to the poem "La Vita Nuova".

The Lucent logo, the Innovation Ring, was designed by Landor Associates, a prominent San Francisco-based branding consultancy. One source inside Lucent says that the logo is a Zen Buddhist symbol for "eternal truth", the Enso, turned 90 degrees and modified. Another source says it represents the mythic ouroboros, a snake holding its tail in its mouth. Lucent's logo also has been said to represent constant re-creating and re-thinking. Carly Fiorina picked the logo because her mother was a painter and she rejected the sterile geometric logos of most high tech companies.

After the logo was compared in the media to the ring a coffee mug leaves on paper, a "Dilbert" comic strip showed Dogbert as an overpaid consultant designing a new company logo; he takes a piece of paper that his coffee cup was sitting on and calls it the "Brown Ring of Quality". A telecommunication commentator referred to the logo as "a big red zero" and predicted financial losses.

One of the primary reasons AT&T Corporation chose to spin off its equipment manufacturing business was to permit it to profit from sales to competing telecommunications providers; these customers had previously shown reluctance to purchase from a direct competitor. Bell Labs brought prestige to the new company, as well as the revenue from thousands of patents.

At the time of its spinoff, Lucent was placed under the leadership of Henry Schacht, who was brought in to oversee its transition from an arm of AT&T into an independent corporation. Richard McGinn, who was serving as President and COO, succeeded Schacht as CEO in 1997 while Schacht remained chairman of the board. Lucent became a "darling" stock of the investment community in the late 1990s, and its split-adjusted spinoff price of $7.56/share rose to a high of $84. Its market capitalization reached a high of $258 billion, and it was at the time the most widely held company with 5.3 million shareholders.

In 1997, Lucent acquired Milpitas-based voicemail market leader Octel Communications Corporation for $2.1 billion, a move which immediately rendered the Business Systems Group profitable. By 1999 Lucent stock continued to soar and in that year Lucent acquired Ascend Communications, an Alameda, California–based manufacturer of communications equipment for US$24 billion. Lucent held discussions to acquire Juniper Networks but decided instead to build its own routers.

In 1997, Lucent acquired Livingston Enterprises Inc. for $650 million in stock. Livingston was known most for the creation of the RADIUS protocol and their PortMaster product that was used widely by dial-up internet service providers.

In 1995, Carly Fiorina led corporate operations. In that capacity, she reported to Lucent chief executive Henry B. Schacht. She played a key role in planning and implementing the 1996 initial public offering of a successful stock and company launch strategy. Under her guidance, the spin-off raised 3 billion.

Later in 1996, Fiorina was appointed president of Lucent's consumer products sector, reporting to president and chief operating officer Rich McGinn. In 1997, she was named group president for Lucent's 19 billion global service-provider business, overseeing marketing and sales for the company's largest customer segment. That year, Fiorina chaired a 2.5 billion joint venture between Lucent's consumer communications and Royal Philips Electronics, under the name Philips Consumer Communications (PCC). The focus of the venture was to bring both companies to the top three in technology, distribution, and brand recognition.

Ultimately, the project struggled and dissolved a year later after it garnered only 2% market share in mobile phones. Losses were at $500 million on sales of $2.5 billion. As a result of the failed joint venture, Philips announced the closure of one-quarter of the company's 230 factories worldwide, and Lucent closed down its wireless handset portion of the venture. Analysts suggested that the joint venture's failure was due to a combination of technology and management problems. Upon the end of the joint venture, PCC sent 5,000 employees back to Philips, many of which were laid off, and 8,400 employees back to Lucent.

Under Fiorina, the company added 22,000 jobs and revenues seemed to grow from 19 billion to 38 billion. However, the real cause of Lucent spurring sales under Fiorina was by lending money to their own customers. According to "Fortune" magazine, "In a neat bit of accounting magic, money from the loans began to appear on Lucent’s income statement as new revenue while the dicey debt got stashed on its balance sheet as an allegedly solid asset". Lucent's stock price grew 10-fold.

At the start of 2000, Lucent's "private bubble" burst, while competitors like Nortel Networks and Alcatel were still going strong; it would be many months before the rest of the telecom industry bubble collapsed. Previously Lucent had 14 straight quarters where it exceeded analysts' expectations, leading to high expectations for the 15th quarter, ending Dec. 31, 1999. On January 6, 2000, Lucent made the first of a string of announcements that it had missed its quarterly estimates, as CEO Rich McGinn grimly announced that Lucent had run into special problems during that quarter—including disruptions in its optical networking business—and reported flat revenues and a big drop in profits. That caused the stock to plunge by 28%, shaving $64 billion off of the company's market capitalization. When it was later revealed that it had used dubious accounting and sales practices to generate some of its earlier quarterly numbers, Lucent fell from grace. It was said that "Rich McGinn couldn't accept Lucent's fall from its early triumphs." He described himself once as imposing "audacious" goals on his managers, believing the stretch for performance would produce dream results. Henry Schacht defended the corporate culture that McGinn created and also noted that McGinn did not sell any Lucent shares while serving as CEO. In November 2000, the company disclosed to the Securities and Exchange Commission that it had a $125 million accounting error for the third quarter of 2000, and by December 2000 it reported it had overstated its revenues for its latest quarter by nearly $700 million. Although no wrongdoing was found on his part, McGinn was forced to resign as CEO and he was replaced by Schacht on an interim basis. Subsequently, its CFO, Deborah Hopkins, left the company in May 2001 with Lucent's stock at $9.06 whereas at the time she was hired it was at $46.82.

In 2001 there were merger discussions between Lucent and Alcatel, which would have seen Lucent acquired at its current market price without a premium; the newly combined entity would have been headquartered in Murray Hill. However, these negotiations collapsed when Schacht insisted on an equal 7-7 split of the merged company's board of directors, while Alcatel chief executive officer Serge Tchuruk wanted 8 of the 14 board seats for Alcatel due to it being in a stronger position. The failure of the merger talks caused Lucent's share price to collapse, and by October 2002 the stock price had bottomed at 55 cents per share.

Patricia Russo, formerly Lucent's EVP of the Corporate Office who then left for Eastman Kodak to serve as COO, was named permanent Chairman and CEO of Lucent in 2002, succeeding Schacht who remained on the Board of Directors.

In April 2000, Lucent sold its Consumer Products unit to VTech and Consumer Phone Services. In October 2000, Lucent spun off its Business Systems arm into Avaya, Inc., and in June 2002, it spun off its microelectronics division into Agere Systems. The spinoffs of enterprise networking and wireless, the industry's key growth businesses from 2003 onward, meant that Lucent no longer had the capacity to serve this market.

Lucent was reduced to 30,500 employees, down from about 165,000 employees at its zenith. The layoffs of so many experienced employees meant that the company was in a weakened position and unable to reestablish itself when the market recovered in 2003. By early 2003, Lucent's market value was $15.6 billion (which includes $6.8 billion of current value for two companies that Lucent had recently spun off, Avaya and Agere Systems), making the shares worth around $2.13, a far cry from its dotcom bubble peak of around $84, when Lucent was worth $258 billion.

Lucent continued to be active in the areas of telephone switching, optical, data and wireless networking.

On April 2, 2006, Lucent announced a merger agreement with Alcatel, which was 1.5 times the size of Lucent. Serge Tchuruk became non-executive chairman, and Russo served as CEO of the newly merged company, Alcatel-Lucent, until they were both forced to resign at the end of 2008. The merger failed to produce the expected synergies, and there were significant write-downs of Lucent's assets that Alcatel purchased.

Lucent was divided into several core groups:

The Murray Hill anechoic chamber, built in 1940, is the world's oldest wedge-based anechoic chamber. The interior room measures approximately high by wide by deep. The exterior concrete and brick walls are about thick to keep outside noise from entering the chamber. The chamber absorbs over 99.995% of the incident acoustic energy above 200 Hz. At one time the Murray Hill chamber was cited in the Guinness Book of World Records as the world's quietest room. It is possible to hear the sounds of skeletal joints and heart beats very prominently.

The Murray Hill facility was the global headquarters for Lucent Technologies. The Murray Hill facility also has the largest copper-roof in the world. When Lucent Technologies was experiencing financial troubles in 2000 and 2001, one out of every three fluorescent lights was turned off in the facility. The same was done in the Naperville, Illinois, and Allentown, Pennsylvania, facilities for a while. The facility had a cricket field and featured a nearby station from which enthusiasts could control RC airplanes and helicopters.



</doc>
<doc id="18158" url="https://en.wikipedia.org/wiki?curid=18158" title="Lupercalia">
Lupercalia

Lupercalia was an ancient, possibly pre-Roman pastoral annual festival, observed in the city of Rome between 13–15 February to avert evil spirits and purify the city, releasing health and fertility. Lupercalia was also called "dies Februatus", after the instruments of purification called "februa", which gave February "(Februarius)" its name.

The festival was later known as Februa ("Purifications" or "Purgings") after the ' which was used on the day. It was also known as ' and gave its name to Juno Februalis, Februlis, or Februata in her role as its patron deity; to a god called Februus, and to February ('), the month during which it occurred. Ovid connects ' to an Etruscan word for "purging". Some sources connect the Latin word for fever ("") with the same idea of purification or purging, due to the sweating commonly seen in association with fevers.

The name "Lupercalia" was believed in antiquity to evince some connection with the Ancient Greek festival of the Arcadian Lykaia, a wolf festival (, "lýkos"; ), and the worship of "Lycaean Pan", assumed to be a Greek equivalent to Faunus, as instituted by Evander. Justin describes a cult image of "the Lycaean god, whom the Greeks call Pan and the Romans Lupercus," as nude, save for a goatskin girdle. It stood in the Lupercal, the cave where tradition held that Romulus and Remus were suckled by the she-wolf (Lupa). The cave lay at the foot of the Palatine Hill, on which Romulus was thought to have founded Rome.

The rites were confined to the Lupercal cave, the Palatine Hill, and the Forum, all of which were central locations in Rome's foundation myth. Near the cave stood a sanctuary of Rumina, goddess of breastfeeding; and the wild fig-tree ("Ficus Ruminalis") to which Romulus and Remus were brought by the divine intervention of the river-god Tiberinus; some Roman sources name the wild fig tree "caprificus", literally "goat fig". Like the cultivated fig, its fruit is pendulous, and the tree exudes a milky sap if cut, which makes it a good candidate for a cult of breastfeeding.

The Lupercalia had its own priesthood, the "Luperci" ("brothers of the wolf"), whose institution and rites were attributed either to the Arcadian culture-hero Evander, or to Romulus and Remus, erstwhile shepherds who had each established a group of followers. The "Luperci" were young men ("iuvenes"), usually between the ages of 20 and 40. They formed two religious "collegia" (associations) based on ancestry; the "Quinctiliani" (named after gens Quinctia) and the "Fabiani" (named after "gens" Fabia). Each college was headed by a "magister". In 44 BC, a third college, the "Juliani", was instituted in honor of Julius Caesar; its first "magister" was Mark Antony. The college of "Juliani" disbanded or lapsed following Caesar's assassination, and was not re-established in the reforms of his successor, Augustus. In the Imperial era, membership of the two traditional "collegia" was opened to "iuvenes" of equestrian status.

At the Lupercal altar, a male goat (or goats) and a dog were sacrificed by one or another of the "Luperci", under the supervision of the Flamen dialis, Jupiter's chief priest. An offering was also made of salted mealcakes, prepared by the Vestal Virgins. After the blood sacrifice, two "Luperci" approached the altar. Their foreheads were anointed with blood from the sacrificial knife, then wiped clean with wool soaked in milk, after which they were expected to smile and/or laugh.

The sacrificial feast followed, after which the Luperci cut thongs (known as "") from the flayed skin of the animal, and ran with these, naked or near-naked, along the old Palatine boundary, in an anticlockwise direction around the hill. In Plutarch's description of the Lupercalia, written during the early Empire,
...many of the noble youths and of the magistrates run up and down through the city naked, for sport and laughter striking those they meet with shaggy thongs. And many women of rank also purposely get in their way, and like children at school present their hands to be struck, believing that the pregnant will thus be helped in delivery, and the barren to pregnancy.
The "Luperci" completed their circuit of the Palatine, then returned to the "Lupercal" cave. 
The Februa was of ancient and possibly Sabine origin. After February was added to the Roman calendar, Februa occurred on its fifteenth day (""). Of its various rituals, the most important came to be those of the Lupercalia. The Romans themselves attributed the instigation of the Lupercalia to Evander, a culture hero from Arcadia who was credited with bringing the Olympic pantheon, Greek laws and alphabet to Italy, where he founded the city of Pallantium on the future site of Rome, 60 years before the Trojan War.

Lupercalia was celebrated in parts of Italy and Gaul; "Luperci" are attested by inscriptions at Velitrae, Praeneste, Nemausus (modern Nîmes) and elsewhere. The ancient cult of the Hirpi Sorani ("wolves of Soranus", from Sabine "hirpus" "wolf"), who practiced at Mt. Soracte, north of Rome, had elements in common with the Roman Lupercalia.

Descriptions of the Lupercalia festival of 44 BC attest to its continuity; Julius Caesar used it as the backdrop for his (possibly staged) public refusal of a golden crown offered to him by Mark Antony. The Lupercal cave was restored or rebuilt by Augustus, and has been speculated to be identical with a grotto discovered in 2007, below the remains of Augustus' residence; according to scholarly consensus, the grotto is a nymphaeum, not the Lupercal. The Lupercalia festival is marked on a calendar of 354 alongside traditional and Christian festivals. Despite the banning in 391 of all non-Christian cults and festivals, Lupercalia was celebrated by the nominally Christian populace on a regular basis into the reign of the emperor Anastasius. Pope Gelasius I (494–96) claimed that only the "vile rabble" were involved in the festival and sought its forceful abolition; the Senate protested that the Lupercalia was essential to Rome's safety and well-being. This prompted Gelasius' scornful suggestion that "If you assert that this rite has salutary force, celebrate it yourselves in the ancestral fashion; run nude yourselves that you may properly carry out the mockery."

There is no contemporary evidence to support the popular notions that Gelasius abolished the Lupercalia, or that he, or any other prelate, replaced it with the Feast of the Purification of the Blessed Virgin Mary. A literary association between Lupercalia and the romantic elements of Saint Valentine's Day dates back to Chaucer and poetic traditions of courtly love.

Horace's Ode III, 18 alludes to the Lupercalia. The festival or its associated rituals gave its name to the Roman month of February ("") and thence to the modern month. The Roman god Februus personified both the month and purification, but seems to postdate both.

William Shakespeare's play "Julius Caesar" begins during the Lupercalia. Mark Antony is instructed by Caesar to strike his wife Calpurnia, in the hope that she will be able to conceive.

Research published in 2019 suggests that the word Leprechaun derives from "Lupercus".





</doc>
<doc id="18162" url="https://en.wikipedia.org/wiki?curid=18162" title="Lists of atheists">
Lists of atheists

Atheism is, in a broad sense, the lack of belief in the existence of deities. In a narrower sense, atheism is simply the absence of belief that any deities exist. This is a compilation of the various lists of atheists with articles in Wikipedia. Living persons in these lists are people whose atheism is relevant to their notable activities or public life, and who have publicly identified themselves as atheists.






</doc>
<doc id="18163" url="https://en.wikipedia.org/wiki?curid=18163" title="List of Buddhists">
List of Buddhists

This is a list of notable Buddhists, encompassing all the major branches of the religion (i.e. in Buddhism), and including interdenominational and eclectic Buddhist practitioners. This list includes both formal teachers of Buddhism, and people notable in other areas who are publicly Buddhist or who have espoused Buddhism.

Individuals are grouped by nationality, except in cases where their influence was felt elsewhere. Gautama Buddha and his immediate disciples ('Buddhists') are listed separately from later Indian Buddhist thinkers, teachers and contemplatives.


Clergy

Laity













For Theravada , Bhikkhu(male) and Bhikkhuni(female) mean monk in Pali (Theravada use Pali language for studying Tripitaka)



American

Chinese

European

Japanese

Korean

Malaysian

Taiwanese

Vietnamese















</doc>
<doc id="18166" url="https://en.wikipedia.org/wiki?curid=18166" title="List of agnostics">
List of agnostics

Listed here are persons who have identified themselves as theologically agnostic. Also included are individuals who have expressed the view that the veracity of a god's existence is unknown or inherently unknowable.












</doc>
<doc id="18167" url="https://en.wikipedia.org/wiki?curid=18167" title="Linked list">
Linked list

In computer science, a linked list is a linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence. In its most basic form, each node contains: data, and a reference (in other words, a "link") to the next node in the sequence. This structure allows for efficient insertion or removal of elements from any position in the sequence during iteration. More complex variants add additional links, allowing more efficient insertion or removal of nodes at arbitrary positions. A drawback of linked lists is that access time is linear (and difficult to pipeline). Faster access, such as random access, is not feasible. Arrays have better cache locality compared to linked lists.

Linked lists are among the simplest and most common data structures. They can be used to implement several other common abstract data types, including lists, stacks, queues, associative arrays, and S-expressions, though it is not uncommon to implement those data structures directly without using a linked list as the basis.

The principal benefit of a linked list over a conventional array is that the list elements can be easily inserted or removed without reallocation or reorganization of the entire structure because the data items need not be stored contiguously in memory or on disk, while restructuring an array at run-time is a much more expensive operation. Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal.

On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operations—such as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be inserted—may require iterating through most or all of the list elements. The advantages and disadvantages of using linked lists are given below. Linked list are dynamic, so the length of list can increase or decrease as necessary. Each node does not necessarily follow the previous one physically in the memory.


Linked lists were developed in 1955–1956 by Allen Newell, Cliff Shaw and Herbert A. Simon at RAND Corporation as the primary data structure for their Information Processing Language. IPL was used by the authors to develop several early artificial intelligence programs, including the Logic Theory Machine, the General Problem Solver, and a computer chess program. Reports on their work appeared in IRE Transactions on Information Theory in 1956, and several conference proceedings from 1957 to 1959, including Proceedings of the Western Joint Computer Conference in 1957 and 1958, and Information Processing (Proceedings of the first UNESCO International Conference on Information Processing) in 1959. The now-classic diagram consisting of blocks representing list nodes with arrows pointing to successive list nodes appears in "Programming the Logic Theory Machine" by Newell and Shaw in Proc. WJCC, February 1957. Newell and Simon were recognized with the ACM Turing Award in 1975 for having "made basic contributions to artificial intelligence, the psychology of human cognition, and list processing".
The problem of machine translation for natural language processing led Victor Yngve at Massachusetts Institute of Technology (MIT) to use linked lists as data structures in his COMIT programming language for computer research in the field of linguistics. A report on this language entitled "A programming language for mechanical translation" appeared in Mechanical Translation in 1958.

LISP, standing for list processor, was created by John McCarthy in 1958 while he was at MIT and in 1960 he published its design in a paper in the Communications of the ACM, entitled "Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I". One of LISP's major data structures is the linked list.

By the early 1960s, the utility of both linked lists and languages which use these structures as their primary data representation was well established. Bert Green of the MIT Lincoln Laboratory published a review article entitled "Computer languages for symbol manipulation" in IRE Transactions on Human Factors in Electronics in March 1961 which summarized the advantages of the linked list approach. A later review article, "A Comparison of list-processing computer languages" by Bobrow and Raphael, appeared in Communications of the ACM in April 1964.

Several operating systems developed by Technical Systems Consultants (originally of West Lafayette Indiana, and later of Chapel Hill, North Carolina) used singly linked lists as file structures. A directory entry pointed to the first sector of a file, and succeeding portions of the file were located by traversing pointers. Systems using this technique included Flex (for the Motorola 6800 CPU), mini-Flex (same CPU), and Flex9 (for the Motorola 6809 CPU). A variant developed by TSC for and marketed by Smoke Signal Broadcasting in California, used doubly linked lists in the same manner.

The TSS/360 operating system, developed by IBM for the System 360/370 machines, used a double linked list for their file system catalog. The directory structure was similar to Unix, where a directory could contain files and other directories and extend to any depth.

Each record of a linked list is often called an 'element' or 'node'.

The field of each node that contains the address of the next node is usually called the 'next link' or 'next pointer'. The remaining fields are known as the 'data', 'information', 'value', 'cargo', or 'payload' fields.

The 'head' of a list is its first node. The 'tail' of a list may refer either to the rest of the list after the head, or to the last node in the list. In Lisp and some derived languages, the next node may be called the 'cdr' (pronounced "could-er") of the list, while the payload of the head node may be called the 'car'.

Singly linked lists contain nodes which have a data field as well as 'next' field, which points to the next node in line of nodes. Operations that can be performed on singly linked lists include insertion, deletion and traversal.

The following code demonstrates how to add a new node with data "value" to the end of a singly linked list:
node addNode(node head, int value) {

In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence. The two links may be called 'forward('s') and 'backwards', or 'next' and 'prev'('previous').

A technique known as XOR-linking allows a doubly linked list to be implemented using a single link field in each node. However, this technique requires the ability to do bit operations on addresses, and therefore may not be available in some high-level languages.
Many modern operating systems use doubly linked lists to maintain references to active processes, threads, and other dynamic objects. A common strategy for rootkits to evade detection is to unlink themselves from these lists.

In a 'multiply linked list', each node contains two or more link fields, each field being used to connect the same set of data records in a different order of same set(e.g., by name, by department, by date of birth, etc.). While doubly linked lists can be seen as special cases of multiply linked list, the fact that the two and more orders are opposite to each other leads to simpler and more efficient algorithms, so they are usually treated as a separate case.

In the last node of a list, the link field often contains a null reference, a special value is used to indicate the lack of further nodes. A less common convention is to make it point to the first node of the list; in that case, the list is said to be 'circular' or 'circularly linked'; otherwise, it is said to be 'open' or 'linear'. It is a list where the last pointer points to the first node.

In the case of a circular doubly linked list, the first node also points to the last node of the list.

In some implementations an extra 'sentinel' or 'dummy' node may be added before the first data record or after the last one. This convention simplifies and accelerates some list-handling algorithms, by ensuring that all links can be safely dereferenced and that every list (even one that contains no data elements) always has a "first" and "last" node.

An empty list is a list that contains no data records. This is usually the same as saying that it has zero nodes. If sentinel nodes are being used, the list is usually said to be empty when it has only sentinel nodes.

The link fields need not be physically part of the nodes. If the data records are stored in an array and referenced by their indices, the link field may be stored in a separate array with the same indices as the data records.

Since a reference to the first node gives access to the whole list, that reference is often called the 'address', 'pointer', or 'handle' of the list. Algorithms that manipulate linked lists usually get such handles to the input lists and return the handles to the resulting lists. In fact, in the context of such algorithms, the word "list" often means "list handle". In some situations, however, it may be convenient to refer to a list by a handle that consists of two links, pointing to its first and last nodes.

The alternatives listed above may be arbitrarily combined in almost every way, so one may have circular doubly linked lists without sentinels, circular singly linked lists with sentinels, etc.

As with most choices in computer programming and design, no method is well suited to all circumstances. A linked list data structure might work well in one case, but cause problems in another. This is a list of some of the common tradeoffs involving linked list structures.

A "dynamic array" is a data structure that allocates all elements contiguously in memory, and keeps a count of the current number of elements. If the space reserved for the dynamic array is exceeded, it is reallocated and (possibly) copied, which is an expensive operation.

Linked lists have several advantages over dynamic arrays. Insertion or deletion of an element at a specific point of a list, assuming that we have indexed a pointer to the node (before the one to be removed, or before the insertion point) already, is a constant-time operation (otherwise without this reference it is O(n)), whereas insertion in a dynamic array at random locations will require moving half of the elements on average, and all the elements in the worst case. While one can "delete" an element from an array in constant time by somehow marking its slot as "vacant", this causes fragmentation that impedes the performance of iteration.

Moreover, arbitrarily many elements may be inserted into a linked list, limited only by the total memory available; while a dynamic array will eventually fill up its underlying array data structure and will have to reallocate—an expensive operation, one that may not even be possible if memory is fragmented, although the cost of reallocation can be averaged over insertions, and the cost of an insertion due to reallocation would still be amortized O(1). This helps with appending elements at the array's end, but inserting into (or removing from) middle positions still carries prohibitive costs due to data moving to maintain contiguity. An array from which many elements are removed may also have to be resized in order to avoid wasting too much space.

On the other hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while linked lists allow only sequential access to elements. Singly linked lists, in fact, can be easily traversed in only one direction. This makes linked lists unsuitable for applications where it's useful to look up an element by its index quickly, such as heapsort. Sequential access on arrays and dynamic arrays is also faster than on linked lists on many machines, because they have optimal locality of reference and thus make good use of data caching.

Another disadvantage of linked lists is the extra storage needed for references, which often makes them impractical for lists of small data items such as characters or boolean values, because the storage overhead for the links may exceed by a factor of two or more the size of the data. In contrast, a dynamic array requires only the space for the data itself (and a very small amount of control data). It can also be slow, and with a naïve allocator, wasteful, to allocate memory separately for each new element, a problem generally solved using memory pools.

Some hybrid solutions try to combine the advantages of the two representations. Unrolled linked lists store several elements in each list node, increasing cache performance while decreasing memory overhead for references. CDR coding does both these as well, by replacing references with the actual data referenced, which extends off the end of the referencing record.

A good example that highlights the pros and cons of using dynamic arrays vs. linked lists is by implementing a program that resolves the Josephus problem. The Josephus problem is an election method that works by having a group of people stand in a circle. Starting at a predetermined person, you count around the circle "n" times. Once you reach the "n"th person, take them out of the circle and have the members close the circle. Then count around the circle the same "n" times and repeat the process, until only one person is left. That person wins the election. This shows the strengths and weaknesses of a linked list vs. a dynamic array, because if you view the people as connected nodes in a circular linked list then it shows how easily the linked list is able to delete nodes (as it only has to rearrange the links to the different nodes). However, the linked list will be poor at finding the next person to remove and will need to search through the list until it finds that person. A dynamic array, on the other hand, will be poor at deleting nodes (or elements) as it cannot remove one node without individually shifting all the elements up the list by one. However, it is exceptionally easy to find the "n"th person in the circle by directly referencing them by their position in the array.

The list ranking problem concerns the efficient conversion of a linked list representation into an array. Although trivial for a conventional computer, solving this problem by a parallel algorithm is complicated and has been the subject of much research.

A balanced tree has similar memory access patterns and space overhead to a linked list while permitting much more efficient indexing, taking O(log n) time instead of O(n) for a random access. However, insertion and deletion operations are more expensive due to the overhead of tree manipulations to maintain balance. Schemes exist for trees to automatically maintain themselves in a balanced state: AVL trees or red-black trees.

While doubly linked and circular lists have advantages over singly linked linear lists, linear lists offer some advantages that make them preferable in some situations.

A singly linked linear list is a recursive data structure, because it contains a pointer to a "smaller" object of the same type. For that reason, many operations on singly linked linear lists (such as merging two lists, or enumerating the elements in reverse order) often have very simple recursive algorithms, much simpler than any solution using iterative commands. While those recursive solutions can be adapted for doubly linked and circularly linked lists, the procedures generally need extra arguments and more complicated base cases.

Linear singly linked lists also allow tail-sharing, the use of a common final portion of sub-list as the terminal portion of two different lists. In particular, if a new node is added at the beginning of a list, the former list remains available as the tail of the new one—a simple example of a persistent data structure. Again, this is not true with the other variants: a node may never belong to two different circular or doubly linked lists.

In particular, end-sentinel nodes can be shared among singly linked non-circular lists. The same end-sentinel node may be used for "every" such list. In Lisp, for example, every proper list ends with a link to a special node, denoted by codice_1 or codice_2, whose codice_3 and codice_4 links point to itself. Thus a Lisp procedure can safely take the codice_3 or codice_4 of "any" list.

The advantages of the fancy variants are often limited to the complexity of the algorithms, not in their efficiency. A circular list, in particular, can usually be emulated by a linear list together with two variables that point to the first and last nodes, at no extra cost.

Double-linked lists require more space per node (unless one uses XOR-linking), and their elementary operations are more expensive; but they are often easier to manipulate because they allow fast and easy sequential access to the list in both directions. In a doubly linked list, one can insert or delete a node in a constant number of operations given only that node's address. To do the same in a singly linked list, one must have the "address of the pointer" to that node, which is either the handle for the whole list (in case of the first node) or the link field in the "previous" node. Some algorithms require access in both directions. On the other hand, doubly linked lists do not allow tail-sharing and cannot be used as persistent data structures

A circularly linked list may be a natural option to represent arrays that are naturally circular, e.g. the corners of a polygon, a pool of buffers that are used and released in FIFO ("first in, first out") order, or a set of processes that should be time-shared in round-robin order. In these applications, a pointer to any node serves as a handle to the whole list.

With a circular list, a pointer to the last node gives easy access also to the first node, by following one link. Thus, in applications that require access to both ends of the list (e.g., in the implementation of a queue), a circular structure allows one to handle the structure by a single pointer, instead of two.

A circular list can be split into two circular lists, in constant time, by giving the addresses of the last node of each piece. The operation consists in swapping the contents of the link fields of those two nodes. Applying the same operation to any two nodes in two distinct lists joins the two list into one. This property greatly simplifies some algorithms and data structures, such as the quad-edge and face-edge.

The simplest representation for an empty "circular" list (when such a thing makes sense) is a null pointer, indicating that the list has no nodes. Without this choice, many algorithms have to test for this special case, and handle it separately. By contrast, the use of null to denote an empty "linear" list is more natural and often creates fewer special cases.

Sentinel node may simplify certain list operations, by ensuring that the next or previous nodes exist for every element, and that even empty lists have at least one node. One may also use a sentinel node at the end of the list, with an appropriate data field, to eliminate some end-of-list tests. For example, when scanning the list looking for a node with a given value "x", setting the sentinel's data field to "x" makes it unnecessary to test for end-of-list inside the loop. Another example is the merging two sorted lists: if their sentinels have data fields set to +∞, the choice of the next output node does not need special handling for empty lists.

However, sentinel nodes use up extra space (especially in applications that use many short lists), and they may complicate other operations (such as the creation of a new empty list).

However, if the circular list is used merely to simulate a linear list, one may avoid some of this complexity by adding a single sentinel node to every list, between the last and the first data nodes. With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link. The list handle should then be a pointer to the last data node, before the sentinel, if the list is not empty; or to the sentinel itself, if the list is empty.

The same trick can be used to simplify the handling of a doubly linked linear list, by turning it into a circular doubly linked list with a single sentinel node. However, in this case, the handle should be a single pointer to the dummy node itself.

When manipulating linked lists in-place, care must be taken to not use values that you have invalidated in previous assignments. This makes algorithms for inserting or deleting linked list nodes somewhat subtle. This section gives pseudocode for adding or removing nodes from singly, doubly, and circularly linked lists in-place. Throughout we will use "null" to refer to an end-of-list marker or sentinel, which may be implemented in a number of ways.

Our node data structure will have two fields. We also keep a variable "firstNode" which always points to the first node in the list, or is "null" for an empty list.

Traversal of a singly linked list is simple, beginning at the first node and following each "next" link until we come to the end:

The following code inserts a node after an existing node in a singly linked list. The diagram shows how it works. Inserting a node before an existing one cannot be done directly; instead, one must keep track of the previous node and insert a node after it.

Inserting at the beginning of the list requires a separate function. This requires updating "firstNode".

Similarly, we have functions for removing the node "after" a given node, and for removing a node from the beginning of the list. The diagram demonstrates the former. To find and remove a particular node, one must again keep track of the previous element.

Notice that codice_7 sets codice_8 to codice_9 when removing the last node in the list.

Since we can't iterate backwards, efficient codice_10 or codice_11 operations are not possible. Inserting to a list before a specific node requires traversing the list, which would have a worst case running time of O(n). 

Appending one linked list to another can be inefficient unless a reference to the tail is kept as part of the List structure, because we must traverse the entire first list in order to find the tail, and then append the second list to this. Thus, if two linearly linked lists are each of length formula_1, list appending has asymptotic time complexity of formula_2. In the Lisp family of languages, list appending is provided by the codice_12 procedure.

Many of the special cases of linked list operations can be eliminated by including a dummy element at the front of the list. This ensures that there are no special cases for the beginning of the list and renders both codice_13 and codice_7 unnecessary. In this case, the first useful data in the list will be found at codice_15.

In a circularly linked list, all nodes are linked in a continuous circle, without using "null." For lists with a front and a back (such as a queue), one stores a reference to the last node in the list. The "next" node after the last node is the first node. Elements can be added to the back of the list and removed from the front in constant time.

Circularly linked lists can be either singly or doubly linked.

Both types of circularly linked lists benefit from the ability to traverse the full list beginning at any given node. This often allows us to avoid storing "firstNode" and "lastNode", although if the list may be empty we need a special representation for the empty list, such as a "lastNode" variable which points to some node in the list or is "null" if it's empty; we use such a "lastNode" here. This representation significantly simplifies adding and removing nodes with a non-empty list, but empty lists are then a special case.

Assuming that "someNode" is some node in a non-empty circular singly linked list, this code iterates through that list starting with "someNode":

Notice that the test "while node ≠ someNode" must be at the end of the loop. If the test was moved to the beginning of the loop, the procedure would fail whenever the list had only one node.

This function inserts a node "newNode" into a circular linked list after a given node "node". If "node" is null, it assumes that the list is empty.

Suppose that "L" is a variable pointing to the last node of a circular linked list (or null if the list is empty). To append "newNode" to the "end" of the list, one may do

To insert "newNode" at the "beginning" of the list, one may do

Languages that do not support any type of reference can still create links by replacing pointers with array indices. The approach is to keep an array of records, where each record has integer fields indicating the index of the next (and possibly previous) node in the array. Not all nodes in the array need be used. If records are also not supported, parallel arrays can often be used instead.

As an example, consider the following linked list record that uses arrays instead of pointers:

A linked list can be built by creating an array of these structures, and an integer variable to store the index of the first element.

Links between elements are formed by placing the array index of the next (or previous) cell into the Next or Prev field within a given element. For example:

In the above example, codice_16 would be set to 2, the location of the first entry in the list. Notice that entry 3 and 5 through 7 are not part of the list. These cells are available for any additions to the list. By creating a codice_17 integer variable, a free list could be created to keep track of what cells are available. If all entries are in use, the size of the array would have to be increased or some elements would have to be deleted before new entries could be stored in the list.

The following code would traverse the list and display names and account balance:

When faced with a choice, the advantages of this approach include:

This approach has one main disadvantage, however: it creates and manages a private memory space for its nodes. This leads to the following issues:
For these reasons, this approach is mainly used for languages that do not support dynamic memory allocation. These disadvantages are also mitigated if the maximum size of the list is known at the time the array is created.

Many programming languages such as Lisp and Scheme have singly linked lists built in. In many functional languages, these lists are constructed from nodes, each called a "cons" or "cons cell". The cons has two fields: the "car", a reference to the data for that node, and the "cdr", a reference to the next node. Although cons cells can be used to build other data structures, this is their primary purpose.

In languages that support abstract data types or templates, linked list ADTs or templates are available for building linked lists. In other languages, linked lists are typically built using references together with records.

When constructing a linked list, one is faced with the choice of whether to store the data of the list directly in the linked list nodes, called "internal storage", or merely to store a reference to the data, called "external storage". Internal storage has the advantage of making access to the data more efficient, requiring less storage overall, having better locality of reference, and simplifying memory management for the list (its data is allocated and deallocated at the same time as the list nodes).

External storage, on the other hand, has the advantage of being more generic, in that the same data structure and machine code can be used for a linked list no matter what the size of the data is. It also makes it easy to place the same data in multiple linked lists. Although with internal storage the same data can be placed in multiple lists by including multiple "next" references in the node data structure, it would then be necessary to create separate routines to add or delete cells based on each field. It is possible to create additional linked lists of elements that use internal storage by using external storage, and having the cells of the additional linked lists store references to the nodes of the linked list containing the data.

In general, if a set of data structures needs to be included in linked lists, external storage is the best approach. If a set of data structures need to be included in only one linked list, then internal storage is slightly better, unless a generic linked list package using external storage is available. Likewise, if different sets of data that can be stored in the same data structure are to be included in a single linked list, then internal storage would be fine.

Another approach that can be used with some languages involves having different data structures, but all have the initial fields, including the "next" (and "prev" if double linked list) references in the same location. After defining separate structures for each type of data, a generic structure can be defined that contains the minimum amount of data shared by all the other structures and contained at the top (beginning) of the structures. Then generic routines can be created that use the minimal structure to perform linked list type operations, but separate routines can then handle the specific data. This approach is often used in message parsing routines, where several types of messages are received, but all start with the same set of fields, usually including a field for message type. The generic routines are used to add new messages to a queue when they are received, and remove them from the queue in order to process the message. The message type field is then used to call the correct routine to process the specific type of message.

Suppose you wanted to create a linked list of families and their members. Using internal storage, the structure might look like the following:

To print a complete list of families and their members using internal storage, we could write:

Using external storage, we would create the following structures:

To print a complete list of families and their members using external storage, we could write:

Notice that when using external storage, an extra step is needed to extract the record from the node and cast it into the proper data type. This is because both the list of families and the list of members within the family are stored in two linked lists using the same data structure ("node"), and this language does not have parametric types.

As long as the number of families that a member can belong to is known at compile time, internal storage works fine. If, however, a member needed to be included in an arbitrary number of families, with the specific number known only at run time, external storage would be necessary.

Finding a specific element in a linked list, even if it is sorted, normally requires O("n") time (linear search). This is one of the primary disadvantages of linked lists over other data structures. In addition to the variants discussed above, below are two simple ways to improve search time.

In an unordered list, one simple heuristic for decreasing average search time is the "move-to-front heuristic", which simply moves an element to the beginning of the list once it is found. This scheme, handy for creating simple caches, ensures that the most recently used items are also the quickest to find again.

Another common approach is to "index" a linked list using a more efficient external data structure. For example, one can build a red-black tree or hash table whose elements are references to the linked list nodes. Multiple such indexes can be built on a single list. The disadvantage is that these indexes may need to be updated each time a node is added or removed (or at least, before that index is used again).

A random access list is a list with support for fast random access to read or modify any element in the list. One possible implementation is a skew binary random access list using the skew binary number system, which involves a list of trees with special properties; this allows worst-case constant time head/cons operations, and worst-case logarithmic time random access to an element by index. Random access lists can be implemented as persistent data structures.

Random access lists can be viewed as immutable linked lists in that they likewise support the same O(1) head and tail operations.

A simple extension to random access lists is the min-list, which provides an additional operation that yields the minimum element in the entire list in constant time (without mutation complexities).

Both stacks and queues are often implemented using linked lists, and simply restrict the type of operations which are supported.

The skip list is a linked list augmented with layers of pointers for quickly jumping over large numbers of elements, and then descending to the next layer. This process continues down to the bottom layer, which is the actual list.

A binary tree can be seen as a type of linked list where the elements are themselves linked lists of the same nature. The result is that each node may include a reference to the first node of one or two other linked lists, which, together with their contents, form the subtrees below that node.

An unrolled linked list is a linked list in which each node contains an array of data values. This leads to improved cache performance, since more list elements are contiguous in memory, and reduced memory overhead, because less metadata needs to be stored for each element of the list.

A hash table may use linked lists to store the chains of items that hash to the same position in the hash table.

A heap shares some of the ordering properties of a linked list, but is almost always implemented using an array. Instead of references from node to node, the next and previous data indexes are calculated using the current data's index.

A self-organizing list rearranges its nodes based on some heuristic which reduces search times for data retrieval by keeping commonly accessed nodes at the head of the list.




</doc>
<doc id="18168" url="https://en.wikipedia.org/wiki?curid=18168" title="Logic gate">
Logic gate

In electronics, a logic gate is an idealized or physical device implementing a Boolean function; that is, it performs a logical operation on one or more binary inputs and produces a single binary output. Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison).

Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements. With amplification, logic gates can be cascaded in the same way that Boolean functions can be composed, allowing the construction of a physical model of all of Boolean logic, and therefore, all of the algorithms and mathematics that can be described with Boolean logic.

Logic circuits include such devices as multiplexers, registers, arithmetic logic units (ALUs), and computer memory, all the way up through complete microprocessors, which may contain more than 100 million gates. In modern practice, most gates are made from MOSFETs (metal–oxide–semiconductor field-effect transistors).

Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates.

In reversible logic, Toffoli gates are used.

To build a functionally complete logic system, relays, valves (vacuum tubes), or transistors can be used. The simplest family of logic gates using bipolar transistors is called resistor–transistor logic (RTL). Unlike simple diode logic gates (which do not have a gain element), RTL gates can be cascaded indefinitely to produce more complex logic functions. RTL gates were used in early integrated circuits. For higher speed and better density, the resistors used in RTL were replaced by diodes resulting in diode–transistor logic (DTL). Transistor–transistor logic (TTL) then supplanted DTL. As integrated circuits became more complex, bipolar transistors were replaced with smaller field-effect transistors (MOSFETs); see PMOS and NMOS. To reduce power consumption still further, most contemporary chip implementations of digital systems now use CMOS logic. CMOS uses complementary (both n-channel and p-channel) MOSFET devices to achieve a high speed with low power dissipation.

For small-scale logic, designers now use prefabricated logic gates from families of devices such as the TTL 7400 series by Texas Instruments, the CMOS 4000 series by RCA, and their more recent descendants. Increasingly, these fixed-function logic gates are being replaced by programmable logic devices, which allow designers to pack many mixed logic gates into a single integrated circuit. The field-programmable nature of programmable logic devices such as FPGAs has reduced the 'hard' property of hardware; it is now possible to change the logic design of a hardware system by reprogramming some of its components, thus allowing the features or function of a hardware implementation of a logic system to be changed. Other types of logic gates include, but are not limited to:
Electronic logic gates differ significantly from their relay-and-switch equivalents. They are much faster, consume much less power, and are much smaller (all by a factor of a million or more in most cases). Also, there is a fundamental structural difference. The switch circuit creates a continuous metallic path for current to flow (in either direction) between its input and its output. The semiconductor logic gate, on the other hand, acts as a high-gain voltage amplifier, which sinks a tiny current at its input and produces a low-impedance voltage at its output. It is not possible for current to flow between the output and the input of a semiconductor logic gate.

Another important advantage of standardized integrated circuit logic families, such as the 7400 and 4000 families, is that they can be cascaded. This means that the output of one gate can be wired to the inputs of one or several other gates, and so on. Systems with varying degrees of complexity can be built without great concern of the designer for the internal workings of the gates, provided the limitations of each integrated circuit are considered.

The output of one gate can only drive a finite number of inputs to other gates, a number called the 'fan-out limit'. Also, there is always a delay, called the 'propagation delay', from a change in input of a gate to the corresponding change in its output. When gates are cascaded, the total propagation delay is approximately the sum of the individual delays, an effect which can become a problem in high-speed circuits. Additional delay can be caused when many inputs are connected to an output, due to the distributed capacitance of all the inputs and wiring and the finite amount of current that each output can provide.

The binary number system was refined by Gottfried Wilhelm Leibniz (published in 1705), influenced by the ancient "I Ching"s binary system. Leibniz established that, by using the binary system, the principles of arithmetic and logic could be combined.

In an 1886 letter, Charles Sanders Peirce described how logical operations could be carried out by electrical switching circuits. Eventually, vacuum tubes replaced relays for logic operations. Lee De Forest's modification, in 1907, of the Fleming valve can be used as a logic gate. Ludwig Wittgenstein introduced a version of the 16-row truth table as proposition 5.101 of "Tractatus Logico-Philosophicus" (1921). Walther Bothe, inventor of the coincidence circuit, got part of the 1954 Nobel Prize in physics, for the first modern electronic AND gate in 1924. Konrad Zuse designed and built electromechanical logic gates for his computer Z1 (from 1935–38). 

From 1934 to 1936, NEC engineer Akira Nakashima introduced switching circuit theory in a series of papers showing that two-valued Boolean algebra, which he discovered independently, can describe the operation of switching circuits. His work was later cited by Claude E. Shannon, who elaborated on the use of Boolean algebra in the analysis and design of switching circuits in 1937. Using this property of electrical switches to implement logic is the fundamental concept that underlies all electronic digital computers. Switching circuit theory became the foundation of digital circuit design, as it became widely known in the electrical engineering community during and after World War II, with theoretical rigor superseding the "ad hoc" methods that had prevailed previously.

Metal-oxide-semiconductor (MOS) logic originates from the MOSFET (metal-oxide-semiconductor field-effect transistor), invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. They first demonstrated both PMOS logic and NMOS logic in 1960. Both types were later combined and adapted into complementary MOS (CMOS) logic by Chih-Tang Sah and Frank Wanlass at Fairchild Semiconductor in 1963.

Active research is taking place in molecular logic gates.

There are two sets of symbols for elementary logic gates in common use, both defined in ANSI/IEEE Std 91-1984 and its supplement ANSI/IEEE Std 91a-1991. The "distinctive shape" set, based on traditional schematics, is used for simple drawings and derives from United States Military Standard MIL-STD-806 of the 1950s and 1960s. It is sometimes unofficially described as "military", reflecting its origin. The "rectangular shape" set, based on ANSI Y32.14 and other early industry standards as later refined by IEEE and IEC, has rectangular outlines for all types of gate and allows representation of a much wider range of devices than is possible with the traditional symbols. The IEC standard, IEC 60617-12, has been adopted by other standards, such as EN 60617-12:1999 in Europe, BS EN 60617-12:1999 in the United Kingdom, and DIN EN 60617-12:1998 in Germany.

The mutual goal of IEEE Std 91-1984 and IEC 60617-12 was to provide a uniform method of describing the complex logic functions of digital circuits with schematic symbols. These functions were more complex than simple AND and OR gates. They could be medium scale circuits such as a 4-bit counter to a large scale circuit such as a microprocessor.

IEC 617-12 and its successor IEC 60617-12 do not explicitly show the "distinctive shape" symbols, but do not prohibit them. These are, however, shown in ANSI/IEEE 91 (and 91a) with this note: "The distinctive-shape symbol is, according to IEC Publication 617, Part 12, not preferred, but is not considered to be in contradiction to that standard." IEC 60617-12 correspondingly contains the note (Section 2.1) "Although non-preferred, the use of other symbols recognized by official national standards, that is distinctive shapes in place of symbols [list of basic gates], shall not be considered to be in contradiction with this standard. Usage of these other symbols in combination to form complex symbols (for example, use as embedded symbols) is discouraged." This compromise was reached between the respective IEEE and IEC working groups to permit the IEEE and IEC standards to be in mutual compliance with one another.

A third style of symbols, DIN 40700 (1976), was in use in Europe and is still widely used in European academia, see the logic table in .

In the 1980s, schematics were the predominant method to design both circuit boards and custom ICs known as gate arrays. Today custom ICs and the field-programmable gate array are typically designed with Hardware Description Languages (HDL) such as Verilog or VHDL.

Output comparison of 1-input logic gates.
Output comparison of 2-input logic gates.
Charles Sanders Peirce (during 1880–81) showed that NOR gates alone (or alternatively NAND gates alone) can be used to reproduce the functions of all the other logic gates, but his work on it was unpublished until 1933. The first published proof was by Henry M. Sheffer in 1913, so the NAND logical operation is sometimes called Sheffer stroke; the logical NOR is sometimes called "Peirce's arrow". Consequently, these gates are sometimes called "universal logic gates".

By use of De Morgan's laws, an "AND" function is identical to an "OR" function with negated inputs and outputs. Likewise, an "OR" function is identical to an "AND" function with negated inputs and outputs. A NAND gate is equivalent to an OR gate with negated inputs, and a NOR gate is equivalent to an AND gate with negated inputs.

This leads to an alternative set of symbols for basic gates that use the opposite core symbol ("AND" or "OR") but with the inputs and outputs negated. Use of these alternative symbols can make logic circuit diagrams much clearer and help to show accidental connection of an active high output to an active low input or vice versa. Any connection that has logic negations at both ends can be replaced by a negationless connection and a suitable change of gate or vice versa. Any connection that has a negation at one end and no negation at the other can be made easier to interpret by instead using the De Morgan equivalent symbol at either of the two ends. When negation or polarity indicators on both ends of a connection match, there is no logic negation in that path (effectively, bubbles "cancel"), making it easier to follow logic states from one symbol to the next. This is commonly seen in real logic diagrams – thus the reader must not get into the habit of associating the shapes exclusively as OR or AND shapes, but also take into account the bubbles at both inputs and outputs in order to determine the "true" logic function indicated.

A De Morgan symbol can show more clearly a gate's primary logical purpose and the polarity of its nodes that are considered in the "signaled" (active, on) state. Consider the simplified case where a two-input NAND gate is used to drive a motor when either of its inputs are brought low by a switch. The "signaled" state (motor on) occurs when either one OR the other switch is on. Unlike a regular NAND symbol, which suggests AND logic, the De Morgan version, a two negative-input OR gate, correctly shows that OR is of interest. The regular NAND symbol has a bubble at the output and none at the inputs (the opposite of the states that will turn the motor on), but the De Morgan symbol shows both inputs and output in the polarity that will drive the motor.

De Morgan's theorem is most commonly used to implement logic gates as combinations of only NAND gates, or as combinations of only NOR gates, for economic reasons.

Logic gates can also be used to store data. A storage element can be constructed by connecting several gates in a "latch" circuit. More complicated designs that use clock signals and that change only on a rising or falling edge of the clock are called edge-triggered "flip-flops". Formally, a flip-flop is called a bistable circuit, because it has two stable states which it can maintain indefinitely. The combination of multiple flip-flops in parallel, to store a multiple-bit value, is known as a register. When using any of these gate setups the overall system has memory; it is then called a sequential logic system since its output can be influenced by its previous state(s), i.e. by the "sequence" of input states. In contrast, the output from combinational logic is purely a combination of its present inputs, unaffected by the previous input and output states.

These logic circuits are known as computer memory. They vary in performance, based on factors of speed, complexity, and reliability of storage, and many different types of designs are used based on the application.

A three-state logic gate is a type of logic gate that can have three different outputs: high (H), low (L) and high-impedance (Z). The high-impedance state plays no role in the logic, which is strictly binary. These devices are used on buses of the CPU to allow multiple chips to send data. A group of three-states driving a line with a suitable control circuit is basically equivalent to a multiplexer, which may be physically distributed over separate devices or plug-in cards.

In electronics, a high output would mean the output is sourcing current from the positive power terminal (positive voltage). A low output would mean the output is sinking current to the negative power terminal (zero voltage). High impedance would mean that the output is effectively disconnected from the circuit.

Since the 1990s, most logic gates are made in CMOS (complementary metal oxide semiconductor) technology that uses both NMOS and PMOS transistors. Often millions of logic gates are packaged in a single integrated circuit.

There are several logic families with different characteristics (power consumption, speed, cost, size) such as: RDL (resistor–diode logic), RTL (resistor-transistor logic), DTL (diode–transistor logic), TTL (transistor–transistor logic) and CMOS. There are also sub-variants, e.g. standard CMOS logic vs. advanced types using still CMOS technology, but with some optimizations for avoiding loss of speed due to slower PMOS transistors.

Non-electronic implementations are varied, though few of them are used in practical applications. Many early electromechanical digital computers, such as the Harvard Mark I, were built from relay logic gates, using electro-mechanical relays. Logic gates can be made using pneumatic devices, such as the Sorteberg relay or mechanical logic gates, including on a molecular scale. Logic gates have been made out of DNA (see DNA nanotechnology) and used to create a computer called MAYA (see MAYA-II). Logic gates can be made from quantum mechanical effects (though quantum computing usually diverges from boolean design; see quantum logic gate). Photonic logic gates use nonlinear optical effects.

In principle any method that leads to a gate that is functionally complete (for example, either a NOR or a NAND gate) can be used to make any kind of digital logic circuit. Note that the use of 3-state logic for bus systems is not needed, and can be replaced by digital multiplexers, which can be built using only simple logic gates (such as NAND gates, NOR gates, or AND and OR gates).



</doc>
<doc id="18171" url="https://en.wikipedia.org/wiki?curid=18171" title="Linear search">
Linear search

In computer science, a linear search or sequential search is a method for finding an element within a list. It sequentially checks each element of the list until a match is found or the whole list has been searched.

A linear search runs in at worst linear time and makes at most comparisons, where is the length of the list. If each element is equally likely to be searched, then linear search has an average case of comparisons, but the average case can be affected if the search probabilities for each element vary. Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists.

A linear search sequentially checks each element of the list until it finds an element that matches the target value. If the algorithm reaches the end of the list, the search terminates unsuccessfully.

Given a list of elements with values or records , and target value , the following subroutine uses linear search to find the index of the target in .


The basic algorithm above makes two comparisons per iteration: one to check if equals , and the other to check if still points to a valid index of the list. By adding an extra record to the list (a sentinel value) that equals the target, the second comparison can be eliminated until the end of the search, making the algorithm faster. The search will reach the sentinel if the target is not contained within the list.


If the list is ordered such that , the search can establish the absence of the target more quickly by concluding the search once exceeds the target. This variation requires a sentinel that is greater than the target.

For a list with "n" items, the best case is when the value is equal to the first element of the list, in which case only one comparison is needed. The worst case is when the value is not in the list (or occurs only once at the end of the list), in which case "n" comparisons are needed.

If the value being sought occurs "k" times in the list, and all orderings of the list are equally likely, the expected number of comparisons is

For example, if the value being sought occurs once in the list, and all orderings of the list are equally likely, the expected number of comparisons is formula_2. However, if it is "known" that it occurs once, then at most "n" - 1 comparisons are needed, and the expected number of comparisons is 

(for example, for "n" = 2 this is 1, corresponding to a single if-then-else construct).

Either way, asymptotically the worst-case cost and the expected cost of linear search are both O("n").

The performance of linear search improves if the desired value is more likely to be near the beginning of the list than to its end. Therefore, if some values are much more likely to be searched than others, it is desirable to place them at the beginning of the list.

In particular, when the list items are arranged in order of decreasing probability, and these probabilities are geometrically distributed, the cost of linear search is only O(1). 

Linear search is usually very simple to implement, and is practical when the list has only a few elements, or when performing a single search in an un-ordered list.

When many values have to be searched in the same list, it often pays to pre-process the list in order to use a faster method. For example, one may sort the list and use binary search, or build an efficient search data structure from it. Should the content of the list change frequently, repeated re-organization may be more trouble than it is worth.

As a result, even though in theory other search algorithms may be faster than linear search (for instance binary search), in practice even on medium-sized arrays (around 100 items or less) it might be infeasible to use anything else. On larger arrays, it only makes sense to use other, faster search methods if the data is large enough, because the initial time to prepare (sort) the data is comparable to many linear searches 



</doc>
<doc id="18172" url="https://en.wikipedia.org/wiki?curid=18172" title="Land mine">
Land mine

A land mine is an explosive device concealed under or on the ground and designed to destroy or disable enemy targets, ranging from combatants to vehicles and tanks, as they pass over or near it. Such a device is typically detonated automatically by way of pressure when a target steps on it or drives over it, although other detonation mechanisms are also sometimes used. A land mine may cause damage by direct blast effect, by fragments that are thrown by the blast, or by both.

The use of land mines is controversial because of their potential as indiscriminate weapons. They can remain dangerous many years after a conflict has ended, harming civilians and the economy. 78 countries are contaminated with land mines and 15,000–20,000 people are killed every year while countless more are maimed. Approximately 80% of land mine casualties are civilian, with children as the most affected age group. Most killings occur in times of peace. With pressure from a number of campaign groups organised through the International Campaign to Ban Landmines, a global movement to prohibit their use led to the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, also known as the "Ottawa Treaty". To date, 164 nations have signed the treaty, but these do not include China, the Russian Federation, and the United States.

In the Anti-Personnel Mine Ban Convention (also known as the Ottawa Treaty) and the Protocol on Mines, Booby-Traps and Other Devices, a "mine" is defined as a "munition designed to be placed under, on or near the ground or other surface area and to be exploded by the presence, proximity or contact of a person or vehicle." Similar in function is the "booby-trap", which the Protocol defines as "any device or material which is designed, constructed or adapted to kill or injure and which functions unexpectedly when a person disturbs or approaches an apparently harmless object or performs an apparently safe act." Such actions might include opening a door or picking up an object. Normally, mines are mass-produced and placed in groups, while booby traps are improvised and deployed one at a time. Also, booby traps can be non-explosive devices such as the punji stick. Overlapping both categories is the "improvised explosive device" (IED), which is "a device placed or fabricated in an improvised manner incorporating explosive material, destructive, lethal, noxious, incendiary, pyrotechnic materials or chemicals designed to destroy, disfigure, distract or harass. They may incorporate military stores, but are normally devised from non-military components." Some meet the definition of mines or booby traps and are also referred to as improvised, artisanal or locally manufactured mines. Other types of IED are remotely activated, so are not considered mines.

"Remotely delivered mines" are dropped from an aircraft or carried by devices such as artillery shells or rockets. Another type of remotely delivered explosive is the "cluster munition", a device that releases several submunitions ("bomblets") over a large area. If they do not explode, they are referred to as "unexploded ordnance" (UXO), along with unexploded artillery shells and other explosive devices that were not manually placed (that is, mines and booby traps are not UXOs). "Explosive remnants of war" (ERW) include UXO and "abandoned explosive ordnance" (AXO), devices that were never used and were left behind after a conflict.

Land mines are divided into two types: anti-tank mines, which are designed to disable tanks or other vehicles; and anti-personnel mines, which are designed to injure or kill people.

The history of land mines can be divided up into three main phases: In the ancient world, buried spikes provided many of the same functions as modern mines. Mines using gunpowder as the explosive were used from the Ming Dynasty to the American Civil War. Subsequently, high explosives were developed and used in land mines.

Some fortifications in the Roman Empire were surrounded by a series of hazards buried in the ground. These included "goads", foot-long pieces of wood with iron hooks on their ends; "lilia" (lilies, so named after their appearance), which were pits in which sharpened logs were arranged in a five-point pattern; and "abatis", fallen trees with sharpened branches facing outwards. As with modern land mines, they were "victim-operated", often concealed, and formed zones that were wide enough so that the enemy could not do much harm from outside, but were under fire (from spear throws, in this case) if they attempted to remove the obstacles. A notable use of these defenses was by Julius Caesar in the Battle of Alesia. His forces were besieging Vercingetorix, the leader of the Gauls, but Vercingetorix managed to send for reinforcements. To maintain the siege and defend against the reinforcements, Caesar formed a line of fortifications on both sides, and they played an important role in his victory. Lilies were also used by Scots against the English at the Battle of Bannockburn in 1314, and by Germans at the Battle of Passchendaele in the First World War.

A more easily deployed defense used by the Romans was the caltrop, a weapon about 12–15 cm across with four sharp spikes that are oriented so that when it is thrown on the ground, one spike always points up. As with modern antipersonnel mines, caltrops are designed to disable soldiers rather than kill them; they are also more effective in stopping mounted forces, who lack the advantage of being able to carefully scrutinize each step they take (though forcing foot-mounted forces to take the time to do so has benefits in and of itself). They were used by the Jin Dynasty in China at the Battle of Zhongdu to slow down the advance of Genghis Khan's army; Joan of Arc was wounded by one in the Siege of Orléans; in Japan they are known as tetsu-bishu and were used by ninjas from the fourteenth century onwards. Caltrops are still strung together and used as roadblocks in some modern conflicts.

Starting in the ninth century, the Chinese began centuries of experiments that resulted in gunpowder, an explosive mixture of sulfur, charcoal and potassium nitrate. Gunpowder was first used in battle in the thirteenth century. An "enormous bomb", credited to Lou Qianxia, was used in 1277 by the Chinese at the Battle of Zhongdu, although it probably had little effect. Gunpowder was difficult to use in mines because it is hygroscopic, easily absorbing water from the atmosphere, and when wet is no longer explosive.

A 14th-century military treatise, the "Huolongjing" (Fire Dragon Manual), describes hollow cast iron cannonball shells filled with gunpowder. The wad of the mine was made of hard wood, carrying three different fuses in case of defective connection to the touch hole. These fuses were long and lit by hand, so they required carefully timed calculation of enemy movements.

The "Huolongjing" also describes land mines that were set off by enemy movement. A nine-foot length of bamboo was waterproofed by wrapping it in cowhide and covering it with oil. It was filled with compressed gunpowder and lead or iron pellets, sealed with wax and concealed in a trench. The triggering mechanism was not fully described until the early 17th century. When the enemy stepped onto hidden boards, they dislodge a pin, causing a weight to fall. A cord attached to the weight was wrapped around a drum attached to two steel wheels; when the weight fell, the wheels struck sparks against flint, igniting a set of fuses to multiple mines. A similar mechanism was used in the first wheellock musket in Europe as sketched by Leonardo da Vinci around 1500 AD.

Another victim-operated device was the "underground sky-soaring thunder", which lured bounty hunters with halberds, pikes, and lances planted in the ground. If they pulled on one of these weapons, the butt end disturbed a bowl underneath and a slow-burning incandescent material in the bowl ignited the fuses.

The fuse mechanisms for the above devices were cumbersome and unreliable. By the time Europeans arrived in China, landmines were largely forgotten.

At Augsburg in 1573, three centuries after the Chinese invented the first pressure-operated mine, a German military engineer by the name of Samuel Zimmermann invented the "Fladdermine" (flying mine). It consisted of a few pounds of black powder buried near the surface and was activated by stepping on it or tripping a wire that made a flintlock fire. Such mines were deployed on the slope in front of a fort. They were used during the Franco-Prussian War but were probably not very effective because a flintlock does not work for long when left untended.

Another device, the fougasse, was not victim-operated or mass-produced, but it was a precursor of modern fragmentation mines and the claymore mine. If consisted of a cone-shape hole with gunpowder at the bottom, covered either by rocks and scrap iron ("stone fougasse") or mortar shells, similar to large black powder hand grenades ("shell fougasse"). It was triggered by a flintlock connected to a tripwire on the surface. It could sometimes cause heavy casualties but required high maintenance due to the susceptibility of black powder to dampness. Consequently, it was mainly employed in the defenses of major fortifications, in which role it used in several European wars of the eighteenth century and the American Revolution.

One of the greatest limitations of early land mines was the unreliable fuses and their susceptibility to dampness. This changed with the invention of the safety fuse. Later, "Command initiation", the ability to detonate a charge immediately instead of waiting several minutes for a fuse to burn, became possible after electricity was developed. An electrical current sent down a wire could ignite the charge with a spark. The Russians claim first use of this technology in the Russo-Turkish War of 1828–1829, and with it the fougasse remained useful until it was superseded by the claymore in the 1960s.

Victim-activated mines were also unreliable because they relied on a flintlock to ignite the explosive. The percussion cap, developed in the early 19th century, made them much more reliable, and pressure-operated mines were deployed on land and sea in the Crimean War (1853–1856).

During the American Civil War, the Confederate brigadier general Gabriel J. Rains deployed thousands of "torpedoes" consisting of artillery shells with pressure caps, beginning with the Battle of Yorktown in 1862. As a Captain, Rains had earlier employed explosive booby traps during the Seminole Wars in Florida in 1840. Over the course of the war, mines only caused a few hundred casualties, but they had a large effect on morale and slowed down the advance of Union troops. Many on both sides considered the use of mines barbaric, and in response, generals in the Union Army forced Confederate prisoners to remove the mines.

Starting in the 19th century, more powerful explosives than gunpowder were developed, often for non-military reasons such as blasting train tunnels in the Alps and Rockies. Guncotton, up to four times more powerful than gunpowder, was invented by Christian Schonbein in 1846. It was dangerous to make until Frederick Augustus Abel developed a safe method in 1865. From the 1870s to the First World War, it was the standard explosive used by the British military.

In 1847, Ascanio Sobrero invented nitroglycerine to treat angina pectoris and it turned out to be a much more powerful explosive than guncotton. It was very dangerous to use until Alfred Nobel found a way to incorporate it in a solid mixture called dynamite and developed a safe detonator. Even then, dynamite needed to be stored carefully or it could form crystals that detonated easily. Thus, the military still preferred guncotton.

In 1863, the German chemical industry developed trinitrotoluene (TNT). This had the advantage that it was difficult to detonate, so it could withstand the shock of firing by artillery pieces. It was also advantageous for land mines for several reasons: it was not detonated by the shock of shells landing nearby; it was lightweight, unaffected by damp, and stable under a wide range of conditions; it could be melted to fill a container of any shape, and it was cheap to make. Thus, it became the standard explosive in mines after the First World War.

In their colonial conflicts, the British had fewer scruples about using mines than the Americans had in the Civil War. The British used mines in the Siege of Khartoum to hold off a much larger Sudanese Mahdist force for ten months. In the end, however, the town was taken and the British massacred. In the Boer War (1899–1903), they succeeded in holding Mafeking against Boer forces with the help of a mixture of real and fake minefields; and they laid mines alongside railroad tracks to discourage sabotage.

In the Russo-Japanese War of 1904–1905, both sides used land and sea mines, although the effect on land was mainly moral. The naval mines were far more effective, destroying several battleships.

One sign of the increasing power of explosives used in land mines was that, by the First World War, they burst into about 1,000 high-velocity fragments; in the Franco-Prussian War (1870), it had only been 20 to 30 fragments. Nevertheless, antipersonnel mines were not a big factor in the war because machine guns, barbed wire and rapid-fire artillery were far more effective defenses. An exception was in Africa (now Tanzania and Namibia) where the warfare was much more mobile.

Towards the end of the war, the British started to use tanks to break through trench defenses. The Germans responded with anti-tank guns and mines. Improvised mines gave way to mass-produced mines consisting of wooden boxes filled with guncotton, and minefields were standardized to stop masses of tanks from advancing.

Between World Wars, the future Allies did little work on land mines, but the Germans developed a series of anti-tank mines, the "Tellermines" (plate mines). They also developed the "Schrapnell mine" (also known as the S-mine), the first bouncing mine. When triggered, this jumped up to about waist height and exploded, sending thousands of steel balls in all directions. Triggered by pressure, trip wires or electronics, it could harm soldiers within an area of about 2800 square feet.

Tens of millions of mines were laid in the Second World War, particularly in the deserts of North Africa and the steppes of Eastern Europe, where the open ground favored tanks. However, the first country to use them was Finland. They were defending against a much larger Soviet force with over 6,000 tanks, twenty times the number the Finns had; but they had terrain that was broken up by lakes and forests, so tank movement was restricted to roads and tracks. Their defensive line, the Mannerheim Line, integrated these natural defenses with mines, including simple fragmentation mines mounted on stakes.

While the Germans were advancing rapidly using "blitzkrieg" tactics, they did not make much use of mines. After 1942, however, they were on the defensive and became the most inventive and systematic users of mines. Their production shot up and they began inventing new types of mines as the Allies found ways to counter the existing ones. To make it more difficult to remove antitank mines, they surrounded them with S-mines and added anti-handling devices that would explode when soldiers tried to lift them. They also took a formal approach to laying mines and they kept detailed records of the locations of mines.

In the Second Battle of El Alamein in 1942, the Germans prepared for an Allied attack by laying about half a million mines in two fields running across the entire battlefield and five miles deep. Nicknamed the Devil's gardens, they were covered by 88 mm anti-tank guns and small-arms fire. The Allies prevailed, but at the cost of over half their tanks; 20 percent of the losses were caused by mines.

The Soviets learned the value of mines from their war with Finland, and when Germany invaded, they made heavy use of them, manufacturing over 67 million. At the Battle of Kursk, which put an end to the German advance, they laid over a million mines in eight belts with an overall depth of 35 kilometres.

Mines forced tanks to slow down and wait for soldiers to go ahead and remove the mines. The main method of breaching minefields involved prodding the dirt with a bayonet or stick at an angle of 30 degrees (to avoid putting pressure on the top of the mine and detonating it). Since all mines at the beginning of the war had metal casings, metal detectors could be used to speed up the locating of mines. A Polish officer, Józef Kosacki, developed a portable mine detector known as the Polish mine detector. To counter the detector, Germans developed mines with wooden casings, the Schu-mine 42 (antipersonnel) and Holzmine 42 (anti-tank). Effective, cheap and easy to make, the "schu" mine became the most common mine in the war. Mine casings were also made of glass, concrete and clay. The Russians developed a mine with a pressed-cardboard casing, the PMK40, and the Italians made an anti-tank mine out of bakelite. In 1944, the Germans created the Topfmine, an entirely non-metallic mine. They ensured that they could detect their own mines by covering them with radioactive sand, but the Allies did not find this out until after the war.

Several mechanical methods for clearing mines were tried. Heavy rollers attached to tanks or cargo trucks, but they did not last long and their weight made the tanks considerably slower. Tanks and bulldozers pushed ploughs that in turn pushed aside any mines to a depth of 30 cm. The Bangalore torpedo, a long thin tube filled with explosives, was invented in 1912 and used to clear barbed wire. Larger versions such as the Snake and the Conger were developed but were not very effective. One of the best options was the flail, which chains with weights on the end attached to rotating drums. The first version, the Scorpion, was attached to the Matilda tank and used in the Second Battle of El Alamein. The Crab, attached to the Sherman tank, was faster (2 kilometers per hour); it was used during D-Day and the aftermath.

During the Cold War, the members of NATO were concerned about massive armored attacks by the Soviet Union. They planned for a minefield stretching across the entire West German border, and developed new types of mine. The British designed an anti-tank mine, the Mark 7, to defeat rollers by detonating the second time it was pressed. It also had a 0.7-second delay so the tank would be directly over the mine. They also developed the first scatterable mine, the No. 7 ("Dingbat"). The Americans used the M6 antitank mine and tripwire-operated bouncing antipersonnel mines such as the M2 and M16.

In the Korean War, land mine use was dictated by the steep terrain, narrow valleys, forest cover and lack of developed roads. This made tanks less effective and more easily stopped by mines. However, mines laid near roads were often easy to spot. In response to this problem, the US developed the M24, a mine that was placed off to the side of the road. When triggered by a tripwire, it fired a rocket. However, the mine was not available until after the war.

The Chinese had a lot of success with massed infantry attacks. The extensive forest cover limited the range of machine guns, but anti-personnel mines were effective. However, mines were poorly recorded and marked, often becoming as much a hazard to allies as enemies. Tripwire-operated mines were not defended by pressure mines; the Chinese were often able to disable them and reuse them against UN forces.

Looking for more destructive mines, the Americans developed the Claymore, a directional fragmentation mine that hurls steel balls in a 60 degree arc at a lethal speed of 1,200 metres per second. They also developed a pressure-operated mine, the M14 ("toe-popper"). These, too, were ready too late for the Korean war.
In 1948, the British developed the No. 6 antipersonnel mine a minimum-metal mine with a narrow diameter, making it difficult to detect with metal detectors or prodding. Its three-pronged pressure piece inspired the nickname "Carrot Mine". However, it was unreliable in wet conditions. In the 1960s the Canadians developed a similar, but more reliable mine, the C3A1 ("Elsie") and the British army adopted it. The British also developed the L9 Bar Mine, a wide anti-tank mine with a rectangular shape, which covered more area, allowing a minefield to be laid four times as fast as previous mines. They also upgraded the Dingbat to the Ranger, a plastic mine that was fired from a truck-mounted discharger that could fire 72 mines at a time.

In the 1950s, the US Operation Doan Brook studied the feasibility of delivering mines by air. This led to three types of air-delivered mine. Wide Area Anti-Personnel Mines (WAAPMs) were small steel spheres that discharged tripwires when they hit the ground; each dispenser held 540 mines. The BLU-43 Dragontooth was small and had a flattened W shape to slow its descent, while the Gravel mine was larger. Both were packed by the thousand into bombs. All three were designed to inactivate after a period of time, but any that failed to activate presented a safety challenge. Over 37 million Gravel mines were produced between 1967 and 1968, and when they were dropped in places like Vietnam their locations were unmarked and unrecorded. A similar problem was presented by unexploded cluster munitions.

The next generation of scatterable mines arose in response to the increasing mobility of war. The Germans developed the Skorpion system, which scattered AT2 mines from a tracked vehicle. The Italians developed a helicopter delivery system that could rapidly switch between SB-33 anti-personnel mines and SB-81 anti-tank mines. The US developed a range of systems called the Family of Scatterable Mines (FASCAM) that could deliver mines by fast jet, artillery, helicopter and ground launcher.

In the First World War, the Germans developed a device, nicknamed the “Yperite Mine” by the British, that they left behind in abandoned trenches and bunkers. It was detonated by a delayed charge, spreading mustard gas (“Yperite”). In the Second World War they developed a modern chemical mine, the Spruh-Buchse 37 (Bounding Gas Mine 37), but never used it. The United States developed the M1 chemical mine , which used mustard gas, in 1939; and the M23 chemical mine, which used the VX nerve agent, in 1960. The Soviets developed the KhF, a "bounding chemical mine". The French had chemical mines and the Iraqis were believed to have them before the invasion of Kuwait. In 1997, the Chemical Weapons Convention came into force, prohibiting the use of chemical weapons and mandating their destruction. As of 30 April 2019, 97% of the declared stockpiles of chemical weapons were destroyed.

For a few decades during the Cold War, the U.S. developed atomic demolition munitions, often referred to as nuclear land mines. These were portable nuclear bombs that could be placed by hand, and could be detonated remotely or with a timer. Some of these were deployed in Europe. Governments in West Germany, Turkey and Greece wanted to have nuclear minefields as a defense against attack from the Warsaw Pact. However, such weapons were politically and tactically infeasible, and by 1989 the last of these munitions was retired. The British also had a project, codenamed Blue Peacock, to develop nuclear mines to be buried in Germany; the project was cancelled in 1958.

A conventional land mine consists of a casing that is mostly filled with the main charge. It has a firing mechanism such as a pressure plate; this triggers a detonator or igniter, which in turn sets off a booster charge. There may be additional firing mechanisms in anti-handling devices.

A land mine can be triggered by a number of things including pressure, movement, sound, magnetism and vibration. Anti-personnel mines commonly use the pressure of a person's foot as a trigger, but tripwires are also frequently employed. Most modern anti-vehicle mines use a magnetic trigger to enable it to detonate even if the tires or tracks did not touch it. Advanced mines are able to sense the difference between friendly and enemy types of vehicles by way of a built-in signature catalog. This will theoretically enable friendly forces to use the mined area while denying the enemy access.

Many mines combine the main trigger with a touch or tilt trigger to prevent enemy engineers from defusing it. Land mine designs tend to use as little metal as possible to make searching with a metal detector more difficult; land mines made mostly of plastic have the added advantage of being very inexpensive.

Some types of modern mines are designed to self-destruct, or chemically render themselves inert after a period of weeks or months to reduce the likelihood of civilian casualties at the conflict's end. These self-destruct mechanisms are not absolutely reliable, and most land mines laid historically are not equipped in this manner.

There is a common misperception that a landmine is armed by stepping on it and only triggered by stepping off, providing tension in movies. In fact the initial pressure trigger will detonate the mine, as they are designed to kill or maim, not to make someone stand very still until it can be disarmed.

Anti-handling devices detonate the mine if someone attempts to lift, shift or disarm it. The intention is to hinder deminers by discouraging any attempts to clear minefields. There is a degree of overlap between the function of a boobytrap and an anti-handling device insofar as some mines have optional fuze pockets into which standard pull or pressure-release boobytrap firing devices can be screwed. Alternatively, some mines may mimic a standard design, but actually be specifically intended to kill deminers, such as the MC-3 and PMN-3 variants of the PMN mine. Anti-handling devices can be found on both anti-personnel mines and anti-tank mines, either as an integral part of their design or as improvised add-ons. For this reason, the standard render safe procedure for mines is often to destroy them on site without attempting to lift them.

Anti-tank mines were created not long after the invention of the tank in the First World War. At first improvised, purpose-built designs were developed. Set off when a tank passes, they attack the tank at one of its weaker areas — the tracks. They are designed to immobilize or destroy vehicles and their occupants. In U.S. military terminology destroying the vehicles is referred to as a catastrophic kill while only disabling its movement is referred to as a mobility kill.

Anti-tank mines are typically larger than anti-personnel mines and require more pressure to detonate. The high trigger pressure, normally requiring prevents them from being set off by infantry or smaller vehicles of lesser importance. More modern anti-tank mines use shaped charges to focus and increase the armor penetration of the explosives.

Anti-personnel mines are designed primarily to kill or injure people, as opposed to vehicles. They are often designed to injure rather than kill in order to increase the logistical support (evacuation, medical) burden on the opposing force. Some types of anti-personnel mines can also damage the tracks or wheels of armored vehicles.

In the asymmetric warfare conflicts and civil wars of the 21st century, improvised explosives, known as IEDs, have partially supplanted conventional landmines as the source of injury to dismounted (pedestrian) soldiers and civilians. IEDs are used mainly by insurgents and terrorists against regular armed forces and civilians. The injuries from the anti-personnel IED were recently reported in BMJ Open to be far worse than with landmines resulting in multiple limb amputations and lower body mutilation.

Land mines were designed for two main uses: 

Land mines are currently used in large quantities mostly for this first purpose, thus their widespread use in the demilitarized zones (DMZs) of likely flashpoints such as Cyprus, Afghanistan and Korea. As of 2013, the only governments that still laid land mines were Myanmar in its internal conflict, and Syria in its civil war.

In military science, minefields are considered a defensive or harassing weapon, used to slow the enemy down, to help deny certain terrain to the enemy, to focus enemy movement into kill zones, or to reduce morale by randomly attacking material and personnel. In some engagements during World War II, anti-tank mines accounted for half of all vehicles disabled.

Since combat engineers with mine-clearing equipment can clear a path through a minefield relatively quickly, mines are usually considered effective only if covered by fire.

The extents of minefields are often marked with warning signs and cloth tape, to prevent friendly troops and non-combatants from entering them. Of course, sometimes terrain can be denied using dummy minefields. Most forces carefully record the location and disposition of their own minefields, because warning signs can be destroyed or removed, and minefields should eventually be cleared. Minefields may also have marked or unmarked safe routes to allow friendly movement through them.

Placing minefields without marking and recording them for later removal is considered a war crime under Protocol II of the Convention on Certain Conventional Weapons, which is itself an annex to the Geneva Conventions.

Artillery and aircraft scatterable mines allow minefields to be placed in front of moving formations of enemy units, including the reinforcement of minefields or other obstacles that have been breached by enemy engineers. They can also be used to cover the retreat of forces disengaging from the enemy, or for interdiction of supporting units to isolate front line units from resupply. In most cases these minefields consist of a combination of anti-tank and anti-personnel mines, with the anti-personnel mines making removal of the anti-tank mines more difficult. Mines of this type used by the United States are designed to self-destruct after a preset period of time, reducing the requirement for mine clearing to only those mines whose self-destruct system did not function. Some designs of these scatterable mines require an electrical charge (capacitor or battery) to detonate. After a certain period of time, either the charge dissipates, leaving them effectively inert or the circuitry is designed such that upon reaching a low level, the device is triggered, thus destroying the mine.

None of the conventional tactics and norms of mine warfare applies when they are employed in a guerrilla role:

Land mines were commonly deployed by insurgents during the South African Border War, leading directly to the development of the first dedicated mine-protected armoured vehicles in South Africa. Namibian insurgents used anti-tank mines to throw South African military convoys into disarray before attacking them. To discourage detection and removal efforts, they also laid anti-personnel mines directly parallel to the anti-tank mines. This initially resulted in heavy South African military and police casualties, as the vast distances of road network vulnerable to insurgent sappers every day made comprehensive detection and clearance efforts impractical. The only other viable option was the adoption of mine-protected vehicles which could remain mobile on the roads with little risk to their passengers even if a mine was detonated. South Africa is widely credited with inventing the v-hull, a vee-shaped hull for armoured vehicles which deflects mine blasts away from the passenger compartment.

During the ongoing Syrian Civil War, Iraqi Civil War (2014–2017) and Yemeni Civil War (2015–present) landmines have been used for both defensive and guerrilla purposes.

Minefields may be laid by several means. The preferred, but most labour-intensive, way is to have engineers bury the mines, since this will make the mines practically invisible and reduce the number of mines needed to deny the enemy an area. Mines can be laid by specialized mine-laying vehicles. Mine-scattering shells may be fired by artillery from a distance of several tens of kilometers.

Mines may be dropped from helicopters or airplanes, or ejected from cluster bombs or cruise missiles.

Anti-tank minefields can be scattered with anti-personnel mines to make clearing them manually more time-consuming; and anti-personnel minefields are scattered with anti-tank mines to prevent the use of armored vehicles to clear them quickly. Some anti-tank mine types are also able to be triggered by infantry, giving them a dual purpose even though their main and official intention is to work as anti-tank weapons.

Some minefields are specifically booby-trapped to make clearing them more dangerous. Mixed anti-personnel and anti-tank minefields, anti-personnel mines "under" anti-tank mines, and fuses separated from mines have all been used for this purpose. Often, single mines are backed by a secondary device, designed to kill or maim personnel tasked with clearing the mine.

Multiple anti-tank mines have been buried in stacks of two or three with the bottom mine fuzed, in order to multiply the penetrating power. Since the mines are buried, the ground directs the energy of the blast in a single direction—through the bottom of the target vehicle or on the track.

Another specific use is to mine an aircraft runway immediately after it has been bombed in order to delay or discourage repair. Some cluster bombs combine these functions. One example was the British JP233 cluster bomb which includes munitions to damage (crater) the runway as well as anti-personnel mines in the same cluster bomb. As a result of the anti-personnel mine ban it was withdrawn from British Royal Air Force service, and the last stockpiles of the mine were destroyed on 19 October 1999.

Metal detectors were first used for demining, after their invention by the Polish officer Józef Kosacki. His invention, known as the Polish mine detector, was used by the Allies alongside mechanical methods, to clear the German mine fields during the Second Battle of El Alamein when 500 units were shipped to Field Marshal Montgomery's Eighth Army.

The Nazis used captured civilians who were chased across minefields to detonate the explosives. According to Laurence Rees "Curt von Gottberg, the SS-Obergruppenführer who, during 1943, conducted another huge anti-partisan action called Operation Kottbus on the eastern border of Belarus, reported that 'approximately two to three thousand local people were blown up in the clearing of the minefields'."

Whereas the placing and arming of mines is relatively inexpensive and simple, the process of detecting and removing them is typically expensive, slow, and dangerous. This is especially true of irregular warfare where mines were used on an ad hoc basis in unmarked areas. Anti-personnel mines are most difficult to find, due to their small size and the fact that many are made almost entirely of non-metallic materials specifically to escape detection.

Manual clearing remains the most effective technique for clearing mine fields, although hybrid techniques involving the use of animals and robots are being developed. Animals are desirable due to their strong sense of smell, which is more than capable of detecting a land mine. Animals like rats and dogs can also differentiate between other metal objects and land mines because they can be trained to detect the explosive agent itself.

Other techniques involve the use of geo-location technologies. A joint team of researchers at the University of New South Wales and Ohio State University is working to develop a system based on multi-sensor integration.

The laying of land mines has inadvertently led to a positive development in the Falkland Islands. Mine fields laid near the sea during the Falklands War have become favorite places for penguins, which do not weigh enough to detonate the mines. Therefore, they can breed safely, free of human intrusion. These odd sanctuaries have proven so popular and lucrative for ecotourism that efforts exist to prevent removal of the mines.

The use of land mines is controversial because they are indiscriminate weapons, harming soldier and civilian alike. They remain dangerous after the conflict in which they were deployed has ended, killing and injuring civilians and rendering land impassable and unusable for decades. To make matters worse, many factions have not kept accurate records (or any at all) of the exact locations of their minefields, making removal efforts painstakingly slow. These facts pose serious difficulties in many developing nations where the presence of mines hampers resettlement, agriculture, and tourism. The International Campaign to Ban Landmines campaigned successfully to prohibit their use, culminating in the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, known informally as the Ottawa Treaty.

The Treaty came into force on 1 March 1999. The treaty was the result of the leadership of the Governments of Canada, Norway, South Africa and Mozambique working with the "International Campaign to Ban Landmines", launched in 1992. The campaign and its leader, Jody Williams, won the Nobel Peace Prize in 1997 for its efforts.

The treaty does not include anti-tank mines, cluster bombs or claymore-type mines operated in command mode and focuses specifically on anti-personnel mines, because these pose the greatest long term (post-conflict) risk to humans and animals since they are typically designed to be triggered by any movement or pressure of only a few kilograms, whereas anti-tank mines require much more weight (or a combination of factors that would exclude humans). Existing stocks must be destroyed within four years of signing the treaty.

Signatories of the Ottawa Treaty agree that they will not use, produce, stockpile or trade in anti-personnel land mines. In 1997, there were 122 signatories; the Treaty has now been signed by 162 countries. As of early 2016, 162 countries have joined the Treaty. Thirty-six countries, including the People's Republic of China, the Russian Federation and the United States, which together may hold tens of millions of stockpiled antipersonnel mines, are not party to the Convention. Another 34 have yet to sign on. The United States did not sign because the treaty lacks an exception for the Korean Demilitarized Zone.

There is a clause in the treaty, Article 3, which permits countries to retain land mines for use in training or development of countermeasures. Sixty-four countries have taken this option.

As an alternative to an outright ban, 10 countries follow regulations that are contained in a 1996 amendment of Protocol II of the Convention on Conventional Weapons (CCW). The countries are China, Finland, India, Israel, Morocco, Pakistan, South Korea and the United States. Sri Lanka, which had adhered to this regulation announced in 2016, that it would join the Ottawa Treaty.

Before the Ottawa Treaty was adopted, the Arms Project of Human Rights Watch identified "almost 100 companies and government agencies in 48 countries" that had manufactured "more than 340 types of antipersonnel landmines in recent decades." Five to ten million mines were produced per year with a value of $50 to $200 million. The largest producers were probably China, Italy and the Soviet Union. The companies involved included giants such as Daimler-Benz, the Fiat Group, the Daewoo Group, RCA and General Electric.

As of 2017, the "Landmine & Cluster Munition Monitor" identified four countries that were "likely to be actively producing" land mines: India, Myanmar, Pakistan and South Korea. Another seven states reserved the right to make them but were probably not doing so: China, Cuba, Iran, North Korea, Russia, Singapore, and Vietnam.

Throughout the world there are millions of hectares that are contaminated with land mines.

From 1999 to 2017, the "Landmine Monitor" has recorded over 120,000 casualties from mines, IEDs and explosive remnants of war; it estimates that another 1,000 per year go unrecorded. The estimate for all time is over half a million. In 2017, at least 2,793 were killed and 4,431 injured. 87% of the casualties were civilians and 47% were children (less than 18 years old). The largest numbers of casualties were in Afghanistan (2,300), Syria (1,906), and Ukraine (429).

Natural disasters can have a significant impact on efforts to demine areas of land. For example, the floods that occurred in Mozambique in 1999 and 2000 may have displaced hundreds of thousands of land mines left from the war. Uncertainty about their locations delayed recovery efforts.

From a recent study by Asmeret Asefaw Berhe, land degradation caused by land mines "can be classified into five groups: access denial, loss of biodiversity, micro-relief disruption, chemical composition, and loss of productivity". The effects of an explosion depend on: "(i) the objectives and methodological approaches of the investigation; (ii) concentration of mines in a unit area; (iii) chemical composition and toxicity of the mines; (iv) previous uses of the land and (v) alternatives that are available for the affected populations."

The most prominent ecological issue associated with landmines (or fear of them) is denial of access to vital resources (where "access" refers to the ability to use resources, in contrast to "property", the right to use them). The presence and fear of presence of even a single landmine can discourage access for agriculture, water supplies and possibly conservation measures. Reconstruction and development of important structures such as schools and hospitals are likely to be delayed, and populations may shift to urban areas, increasing overcrowding and the risk of spreading diseases.

Access denial can have positive effects on the environment. When a mined area becomes a "no-man's land", plants and vegetation have a chance to grow and recover. For example, formerly arable lands in Nicaragua returned to forests and remained undisturbed after the establishment of landmines. (Similarly, the Penguins of the Falkland Islands have benefited.) However, these benefits can only last as long as animals, tree limbs, etc. do not detonate the mines. In addition, long idle periods could "potentially end up creating or exacerbating loss of productivity", particularly within land of low quality.

Landmines can threaten biodiversity by wiping out vegetation and wildlife during explosions or demining. This extra burden can push threatened and endangered species to extinction. They have also been used by poachers to target endangered species. Displace people refugees hunt animals for food and destroy habitat by making shelters.

Shrapnel, or abrasions of bark or roots caused by detonated mines, can cause the slow death of trees and provide entry sites for wood-rotting fungi. When landmines make land unavailable for farming, residents resort to the forests to meet all of their survival needs. This exploitation furthers the loss of biodiversity.

Near mines that have exploded or decayed, soils tend to be contaminated, particularly with heavy metals. Products produced from the explosives, both organic and inorganic substances, are most likely to be "long lasting, water-soluble and toxic even in small amounts". They can be implemented either "directly or indirectly into soil, water bodies, microorganisms and plants with drinking water, food products or during respiration".

Toxic compounds can also find their way into bodies of water accumulate in land animals, fish and plants. They can act "as a nerve poison to hamper growth", with deadly effect.







</doc>
<doc id="18173" url="https://en.wikipedia.org/wiki?curid=18173" title="List of libertarian political parties">
List of libertarian political parties

Many countries and subnational political entities have libertarian parties. Although these parties may describe themselves as libertarian, their ideologies differ considerably and not all of them support all elements of libertarianism.



</doc>
<doc id="18175" url="https://en.wikipedia.org/wiki?curid=18175" title="Loa">
Loa

Loa (, also written lwa as in Haitian Creole) are the spirits of Haitian Vodou and Louisiana Voodoo. They are also referred to as "mystères" and "the invisibles" and are intermediaries between Bondye (from French "Bon Dieu", meaning "good God")—the Supreme Creator, who is distant from the world—and humanity. Unlike saints or angels, however, they are not simply prayed to, they are served. They are each distinct beings with their own personal likes and dislikes, distinct sacred rhythms, songs, dances, ritual symbols, and special modes of service. Contrary to popular belief, the loa are not deities in and of themselves; they are intermediaries for, and dependent on, a distant Bondye.

The words "loa" and "lwa" come from the French "les lois"; "the laws" in English.

The enslaved Fon and Ewe in Haiti and Louisiana syncretized the loa with the Catholic saints—vodoun altars will frequently display images of Catholic saints. For example, Papa Legba is syncretized with Saint Peter or Lazarus of Bethany.

Syncretism also works the other way in Haitian Vodou and many Catholic saints have become loa in their own right, most notably Philomena, the archangel Michael, Jude the Apostle, and John the Baptist.

In a ritual the loa are called down by the "houngan" (priest), "mambo" (priestess), or the "bokor" and the "caplata" (sorcerers and witches) to take part in the service, receive offerings, and grant requests. The loa arrive in the peristyle (ritual space) by mounting (possessing) a horse (ritualist) in Creole referred as "Chwal"—who is said to be "ridden". This can be quite a violent occurrence as the participant can flail about or convulse before falling to the ground, but some loa, such as Ayizan, will mount their "horses" very quietly.

Certain loa display very distinctive behavior by which they can be recognized, specific phrases, and specific actions. As soon as a loa is recognized, the symbols appropriate to them will be given to them. For example, Erzulie Freda will be given a glass of pink champagne, she is sprinkled with her perfumes, fine gifts of food will be presented to her or she even puts on her jewelry; Legba will be given his cane, straw hat, and pipe; Baron Samedi will often fall flat on the floor and the vodousants around him will dress him and prepare him as they do in a morgue with cotton in his nose.
Once the loa have arrived, fed, been served, and possibly given help or advice, they leave the peristyle. Certain loa can become obstinate, for example the Guédé are notorious for wanting just one more smoke, or one more drink, but it is the job of the houngan or mambo to keep the spirits in line while ensuring they are adequately provided for.

There are many families or ""nanchons"" (from "nations") of loa: Rada (also Radha), Petro (also Pethro, Petwo), Nago, Kongo, and Ghede (also Guede, or Gede), among others.

The Rada loa are generally older, as many of these spirits come from Africa and the kingdom of Dahomey. The Rada Loa are mainly water spirits and many of the Rada loa are served with a water. The Rada are "Cool" in the sense they are less aggressive than the Petro. They include Legba, Loko, Ayizan, Damballa Wedo and Ayida-Weddo, Maîtresse Mambo Erzulie Fréda Dahomey, La Sirène, and Agwé. Many of these spirits are served with white (as opposed to the specific colours of individual loa).

The Petro loa are generally the more fiery, occasionally aggressive and warlike loa, and are associated with Haiti and the New World. They include Ezili Dantor, Marinette, and Met Kalfu (Maitre Carrefour, "Master Crossroads"). Their traditional colour is red.

Originating from the Congo region, these loa include the many Simbi loa. It also includes Marinette, a fierce and much feared female loa.

Originating from Yorubaland, this nation includes many of the Ogoun loa.

The Guédé are the spirits of the dead. They are traditionally led by the Barons (La Croix, Samedi, Cimitière, Kriminel), and Maman Brigitte. The Ghede as a family are loud, rude (although rarely to the point of real insult), sexual, and usually a lot of fun. As those who have lived already, they have nothing to fear, and frequently will display how far past consequence and feeling they are when they come through in a service—eating glass, raw chillis, and anointing their sensitive areas with chilli rum, for example. Their traditional colours are black and purple.




</doc>
<doc id="18178" url="https://en.wikipedia.org/wiki?curid=18178" title="Labour economics">
Labour economics

Labour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour is a commodity that supplied by labourers in exchange for a wage paid by demanding firms. 

Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.

Labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. Some theories focus on human capital (referring to the skills that workers possess, not necessarily their actual work). Labour is unique to study because it is a special type of good that cannot be separated from the owner (i.e. the work cannot be separated from the person who does it). A labour market is also different from other markets in that workers are the suppliers and firms are the demanders. 

There are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.

The Labour force (LF) is defined as the number of people of working age, who are either employed or actively looking for work (unemployed). The labour force participation rate (LFPR) is the number of people in the labour force divided by the size of the adult civilian non-institutional population (or by the population of working age that is not institutionalized), LFPR = LF/Population.

The non-labour force includes those who are not looking for work, those who are institutionalized (such as in prisons or psychiatric wards), stay-at home spouses, children not of working age, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.

The skills required in a labor force can vary from individual to individual, as well as from firm to firm. Some firms have specific skills they are interested in, limiting the labour force to certain criteria. A firm requiring specific skills will help determine the size of the market.

Variables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements. Changes in unemployment depend on inflows (non-employed people starting to look for jobs and employed people who lose their jobs that are looking for new ones) and outflows (people who find new employment and people who stop looking for employment). When looking at the overall macro economy, several types of unemployment have been identified, which can be separated into two categories of natural and unnatural unemployment.

"Natural Unemployment"


"Unnatural Unemployment"


Neoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine price (in this case the wage rate) and quantity (in this case the number of people employed).

However, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.

Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.

Households are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.

Let "w" denote the hourly wage, "k" denote total hours available for labour and leisure, "L" denote the chosen number of working hours, π denote income from non-labour sources, and "A" denote leisure hours chosen. The individual's problem is to maximise utility "U", which depends on total income available for spending on consumption and also depends on time spent in leisure, subject to a time constraint, with respect to the choices of labour time and leisure time:

This is shown in the graph below, which illustrates the trade-off between allocating time to leisure activities and allocating it to income-generating activities. The linear constraint indicates that every additional hour of leisure undertaken requires the loss of an hour of labour and thus of the fixed amount of goods that that labour's income could purchase. Individuals must choose how much time to allocate to leisure activities and how much to working. This allocation decision is informed by the indifference curve labelled IC. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility. The point where the highest indifference curve is just tangent to the constraint line (point A), illustrates the optimum for this supplier of labour services.

If consumption is measured by the value of income obtained, this diagram can be used to show a variety of interesting effects. This is because the absolute value of the slope of the budget constraint is the wage rate. The point of optimisation (point A) reflects the equivalency between the wage rate and the marginal rate of substitution of leisure for income (the absolute value of the slope of the indifference curve). Because the marginal rate of substitution of leisure for income is also the ratio of the marginal utility of leisure (MU) to the marginal utility of income (MU), one can conclude:

where "Y" is total income and the right side is the wage rate.
If the wage rate increases, this individual's constraint line pivots up from X,Y to X,Y. He/she can now purchase more goods and services. His/her utility will increase from point A on IC to point B on IC.
To understand what effect this might have on the decision of how many hours to work, one must look at the income effect and substitution effect.

The wage increase shown in the previous diagram can be decomposed into two separate effects. The pure income effect is shown as the movement from point A to point C in the next diagram. Consumption increases from Y to Y and – since the diagram assumes that leisure is a normal good – leisure time increases from X to X. (Employment time decreases by the same amount as leisure increases.)

But that is only part of the picture. As the wage rate rises, the worker will substitute away from leisure and into the provision of labour—that is, will work more hours to take advantage of the higher wage rate, or in other words substitute away from leisure because of its higher opportunity cost. This substitution effect is represented by the shift from point C to point B. The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances. In some cases, such as the one shown, the substitution effect is greater than the income effect (in which case more time will be allocated to working), but in other cases the income effect will be greater than the substitution effect (in which case less time is allocated to working). The intuition behind this latter case is that the individual decides that the higher earnings on the previous amount of labour can be "spent" by purchasing more leisure.

If the substitution effect is greater than the income effect, an individual's supply of labour services will increase as the wage rate rises, which is represented by a positive slope in the labour supply curve (as at point E in the adjacent diagram, which exhibits a positive wage elasticity). This positive relationship is increasing until point F, beyond which the income effect dominates the substitution effect and the individual starts to reduce the amount of labour hours he supplies (point G) as wage increases; in other words, the wage elasticity is now negative.

The direction of slope may change more than once for some individuals, and the labour supply curve is different for different individuals.

Other variables that affect the labour supply decision, and can be readily incorporated into the model, include taxation, welfare, work environment, and income as a signal of ability or social contribution.

A firm's labour demand is based on its marginal physical product of labour (MPP). This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour). (See also Production theory basics.)

Labour demand is a derived demand; that is, hiring labour is not desired for its own sake but rather because it aids in producing output, which contributes to an employer's revenue and hence profits. The demand for an additional amount of labour depends on the Marginal Revenue Product (MRP) and the marginal cost (MC) of the worker. With a perfectly competitive goods market, the MRP is calculated by multiplying the price of the end product or service by the Marginal Physical Product of the worker. If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit. The firm only employs however up to the point where MRP=MC, and not beyond, in neoclassical economic theory.

The MRP of the worker is affected by other inputs to production with which the worker can work (e.g. machinery), often aggregated under the term "capital". It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as "human capital". Since the amount of physical capital affects MRP, and since financial capital flows can affect the amount of physical capital available, MRP and thus wages can be affected by financial capital flows within and between countries, and the degree of capital mobility within and between countries.

According to neoclassical theory, over the relevant range of outputs, the marginal physical product of labour is declining (law of diminishing returns). That is, as more and more units of labour are employed, their additional output begins to decline.

Additionally, although the MRP is a good way of expressing an employer's demand, other factors such as social group formation can the demand, as well as the labor supply. This constantly restructures exactly what a labor market is, and leads way to causing problems for theories of inflation.

The marginal revenue product of labour can be used as the demand for labour curve for this firm in the short run. In competitive markets, a firm faces a perfectly elastic supply of labour which corresponds with the wage rate and the marginal resource cost of labour (W = S = MFC). In imperfect markets, the diagram would have to be adjusted because MFC would then be equal to the wage rate divided by marginal costs. Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram.

The demand for labour of this firm can be summed with the demand for labour of all other firms in the economy to obtain the aggregate demand for labour. Likewise, the supply curves of all the individual workers (mentioned above) can be summed to obtain the aggregate supply of labour. These supply and demand curves can be analysed in the same way as any other industry demand and supply curves to determine equilibrium wage and employment levels.

Wage differences exist, particularly in mixed and fully/partly flexible labour markets. For example, the wages of a doctor and a port cleaner, both employed by the NHS, differ greatly. There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner. In addition, the barriers to becoming a doctor are far greater than that of becoming a port cleaner. To become a doctor takes a lot of education and training which is costly, and only those who excel in academia can succeed in becoming doctors. The port cleaner however requires relatively less training. The supply of doctors is therefore significantly less elastic than that of port cleaners. Demand is also inelastic as there is a high demand for doctors and medical care is a necessity, so the NHS will pay higher wage rates to attract the profession.

Some labour markets have a single employer and thus do not satisfy the perfect competition assumption of the neoclassical model above. The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model.

In many real-life situations the assumption of perfect information is unrealistic. An employer does not necessarily know how hard workers are working or how productive they are. This provides an incentive for workers to shirk from providing their full effort, called moral hazard. Since it is difficult for the employer to identify the hard-working and the shirking employees, there is no incentive to work hard and productivity falls overall, leading to the hiring of more workers and a lower unemployment rate.

One solution that is used to avoid moral hazard is stock options that grant employees the chance to benefit directly from a firm's success. However, this solution has attracted criticism as executives with large stock-option packages have been suspected of acting to over-inflate share values to the detriment of the long-run welfare of the firm. Another solution, foreshadowed by the rise of temporary workers in Japan and the firing of many of these workers in response to the financial crisis of 2008, is more flexible job- contracts and -terms that encourage employees to work less than full-time by partially compensating for the loss of hours, relying on workers to adapt their working time in response to job requirements and economic conditions instead of the employer trying to determine how much work is needed to complete a given task and overestimating.

Another aspect of uncertainty results from the firm's imperfect knowledge about worker ability. If a firm is unsure about a worker's ability, it pays a wage assuming that the worker's ability is the average of similar workers. This wage under compensates high-ability workers which may drive them away from the labour market as well as at the same time attracting low-ability workers. Such a phenomenon, called adverse selection, can sometimes lead to market collapse.

One way to combat adverse selection, firms will try to use signalling, pioneered by Michael Spence, whereby employers could use various characteristics of applicants differentiate between high-ability or low-ability workers. One common signal used is education, whereby employers assume that high-ability workers will have higher levels of education. Employers can then compensate high-ability workers with higher wages. However, signalling does not always work, and it may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true.

One of the major research achievements of the 1990-2010 period was the development of a framework with dynamic search, matching, and bargaining.

At the micro level, one sub-discipline eliciting increased attention in recent decades is analysis of internal labour markets, that is, "within" firms (or other organisations), studied in personnel economics from the perspective of personnel management. By contrast, external labour markets "imply that workers move somewhat fluidly between firms and wages are determined by some aggregate process where firms do not have significant discretion over wage setting." The focus is on "how firms establish, maintain, and end employment relationships and on how firms provide incentives to employees," including models and empirical work on incentive systems and as constrained by economic efficiency and risk/incentive tradeoffs relating to personnel compensation.

Inequality and discrimination in the workplace can have many affects on workers.

In the context of labour economics, inequality is usually referring the to unequal distribution of earning between households. Inequality is commonly measured by economists using the Gini coefficient. This coefficient does not have a concrete meaning, but is more used as a way to compare inequality across regions. The higher the Gini coefficient is calculated to be the larger inequality exists in a region. Over time, inequality has, on average, been increasing. This is due to numerous factors including labour supply and demand shifts as well as institutional changes in the labour market. On the shifts in labour supply and demand, factors include demand for skilled workers going up more than the supply of skilled workers and relative to unskilled workers as well as technological changes that increase productivity; all of these things cause wages to go up for skilled labor while unskilled worker wages stay the same or decline. As for the institutional changes, a decrease in union power and a declining real minimum wage, which both reduce unskilled workers wages, and tax cuts for the wealthy all increase the inequality gap between groups of earners.

As for discrimination, it is the difference in pay that can be attributed to the demographic differences between people, such as gender, race, ethnicity, religion, sexual orientation, etc, even though these factors do not affect the productivity of the worker. Many regions and countries have enacted government policies to combat discrimination, including discrimination in the workplace. Discrimination can be modeled and measured in numerous ways. The oaxaca decomposition is a common method used to calculate the amount of discrimination that exists when wages differ between groups of people. This decomposition aims to calculate the difference in wages that occurs because of differences in skills versus the returns to those skills. A way of modeling discrimination in the workplace when dealing with wages are Gary Becker's taste models. Using taste models, employer discrimination can be thought of as the employer not hiring the minority worker because their perceived cost of hiring that worker is higher than that of the cost of hiring a non-minority worker, which causes less hiring of the minority. Another taste model is for employee discrimination, which does not cause a decline in the hiring of minorities, but instead causes a more segregated workforce because the prejudiced worker feels that they should be paid more to work next to the worker they are prejudiced against or that they are not paid an equal amount as the worker they are prejudiced against. One more taste model involves customer discrimination, whereby the employers themselves are not prejudiced but believe that their customers might be, so therefore the employer is less likely to hire the minority worker if they are going to interact with customers that are prejudiced. There are many other taste models other than these that Gary Becker has made to explain discrimination that causes differences in hiring in wages in the labour market.

Many sociologists, political economists, and heterodox economists claim that labour economics tends to lose sight of the complexity of individual employment decisions. These decisions, particularly on the supply side, are often loaded with considerable emotional baggage and a purely numerical analysis can miss important dimensions of the process, such as social benefits of a high income or wage rate regardless of the marginal utility from increased consumption or specific economic goals.

From the perspective of mainstream economics, neoclassical models are not meant to serve as a full description of the psychological and subjective factors that go into a given individual's employment relations, but as a useful approximation of human behaviour in the aggregate, which can be fleshed out further by the use of concepts such as information asymmetry, transaction costs, contract theory etc.

Also missing from most labour market analyses is the role of unpaid labour such as unpaid internships where workers with little or no experience are allowed to work a job without pay so that they can gain experience in a particular profession. Even though this type of labour is unpaid it can nevertheless play an important part in society if not abused by employers. The most dramatic example is child raising. However, over the past 25 years an increasing literature, usually designated as the economics of the family, has sought to study within household decision making, including joint labour supply, fertility, child raising, as well as other areas of what is generally referred to as home production.

The labour market, as institutionalised under today's market economic systems, has been criticised, especially by both mainstream socialists and anarcho-syndicalists, who utilise the term wage slavery as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.

According to Noam Chomsky, analysis of the psychological implications of wage slavery goes back to the Enlightenment era. In his 1791 book "On the Limits of State Action", classical liberal thinker Wilhelm von Humboldt explained how "whatever does not spring from a man's free choice, or is only the result of instruction and guidance, does not enter into his very nature; he does not perform it with truly human energies, but merely with mechanical exactness" and so when the labourer works under external control, "we may admire what he does, but we despise what he is." Both the Milgram and Stanford experiments have been found useful in the psychological study of wage-based workplace relations.

The American philosopher John Dewey posited that until "industrial feudalism" is replaced by "industrial democracy," politics will be "the shadow cast on society by big business". Thomas Ferguson has postulated in his investment theory of party competition that the undemocratic nature of economic institutions under capitalism causes elections to become occasions when blocs of investors coalesce and compete to control the state.

As per anthropologist David Graeber, the earliest wage labour contracts we know about were in fact contracts for the rental of chattel slaves (usually the owner would receive a share of the money, and the slave, another, with which to maintain his or her living expenses.) Such arrangements, according to Graeber, were quite common in New World slavery as well, whether in the United States or Brazil. C. L. R. James argued that most of the techniques of human organisation employed on factory workers during the industrial revolution were first developed on slave plantations.

Additionally, Marxists posit that labour-as-commodity, which is how they regard wage labour, provides an absolutely fundamental point of attack against capitalism. "It can be persuasively argued," noted one concerned philosopher, "that the conception of the worker's labour as a commodity confirms Marx's stigmatisation of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it."




</doc>
<doc id="18179" url="https://en.wikipedia.org/wiki?curid=18179" title="Lammas">
Lammas

Lammas Day (Anglo-Saxon "hlaf-mas", "loaf-mass"), is a holiday celebrated in some English-speaking countries in the Northern Hemisphere on 1 August. It is a festival to mark the annual wheat harvest, and is the first harvest festival of the year. On this day it was customary to bring to church a loaf made from the new crop, which began to be harvested at Lammastide, which falls at the halfway point between the summer solstice and autumn September equinox.

The loaf was blessed, and in Anglo-Saxon England it might be employed afterwards in protective rituals: a book of Anglo-Saxon charms directed that the Lammas bread be broken into four bits, which were to be placed at the four corners of the barn, to protect the garnered grain.

In many parts of England, tenants were bound to present freshly harvested wheat to their landlords on or before the first day of August. In the "Anglo-Saxon Chronicle", where it is referred to regularly, it is called "the feast of first fruits". The blessing of first fruits was performed annually in both the Eastern and Western Churches on the first or the sixth of August (the latter being the feast of the Transfiguration of Christ).

Lammas has coincided with the feast of St. Peter in Chains, commemorating St. Peter's miraculous deliverance from prison, but in the liturgical reform of 1969, the feast of St. Alphonsus Liguori was transferred to this day, the day of St. Alphonsus' death.

In medieval times the feast was sometimes known in England and Scotland as the "Gule of August", but the meaning of "gule" is unclear. Ronald Hutton suggests following the 18th-century Welsh clergyman antiquary John Pettingall that it is merely an Anglicisation of ', the Welsh name of the "feast of August". The "OED" and most etymological dictionaries give it a more circuitous origin similar to "gullet"; from Old French ', a diminutive of ', "throat, neck," from Latin ' "throat".

Several antiquaries beginning with John Brady offered a back-construction to its being originally known as "Lamb-mass", under the undocumented supposition that tenants of the Cathedral of York, dedicated to St. Peter ad Vincula, of which this is the feast, would have been required to bring a live lamb to the church, or, with John Skinner, "because Lambs then grew out of season." This is a folk etymology, of which "OED" notes that it was "subsequently felt as if from ".

For many villeins, the wheat must have run low in the days before Lammas, and the new harvest began a season of plenty, of hard work and company in the fields, reaping in teams. Thus there was a spirit of celebratory play.

In the medieval agricultural year, Lammas also marked the end of the hay harvest that had begun after Midsummer. At the end of hay-making a sheep would be loosed in the meadow among the mowers, for him to keep who could catch it.

In Shakespeare's "Romeo and Juliet" (1.3.19) it is observed of Juliet, "Come Lammas Eve at night shall she [Juliet] be fourteen." Since Juliet was born Lammas eve, she came before the harvest festival, which is significant since her life ended before she could reap what she had sown and enjoy the bounty of the harvest, in this case full consummation and enjoyment of her love with Romeo.

Another well-known cultural reference is the opening of "The Battle of Otterburn": "It fell about the Lammas tide when the muir-men win their hay".

William Hone speaks in "The Every-Day Book" (1838) of a later festive Lammas day sport common among Scottish farmers near Edinburgh. He says that they "build towers...leaving a hole for a flag-pole in the centre so that they may raise their colours." When the flags over the many peat-constructed towers were raised, farmers would go to others' towers and attempt to "level them to the ground." A successful attempt would bring great praise. However, people were allowed to defend their towers, and so everyone was provided with a "tooting-horn" to alert nearby country folk of the impending attack and the battle would turn into a "brawl." According to Hone, more than four people had died at this festival and many more were injured. At the day's end, races were held, with prizes given to the townspeople.

Lughnasadh or Lammas is also the name used for one of the eight sabbats in the Neopagan Wheel of the Year. It is the first of the three autumn harvest festivals, the other two being the autumn equinox (also called Mabon) and Samhain. In the Northern Hemisphere it takes place around 1 August, while in the Southern Hemisphere it is celebrated around 1 February.

Lammas is one of the Scottish quarter days.

"Lammas leaves" or "Lammas growth" refers to a second crop of leaves produced in high summer by some species of trees in temperate countries to replace those lost to insect damage. They often differ slightly in shape, texture and/or hairiness from the earlier leaves.

A low-impact development project at Tir y Gafel, Glandwr, Pembrokeshire, Lammas Ecovillage, is a collective initiative for nine self-built homes. It was the first such project to obtain planning permission based on a predecessor of what is now the sixth national planning guidance for sustainable rural communities originally proposed by the One Planet Council.

The "Doctor Who" serial "The Image of the Fendahl" takes place on Lammas Eve.

In the "Inspector Morse" episode "Day of the Devil", Lammas Day is presented as a Satanic (un)holy day, "the Devil's day".

Katherine Kurtz's alternate World War II fantasy "history" takes its title, "Lammas Night", from pagan tradition surrounding the first of August and the Divine Right of Kings.




</doc>
<doc id="18182" url="https://en.wikipedia.org/wiki?curid=18182" title="Longmeadow, Massachusetts">
Longmeadow, Massachusetts

Longmeadow is a town in Hampden County, Massachusetts, in the United States. The population was 15,784 at the 2010 census.

Longmeadow was first settled in 1644, and officially incorporated October 17, 1783. The town was originally farmland within the limits of Springfield. It remained relatively pastoral until the street railway was built , when the population tripled over a fifteen-year period. After Interstate 91 was built in the wetlands on the west side of town, population tripled again between 1960 and 1975.

During the 19th and early 20th centuries, Longmeadow was best known as the site from which Longmeadow brownstone was mined. Several famous American buildings, including Princeton University's Neo-Gothic library, are made of Longmeadow brownstone. In 1894, the more populous and industrialized "East Village" portion of the town containing the brownstone quarries split off to become East Longmeadow.

Designed by famed golf course architect Donald Ross in 1922, the Longmeadow Country Club was the proving ground for golf equipment designed and manufactured by the Spalding Co. of Chicopee. Bobby Jones, a consultant for Spalding, was a member in standing at LCC and made a number of his instructional films at LCC in the 1930s.

Longmeadow is located in the western part of the state, just south of the city of Springfield, and is bordered on the west by the Connecticut River and Agawam, to the east by East Longmeadow, and to the south by Enfield, Connecticut. It extends approximately north to south and east to west. It is approximately north of Hartford.

More than 30% of the town is permanent open space. Conservation areas on the west side of town include more than bordering the Connecticut River. The area supports a wide range of wildlife including deer, beaver, wild turkeys, foxes, and eagles. Springfield's Forest Park, which at is the largest city park in New England, forms the northern border of the town. The private Twin Hills and public Franconia golf courses, plus town athletic fields and conservation land, cover nearly 2/3 of the eastern border of the town. Two large public parks, the Longmeadow Country Club, and three conservation areas account for the bulk of the remaining formal open space. Almost 20% of the houses in town are in proximity to a "dingle", a tree-lined steep-sided sandy ravine with a wetland at the bottom that provides a privacy barrier between yards.

Longmeadow has a town common, commonly referred to as "The Green", located along U.S. Route 5 on the west side of town. It is about long. Roughly 100 houses date back before 1900, most of which are in the historic district, are located near the town green. Longmeadow’s Town Green is a historic district on the National Register of Historic Places, and it is surrounded by a number of buildings dating back to the 18th and 19th centuries. Longmeadow is unique as the town green has maintained its residential purpose and has resisted commercial pressure. The current function as listed by the National Register of Historic Places is domestic and landscape. The current sub-function as listed by the National Register of Historic Places is park and single dwelling. Houses along the photogenic main street (Longmeadow Street) are set back farther than in most towns of similar residential density. The town has three recently remodeled elementary schools, two secondary schools, and one high school. The commercial center of town is an area called "The Longmeadow Shops", including restaurants and clothing stores.

According to the United States Census Bureau, the town has a total area of , of which are land and , or 5.34%, are water.

As of the census of 2000, there were 15,633 people, 5,734 households, and 4,432 families residing in the town. The population density was . There were 5,879 housing units at an average density of . The racial makeup of the town was 95.42% White, 0.69% African American, 0.05% Native American, 2.90% Asian, 0.06% Pacific Islander, 0.26% from other races, and 0.62% from two or more races. Hispanic or Latino of any race were 1.09% of the population.

There were 5,734 households out of which 37.1% had children under the age of 18 living with them, 69.1% were married couples living together, 6.4% had a female householder with no husband present, and 22.7% were non-families. 20.4% of all households were made up of individuals and 14.0% had someone living alone who was 65 years of age or older. The average household size was 2.66 and the average family size was 3.09.

In the town, the population was spread out with 26.8% under the age of 18, 4.6% from 18 to 24, 22.0% from 25 to 44, 28.7% from 45 to 64, and 17.8% who were 65 years of age or older. The median age was 43 years. For every 100 females, there were 87.7 males. For every 100 females age 18 and over, there were 82.0 males.

The median income for a household in the town was $109,586, and the median income for a family was $115,578. Males had a median income of $68,238 versus $40,890 for females. The per capita income for the town was $48,949. About 1.0% of families and 2.1% of the population were below the poverty line, including 0.3% of those under age 18 and 8.3% of those age 65 or over.

The town is chartered as an Open Town Meeting form of government. The town government also consists of a Select Board with five members, elected by the town. The public school system is governed by the School Committee. The School Committee is made up of seven voting members elected by the town, the superintendent of schools, two assistant-superintendents, a secretary, and a student representative.

The Longmeadow public school system operates six schools. Blueberry Hill School, Center School, and Wolf Swamp Road School are K−5 elementary schools. Williams Middle School and Glenbrook Middle School serve grades 6–8. Longmeadow High School serves all students in the town between grades 9 and 12. The town's elementary schools have been recently rebuilt, statements of interest for improvements to the two middle schools and Longmeadow High School were filed with the Massachusetts School Building Authority in 2007. In 2010, the voters of Longmeadow approved a 2.5% budget override to support the construction of a new $78 million high school. The town received an estimated $34 million in state funds to be used towards the new construction The new High School was completed and opened to students on February 26, 2013. After students and faculty had moved into the new school, the demolition of the old school was begun. The demolition was completed by June 2013. The school had its grand opening in September 2013 with both the brand new school and renovated business & administration wing open.

Longmeadow also hosts two private parochial schools, the Lubavitcher Yeshiva Academy (LYA) and St. Mary's Academy. LYA was established in 1946 in response to the Greater Springfield Jewish community's need for a quality Jewish day school. In 1999, LYA became the first Jewish day school to be accredited by the New England Association of Schools and Colleges (NEASC). The more than 90 students that the school serves each year from across the spectrum of Jewish life includes orthodox, conservative, reform and unaffiliated families. St. Mary's School, located behind St. Mary's Church, serves Catholic students grades Pre-K through Grade 8.

Approximately 50% of the students at Longmeadow High School participate in the music program. The choruses have won gold medals at the MICCA competition. The jazz ensemble has won numerous gold medals as well, but no longer competes. The wind ensemble and symphony orchestra have had the honor of performing in Indianapolis, Boston (Boston Symphony Hall), and New York (Carnegie Hall). In 2010, Longmeadow was awarded The American Prize in Orchestral Performance. The music program's crowning achievement has been receiving three national Grammy Awards based on the high level of excellence maintained throughout all groups in the music program.

Longmeadow also contains the 46-acre primary campus for Bay Path University, a private undergraduate and graduate institution.

Thomas Herrala - Head Coach of nationally ranked New Trier Township High School Lacrosse in Winnekta, IL.(7 state titles as head coach; 12 state titles overall; 200 wins as head coach)



</doc>
<doc id="18183" url="https://en.wikipedia.org/wiki?curid=18183" title="Body relative direction">
Body relative direction

Body relative directions (also known as egocentric coordinates) are geometrical orientations relative to a body such as a human person's. 
The most common ones are: left and right; forward(s) and backward(s); up and down.
They form three pairs of orthogonal axes.

Since definitions of left and right based on the geometry of the natural environment are unwieldy, in practice, the meaning of relative direction words is conveyed through tradition, acculturation, education, and direct reference. One common definition of up and down uses gravity and the planet Earth as a frame of reference. Since there is a very noticeable force of gravity acting between the Earth and any other nearby object, down is defined as that direction which an object moves in reference to the Earth when the object is allowed to fall freely. Up is then defined as the opposite direction of down. Another common definition uses a human body, standing upright, as a frame of reference. In that case, up is defined as the direction from feet to head, perpendicular to the surface of the Earth. In most cases, up is a directionally oriented position generally opposite to that of the pull of gravity.
In situations where a common frame of reference is needed, it is most common to use an egocentric view. A simple example is road signage. Another example is stage blocking, where "stage left" "stage right" "stage up" and "stage down" are, by convention, defined from the actor's point of view, but up and down stage do not follow gravitational conventions of up and down. An example of a non-egocentric view is page layout, where the relative terms "upper half" "left margin," etc. are defined in terms of the observer but employed in reverse for a type compositor, returning to an egocentric view. In medicine and science, where precise definitions are crucial, relative directions (left and right) are the sides of the organism, not those of the observer. The same is true in heraldry, where left and right in a coat of arms is treated as if the shield were being held by the armiger. To avoid confusion, Latin terminology is employed: "dexter" and "sinister" for right and left. Proper right and proper left are terms mainly used to describe images, and overcome the potential confusion that a figure's right or "proper right" hand is on the left hand as the viewer of a frontal image sees it.

Forward and backward may be defined by referring to an object's or person's motion. Forward is defined as the direction in which the object is moving. Backward is then defined as the opposite direction to forward. Alternatively, 'forward' may be the direction pointed by the observer's nose, defining 'backward' as the direction from the nose to the sagittal border in the observer's skull. With respect to a ship 'forward' would indicate the relative position of any object lying in the direction the ship is pointing. For symmetrical objects, it is also necessary to define forward and backward in terms of expected direction. Many mass transit trains are built symmetrically with paired control booths, and definitions of forward, backward, left, and right are temporary.

Given significant distance from the magnetic poles, one can figure which hand is which using a magnetic compass and the sun. Facing the sun, before noon, the north pointer of the compass points to the "left" hand. After noon, it points to the "right".

The right-hand rule is one common way to relate the three principal directions. For many years a fundamental question in physics was whether a left-hand rule would be equivalent. Many natural structures, including human bodies, follow a certain "handedness", but it was widely assumed that nature did not distinguish the two possibilities. This changed with the discovery of parity violations in particle physics. If a sample of cobalt-60 atoms is magnetized so that they spin counterclockwise around some axis, the beta radiation resulting from their nuclear decay will be preferentially directed opposite that axis. Since counter-clockwise may be defined in terms of up, forward, and right, this experiment unambiguously differentiates left from right using only natural elements: if they were reversed, or the atoms spun clockwise, the radiation would follow the spin axis instead of being opposite to it.

Bow, stern, port, and starboard, fore and aft are nautical terms that convey an impersonal relative direction in the context of the moving frame of persons aboard a ship. The need for impersonal terms is most clearly seen in a rowing shell where the majority of the crew face aft ("backwards"), hence the oars to their right are actually on the port side of the boat. Rowers eschew the terms left, right, port and starboard in favor of stroke-side and bow-side. The usage derives from the tradition of having the stroke (the rower closest to the stern of the boat) oar on the port side of the boat.

Most human cultures use relative directions for reference, but there are exceptions. Australian Aboriginal peoples like the Guugu Yimithirr, Kaiadilt and Thaayorre have no words denoting the egocentric directions in their language; instead, they exclusively refer to cardinal directions, even when describing small-scale spaces. For instance, if they wanted someone to move over on the car seat to make room, they might say "move a bit to the east". To tell someone where exactly they left something in their house, they might say, "I left it on the southern edge of the western table." Or they might warn a person to "look out for that big ant just north of your foot". Other peoples "from Polynesia to Mexico and from Namibia to Bali" similarly have predominantly "geographic languages". American Sign Language makes heavy use of geographical direction through absolute orientation.

Left-right discrimination (LRD) refers to a person's ability to differentiate between left and right. The inability to accurately differentiate between left and right is known as left-right confusion (LRC). According to research performed by John R. Clarke of Drexel University, LRC affects approximately 15% of the population. People who suffer from LRC can typically perform daily navigational tasks, such as driving according to road signs or following a map, but may have difficulty performing actions that require a precise understanding of directional commands, such as ballroom dancing.

Data regarding LRC prevalence is primarily based on behavioral studies, self-assessments, and surveys. Gormley and Brydges found that in a group of 800 adults, 17% of women and 9% of men reported difficulty differentiating between left and right. Such studies suggest that women are more prone to LRC than men, with women reporting higher rates of LRC in both accuracy and speed of response.

The Bergen Left-Right Discrimination (BLRD) test is designed to measure individual performance in LRD accuracy. However, this test has been criticized for incorporating tasks that require the use of additional strategies, such as mental rotation (MR). Because men have been shown to consistently outperform women in MR tasks, tests involving the use of this particular strategy may present alternative cognitive demands and lead to inaccurate assessment of LRD performance. An extended version of the BLRD test was designed to allow for differential evaluation of LRD and MR abilities, in which subtests were created with either high or low demands on mental rotation. Results from these studies did not find sex differences in LRD performance when mental rotation demands were low. Another study found that sex differences in left-right discrimination existed in terms of self-reported difficulty, but not in actual tested ability.

Alternatively, studies focused on LRD as a phenomenon distinct from MR concluded that there are sex differences present in LRD. Scientists controlled for MR demands, potential menstrual cycle effects, and other hormone fluctuations, and determined that the neurocognitive mechanisms that support LRD are different for men and women. This research revealed that inferior parietal and right angular gyrus activation were correlated with LRD performance in both men and women. Women also demonstrated increased prefrontal activation, but did not exhibit greater bilateral activation. Additionally, no correlation was found between LRD accuracy and brain activation, or between brain activation and reaction time, for either sex. These results indicate that there are sex differences in the neurocognitive mechanisms underlying LRD performance; however, findings did not suggest that women are more prone to LRC than men.

Humans are constantly making decisions about spatial relations; however, some spatial relations, such as left-right, are commonly confused, while other spatial relations, such as up-down, above-below, and front-back, are seldom, if ever, mistaken. The ability to categorize and compartmentalize space is an essential tool for navigating this 3D world; an ability shown to develop in early infancy. Infant ability to visually match above-below and left-right relations appears to diminish in early toddlerhood, as language acquisition may complicate verbal labeling. Children learn to verbally discriminate between above-below relations around the age of three, and learn left-right linguistic labels between the ages of six and seven; however, these classifications may only exist in the linguistic context. In other words, children may learn the terms for left and right without having developed a cognitive representation to allow for the accurate application of such spatial distinctions.

Research seeks to explain the neural activity associated with left-right discrimination, attempting to identify differences in the encoding, consolidation, and retrieval of left-right versus above-below relations. One study found that neural activity patterns for left-right and above-below distinctions are represented differently in the brain, leading to the theory that these spatial judgements are supported by separate cognitive mechanisms. Experiments used magnetoencephalography (MEG) to record neural activity during a computerized nonverbal task, examining left-right and above-below differences in encoding and working memory. Results showed differences in neural activity patterns in the right cerebellum, right superior temporal gyrus, and left temporoparietal junction during the encoding phase, and indicated differential neural activity in the inferior parietal, right superior temporal, and right cerebellum regions in the working memory tests.

Although some individuals may struggle with LRD more than others, discriminating between left and right in the face of distraction has been shown to impair even the most proficient individual’s ability to accurately differentiate between the two. This issue is of particular importance to medical students, clinicians and health care professionals, where distraction in the workplace and LRD inaccuracy can lead to severe consequences, including laterality errors and wrong-side surgeries. Laterality errors in the field of aviation may also lead to equally devastating results, for example, causing a major airline crash.

Distraction has a significant impact on LRD accuracy, and the type of distraction can alter the magnitude of these effects. For example, cognitive distraction, which occurs when an individual is not directly focused on the task at hand, has a more profound effect on LRD performance than auditory distraction, such as the presence of continuous ambient noise. Additionally, in the field of health care, it has been noted that mental rotation is often involved in making left-right distinctions, such as when a medical practitioner is facing their patient and must adjust for the opposite left-right relations.



</doc>
<doc id="18184" url="https://en.wikipedia.org/wiki?curid=18184" title="Lizard">
Lizard

Lizards are a widespread group of squamate reptiles, with over 6,000 species, ranging across all continents except Antarctica, as well as most oceanic island chains. The group is paraphyletic as it excludes the snakes and Amphisbaenia; some lizards are more closely related to these two excluded groups than they are to other lizards. Lizards range in size from chameleons and geckos a few centimeters long to the 3 meter long Komodo dragon.

Most lizards are quadrupedal, running with a strong side-to-side motion. Others are legless, and have long snake-like bodies. Some such as the forest-dwelling "Draco" lizards are able to glide. They are often territorial, the males fighting off other males and signalling, often with brightly colours, to attract mates and to intimidate rivals. Lizards are mainly carnivorous, often being sit-and-wait predators; many smaller species eat insects, while the Komodo eats mammals as big as water buffalo.

Lizards make use of a variety of antipredator adaptations, including venom, camouflage, reflex bleeding, and the ability to sacrifice and regrow their tails.

The adult length of species within the suborder ranges from a few centimeters for chameleons such as "Brookesia micra" and geckos such as "Sphaerodactylus ariasae" to nearly in the case of the largest living varanid lizard, the Komodo dragon. Most lizards are fairly small animals.

Lizards typically have rounded torsos, elevated heads on short necks, four limbs and long tails. Some are legless, including snakes. Lizards and snakes share a movable quadrate bone, distinguishing them from the rhynchocephalians, which have more rigid diapsid skulls . Some lizards such as chameleons have prehensile tails, assisting them in climbing among vegetation.

As in other reptiles, the skin of lizards is covered in overlapping scales made of keratin. This provides protection from the environment and reduces water loss through evaporation. This adaptation enables lizards to thrive in some of the driest deserts on earth. The skin is tough and leathery, and is shed (sloughed) as the animal grows. Unlike snakes which shed the skin in a single piece, lizards slough their skin in several pieces. The scales may be modified into spines for display or protection, and some species have bone osteoderms underneath the scales.

The dentitions of lizards reflect their wide range of diets, including carnivorous, insectivorous, omnivorous, herbivorous, nectivorous, and molluscivorous. Species typically have uniform teeth suited to their diet, but several species have variable teeth, such as cutting teeth in the front of the jaws and crushing teeth in the rear. Most species are pleurodont, though agamids and chameleons are acrodont.

The tongue can be extended outside the mouth, and is often long. In the beaded lizards, whiptails and monitor lizards, the tongue is forked and used mainly or exclusively to sense the environment, continually flicking out to sample the environment, and back to transfer molecules to the vomeronasal organ responsible for chemosensation, analogous to but different from smell or taste. In geckos, the tongue is used to lick the eyes clean: they have no eyelids. Chameleons have very long sticky tongues which can be extended rapidly to catch their insect prey.

Three lineages, the geckos, anoles, and chameleons, have modified the scales under their toes to form adhesive pads, highly prominent in the first two groups. The pads are composed of millions of tiny setae (hair-like structures) which fit closely to the substrate to adhere using van der Waals forces; no liquid adhesive is needed. In addition, the toes of chameleons are divided into two opposed groups on each foot (zygodactyly), enabling them to perch on branches as birds do.

Aside from legless lizards, most lizards are quadrupedal and move using gaits with alternating movement of the right and left limbs with substantial body bending. This body bending prevents significant respiration during movement, limiting their endurance, in a mechanism called Carrier's constraint. Several species can run bipedally, and a few can prop themselves up on their hindlimbs and tail while stationary. Several small species such as those in the genus "Draco" can glide: some can attain a distance of , losing in height. Some species, like geckos and chameleons, adhere to vertical surfaces including glass and ceilings. Some species, like the common basilisk, can run across water.

Lizards make use of their senses of sight, touch, olfaction and hearing like other vertebrates. The balance of these varies with the habitat of different species; for instance, skinks that live largely covered by loose soil rely heavily on olfaction and touch, while geckos depend largely on acute vision for their ability to hunt and to evaluate the distance to their prey before striking. Monitor lizards have acute vision, hearing, and olfactory senses. Some lizards make unusual use of their sense organs: chameleons can steer their eyes in different directions, sometimes providing non-overlapping fields of view, such as forwards and backwards at once. Lizards lack external ears, having instead a circular opening in which the tympanic membrane (eardrum) can be seen. Many species rely on hearing for early warning of predators, and flee at the slightest sound.

As in snakes and many mammals, all lizards have a specialised olfactory system, the vomeronasal organ, used to detect pheromones. Monitor lizards transfer scent from the tip of their tongue to the organ; the tongue is used only for this information-gathering purpose, and is not involved in manipulating food.

Some lizards, particularly iguanas, have retained a photosensory organ on the top of their heads called the parietal eye, a basal ("primitive") feature also present in the tuatara. This "eye" has only a rudimentary retina and lens and cannot form images, but is sensitive to changes in light and dark and can detect movement. This helps them detect predators stalking it from above.

Until 2006 it was thought that among lizards, only the Gila monster and the Mexican beaded lizard were venomous. However, several species of monitor lizards, including the Komodo dragon, produce powerful venom in their oral glands. Lace monitor venom, for instance, causes swift loss of consciousness and extensive bleeding through its pharmacological effects, both lowering blood pressure and preventing blood clotting. Nine classes of toxin known from snakes are produced by lizards. The range of actions provides the potential for new medicinal drugs based on lizard venom proteins.

Genes associated with venom toxins have been found in the salivary glands on a wide range of lizards, including species traditionally thought of as non-venomous, such as iguanas and bearded dragons. This suggests that these genes evolved in the common ancestor of lizards and snakes, some 200 million years ago (forming a single clade, the Toxicofera). However, most of these putative venom genes were "housekeeping genes" found in all cells and tissues, including skin and cloacal scent glands. The genes in question may thus be evolutionary precursors of venom genes.

Recent studies (2013 and 2014) on the lung anatomy of the savannah monitor and green iguana found them to have a unidirectional airflow system, which involves the air moving in a loop through the lungs when breathing. This was previously thought to only exist in the archosaurs (crocodilians and birds). This may be evidence that unidirectional airflow is an ancestral trait in diapsids.

As with all amniotes, lizards rely on internal fertilisation and copulation involves the male inserting one of his hemipenes into the female's cloaca. The majority of species are oviparous (egg laying). The female deposits the eggs in a protective structure like a nest or crevice or simply on the ground. Depending on the species, clutch size can vary from 4–5 percent of the females body weight to 40–50 percent and clutches range from one or a few large eggs to dozens of small ones. 

In most lizards, the eggs have leathery shells to allow for the exchange of water, although more arid-living species have calcified shells to retain water. Inside the eggs, the embryos use nutrients from the yolk. Parental care is uncommon and the female usually abandons the eggs after laying them. Brooding and protection of eggs does occur in some species. The female prairie skink uses respiratory water loss to maintain the humidity of the eggs which facilitates embryonic development. In lace monitors, the young hatch close to 300 days, and the female returns to help them escape the termite mound were the eggs were laid.

Around 20 percent of lizard species reproduce via viviparity (live birth). This is particularly common in Anguimorphs. Viviparous species give birth to relatively developed young which look like miniature adults. Embryos are nourished via a placenta-like structure. A minority of lizards have parthenogenesis (reproduction from unfertilised eggs). These species consist of all females who reproduce asexually with no need for males. This is known in occur in various species of whiptail lizards. Parthenogenesis was also recorded in species that normally reproduce sexually. A captive female Komodo dragon produced a clutch of eggs, despite being separated from males for over two years.

Sex determination in lizards can be temperature-dependent. The temperature of the eggs' micro-environment can determine the sex of the hatched young: low temperature incubation produces more females while higher temperatures produce more males. However, some lizards have sex chromosomes and both male heterogamety (XY and XXY) and female heterogamety (ZW) occur.

The majority of lizard species are active during the day, though some are active at night, notably geckos. As ectotherms, lizards have a limited ability to regulate their body temperature, and must seek out and bask in sunlight to gain enough heat to become fully active.

Most social interactions among lizards are between breeding individuals. Territoriality is common and is correlated with species that use sit-and-wait hunting strategies. Males establish and maintain territories that contain resources which attract females and which they defend from other males. Important resources include basking, feeding, and nesting sites as well as refuges from predators. The habitat of a species affects the structure of territories, for example, rock lizards have territories atop rocky outcrops. Some species may aggregate in groups, enhancing vigilance and lessening the risk of predation for individuals, particularly for juveniles. Agonistic behaviour typically occurs between sexually mature males over territory or mates and may involve displays, posturing, chasing, grappling and biting.

Lizards signal both to attract mates and to intimidate rivals. Visual displays include body postures and inflation, push-ups, bright colours, mouth gapings and tail waggings. Male anoles and iguanas have dewlaps or skin flaps which come in various sizes, colours and patterns and the expansion of the dewlap as well as head-bobs and body movements add to the visual signals. Some species have deep blue dewlaps and communicate with ultraviolet signals. Blue-tongued skinks will flash their tongues as a threat display. Chameleons are known to change their complex colour patterns when communicating, particularly during agonistic encounters. They tend to show brighter colours when displaying aggression and darker colours when they submit or "give up".

Several gecko species are brightly coloured; some species tilt their bodies to display their coloration. In certain species, brightly coloured males turn dull when not in the presence of rivals or females. While it is usually males that display, in some species females also use such communication. In the bronze anole, head-bobs are a common form of communication among females, the speed and frequency varying with age and territorial status. Chemical cues or pheromones are also important in communication. Males typically direct signals at rivals, while females direct them at potential mates. Lizards may be able to recognise individuals of the same species by their scent.

Acoustic communication is less common in lizards. Hissing, a typical reptilian sound, is mostly produced by larger species as part of a threat display, accompanying gaping jaws. Some groups, particularly geckos, snake-lizards, and some iguanids, can produce more complex sounds and vocal apparatuses have independently evolved in different groups. These sounds are used for courtship, territorial defense and in distress, and include clicks, squeaks, barks and growls. The mating call of the male tokay gecko is heard as "tokay-tokay!". Tactile communication involves individuals rubbing against each other, either in courtship or in aggression. Some chameleon species communicate with one another by vibrating the substrate that they are standing on, such as a tree branch or leaf.

Lizards are found worldwide, excluding the far north and Antarctica, and some islands. They can be found in elevations from sea level to . They prefer warmer, tropical climates but are adaptable and can live in all but the most extreme environments. Lizards also exploit a number of habitats; most primarily live on the ground, but others may live in rocks, on trees, underground and even in water. The marine iguana is adapted for life in the sea.

The majority of lizard species are predatory and the most common prey items are small, terrestrial invertebrates, particularly insects. Many species are sit-and-wait predators though others may be more active foragers. Chameleons prey on numerous insect species, such as beetles, grasshoppers and winged termites as well as spiders. They rely on persistence and ambush to capture these prey. An individual perches on a branch and stays perfectly still, with only its eyes moving. When an insect lands, the chameleon focuses its eyes on the target and slowly moves towards it before projecting its long sticky tongue which, when hauled back, brings the attach prey with it. Geckos feed on crickets, beetles, termites and moths.

Termites are an important part of the diets of some species of Autarchoglossa, since, as social insects, they can be found in large numbers in one spot. Ants may form a prominent part of the diet of some lizards, particularly among the lacertas. Horned lizards are also well known for specializing on ants. Due to their small size and indigestible chitin, ants must be consumed in large amounts, and ant-eating lizards have larger stomachs than even herbivorous ones. Species of skink and alligator lizards eat snails and their power jaws and molar-like teeth are adapted for breaking the shells.

Larger species, such as monitor lizards, can feed on larger prey including fish, frogs, birds, mammals and other reptiles. Prey may be swallowed whole and torn into smaller pieces. Both bird and reptile eggs may also be consumed as well. Gila monsters and beaded lizards climb trees to reach both the eggs and young of birds. Despite being venomous, these species rely on their strong jaws to kill prey. Mammalian prey typically consists of rodents and leporids; the Komodo dragon can kill prey as large as water buffalo. Dragons are prolific scavengers, and a single decaying carcass can attract several from away. A dragon is capable of consuming a carcass in 17 minutes.

Around 2 percent of lizard species, including many iguanids, are herbivores. Adults of these species eat plant parts like flowers, leaves, stems and fruit, while juveniles eat more insects. Plant parts can be hard to digest, and, as they get closer to adulthood, juvenile iguanas eat faeces from adults to acquire the microflora necessary for their transition to a plant-based diet. Perhaps the most herbivorous species is the marine iguana which dives to forage for algae, kelp and other marine plants. Some non-herbivorous species supplement their insect diet with fruit, which is easily digested.

Lizards have a variety of antipredator adaptations, including running and climbing, venom, camouflage, tail autotomy, and reflex bleeding.

Lizards exploit a variety of different camouflage methods. Many lizards are disruptively patterned. In some species, such as Aegean wall lizards, individuals vary in colour, and select rocks which best match their own colour to minimise the risk of being detected by predators. The Moorish gecko is able to change colour for camouflage: when a light-coloured gecko is placed on a dark surface, it darkens within an hour to match the environment. The chameleons in general use their ability to change their coloration for signalling rather than camouflage, but some species such as Smith's dwarf chameleon do use active colour change for camouflage purposes.
The flat-tail horned lizard's body is coloured like its desert background, and is flattened and fringed with white scales to minimise its shadow.

Many lizards, including geckos and skinks, are capable of shedding their tails (autotomy). The detached tail, sometimes brilliantly coloured, continues to writhe after detaching, distracting the predator's attention from the fleeing prey. Lizards partially regenerate their tails over a period of weeks. Some 326 genes are involved in regenerating lizard tails. The fish-scale gecko "Geckolepis megalepis " sheds patches of skin and scales if grabbed.

Many lizards attempt to escape from danger by running to a place of safety; for example, wall lizards can run up walls and hide in holes or cracks. Horned lizards adopt differing defences for specific predators. They may play dead to deceive a predator that has caught them; attempt to outrun the rattlesnake, which does not pursue prey; but stay still, relying on their cryptic coloration, for "Masticophis" whip snakes which can catch even swift prey. If caught, some species such as the greater short-horned lizard puff themselves up, making their bodies hard for a narrow-mouthed predator like a whip snake to swallow. Finally, horned lizards can squirt blood at cat and dog predators from a pouch beneath its eyes, to a distance of about ; the blood tastes foul to these attackers.

The earliest known fossil remains of a lizard belong to the iguanian species "Tikiguania estesi", found in the Tiki Formation of India, which dates to the Carnian stage of the Triassic period, about 220 million years ago. However, doubt has been raised over the age of "Tikiguania" because it is almost indistinguishable from modern agamid lizards. The "Tikiguania" remains may instead be late Tertiary or Quaternary in age, having been washed into much older Triassic sediments. Lizards are most closely related to the Rhynchocephalia, which appeared in the Late Triassic, so the earliest lizards probably appeared at that time. Mitochondrial phylogenetics suggest that the first lizards evolved in the late Permian. It had been thought on the basis of morphological data that iguanid lizards diverged from other squamates very early on, but molecular evidence contradicts this.

Mosasaurs probably evolved from an extinct group of aquatic lizards known as aigialosaurs in the Early Cretaceous. Dolichosauridae is a family of Late Cretaceous aquatic varanoid lizards closely related to the mosasaurs.

The position of the lizards and other Squamata among the reptiles was studied using fossil evidence by Rainer Schoch and Hans-Dieter Sues in 2015. Lizards form about 60% of the extant non-avian reptiles.
Both the snakes and the Amphisbaenia (worm lizards) are clades deep within the Squamata (the smallest clade that contains all the lizards), so "lizard" is paraphyletic.
The cladogram is based on genomic analysis by Wiens and colleagues in 2012 and 2016. Excluded taxa are shown in upper case on the cladogram.

In the 13th century, lizards were recognized in Europe as part of a broad category of "reptiles" that consisted of a miscellany of egg-laying creatures, including "snakes, various fantastic monsters, […], assorted amphibians, and worms", as recorded by Vincent of Beauvais in his "Mirror of Nature". The seventeenth century saw changes in this loose description. The name Sauria was coined by James Macartney (1802); it was the Latinisation of the French name "Sauriens", coined by Alexandre Brongniart (1800) for an order of reptiles in the classification proposed by the author, containing lizards and crocodilians, later discovered not to be each other's closest relatives. Later authors used the term "Sauria" in a more restricted sense, i.e. as a synonym of Lacertilia, a suborder of Squamata that includes all lizards but excludes snakes. This classification is rarely used today because Sauria so-defined is a paraphyletic group. It was defined as a clade by Jacques Gauthier, Arnold G. Kluge and Timothy Rowe (1988) as the group containing the most recent common ancestor of archosaurs and lepidosaurs (the groups containing crocodiles and lizards, as per Mcartney's original definition) and all its descendants. A different definition was formulated by Michael deBraga and Olivier Rieppel (1997), who defined Sauria as the clade containing the most recent common ancestor of Choristodera, Archosauromorpha, Lepidosauromorpha and all their descendants. However, these uses have not gained wide acceptance among specialists.
Suborder Lacertilia (Sauria) – (lizards) 

Lizards have frequently evolved convergently, with multiple groups independently developing similar morphology and ecological niches. "Anolis" ecomorphs have become a model system in evolutionary biology for studying convergence. Limbs have been lost or reduced independently over two dozen times across lizard evolution, including in the Anniellidae, Anguidae, Cordylidae, Dibamidae, Gymnophthalmidae, Pygopodidae, and Scincidae; snakes are just the most famous and species-rich group of Squamata to have followed this path.

Most lizard species are harmless to humans. Only the largest lizard species, the Komodo dragon, which reaches in length and weighs up to , has been known to stalk, attack, and, on occasion, kill humans. An eight-year-old Indonesian boy died from blood loss after an attack in 2007.

Numerous species of lizard are kept as pets, including bearded dragons, iguanas, anoles, and geckos (such as the popular leopard gecko).

Lizards appear in myths and folktales around the world. In Australian Aboriginal mythology, Tarrotarro, the lizard god, split the human race into male and female, and gave people the ability to express themselves in art. A lizard king named Mo'o features in Hawaii and other cultures in Polynesia. In the Amazon, the lizard is the king of beasts, while among the Bantu of Africa, the god Unkulunkulu sent a chameleon to tell humans they would live forever, but the chameleon was held up, and another lizard brought a different message, that the time of humanity was limited. A popular legend in Maharashtra tells the tale of how a common Indian monitor, with ropes attached, was used to scale the walls of the fort in the Battle of Sinhagad.

Green iguanas are eaten in Central America, where they are sometimes referred to as "chicken of the tree" after their habit of resting in trees and their supposedly chicken-like taste, while spiny-tailed lizards are eaten in Africa. In North Africa, "Uromastyx" species are considered "dhaab" or 'fish of the desert' and eaten by nomadic tribes.

Lizards such as the Gila monster produce toxins with medical applications. Gila toxin reduces plasma glucose; the substance is now synthesised for use in the anti-diabetes drug exenatide (Byetta). Another toxin from Gila monster saliva has been studied for use as an anti-Alzheimer's drug.

Lizards in many cultures share the symbolism of snakes, especially as an emblem of resurrection. This may have derived from their regular moulting. The motif of lizards on Christian candle holders probably alludes to the same symbolism.
According to Jack Tresidder, in Egypt and the Classical world they were beneficial emblems, linked with wisdom. In African, Aboriginal and Melanesian folklore they are linked to cultural heroes or ancestral figures.




</doc>
<doc id="18185" url="https://en.wikipedia.org/wiki?curid=18185" title="List of deists">
List of deists

This is a partial list of people who have been categorized as Deists, the belief in a deity based on natural religion only, or belief in religious truths discovered by people through a process of reasoning, independent of any revelation through scriptures or prophets. They have been selected for their influence on Deism, or for their fame in other areas.



</doc>
<doc id="18187" url="https://en.wikipedia.org/wiki?curid=18187" title="Book of Leviticus">
Book of Leviticus

The Book of Leviticus () is the third book of the Torah and of the Old Testament; scholars generally agree that it developed over a long period of time, reaching its present form during the Persian Period between 538-332 BCE. 

Most of its chapters (1–7, 11–27) consist of God's speeches to Moses, which God commands Moses to repeat to the Israelites. This takes place within the story of the Israelites' Exodus after they escaped Egypt and reached Mt. Sinai (Exodus 19:1). The Book of Exodus narrates how Moses led the Israelites in building the Tabernacle (Exodus 35–40) with God's instructions (Exodus 25–31). Then in Leviticus, God tells the Israelites and their priests how to make offerings in the Tabernacle and how to conduct themselves while camped around the holy tent sanctuary. Leviticus takes place during the month or month-and-a-half between the completion of the Tabernacle (Exodus 40:17) and the Israelites' departure from Sinai (Numbers 1:1, 10:11).

The instructions of Leviticus emphasize ritual, legal and moral practices rather than beliefs. Nevertheless, they reflect the world view of the creation story in Genesis 1 that God wishes to live with humans. The book teaches that faithful performance of the sanctuary rituals can make that possible, so long as the people avoid sin and impurity whenever possible. The rituals, especially the sin and guilt offerings, provide the means to gain forgiveness for sins (Leviticus 4–5) and purification from impurities (Leviticus 11–16) so that God can continue to live in the Tabernacle in the midst of the people.

The English name Leviticus comes from the Latin "Leviticus," which is in turn from the Greek Greek Λευιτικόν, "Leuitikon", referring to the priestly tribe of the Israelites, “Levi.” The Greek expression is in turn a variant of the rabbinic Hebrew "torat kohanim", "law of priests", as many of its laws relate to priests.

In Hebrew the book is called "Vayikra" (), from the opening of the book, "va-yikra" "And He <nowiki>[</nowiki>God<nowiki>]</nowiki> called."

"(The outlines from commentaries are similar, though not identical; compare those of Wenham, Hartley, Milgrom, and Watts)

I. Laws on sacrifice (1:1–7:38)
II. Institution of the priesthood (8:1–10:20)
III. Uncleanliness and its treatment (11:1–15:33)
IV. Day of Atonement: purification of the tabernacle from the effects of uncleanliness and sin (ch. 16)

V. Prescriptions for practical holiness (the Holiness Code, chs. 17–26)
VI. Redemption of votive gifts (ch. 27)

Chapters 1–5 describe the various sacrifices from the sacrificers' point of view, although the priests are essential for handling the blood. Chapters 6–7 go over much the same ground, but from the point of view of the priest, who, as the one actually carrying out the sacrifice and dividing the "portions", needs to know how to do this. Sacrifices are between God, the priest, and the offerers, although in some cases the entire sacrifice is a single portion to God—i.e., burnt to ashes.

Chapters 8–10 describe how Moses consecrates Aaron and his sons as the first priests, the first sacrifices, and God's destruction of two of Aaron's sons for ritual offenses. The purpose is to underline the character of altar priesthood (i.e., those priests with power to offer sacrifices to God) as an Aaronite privilege, and the responsibilities and dangers of their position.

With sacrifice and priesthood established, chapters 11–15 instruct the lay people on purity (or cleanliness). Eating certain animals produces uncleanliness, as does giving birth; certain skin diseases (but not all) are unclean, as are certain conditions affecting walls and clothing (mildew and similar conditions); and genital discharges, including female menses and male gonorrhea, are unclean. The reasoning behind the food rules are obscure; for the rest the guiding principle seems to be that all these conditions involve a loss of "life force", usually but not always blood.

Leviticus 16 concerns the Day of Atonement. This is the only day on which the High Priest is to enter the holiest part of the sanctuary, the holy of holies. He is to sacrifice a bull for the sins of the priests, and a goat for the sins of the laypeople. The priest is to send a second goat into the desert to "Azazel", bearing the sins of the whole people. Azazel may be a wilderness-demon, but its identity is mysterious.

Chapters 17–26 are the Holiness code. It begins with a prohibition on all slaughter of animals outside the Temple, even for food, and then prohibits a long list of sexual contacts and also child sacrifice. The "holiness" injunctions which give the code its name begin with the next section: there are penalties for the worship of Molech, consulting mediums and wizards, cursing one's parents and engaging in unlawful sex. Priests receive instruction on mourning rituals and acceptable bodily defects. The punishment for blasphemy is death, and there is the setting of rules for eating sacrifices; there is an explanation of the calendar, and there are rules for sabbatical and Jubilee years; there are rules for oil lamps and bread in the sanctuary; and there are rules for slavery. The code ends by telling the Israelites they must choose between the law and prosperity on the one hand, or, on the other, horrible punishments, the worst of which will be expulsion from the land.

Chapter 27 is a disparate and probably late addition telling about persons and things serving as dedication to the Lord and how one can redeem, instead of fulfill, vows.

The majority of scholars have concluded that the Pentateuch received its final form during the Persian period (538–332 BC). Nevertheless, Leviticus had a long period of growth before reaching that form.

The entire composition of the book of Leviticus is Priestly literature. Most scholars see chapters 1–16 (the Priestly code) and chapters 17–26 (the Holiness code) as the work of two related schools, but while the Holiness material employs the same technical terms as the Priestly code, it broadens their meaning from pure ritual to the theological and moral, turning the ritual of the Priestly code into a model for the relationship of Israel to God: as the tabernacle, which is apart from uncleanliness, becomes holy by the presence of the Lord, so He will dwell among Israel when Israel receives purification (becomes holy) and separates from other peoples. The ritual instructions in the Priestly code apparently grew from priests giving instruction and answering questions about ritual matters; the Holiness code (or H) used to be a separate document, later becoming part of Leviticus, but it seems better to think of the Holiness authors as editors who worked with the Priestly code and actually produced Leviticus as we now have it.

Many scholars argue that the rituals of Leviticus have a theological meaning concerning Israel's relationship with its God. Jacob Milgrom was especially influential in spreading this view. He maintained that the priestly regulations in Leviticus expressed a rational system of theological thought. The writers expected them to be put into practice in Israel's temple, so the rituals would express this theology as well, as well as ethical concern for the poor. Milgrom also argued that the book's purity regulations (chaps. 11–15) have a basis in ethical thinking. Many other interpreters have followed Milgrom in exploring the theological and ethical implications of Leviticus's regulations (e.g. Marx, Balentine), though some have questioned how systematic they really are. Ritual, therefore, is not taking a series of actions for their own sake, but a means of maintaining the relationship between God, the world, and humankind.

The main function of the priests is service at the altar, and only the sons of Aaron are priests in the full sense. (Ezekiel also distinguishes between altar-priests and lower Levites, but in Ezekiel the altar-priests are sons of Zadok instead of sons of Aaron; many scholars see this as a remnant of struggles between different priestly factions in First Temple times, finding resolution by the Second Temple into a hierarchy of Aaronite altar-priests and lower-level Levites, including singers, gatekeepers and the like).

In chapter 10, God kills Nadab and Abihu, the oldest sons of Aaron, for offering "strange incense". Aaron has two sons left. Commentators have read various messages in the incident: a reflection of struggles between priestly factions in the post–Exilic period (Gerstenberger); or a warning against offering incense outside the Temple, where there might be the risk of invoking strange gods (Milgrom). In any case, there has been a pollution of the sanctuary by the bodies of the two dead priests, leading into the next theme, holiness.

Ritual purity is essential for an Israelite to be able to approach Yahweh and remain part of the community. Uncleanliness threatens holiness; Chapters 11–15 review the various causes of uncleanliness and describe the rituals which will restore cleanliness; one is to maintain cleanliness through observation of the rules on sexual behaviour, family relations, land ownership, worship, sacrifice, and observance of holy days.

Yahweh dwells with Israel in the holy of holies. All of the priestly ritual focuses on Yahweh and the construction and maintenance of a holy space, but sin generates impurity, as do everyday events such as childbirth and menstruation; impurity pollutes the holy dwelling place. Failure to ritually purify the sacred space could result in God leaving, which would be disastrous.

Through sacrifice, the priest "makes atonement" for sin and the offerer receives forgiveness (but only if God accepts the sacrifice—forgiveness comes only from God). Atonement rituals involve the pouring or sprinkling of blood as the symbol of the life of the victim: the blood has the power to wipe out or absorb the sin. The two-part division of the book structurally reflects the role of atonement: chapters 1–16 call for the establishment of the institution for atonement, and chapters 17–27 call for the life of the atoned community in holiness.

The consistent theme of chapters 17–26 is in the repetition of the phrase, "Be holy, for I the Lord your God am holy." Holiness in ancient Israel had a different meaning than in contemporary usage: it might have been regarded as the "god-ness" of God, an invisible but physical and potentially dangerous force. Specific objects, or even days, can be holy, but they derive holiness from being connected with God—the seventh day, the tabernacle, and the priests all derive their holiness from God. As a result, Israel had to maintain its own holiness in order to live safely alongside God.

The need for holiness is for the possession of the Promised Land (Canaan), where the Jews will become a holy people: "You shall not do as they do in the land of Egypt where you dwelt, and you shall not do as they do in the land of Canaan to which I am bringing you...You shall do my ordinances and keep my statutes...I am the Lord, your God" (ch. 18:3).

Leviticus, as part of the Torah, became the law book of Jerusalem's Second Temple as well as of the Samaritan temple. Evidence of its influence is evident among the Dead Sea Scrolls, which included fragments of seventeen manuscripts of Leviticus dating from the third to the first centuries BC. Many other Qumran scrolls cite the book, especially the Temple Scroll and 4QMMT.

Jews and Christians have not observed Leviticus's instructions for animal offerings since the first century AD. Because of the destruction of the temple in Jerusalem in 70 AD, Jewish worship has focused on prayer and the study of Torah. Nevertheless, Leviticus constitutes a major source of Jewish law and is traditionally the first book children learn in the Rabbinic system of education. There are two main Midrashim on Leviticus—the halakhic one (Sifra) and a more aggadic one (Vayikra Rabbah).

The New Testament, particularly the Epistle to the Hebrews, uses ideas and images from Leviticus to describe Christ as the high priest who offers his own blood as a sin offering. Therefore, Christians do not make animal offerings either, as Gordon Wenham summarized: "With the death of Christ the only sufficient "burnt offering" was offered once and for all, and therefore the animal sacrifices which foreshadowed Christ's sacrifice were made obsolete."

Christians generally have the view that the New Covenant supersedes (i.e., replaces) the Old Testament's ritual laws, which includes many of the rules in Leviticus. Christians therefore have usually not observed Leviticus' rules regarding diet, purity, and agriculture. Christian teachings have differed, however, as to where to draw the line between ritual and moral regulations.





Online versions of Leviticus:


Related article:

Brief introduction


</doc>
<doc id="18188" url="https://en.wikipedia.org/wiki?curid=18188" title="L. Frank Baum">
L. Frank Baum

Baum was born in Chittenango, New York in 1856 into a devout Methodist family. He had German, Scots-Irish and English ancestry. He was the seventh of nine children of Cynthia Ann (née Stanton) and Benjamin Ward Baum, only five of whom survived into adulthood. "Lyman" was the name of his father's brother, but he always disliked it and preferred his middle name "Frank".

His father succeeded in many businesses, including barrel-making, oil drilling in Pennsylvania, and real estate. Baum grew up on his parents' expansive estate called Rose Lawn, which he fondly recalled as a sort of paradise. Rose Lawn was located in Mattydale, New York. Frank was a sickly, dreamy child, tutored at home with his siblings. From the age of 12, he spent two miserable years at Peekskill Military Academy but, after being severely disciplined for daydreaming, he had a possibly psychogenic heart attack and was allowed to return home.

Baum started writing early in life, possibly prompted by his father buying him a cheap printing press. He had always been close to his younger brother Henry (Harry) Clay Baum, who helped in the production of "The Rose Lawn Home Journal". The brothers published several issues of the journal, including advertisements from local businesses, which they would give to family and friends for free. By the age of 17, Baum established a second amateur journal called "The Stamp Collector", printed an 11-page pamphlet called "Baum's Complete Stamp Dealers' Directory", and started a stamp dealership with friends.

At 20, Baum took on the national craze of breeding fancy poultry. He specialized in raising the Hamburg. In March 1880, he established a monthly trade journal, "The Poultry Record", and in 1886, when Baum was 30 years old, his first book was published: "The Book of the Hamburgs: A Brief Treatise upon the Mating, Rearing, and Management of the Different Varieties of Hamburgs".

Baum had a flair for being the spotlight of fun in the household, including during times of financial difficulties. His selling of fireworks made the Fourth of July memorable. His skyrockets, Roman candles, and fireworks filled the sky, while many people around the neighborhood would gather in front of the house to watch the displays. Christmas was even more festive. Baum dressed as Santa Claus for the family. His father would place the Christmas tree behind a curtain in the front parlor so that Baum could talk to everyone while he decorated the tree without people managing to see him. He maintained this tradition all his life.

Baum embarked on his lifetime infatuation—and wavering financial success—with the theater. A local theatrical company duped him into replenishing their stock of costumes on the promise of leading roles coming his way. Disillusioned, Baum left the theater — temporarily — and went to work as a clerk in his brother-in-law's dry goods company in Syracuse. This experience may have influenced his story "The Suicide of Kiaros", first published in the literary journal "The White Elephant". A fellow clerk one day was found locked in a store room dead, probably from suicide.

Baum could never stay away long from the stage. He performed in plays under the stage names of Louis F. Baum and George Brooks. In 1880, his father built him a theater in Richburg, New York, and Baum set about writing plays and gathering a company to act in them. "The Maid of Arran" proved a modest success, a melodrama with songs based on William Black's novel "A Princess of Thule". Baum wrote the play and composed songs for it (making it a prototypical musical, as its songs relate to the narrative), and acted in the leading role. His aunt Katharine Gray played his character's aunt. She was the founder of Syracuse Oratory School, and Baum advertised his services in her catalog to teach theater, including stage business, play writing, directing, translating (French, German, and Italian), revision, and operettas.

On November 9, 1882, Baum married Maud Gage, a daughter of Matilda Joslyn Gage, a famous women's suffrage and feminist activist. While Baum was touring with "The Maid of Arran", the theater in Richburg caught fire during a production of Baum's ironically titled parlor drama "Matches", destroying the theater as well as the only known copies of many of Baum's scripts, including "Matches", as well as costumes.

In July 1888, Baum and his wife moved to Aberdeen, Dakota Territory where he opened a store called "Baum's Bazaar". His habit of giving out wares on credit led to the eventual bankrupting of the store, so Baum turned to editing the local newspaper "The Aberdeen Saturday Pioneer" where he wrote the column "Our Landlady". Following the death of Sitting Bull at the hands of Indian agency police, Baum urged the wholesale extermination of all America's native peoples in a column that he wrote on December 20, 1890 (full text below). On January 3, 1891 he returned to the subject in an editorial response to the Wounded Knee Massacre:

The Pioneer has before declared that our only safety depends upon the total extirmination of the Indians. Having wronged them for centuries, we had better, in order to protect our civilization, follow it up by one more wrong and wipe these untamed and untamable creatures from the face of the earth.

A recent analysis of these editorials has challenged their literal interpretation, suggesting that the actual intent of Baum was to generate sympathy for the Indians via obnoxious argument, ostensibly promoting the contrary position.

Baum's description of Kansas in "The Wonderful Wizard of Oz" is based on his experiences in drought-ridden South Dakota. During much of this time, Matilda Joslyn Gage was living in the Baum household. While Baum was in South Dakota, he sang in a quartet which included James Kyle, who became one of the first Populist (People's Party) Senators in the U.S.

Baum's newspaper failed in 1891, and he, Maud, and their four sons moved to the Humboldt Park section of Chicago, where Baum took a job reporting for the "Evening Post". Beginning in 1897, he founded and edited a magazine called "The Show Window", later known as the "Merchants Record and Show Window", which focused on store window displays, retail strategies and visual merchandising. The major department stores of the time created elaborate Christmastime fantasies, using clockwork mechanisms that made people and animals appear to move. The former "Show Window" magazine is still currently in operation, now known as "VMSD" magazine (visual merchandising + store design), based in Cincinnati. In 1900, Baum published a book about window displays in which he stressed the importance of mannequins in drawing customers. He also had to work as a traveling salesman.

In 1897, he wrote and published "Mother Goose in Prose", a collection of Mother Goose rhymes written as prose stories and illustrated by Maxfield Parrish. "Mother Goose" was a moderate success and allowed Baum to quit his sales job (which had had a negative impact on his health). In 1899, Baum partnered with illustrator W. W. Denslow to publish "Father Goose, His Book", a collection of nonsense poetry. The book was a success, becoming the best-selling children's book of the year.

In 1900, Baum and Denslow (with whom he shared the copyright) published "The Wonderful Wizard of Oz" to much critical acclaim and financial success. The book was the best-selling children's book for two years after its initial publication. Baum went on to write thirteen more novels based on the places and people of the Land of Oz.

Two years after "Wizard" publication, Baum and Denslow teamed up with composer Paul Tietjens and director Julian Mitchell to produce a musical stage version of the book under Fred R. Hamlin. Baum and Tietjens had worked on a musical of "The Wonderful Wizard of Oz" in 1901 and based closely upon the book, but it was rejected. This stage version opened in Chicago in 1902 (the first to use the shortened title "The Wizard of Oz"), then ran on Broadway for 293 stage nights from January to October 1903. It returned to Broadway in 1904, where it played from March to May and again from November to December. It successfully toured the United States with much of the same cast, as was done in those days, until 1911, and then became available for amateur use. The stage version starred Anna Laughlin as Dorothy Gale, alongside David C. Montgomery and Fred Stone as the Tin Woodman and Scarecrow respectively, which shot the pair to instant fame.

The stage version differed quite a bit from the book, and was aimed primarily at adults. Toto was replaced with Imogene the Cow, and Tryxie Tryfle (a waitress) and Pastoria (a streetcar operator) were added as fellow cyclone victims. The Wicked Witch of the West was eliminated entirely in the script, and the plot became about how the four friends were allied with the usurping Wizard and were hunted as traitors to Pastoria II, the rightful King of Oz. It is unclear how much control or influence Baum had on the script; it appears that many of the changes were written by Baum against his wishes due to contractual requirements with Hamlin. Jokes in the script, mostly written by Glen MacDonough, called for explicit references to President Theodore Roosevelt, Senator Mark Hanna, Rev. Andrew Danquer, and oil magnate John D. Rockefeller. Although use of the script was rather free-form, the line about Hanna was ordered dropped as soon as Hamlin got word of his death in 1904.

Beginning with the success of the stage version, most subsequent versions of the story, including newer editions of the novel, have been titled "The Wizard of Oz", rather than using the full, original title. In more recent years, restoring the full title has become increasingly common, particularly to distinguish the novel from the Hollywood film.

Baum wrote a new Oz book, "The Marvelous Land of Oz", with a view to making it into a stage production, which was titled "The Woggle-Bug", but Montgomery and Stone balked at appearing when the original was still running. The Scarecrow and Tin Woodman were then omitted from this adaptation, which was seen as a self-rip-off by critics and proved to be a major flop before it could reach Broadway. He also worked for years on a musical version of "Ozma of Oz", which eventually became "The Tik-Tok Man Of Oz". This did fairly well in Los Angeles, but not well enough to convince producer Oliver Morosco to mount a production in New York. He also began a stage version of "The Patchwork Girl of Oz", but this was ultimately realized as a film".

With the success of "Wizard" on page and stage, Baum and Denslow hoped for further success and published "Dot and Tot of Merryland" in 1901. The book was one of Baum's weakest, and its failure further strained his faltering relationship with Denslow. It was their last collaboration. Baum worked primarily with John R. Neill on his fantasy work beginning in 1904, but Baum met Neill few times (all before he moved to California) and often found Neill's art not humorous enough for his liking. He was particularly offended when Neill published "The Oz Toy Book: Cut-outs for the Kiddies" without authorization.

Baum reportedly designed the chandeliers in the Crown Room of the Hotel del Coronado; however, that attribution has yet to be corroborated. Several times during the development of the Oz series, Baum declared that he had written his last Oz book and devoted himself to other works of fantasy fiction based in other magical lands, including "The Life and Adventures of Santa Claus" and "Queen Zixi of Ix". However, he returned to the series each time, persuaded by popular demand, letters from children, and the failure of his new books. Even so, his other works remained very popular after his death, with "The Master Key" appearing on "St. Nicholas Magazine"'s survey of readers' favorite books well into the 1920s.

In 1905, Baum declared plans for an Oz amusement park. In an interview, he mentioned buying Pedloe Island off the coast of California to turn it into an Oz park. However, there is no evidence that he purchased such an island, and no one has ever been able to find any island whose name even resembles Pedloe in that area. Nevertheless, Baum stated to the press that he had discovered a Pedloe Island off the coast of California and that he had purchased it to be "the Marvelous Land of Oz," intending it to be "a fairy paradise for children." Eleven year old Dorothy Talbot of San Francisco was reported to be ascendant to the throne on March 1, 1906, when the Palace of Oz was expected to be completed. Baum planned to live on the island, with administrative duties handled by the princess and her all-child advisers. Plans included statues of the Scarecrow, Tin Woodman, Jack Pumpkinhead, and H.M. Woggle-Bug, T.E. Baum abandoned his Oz park project after the failure of "The Woggle-Bug", which was playing at the Garrick Theatre in 1905.
Because of his lifelong love of theatre, he financed elaborate musicals, often to his financial detriment. One of Baum's worst financial endeavors was his "The Fairylogue and Radio-Plays" (1908), which combined a slideshow, film, and live actors with a lecture by Baum as if he were giving a travelogue to Oz. However, Baum ran into trouble and could not pay his debts to the company who produced the films. He did not get back to a stable financial situation for several years, after he sold the royalty rights to many of his earlier works, including "The Wonderful Wizard of Oz". This resulted in the M.A. Donahue Company publishing cheap editions of his early works with advertising which purported that Baum's newer output was inferior to the less expensive books that they were releasing. Baum had shrewdly transferred most of his property into Maud's name, except for his clothing, his typewriter, and his library (mostly of children's books, such as the fairy tales of Andrew Lang, whose portrait he kept in his study)—all of which, he successfully argued, were essential to his occupation. Maud handled the finances anyway, and thus Baum lost much less than he could have.

Baum made use of several pseudonyms for some of his other non-Oz books. They include:

Baum also anonymously wrote "The Last Egyptian: A Romance of the Nile". He continued theatrical work with Harry Marston Haldeman's men's social group The Uplifters, for which he wrote several plays for various celebrations. He also wrote the group's parodic by-laws. The group also included Will Rogers, but was proud to have had Baum as a member and posthumously revived many of his works despite their ephemeral intent. Many of these play's titles are known, but only "The Uplift of Lucifer" is known to survive (it was published in a limited edition in the 1960s). Prior to that, his last produced play was "The Tik-Tok Man of Oz" (based on "Ozma of Oz" and the basis for "Tik-Tok of Oz"), a modest success in Hollywood that producer Oliver Morosco decided did not do well enough to take to Broadway. Morosco, incidentally, quickly turned to film production, as did Baum.

In 1914, Baum started his own film production company The Oz Film Manufacturing Company, which came as an outgrowth of the Uplifters. He served as its president and principal producer and screenwriter. The rest of the board consisted of Louis F. Gottschalk, Harry Marston Haldeman, and Clarence R. Rundel. The films were directed by J. Farrell MacDonald, with casts that included Violet MacMillan, Vivian Reed, Mildred Harris, Juanita Hansen, Pierre Couderc, Mai Welles, Louise Emmons, J. Charles Haydon, and early appearances by Harold Lloyd and Hal Roach. Silent film actor Richard Rosson appeared in one of the films (Rosson's younger brother Harold Rosson was the cinematographer on "The Wizard of Oz", released in 1939). After little success probing the unrealized children's film market, Baum acknowledged his authorship of "The Last Egyptian" and made a film of it (portions of which are included in "Decasia"), but the Oz name had become box office poison for the time being, and even a name change to Dramatic Feature Films and transfer of ownership to Frank Joslyn Baum did not help. Baum invested none of his own money in the venture, unlike "The Fairylogue and Radio-Plays", but the stress probably took its toll on his health.

On May 5, 1919, Baum suffered a stroke. The following day he slipped into a coma but briefly awoke and spoke his last words to his wife, "Now we can cross the Shifting Sands." Frank died on May 6, 1919. He was buried in Glendale's Forest Lawn Memorial Park Cemetery.

His final Oz book, "Glinda of Oz", was published on July 10, 1920, a year after his death. The Oz series was continued long after his death by other authors, notably Ruth Plumly Thompson, who wrote an additional twenty-one Oz books.

Baum's avowed intentions with the Oz books and his other fairy tales was to retell tales such as those which are found in the works of the Brothers Grimm and Hans Christian Andersen, make them in an American vein, update them, avoid stereotypical characters such as dwarfs or genies, and remove the association of violence and moral teachings. His first Oz books contained a fair amount of violence, but it decreased as the series progressed; in "The Emerald City of Oz", Ozma objects to the use of violence, even to the use of violence against the Nomes who threaten Oz with invasion. His introduction is often cited as the beginning of the sanitization of children's stories, although he did not do a great deal more than eliminate harsh moral lessons.

Another traditional element that Baum intentionally omitted was the emphasis on romance. He considered romantic love to be uninteresting to young children, as well as largely incomprehensible. In "The Wonderful Wizard of Oz", the only element of romance lay in the background of the Tin Woodman and his love for Nimmie Amee, which explains his condition and it does not otherwise affect the tale, and that of Gayelette and the enchantment of the Winged monkeys. The only other stories with such elements were "The Scarecrow of Oz" and "Tik-Tok of Oz", both based on dramatizations, which Baum regarded warily until his readers accepted them.

Sally Roesch Wagner of The Matilda Joslyn Gage Foundation has published a pamphlet titled "The Wonderful Mother of Oz" describing how Matilda Gage's feminist politics were sympathetically channeled by Baum into his Oz books. Much of the politics in the Republican "Aberdeen Saturday Pioneer" dealt with trying to convince the populace to vote for women's suffrage. Baum was the secretary of Aberdeen's Woman's Suffrage Club. Susan B. Anthony visited Aberdeen and stayed with the Baums. Nancy Tystad Koupal notes an apparent loss of interest in editorializing after Aberdeen failed to pass the bill for women's enfranchisement.

Some of Baum's contacts with suffragists of his day seem to have inspired much of his second Oz story "The Marvelous Land of Oz". In this story, General Jinjur leads the girls and women of Oz in a revolt, armed with knitting needles; they succeed and make the men do the household chores. Jinjur proves to be an incompetent ruler, but a female advocating gender equality is ultimately placed on the throne. His Edith Van Dyne stories depict girls and young women engaging in traditionally masculine activities, including the "Aunt Jane's Nieces", "The Flying Girl" and its sequel, and his girl sleuth Josie O'Gorman from The Bluebird Books.

During the period surrounding the 1890 Ghost Dance movement and Wounded Knee Massacre, Baum wrote two editorials about Native Americans for the "Aberdeen Saturday Pioneer" which have provoked controversy in recent times because of his assertion that the safety of white settlers depended on the wholesale genocide of American Indians. Sociologist Robert Venables has argued that Baum was not using sarcasm in the editorials.

The first piece was published on December 20, 1890, five days after the killing of the Lakota Sioux holy man, Sitting Bull (who was being held in custody at the time). Following is the complete text of the editorial:

Baum wrote a second editorial following the December 29, 1890 massacre and published on January 3, 1891:

These two short editorials continue to haunt his legacy. In 2006, two descendants of Baum apologized to the Sioux nation for any hurt that their ancestor had caused.

The short story "The Enchanted Buffalo" claims to be a legend of a tribe of bison, and states that a key element made it into legends of Native American tribes. Baum mentions his characters' distaste for a Hopi snake dance in "Aunt Jane's Nieces and Uncle John", but also deplores the horrible situation of Indian Reservations. "Aunt Jane's Nieces on the Ranch" has a hard-working Mexican present himself as an exception to counter Anglo stereotypes of Mexican laziness. Baum's mother-in-law and Woman's Suffrage leader Matilda Joslyn Gage had great influence over Baum's views. Gage was initiated into the Wolf Clan and admitted into the Iroquois Council of Matrons for her outspoken respect and sympathy for Native American people; it would seem unlikely that Baum could have harbored animosity for them in his mature years.

Numerous political references to the "Wizard" appeared early in the 20th century. Henry Littlefield, an upstate New York high school history teacher, wrote a scholarly article which was the first full-fledged interpretation of the novel as an extended political allegory of the politics and characters of the 1890s. Special attention was paid to the Populist metaphors and debates over silver and gold. Baum was a Republican and avid supporter of Women's Suffrage, and it is thought that he did not support the political ideals of either the Populist movement of 1890–1892 or the Bryanite-silver crusade of 1896–1900. He published a poem in support of William McKinley.

Since 1964, many scholars, economists, and historians have expanded on Littlefield's interpretation, pointing to multiple similarities between the characters (especially as depicted in Denslow's illustrations) and stock figures from editorial cartoons of the period. Littlefield himself wrote to "The New York Times" letters to the editor section spelling out that his theory had no basis in fact, but that his original point was "not to label Baum, or to lessen any of his magic, but rather, as a history teacher at Mount Vernon High School, to invest turn-of-the-century America with the imagery and wonder I have always found in his stories."

Baum's newspaper had addressed politics in the 1890s, and Denslow was an editorial cartoonist as well as an illustrator of children's books. A series of political references is included in the 1902 stage version, such as references by name to the President, to a powerful senator, and to John D. Rockefeller for providing the oil needed by the Tin Woodman. Scholars have found few political references in Baum's Oz books after 1902.

Baum himself was asked whether his stories had hidden meanings, but he always replied that they were written to "please children".

Baum was originally a Methodist, but he joined the Episcopal Church in Aberdeen to participate in community theatricals. Later, he and his wife were encouraged by Matilda Joslyn Gage to become members of the Theosophical Society in 1892. Baum's beliefs are often reflected in his writing. The only mention of a church in his Oz books is the porcelain one which the Cowardly Lion breaks in the Dainty China Country in "The Wonderful Wizard of Oz". The Baums sent their older sons to "Ethical Culture Sunday School" in Chicago, which taught morality, not religion.



1921's "The Royal Book of Oz" was posthumous attributed to Baum but was entirely the work of Ruth Plumly Thompson.





</doc>
<doc id="18189" url="https://en.wikipedia.org/wiki?curid=18189" title="Lake Ladoga">
Lake Ladoga

Lake Ladoga ( or ; [earlier in Finnish "Nevajärvi"]; ; ) is a freshwater lake located in the Republic of Karelia and Leningrad Oblast in northwestern Russia, in the vicinity of Saint Petersburg. 

It is the largest lake located entirely in Europe, the second largest lake after Baikal in Russia, and the 14th largest freshwater lake by area in the world. "Ladoga Lacus", a methane lake on Saturn's moon Titan, is named after the lake.

In one of Nestor's chronicles from the 12th century he mentions a lake called "the Great Nevo", a clear link to the Neva River and, possibly furthermore, to Finnish "nevo" "sea" or "neva" "bog, quagmire". 

Ancient Norse sagas and Hanseatic treaties both mention a city made of lakes named Old Norse Aldeigja or Aldoga. Since the beginning of the 14th century this hydronym was commonly known as "Ladoga". According to T. N. Jackson, it can be taken "almost for granted, that the name of Ladoga first referred to the river, then the city, and only then the lake." Therefore, he considers the primary hydronym Ladoga to originate in the eponymous inflow to the lower reaches of the Volkhov River whose Finnic name was Alodejoki (corresponding to modern ) "river of the lowlands".

The Germanic toponym (Aldeigja → Aldoga) was soon borrowed by the Slavic population and transformed by means of the Old Russian metathesis "ald- → lad-" to . The Old Norse intermediary word between Finnish and Old Russian word is fully supported by archeology, since the Scandinavians first appeared in Ladoga in the early 750s, that is, a couple of decades before the Slavs.

Other theories about the origin of the name derive it from "wave" and "wavy"; or from the Russian dialectal word алодь, meaning "open lake, extensive water field". Eugene Helimski by contrast, offers an etymology rooted in German. In his opinion, the primary name of the lake was "old source", associated to the open sea, in contrast to the name of the Neva River (flowing from Lake Ladoga) which would derive from the German expression for "the new". Through the intermediate form "*Aldaugja", cam about, referring to "Ladoga (city)".

The lake has an average surface area of 17,891 km (excluding the islands). Its north-to-south length is 219 km and its average width is 83 km; the average depth is 51 m, although it reaches a maximum of 230 m in the north-western part. Basin area: 276,000 km, volume: 837 km (earlier estimated as 908 km). There are around 660 islands, with a total area of about 435 km. Ladoga is, on average, 5 m above sea level. Most of the islands, including the famous Valaam archipelago, Kilpola and Konevets, are situated in the northwest of the lake.

Separated from the Baltic Sea by the Karelian Isthmus, it drains into the Gulf of Finland via the Neva River.

Lake Ladoga is navigable, being a part of the Volga-Baltic Waterway connecting the Baltic Sea with the Volga River. The Ladoga Canal bypasses the lake in the south, connecting the Neva to the Svir.

The basin of Lake Ladoga includes about 50,000 lakes and 3,500 rivers longer than 10 km. About 85% of the water inflow is due to tributaries, 13% is due to precipitation, and 2% is due to underground waters.

Geologically, the Lake Ladoga depression is a graben and syncline structure of Proterozoic age (Precambrian). This "Ladoga–Pasha structure", as it known, hosts Jotnian sediments. During the Pleistocene glaciations the depression was partially stripped of its sedimentary rock fill by glacial overdeepening. During the Last Glacial Maximum, about 17,000 years BP, the lake served likely as a channel that concentrated ice of the Fennoscandian Ice Sheet into an ice stream that fed glacier lobes further east. 

Deglaciation following the Weichselian glaciation took place in the Lake Ladoga basin between 12,500 and 11,500 radiocarbon years BP. Lake Ladoga was initially part of the Baltic Ice Lake (70–80 m. above present sea level), a historical freshwater stage of Baltic Sea. It is possible, though not certain, that Ladoga was isolated from it during regression of the subsequent Yoldia Sea brackish stage (10,200–9,500 BP). The isolation threshold should be at Heinjoki to the east of Vyborg, where the Baltic Sea and Ladoga were connected by a strait or a river outlet at least until the formation of the River Neva, and possibly even much later, until the 12th century AD or so.

At 9,500 BP, Lake Onega, previously draining into the White Sea, started emptying into Ladoga via the River Svir. Between 9,500 and 9,100 BP, during the transgression of Ancylus Lake, the next freshwater stage of the Baltic, Ladoga certainly became part of it, even if they hadn't been connected immediately before. During the Ancylus Lake subsequent regression, around 8,800 BP Ladoga became isolated.

Ladoga slowly transgressed in its southern part due to uplift of the Baltic Shield in the north. It has been hypothesized, but not proven, that waters of the Litorina Sea, the next brackish-water stage of the Baltic, occasionally invaded Ladoga between 7,000 and 5,000 BP. Around 5,000 BP the waters of the Saimaa Lake penetrated Salpausselkä and formed a new outlet, River Vuoksi, entering Lake Ladoga in the northwestern corner and raising its level by 1–2 m.

The River Neva originated when the Ladoga waters at last broke through the threshold at Porogi into the lower portions of Izhora River, then a tributary of the Gulf of Finland, between 4,000 and 2,000 BP. Dating of some sediments in the northwestern part of Lake Ladoga suggests it happened at 3,100 radiocarbon years BP (3,410–3,250 calendar years BP).
The Ladoga is rich with fish. 48 forms (species and infra specific taxa) of fish have been encountered in the lake, including roach, carp bream, zander, European perch, ruffe, endemic variety of smelt, two varieties of "Coregonus albula" (vendace), eight varieties of "Coregonus lavaretus", a number of other "Salmonidae" as well as, albeit rarely, endangered European sea sturgeon. Commercial fishing was once a major industry but has been hurt by overfishing. After the war, between 1945–1954, the total annual catch increased and reached a maximum of 4,900 tonnes. However, unbalanced fishery led to the drastic decrease of catch in 1955–1963, sometimes to 1,600 tonnes per year. Trawling has been forbidden in Lake Ladoga since 1956 and some other restrictions were imposed. The situation gradually recovered, and in 1971–1990 the catch ranged between 4,900 and 6,900 tonnes per year, about the same level as the total catch in 1938. Fish farms and recreational fishing are developing. 

It has its own endemic ringed seal subspecies known as the Ladoga seal.

Since the beginning of the 1960s Ladoga has become considerably eutrophicated.

Nizhnesvirsky Natural Reserve is situated along the shore of Lake Ladoga immediately to the north of the mouth of the River Svir.

The Ladoga has a population of Arctic char that is genetically close to the chars of Lake Sommen and Lake Vättern in southern Sweden.

In the Middle Ages, the lake formed a vital part of the trade route from the Varangians to the Eastern Roman Empire, with the Norse emporium at Staraya Ladoga defending the mouth of the Volkhov since the 8th century. In the course of the Swedish–Novgorodian Wars, the area was disputed between the Novgorod Republic and Sweden. In the early 14th century, the fortresses of Korela (Kexholm) and Oreshek (Nöteborg) were established along the banks of the lake.

The ancient Valaam Monastery was founded on the island of Valaam, the largest in Lake Ladoga, abandoned between 1611–1715, magnificently restored in the 18th century, and evacuated to Finland during the Winter War in 1940. In 1989 the monastic activities in the Valaam were resumed. Other historic cloisters in the vicinity are the Konevets Monastery, which sits on the Konevets island, and the Alexander-Svirsky Monastery, which preserves fine samples of medieval Muscovite architecture.

During the Ingrian War, a fraction of the Ladoga coast was occupied by Sweden. In 1617, by the Treaty of Stolbovo, the northern and western coast was ceded by Russia to Sweden. In 1721, after the Great Northern War, it was restitution to Russia by the Treaty of Nystad. In the 18th century, the Ladoga Canal were built to bypass the lake which was prone to winds and storms that destroyed hundreds of cargo ships.

Later, in 1812–1940 the lake was shared between Finland and Russia. According to the conditions of the 1920 Tartu Peace Treaty militarization of the lake was severely restricted. However, both Soviet Russia and Finland had flotillas in Ladoga (see also Finnish Ladoga Naval Detachment). After the Winter War (1939–40) according to the Moscow Peace Treaty, Ladoga, previously shared with Finland, became an internal basin of the Soviet Union.

During the Continuation War (1941–44) not only Finnish and Soviet, but also German and Italian vessels operated there (see also Naval Detachment K and Regia Marina). Under these circumstances, during much of the Siege of Leningrad (1941–44), Lake Ladoga provided the only access to the besieged city because a section of the eastern shore remained in Soviet hands. Supplies were transported into Leningrad with trucks on winter roads over the ice, the "Road of Life", and by boat in the summer. After World War II, Finland lost the Karelia region again to the USSR, and all Finnish citizens were evacuated from the ceded territory. Ladoga became an internal Soviet basin once again. The northern shore, Ladoga Karelia with the town of Sortavala, is now part of the Republic of Karelia. The western shore, Karelian Isthmus, became part of Leningrad Oblast.





</doc>
<doc id="18190" url="https://en.wikipedia.org/wiki?curid=18190" title="Language family">
Language family

A language family is a group of languages related through descent from a common "ancestral language" or "parental language", called the proto-language of that family. The term "family" reflects the tree model of language origination in historical linguistics, which makes use of a metaphor comparing languages to people in a biological family tree, or in a subsequent modification, to species in a phylogenetic tree of evolutionary taxonomy. Linguists therefore describe the "daughter languages" within a language family as being "genetically related".

According to "Ethnologue" the 7,111 living human languages are distributed in 141 different language families. A "living language" is simply one that is currently used as the primary form of communication of a group of people. There are also many dead languages, or languages which have no native speakers living, and extinct languages, which have no native speakers and no descendant languages. Finally, there are some languages that are insufficiently studied to be classified, and probably some which are not even known to exist outside their respective speech communities.

Membership of languages in a language family is established by research in comparative linguistics. Sister languages are said to have a "genetic" or "genealogical" relationship. The latter term is older. Speakers of a language family belong to a common speech community. The divergence of a proto-language into daughter languages typically occurs through geographical separation, with the original speech community gradually evolving into distinct linguistic units. Individuals belonging to other speech communities may also adopt languages from a different language family through the language shift process.

Genealogically related languages present shared retentions; that is, features of the proto-language (or reflexes of such features) that cannot be explained by chance or borrowing (convergence). Membership in a branch or group within a language family is established by shared innovations; that is, common features of those languages that are not found in the common ancestor of the entire family. For example, Germanic languages are "Germanic" in that they share vocabulary and grammatical features that are not believed to have been present in the Proto-Indo-European language. These features are believed to be innovations that took place in Proto-Germanic, a descendant of Proto-Indo-European that was the source of all Germanic languages.

Language families can be divided into smaller phylogenetic units, conventionally referred to as "branches" of the family because the history of a language family is often represented as a tree diagram. A family is a monophyletic unit; all its members derive from a common ancestor, and all attested descendants of that ancestor are included in the family. (Thus, the term "family" is analogous to the biological term "clade".) 

Some taxonomists restrict the term "family" to a certain level, but there is little consensus in how to do so. Those who affix such labels also subdivide branches into "groups", and groups into "complexes". A top-level (i.e., the largest) family is often called a "phylum" or "stock". The closer the branches are to each other, the closer the languages will be related. This means if a branch off of a proto-language is 4 branches down and there is also a sister language to that fourth branch, then the two sister languages are more closely related to each other than to that common ancestral proto-language.

The term "macrofamily" or "superfamily" is sometimes applied to proposed groupings of language families whose status as phylogenetic units is generally considered to be unsubstantiated by accepted historical linguistic methods. For example, the Celtic, Germanic, Slavic, Italic, and Indo-Iranian language families are branches of a larger Indo-European language family. There is a remarkably similar pattern shown by the linguistic tree and the genetic tree of human ancestry 
that was verified statistically. Languages interpreted in terms of the putative phylogenetic tree of human languages are transmitted to a great extent vertically (by ancestry) as opposed to horizontally (by spatial diffusion).

Some closely-knit language families, and many branches within larger families, take the form of dialect continua in which there are no clear-cut borders that make it possible to unequivocally identify, define, or count individual languages within the family. However, when the differences between the speech of different regions at the extremes of the continuum are so great that there is no mutual intelligibility between them, as occurs in Arabic, the continuum cannot meaningfully be seen as a single language. 

A speech variety may also be considered either a language or a dialect depending on social or political considerations. Thus, different sources, especially over time, can give wildly different numbers of languages within a certain family. Classifications of the Japonic family, for example, range from one language (a language isolate with dialects) to nearly twenty—until the classification of Ryukyuan as separate languages within a Japonic language family rather than dialects of Japanese, the Japanese language itself was considered a language isolate and therefore the only language in its family.

Most of the world's languages are known to be related to others. Those that have no known relatives (or for which family relationships are only tentatively proposed) are called language isolates, essentially language families consisting of a single language. An example is Basque. In general, it is assumed that language isolates have relatives or had relatives at some point in their history but at a time depth too great for linguistic comparison to recover them.

A language isolated in its own branch within a family, such as Albanian and Armenian within Indo-European, is often also called an isolate, but the meaning of the word "isolate" in such cases is usually clarified with a modifier. For instance, Albanian and Armenian may be referred to as an "Indo-European isolate". By contrast, so far as is known, the Basque language is an absolute isolate: it has not been shown to be related to any other language despite numerous attempts. Another well-known isolate is Mapudungun, the Mapuche language from the Araucanían language family in Chile. A language may be said to be an isolate currently but not historically if related but now extinct relatives are attested. The Aquitanian language, spoken in Roman times, may have been an ancestor of Basque, but it could also have been a sister language to the ancestor of Basque. In the latter case, Basque and Aquitanian would form a small family together. (Ancestors are not considered to be distinct members of a family.)

A proto-language can be thought of as a mother language (not to be confused with a mother tongue, which is one that a specific person has been exposed to from birth), being the root which all languages in the family stem from. The common ancestor of a language family is seldom known directly since most languages have a relatively short recorded history. However, it is possible to recover many features of a proto-language by applying the comparative method, a reconstructive procedure worked out by 19th century linguist August Schleicher. This can demonstrate the validity of many of the proposed families in the list of language families. For example, the reconstructible common ancestor of the Indo-European language family is called "Proto-Indo-European". Proto-Indo-European is not attested by written records and so is conjectured to have been spoken before the invention of writing.

Shared innovations, acquired by borrowing or other means, are not considered genetic and have no bearing with the language family concept. It has been asserted, for example, that many of the more striking features shared by Italic languages (Latin, Oscan, Umbrian, etc.) might well be "areal features". However, very similar-looking alterations in the systems of long vowels in the West Germanic languages greatly postdate any possible notion of a proto-language innovation (and cannot readily be regarded as "areal", either, since English and continental West Germanic were not a linguistic area). In a similar vein, there are many similar unique innovations in Germanic, Baltic and Slavic that are far more likely to be areal features than traceable to a common proto-language. But legitimate uncertainty about whether shared innovations are areal features, coincidence, or inheritance from a common ancestor, leads to disagreement over the proper subdivisions of any large language family.

A sprachbund is a geographic area having several languages that feature common linguistic structures. The similarities between those languages are caused by language contact, not by chance or common origin, and are not recognized as criteria that define a language family. An example of a sprachbund would be the Indian subcontinent.

The concept of language families is based on the historical observation that languages develop dialects, which over time may diverge into distinct languages. However, linguistic ancestry is less clear-cut than familiar biological ancestry, in which species do not crossbreed. It is more like the evolution of microbes, with extensive lateral gene transfer: Quite distantly related languages may affect each other through language contact, which in extreme cases may lead to languages with no single ancestor, whether they be creoles or mixed languages. In addition, a number of sign languages have developed in isolation and appear to have no relatives at all. Nonetheless, such cases are relatively rare and most well-attested languages can be unambiguously classified as belonging to one language family or another, even if this family's relation to other families is not known.



</doc>
<doc id="18194" url="https://en.wikipedia.org/wiki?curid=18194" title="Looe Island">
Looe Island

Looe Island (, meaning "island of the monk's enclosure"), also known as St George's Island, and historically St Michael's Island is a small island a mile from the mainland town of Looe off Cornwall, England.

According to local legend, Joseph of Arimathea landed here with the Christ Child. Some scholars, including Glyn Lewis, suggest the island could be Ictis, the location described by Diodorus Siculus as a centre for the tin trade in pre-Roman Britain.

The island is now owned and managed by the Cornwall Wildlife Trust charity where access is carefully managed for the benefit of wildlife and landing is only possible via the Cornwall Wildlife Trust authorized boatman. The waters around the island are a marine nature reserve and form part of the Looe Voluntary Marine Conservation Area (VMCA). First established in 1995, the Looe VCMA covers nearly 5 km of coastline and aims to protect the coastal and marine wildlife around Looe.

People have been living on Looe Island since the Iron Age. Evidence of early habitation includes pieces of Roman amphorae as well as stone boat anchors and Roman coins. In the Dark Ages, the island was used a seat of early Christian settlement. The child Jesus was believed to have visited the Island with his uncle, Joseph of Arimathea, who traded with the Cornish tin traders. Therefore, Looe Island became a place of pilgrimage for early Christians and a small thatched roofed chapel was built there during this time.

In the later medieval period, the island came under the overall control of Glastonbury Abbey, with the Prior of Lammana being directly responsible for its governance; the island's chapel was under the care of two Benedictine monks until 1289 when the property was sold to a local landowner. The priory was replaced by a domestic chapel served by a secular priest until the Dissolution of the Monasteries in 1536 when it became property of the Crown. From the 13th to the 16th centuries it was known as St Michael's Island but after the dissolution of the monasteries, it was rededicated in 1594 as St George's Island.

Through the 17th and 18th centuries the island was used by smugglers to avoid the British Government's revenue cutters out of Plymouth and Falmouth. The Old Guildhall Museum in Looe hold information and research about the smuggling families of Looe Island and information is also available in the more recent publications about the island.

In the 20th century, Looe island was owned (and inhabited) by two sisters, Babs and Evelyn Atkins, who wrote two books: "We Bought An Island" and its sequel "Tales From Our Cornish Island" . They chronicle the purchase of the island and what it was like to live there. Evelyn died in 1997 at the age of 87; Babs continued to live on the island until her death in 2004, at the age of 86. On her death, the island was bequeathed to the Cornwall Wildlife Trust; it will be preserved as a nature reserve in perpetuity. The adjoining islet, formerly known as Little Island, now renamed Trelawny Island and connected by a small bridge, was bequeathed by Miss Atkins back to the Trelawny family, who previously owned Looe Island from 1743 to 1921.

Situated in the English Channel, about one mile from East Looe in the direction of Polperro, it is about in area and a mile (1.6 km) in circumference. Its highest point is above sea level. Looe Island, like much of south west England, has a mild climate with frost and snow being rare.

The island is owned and managed by the Cornwall Wildlife Trust. This is a non-profit-making venture, the landing fees and other income being devoted to conserving the island's natural environment and providing facilities. The island is open during the summer to day visitors arriving by the Trust's boat. After a short welcome talk visitors are directed to the small visitor centre from where they can pick up a copy of the self-guided trail. Visitors have some two hours on the island and all trips are subject to tides and weather/sea state. While it is normally accessible only by the Cornwall Wildlife Trust's boat, at extremely low spring tides it is possible for the journey to be made by foot across the slippery, seaweed-covered rocky sea floor. However you have to remain on the beach and promptly head back to the mainland.

In 2008, Channel 4's archaeology series "Time Team" visited the island to carry out an investigation into its early Christian history. They excavated the sites of Christian chapels built on both the island and on the mainland opposite. During their dig they found the remains of a Benedictine chapel that was built in c.1139 by monks from Glastonbury Abbey, a reliquary, graves and the remains of much earlier Anglo-Romano places of worship built of wood with dating evidence suggesting use by Christians before the reign of Constantine the Great.

In 1994/95 Andrew Hugill composed Island Symphony, an electro-acoustic piece utilising sampled sounds sourced over the net plus recorded natural sounds from the island itself.





</doc>
<doc id="18195" url="https://en.wikipedia.org/wiki?curid=18195" title="LaTeX">
LaTeX

LaTeX ( or ) is a document preparation system. When writing, the writer uses plain text as opposed to the formatted text found in WYSIWYG ("what you see is what you get") word processors like Microsoft Word, LibreOffice Writer and Apple Pages. The writer uses markup tagging conventions to define the general structure of a document (such as article, book, and letter), to stylise text throughout a document (such as bold and italics), and to add citations and cross-references. A TeX distribution such as TeX Live or MikTeX is used to produce an output file (such as PDF or DVI) suitable for printing or digital distribution. Within the typesetting system, its name is stylised as LaTeX.

LaTeX is widely used in academia for the communication and publication of scientific documents in many fields, including mathematics, statistics, computer science, engineering, chemistry, physics, economics, linguistics, quantitative psychology, philosophy, and political science. It also has a prominent role in the preparation and publication of books and articles that contain complex multilingual materials, such as Sanskrit and Greek. LaTeX uses the TeX typesetting program for formatting its output, and is itself written in the TeX macro language.

LaTeX can be used as a standalone document preparation system, or as an intermediate format. In the latter role, for example, it is sometimes used as part of a pipeline for translating DocBook and other XML-based formats to PDF. The typesetting system offers programmable desktop publishing features and extensive facilities for automating most aspects of typesetting and desktop publishing, including numbering and cross-referencing of tables and figures, chapter and section headings, the inclusion of graphics, page layout, indexing and bibliographies.

Like TeX, LaTeX started as a writing tool for mathematicians and computer scientists, but even from early in its development, it has also been taken up by scholars who needed to write documents that include complex math expressions or non-Latin scripts, such as Arabic, Sanskrit and Chinese.

LaTeX is intended to provide a high-level, descriptive markup language that accesses the power of TeX in an easier way for writers. In essence, TeX handles the layout side, while LaTeX handles the content side for document processing. LaTeX comprises a collection of TeX macros and a program to process LaTeX documents, and because the plain TeX formatting commands are elementary, it provides authors with ready-made commands for formatting and layout requirements such as chapter headings, footnotes, cross-references and bibliographies.

LaTeX was originally written in the early 1980s by Leslie Lamport at SRI International. The current version is LaTeX2e (stylised as LaTeX2ε). LaTeX is free software and is distributed under the LaTeX Project Public License (LPPL).

LaTeX attempts to follow the design philosophy of separating presentation from content, so that authors can focus on the content of what they are writing without attending simultaneously to its visual appearance. In preparing a LaTeX document, the author specifies the logical structure using simple, familiar concepts such as "chapter", "section", "table", "figure", etc., and lets the LaTeX system handle the formatting and layout of these structures. As a result, it encourages the separation of the layout from the content — while still allowing manual typesetting adjustments whenever needed. This concept is similar to the mechanism by which many word processors allow styles to be defined globally for an entire document, or the use of Cascading Style Sheets in styling HTML documents.

The LaTeX system is a markup language that handles typesetting and rendering, and can be arbitrarily extended by using the underlying macro language to develop custom macros such as new environments and commands. Such macros are often collected into "packages," which could then be made available to address some specific typesetting needs such as the formatting of complex mathematical expressions or graphics (e.g., the use of the codice_1 environment provided by the codice_2 package to produce aligned equations).

In order to create a document in LaTeX, you first write a file, say codice_3, using your preferred text editor. Then you give your codice_3 file as input to the TeX program (with the LaTeX macros loaded), which prompts TeX to write out a file suitable for onscreen viewing or printing. This write-format-preview cycle is one of the chief ways in which working with LaTeX differs from the What-You-See-Is-What-You-Get (WYSIWYG) style of document editing. It is similar to the code-compile-execute cycle known to the computer programmers. Today, many LaTeX-aware editing programs make this cycle a simple matter through the pressing a single key, while showing the output preview on the screen beside the input window. Some online LaTeX editors even automatically refresh the preview, while other online tools provide incremental editing in-place, mixed in with the preview in a streamlined single window.

The example below shows the LaTeX input and corresponding output:

Note how the equation for formula_1 (highlighted in the example code) was typeset by the markup:

where the square root is denoted by "codice_5", and the fractions by "codice_6".

The characters T, E, X in the name come from the Greek capital letters tau, epsilon, and chi, as the name of TeX derives from the (skill, art, technique); for this reason, TeX's creator Donald Knuth promotes a pronunciation of () (that is, with a voiceless velar fricative as in Modern Greek, similar to the ch in loch). Lamport remarks that "TeX is usually pronounced "tech", making "lah"-teck, lah-"teck", and "lay"-teck the logical choices; but language is not always logical, so "lay-tecks" is also possible."

The name is traditionally printed in running text with a special typographical logo: LaTeX.
In media where the logo cannot be precisely reproduced in running text, the word is typically given the unique capitalization "LaTeX". Alternatively, the TeX, LaTeX and XeTeX logos can also be rendered via pure CSS and XHTML for use in graphical web browsers — by following the specifications of the internal codice_7 macro.

LaTeX is typically distributed along with plain TeX under a free software license: the LaTeX Project Public License (LPPL). The LPPL is not compatible with the GNU General Public License, as it requires that modified files must be clearly differentiable from their originals (usually by changing the filename); this was done to ensure that files that depend on other files will produce the expected behavior and avoid dependency hell. The LPPL is DFSG compliant as of version 1.3. As free software, LaTeX is available on most operating systems, which include UNIX (Solaris, HP-UX, AIX), BSD (FreeBSD, macOS, NetBSD, OpenBSD), Linux (Red Hat, Debian, Arch, Gentoo), Windows, DOS, RISC OS, AmigaOS and Plan9.

As a macro package, LaTeX provides a set of macros for TeX to interpret. There are many other macro packages for TeX, including Plain TeX, GNU Texinfo, AMSTeX, and ConTeXt.

When TeX "compiles" a document, it follows (from the user's point of view) the following processing sequence: Macros → TeX → Driver → Output. Different implementations of each of these steps are typically available in TeX distributions. Traditional TeX will output a DVI file, which is usually converted to a PostScript file. More recently, Hàn Thế Thành and others have written a new implementation of TeX called pdfTeX, which also outputs to PDF and takes advantage of features available in that format. The XeTeX engine developed by Jonathan Kew, on the other hand, merges modern font technologies and Unicode with TeX.

The default font for LaTeX is Knuth's Computer Modern, which gives default documents created with LaTeX the same distinctive look as those created with plain TeX. XeTeX allows the use of OpenType and TrueType (that is, outlined) fonts for output files.

There are also many editors for LaTeX, some of which are offline, source-code-based while others are online, partial-WYSIWYG-based. For more, see Comparison of TeX editors.

LaTeX2e is the current version of LaTeX, since it replaced LaTeX 2.09 in 1994. , LaTeX3, which started in the early 1990s, is under a long-term development project. Planned features include improved syntax, hyperlink support, a new user interface, access to arbitrary fonts and a new documentation.

There are numerous commercial implementations of the entire TeX system. System vendors may add extra features like additional typefaces and telephone support. LyX is a free, WYSIWYM visual document processor that uses LaTeX for a back-end. TeXmacs is a free, WYSIWYG editor with similar functionalities as LaTeX, but with a different typesetting engine. Other WYSIWYG editors that produce LaTeX include Scientific Word on MS Windows., and BaKoMa TeX on Windows, Mac and Linux.

A number of community-supported TeX distributions are available, including TeX Live (multi-platform), teTeX (deprecated in favor of TeX Live, UNIX), fpTeX (deprecated), MiKTeX (Windows), proTeXt (Windows), MacTeX (TeX Live with the addition of Mac specific programs), gwTeX (Mac OS X) (deprecated), OzTeX (Mac OS Classic), AmigaTeX (no longer available), PasTeX (AmigaOS, available on the Aminet repository), and Auto-Latex Equations (Google Docs add-on that supports MathJax LaTeX commands).

LaTeX documents (codice_8) can be opened with any text editor. They consist of plain text and do not contain hidden formatting codes or binary instructions. Additionally, TeX documents can be shared by rendering the LaTeX file to Rich Text Format (codice_9) or XML. This can be done using the free software programs LaTeX2RTF or TeX4ht. LaTeX can also be rendered to PDF files using the LaTeX extension pdfLaTeX. LaTeX files containing Unicode text can be processed into PDFs with the codice_10 package, or by the TeX extensions XeLaTeX and LuaLaTeX.

LaTeX was created in the early 1980s by Leslie Lamport, when he was working at SRI. He needed to write TeX macros for his own use, and thought that with a little extra effort he could make a general package usable by others. Peter Gordon, an editor at Addison-Wesley, convinced him to write a LaTeX user's manual for publication (Lamport was initially skeptical that anyone would pay money for it); it came out in 1986 and sold hundreds of thousands of copies. Meanwhile, Lamport released versions of his LaTeX macros in 1984 and 1985. On 21 August 1989, at a TeX Users Group (TUG) meeting at Stanford, Lamport agreed to turn over maintenance and development of LaTeX to Frank Mittelbach. Mittelbach, along with Chris Rowley and Rainer Schöpf, formed the LaTeX3 team; in 1994, they released LaTeX 2e, the current standard version, and continue working on LaTeX3.





</doc>
<doc id="18196" url="https://en.wikipedia.org/wiki?curid=18196" title="List of saints">
List of saints

This is an incomplete list of Christian saints in alphabetical order by Christian name, but, where known and given, a surname, location, or personal attribute (included as part of the name) may affect the ordering.

One list says there are 810 canonized Roman Catholic saints (who have been through the formal institutional process of canonization), although some give numbers in the thousands. (Pope John Paul II alone canonized 110 individuals, plus many group canonizations such as 110 martyr saints of China, 103 Korean martyrs, 117 Vietnamese martyrs, Mexican Martyrs, Spanish martyrs and French revolutionary martyrs.) Among the Eastern Orthodox and Oriental Orthodox Communions, the numbers may be even higher, since there is no fixed process of "canonization" and each individual jurisdiction within the two Orthodox communions independently maintains parallel lists of saints that have only partial overlap. Note that 78 popes are considered saints.

The Anglican Communion recognizes pre-Reformation saints, as does the United Methodist Church. Persons who have led lives of celebrated sanctity or missionary zeal are included in the Calendar of the Prayer Book "without thereby enrolling or commending such persons as saints of the Church". Similarly, any individuals commemorated in the Lutheran calendar of saints will be listed as well.

Wikipedia contains calendars of saints for particular denominations, listed by the day of the year on which they are traditionally venerated, as well as a chronological list of saints and blesseds, listed by their date of death.

 "Common Worship" has "Commemoration".





</doc>
<doc id="18198" url="https://en.wikipedia.org/wiki?curid=18198" title="Lebesgue measure">
Lebesgue measure

In measure theory, a branch of mathematics, the Lebesgue measure, named after French mathematician Henri Lebesgue, is the standard way of assigning a measure to subsets of "n"-dimensional Euclidean space. For "n" = 1, 2, or 3, it coincides with the standard measure of length, area, or volume. In general, it is also called n"-dimensional volume, n"-volume, or simply volume. It is used throughout real analysis, in particular to define Lebesgue integration. Sets that can be assigned a Lebesgue measure are called Lebesgue-measurable; the measure of the Lebesgue-measurable set "A" is here denoted by "λ"("A").

Henri Lebesgue described this measure in the year 1901, followed the next year by his description of the Lebesgue integral. Both were published as part of his dissertation in 1902.

The Lebesgue measure is often denoted by "dx", but this should not be confused with the distinct notion of a volume form.

Given a subset formula_1, with the length of interval formula_2 given by formula_3, the Lebesgue outer measure formula_4 is defined as

The Lebesgue measure is defined on the Lebesgue "σ"-algebra, which is the collection of all sets formula_6 which satisfy the "Carathéodory criterion" which requires that for every formula_7,

For any set in the Lebesgue "σ"-algebra, its Lebesgue measure is given by its Lebesgue outer measure formula_9.

Sets that are not included in the Lebesgue "σ"-algebra are not Lebesgue-measurable. Such sets do exist (e.g. Vitali sets), i.e., the Lebesgue "σ"-algebra is strictly contained in the power set of formula_10.

The first part of the definition states that the subset formula_6 of the real numbers is reduced to its outer measure by coverage by sets of open intervals. Each of these sets of intervals formula_12 covers formula_6 in the sense that when the intervals are combined together by union, they contain formula_6. The total length of any covering interval set can easily overestimate the measure of formula_6, because formula_6 is a subset of the union of the intervals, and so the intervals may include points which are not in formula_6. The Lebesgue outer measure emerges as the greatest lower bound (infimum) of the lengths from among all possible such sets. Intuitively, it is the total length of those interval sets which fit formula_6 most tightly and do not overlap.

That characterizes the Lebesgue outer measure. Whether this outer measure translates to the Lebesgue measure proper depends on an additional condition. This condition is tested by taking subsets formula_19 of the real numbers using formula_6 as an instrument to split formula_19 into two partitions: the part of formula_19 which intersects with formula_6 and the remaining part of formula_19 which is not in formula_6: the set difference of formula_19 and formula_6. These partitions of formula_19 are subject to the outer measure. If for all possible such subsets formula_19 of the real numbers, the partitions of formula_19 cut apart by formula_6 have outer measures whose sum is the outer measure of formula_19, then the outer Lebesgue measure of formula_6 gives its Lebesgue measure. Intuitively, this condition means that the set formula_6 must not have some curious properties which causes a discrepancy in the measure of another set when formula_6 is used as a "mask" to "clip" that set, hinting at the existence of sets for which the Lebesgue outer measure does not give the Lebesgue measure. (Such sets are, in fact, not Lebesgue-measurable.)


The Lebesgue measure on R has the following properties:


All the above may be succinctly summarized as follows:

The Lebesgue measure also has the property of being "σ"-finite.

A subset of R is a "null set" if, for every ε > 0, it can be covered with countably many products of "n" intervals whose total volume is at most ε. All countable sets are null sets.

If a subset of R has Hausdorff dimension less than "n" then it is a null set with respect to "n"-dimensional Lebesgue measure. Here Hausdorff dimension is relative to the Euclidean metric on R (or any metric Lipschitz equivalent to it). On the other hand, a set may have topological dimension less than "n" and have positive "n"-dimensional Lebesgue measure. An example of this is the Smith–Volterra–Cantor set which has topological dimension 0 yet has positive 1-dimensional Lebesgue measure.

In order to show that a given set "A" is Lebesgue-measurable, one usually tries to find a "nicer" set "B" which differs from "A" only by a null set (in the sense that the symmetric difference ("A" − "B") formula_53("B" − "A") is a null set) and then show that "B" can be generated using countable unions and intersections from open or closed sets.

The modern construction of the Lebesgue measure is an application of Carathéodory's extension theorem. It proceeds as follows.

Fix . A box in R is a set of the form
where , and the product symbol here represents a Cartesian product. The volume of this box is defined to be

For "any" subset "A" of R, we can define its outer measure "λ"*("A") by:

We then define the set "A" to be Lebesgue-measurable if for every subset "S" of R,

These Lebesgue-measurable sets form a "σ"-algebra, and the Lebesgue measure is defined by for any Lebesgue-measurable set "A".

The existence of sets that are not Lebesgue-measurable is a consequence of a certain set-theoretical axiom, the axiom of choice, which is independent from many of the conventional systems of axioms for set theory. The Vitali theorem, which follows from the axiom, states that there exist subsets of R that are not Lebesgue-measurable. Assuming the axiom of choice, non-measurable sets with many surprising properties have been demonstrated, such as those of the Banach–Tarski paradox.

In 1970, Robert M. Solovay showed that the existence of sets that are not Lebesgue-measurable is not provable within the framework of Zermelo–Fraenkel set theory in the absence of the axiom of choice (see Solovay's model).

The Borel measure agrees with the Lebesgue measure on those sets for which it is defined; however, there are many more Lebesgue-measurable sets than there are Borel measurable sets. The Borel measure is translation-invariant, but not complete.

The Haar measure can be defined on any locally compact group and is a generalization of the Lebesgue measure (R with addition is a locally compact group).

The Hausdorff measure is a generalization of the Lebesgue measure that is useful for measuring the subsets of R of lower dimensions than "n", like submanifolds, for example, surfaces or curves in R and fractal sets. The Hausdorff measure is not to be confused with the notion of Hausdorff dimension.

It can be shown that there is no infinite-dimensional analogue of Lebesgue measure.



</doc>
<doc id="18201" url="https://en.wikipedia.org/wiki?curid=18201" title="Lake Champlain">
Lake Champlain

Lake Champlain (; ; Abenaki: "Pitawbagok"; ) is a natural freshwater lake in North America mainly within the borders of the United States (in the states of Vermont and New York) but partially situated across the Canada–U.S. border, in the Canadian province of Quebec.

The New York portion of the Champlain Valley includes the eastern portions of Clinton County and Essex County. Most of this area is part of the Adirondack Park. There are recreational facilities in the park and along the relatively undeveloped coastline of Lake Champlain. The cities of Plattsburgh, New York and Burlington, Vermont are on the lake's western and eastern shores, respectively, and the Town of Ticonderoga, New York is in the region's southern part. The Quebec portion is in the regional county municipalities of Le Haut-Richelieu and Brome-Missisquoi. There are a number of islands in the lake; the largest include Grand Isle, Isle La Motte, and North Hero, all part of Grand Isle County, Vermont.

The Champlain Valley is the northernmost unit of a landform system known as the Great Appalachian Valley, which stretches between Quebec, Canada, to the north, and Alabama, US, to the south. The Champlain Valley is a physiographic section of the larger Saint Lawrence Valley, which in turn is part of the larger Appalachian physiographic division.

Lake Champlain is one of numerous large lakes scattered in an arc through Labrador, in Canada, the northern United States, and the Northwest Territories of Canada. It is the thirteenth largest lake by area in the US. Approximately in area, the lake is long and across at its widest point, and has a maximum depth of approximately . The lake varies seasonally from about above mean sea level.

Lake Champlain is in the Lake Champlain Valley between the Green Mountains of Vermont and the Adirondack Mountains of New York, drained northward by the Richelieu River into the St. Lawrence River at Sorel-Tracy, Quebec, northeast and downstream of Montreal, Quebec. It also receives the waters from the Lake George, so its basin collects waters from the northwestern slopes of the Green Mountains and the northernmost eastern peaks of the Adirondack Mountains.

Lake Champlain drains nearly half of Vermont, and approximately 250,000 people get their drinking water from the lake.

The lake is fed in Vermont by the LaPlatte, Lamoille, Missisquoi, Poultney, and Winooski rivers, along with Lewis Creek, Little Otter Creek, and Otter Creek. In New York, it is fed by the Ausable, Boquet, Great Chazy, La Chute, Little Ausable, Little Chazy, Salmon, and Saranac rivers, along with Putnam Creek. In Quebec, it is fed by the Pike River.

It is connected to the Hudson River by the Champlain Canal.

Parts of the lake freeze each winter, and in some winters the entire lake surface freezes, referred to as "closing". In July and August, the lake temperature reaches an average of .

The Chazy Reef is an extensive Ordovician carbonate rock formation that extends from Tennessee to Quebec and Newfoundland. It occurs in prominent outcropping at Goodsell Ridge, Isle La Motte, the northernmost island in Lake Champlain.

The oldest reefs are around "The Head" of the south end of the island; slightly younger reefs are found at the Fisk Quarry, and the youngest (the famous coral reefs) are in fields to the north. Together, these three sites provide a unique narrative of events that took place over 450 million years ago in the ocean in the Southern Hemisphere, long before Lake Champlain's emergence 20,000 years ago.

The lake has long acted as a border between indigenous nations much as it is today between the USA and Canada. The lake is located at the frontier between Abenaki and Mohawk (Iroquois Confederacy) traditional territories. The official toponym for the lake according to the orthography established by the Grand Council of Wanab-aki Nation is Pitawbagok (alternative orthographies include Petonbowk and Bitawbagok), meaning 'middle lake', 'lake in between' or 'double lake'.

The Mohawk name in modern orthography as standardized in 1993 is Kaniatarakwà:ronte, meaning "a bulged lake" or “lake with a bulge in it." An alternate name is Kaniá:tare tsi kahnhokà:ronte (phonetic English spelling "Caniaderi Guarunte" ), meaning 'door of the country' or 'lake to the country'. The lake is an important eastern gateway to Iroquois Confederacy lands.

The lake was named after the French explorer Samuel de Champlain, who encountered it in July 1609. While the ports of Burlington, Vermont, Port Henry, New York, and Plattsburgh, New York today are primarily used by small craft, ferries, and lake cruise ships, they were of substantial commercial and military importance in the 18th and 19th centuries.

New France allocated concessions all along lake Champlain to French settlers and built forts to defend the waterways. In colonial times, Lake Champlain was used as a water (or, in winter, ice) passage between the Saint Lawrence and Hudson valleys. Travelers found it easier to journey by boats and sledges on the lake rather than go overland on unpaved and frequently mud-bound roads. The lake's northern tip at Saint-Jean-sur-Richelieu, Quebec (known as St. John in colonial times under British rule), is a short distance from Montreal, Quebec. The southern tip at Whitehall (Skenesborough in revolutionary times) is a short distance from Saratoga, Glens Falls, and Albany, New York.

Forts were built at Ticonderoga and Crown Point (Fort St. Frederic) to control passage on the lake in colonial times. Important battles were fought at Ticonderoga in 1758 and 1775. During the Revolutionary War, the British and Americans conducted a frenetic shipbuilding race through the spring and summer of 1776, at opposite ends of the lake, and fought a significant naval engagement on October 11 at the Battle of Valcour Island. While it was a tactical defeat for the Americans, and the small fleet led by Benedict Arnold was almost destroyed, the Americans gained a strategic victory; the British invasion was delayed long enough so the approach of winter prevented the fall of these forts until the following year. In this period, the Continental Army gained strength and was victorious at Saratoga.

At the start of the Revolutionary War, British forces occupied the Champlain Valley. However, it did not take long for rebel leaders to realize the importance of controlling Lake Champlain. Early in the war, the colonial militias attempted to expel the British from Boston; however, this undertaking could not be achieved without heavy artillery. The British forts at Ticonderoga and Crown Point, on Lake Champlain, were known to have ample supplies of artillery and were weakly manned by the British. Thus, the colonial militias devised a plan to take control of the two forts and bring the guns back to the fight in Boston.
The necessity of controlling the two forts at Ticonderoga and Crown Point placed Lake Champlain as a strategic arena during the Revolutionary War. By taking control of these forts, Americans not only gained heavy artillery, but control of a vast water highway, as well: Lake Champlain provided a direct invasion route to British Canada. However, had the British controlled the lake, they could have divided the colonies of New England and further depleted the Continental Army.

The Continental Army's first offensive action took place in May 1775, three weeks after the Battles of Lexington and Concord. Ethan Allen, accompanied by 200 Green Mountain Boys, was ordered to capture Fort Ticonderoga and retrieve supplies for the fight in Boston. Benedict Arnold shared the command with Allen, and in early May 1775, they captured Fort Ticonderoga, Crown Point, and the southern Loyalist settlement of Skenesborough. As a result of Allen’s offensive attack on the Champlain Valley in 1775, the American forces controlled the Lake Champlain waterway.

The Continental Army realized the strategic advantage of controlling Lake Champlain, as it leads directly to the heart of Quebec. Immediately after taking Forts Ticonderoga and Crown Point, the Americans began planning an attack on British Canada. The American siege of Quebec was a two-pronged assault and occurred throughout the winter of 1775–1776. Brigadier General Richard Montgomery led the first assault up the Champlain Valley into Canada, while Benedict Arnold led a second army to Quebec via the Maine wilderness.

Despite the strategic advantage of controlling a direct route to Quebec by way of the Champlain Valley, the American siege of British Canada during the winter of 1775 failed. The Continental Army mistakenly assumed they would receive support from the Canadians upon their arrival at Quebec. This was not the case, and the rebel army struggled to take Quebec with diminishing supplies, support, and harsh northern winter weather.

The Continental Army was forced to camp outside Quebec’s walls for the winter, with reinforcements from New York, Pennsylvania, Massachusetts, New Hampshire, and Connecticut allowing the soldiers to maintain their siege of the city. The reinforcements traveled hundreds of miles (kilometres) up the frozen Lake Champlain and St. Lawrence River, but were too late and too few to influence a successful siege of Quebec. In May 1776, with the arrival of a British convoy carrying 10,000 British and Hessian troops to Canada, the Continental forces retreated back down the Champlain Valley to reevaluate their strategy.
"I know of no better method than to secure the important posts of Ticonderoga and Crown Point, and by building a number of armed vessels to command the lakes, otherwise the forces now in Canada will be brought down upon us as quick as possible, having nothing to oppose them… They will doubtless try to construct some armed vessels and then endeavor to penetrate the country toward New York." (Brigadier General John Sullivan to George Washington, June 24, 1776).

Both British and American forces spent the summer of 1776 building their naval fleets, at opposite ends of Lake Champlain. By the October 1776, the Continental Army had 16 operating naval vessels on Lake Champlain, a great increase to the four small ships they had at the beginning of the summer. General Benedict Arnold commanded the American naval fleet on Lake Champlain, which was composed of volunteers and soldiers drafted from the Northern Army. With great contrast to the Continental navy, experienced Royal Navy officers, British seamen, and Hessian artillerymen manned the British fleet on Lake Champlain. By the end of the summer of 1776, the opposing armies were prepared to battle over the strategic advantage of controlling Lake Champlain.

On October 11, 1776, the British and American naval fleets met on the western side of Valcour Island, on Lake Champlain. American General Benedict Arnold established the location, as it provided the Continental fleet with a natural defensive position. The British and American vessels engaged in combat for much of the day, only stopping due to the impending nightfall.

After a long day of combat, the American fleet was in worse shape than the experienced British Navy. Upon ceasefire, Arnold called a council of war with his fellow officers, proposing to escape the British fleet via rowboats under the cover of night. As the British burned Arnold's flagship, the "Royal Savage," to the east, the Americans rowed past the British lines.

The following morning, the British learned of the Americans' escape and set out after the fleeing Continental vessels. On October 13, the British fleet caught up to the struggling American ships near Split Rock Mountain. With no hope of fighting off the powerful British navy, Arnold ordered his men to run their five vessels aground in Ferris Bay, Panton, Vermont. The depleted Continental army escaped on land back to Fort Ticonderoga and Mount Independence; however, they no longer controlled the Lake Champlain waterway.

The approaching winter of 1776–1777 restricted British movement along the recently controlled Lake Champlain. As the British abandoned Crown Point and returned to Canada for the winter, the Americans reduced their garrisons in the Champlain Valley from 13,000 to 2,500 soldiers.

In early 1777, British General John Burgoyne led 8,000 troops from Canada, down Lake Champlain, and into the Champlain Valley. The goal of this invasion was to divide the New England colonies, thus forcing the Continental Army into a separated fight on multiple fronts. Lake Champlain provided Burgoyne with protected passage deep into the American colonies. Burgoyne’s army reached Fort Ticonderoga and Mount Independence in late June 1777. During the night of July 5, the American forces fled Ticonderoga as the British took control of the fort. However, Burgoyne’s southern campaign did not go uncontested.

On October 7, 1777, American General Horatio Gates, who occupied Bemis Heights, met Burgoyne’s army at the Second Battle of Freeman’s Farm. At Freeman’s Farm, Burgoyne’s army suffered its final defeat and ended their invasion south into the colonies. Ten days later, on October 17, 1777, British General Burgoyne surrendered his army at Saratoga. This defeat was instrumental to the momentum of the Revolutionary War, as the defeat of the British army along the Champlain-Hudson waterway convinced France to ally with the American army.

Following the failed British campaign led by General Burgoyne, the British still maintained control over the Champlain waterway for the duration of the Revolutionary War. The British used the Champlain waterway to supply raids across the Champlain Valley from 1778 to 1780, and Lake Champlain permitted direct transportation of supplies from the British posts at the northern end of the lake.

With the end of the Revolutionary War in 1783, the British naval fleet on Lake Champlain retreated up to St. John’s. However, British troops garrisoned at Fort Dutchman's Point (North Hero, Vermont) and Fort au Fer (Champlain, New York) on Lake Champlain, did not leave until the 1796 Jay Treaty.

Eager to take back control of Lake Champlain following the end of the Revolutionary War, Americans flocked to settle the Champlain Valley. Many individuals emigrated from Massachusetts and other New England colonies, such as Salmon Dutton, a settler of Cavendish, Vermont. Dutton emigrated in 1782 and worked as a surveyor, town official, and toll road owner. His home had a dooryard garden, typical of mid-19th century New England village homes, and his experience settling in the Champlain Valley depicts the industries and lifestyles surrounding Lake Champlain following the Revolutionary War.

Similar to the experience of Salmon Dutton, former colonial militia Captain Hezekiah Barnes settled in Charlotte, Vermont, in 1787. Following the war, Barnes also worked as a road surveyor; he also established an inn and trading post in Charlotte, along the main trade route from Montreal down Lake Champlain. Barnes’s stagecoach inn was built in traditional Georgian style, with 10 fireplaces and a ballroom on the interior, and a wraparound porch on the outside. In 1800, Continental Army Captain Benjamin Harrington established a distillery business in Shelburne, Vermont, which supplied his nearby inn. Furthermore, Captain Stevens and Jeremiah Trescott built a water-powered sawmill in South Royalton, Vermont, in the late 1700s. These individual accounts shed light on the significance of Lake Champlain during the post-Revolutionary War period.

During the War of 1812, British and American forces faced each other in the Battle of Lake Champlain, also known as the Battle of Plattsburgh, fought on September 11, 1814. This ended the final British invasion of the northern states during the War of 1812. It was fought just prior to the signing of the Treaty of Ghent, and the American victory denied the British any leverage to demand exclusive control over the Great Lakes or territorial gains against the New England states.

Three US Naval ships have been named after this battle: , , and a cargo ship used during World War I.

Following the War of 1812, the U.S. Army began construction on "Fort Blunder", an unnamed fortification built at the northernmost end of Lake Champlain to protect against attacks from British Canada. Its nickname came from a surveying error: the initial phase of construction on the fort turned out to be taking place on a point north of the Canada–U.S. border. Once this error was spotted, construction was abandoned. Locals scavenged materials used in the abandoned fort for use in their homes and public buildings.

By the Webster-Ashburton Treaty of 1842, the Canada–U.S. border was adjusted northward to include the strategically important site of "Fort Blunder" on the US side. In 1844, work was begun to replace the remains of the 1812-era fort with a massive new Third System masonry fortification, known as Fort Montgomery. Portions of this fort are still standing.

In the early 19th century, the construction of the Champlain Canal connected Lake Champlain to the Hudson River system, allowing north-south commerce by water from New York City to Montreal and Atlantic Canada.

In 1909, 65,000 people celebrated the 300th anniversary of the French discovery of the lake. Attending dignitaries included President William Howard Taft, along with representatives from France, Canada, and the United Kingdom.

In 1929, then-New York Governor Franklin Roosevelt and Vermont Governor John Weeks dedicated the first bridge to span the lake, built from Crown Point to Chimney Point. This bridge lasted until December 2009. Severe deterioration was found, and the bridge was demolished and replaced with the Lake Champlain Bridge, which opened in November 2011.

On February 19, 1932, boats were able to sail on Lake Champlain. It was the first time the lake was known to be free of ice during the winter at that time.

Lake Champlain briefly became the nation's sixth Great Lake on March 6, 1998, when President Clinton signed Senate Bill 927. This bill, which was led by U.S. Senator Patrick Leahy of Vermont and reauthorized the National Sea Grant Program, contained a line declaring Lake Champlain to be a Great Lake. This status enabled its neighboring states to apply for additional federal research and education funds allocated to these national resources. However, following a small uproar, the Great Lake status was rescinded on March 24 (although New York and Vermont universities continue to receive funds to monitor and study the lake).

In 1609, Samuel de Champlain wrote that he saw a lake monster long, as thick as a man's thigh, with silver-gray scales a dagger could not penetrate. The alleged monster had jaws with sharp and dangerous teeth. Native Americans claimed to have seen similar monsters long. This mysterious creature is likely the original Lake Champlain monster. The monster has been memorialized in sports teams' names and mascots, i.e., the Vermont Lake Monsters and Champ, the mascot of the state's minor league baseball team. A Vermont Historical Society publication recounts the story and offers possible explanations for accounts of the so-called monster: "floating logs, schools of large sturgeons diving in a row, or flocks of black birds flying close to the water."

A pollution prevention, control, and restoration plan for Lake Champlain was first endorsed in October 1996 by the governors of New York and Vermont, and the regional administrators of the United States Environmental Protection Agency (EPA). In April 2003, the plan was updated, and Quebec signed onto it. The plan is being implemented by the Lake Champlain Basin Program and its partners at the state, provincial, federal, and local levels. Renowned as a model for interstate and international cooperation, its primary goals are to reduce phosphorus inputs to Lake Champlain, reduce toxic contamination, minimize the risks to humans from water-related health hazards, and control the introduction, spread, and impact of non-native nuisance species to preserve the integrity of the Lake Champlain ecosystem.

Senior staff who helped organize the Environmental Protection Agency in 1970 recall that International Paper was one of the first companies to call upon the brand new agency, because it was being pushed by both New York and Vermont with regard to a discharge of pollution into Lake Champlain.

Agricultural and urban runoff from the watershed or drainage basin is the primary source of excess phosphorus, which exacerbates algae blooms in Lake Champlain. The most problematic blooms have been cyanobacteria, commonly called blue-green algae, in the northeastern part of the Lake, primarily Missisquoi Bay.

To reduce phosphorus runoff to this part of the lake, Vermont and Quebec agreed to reduce their inputs by 60% and 40%, respectively, by an agreement signed in 2002. While agricultural sources (manure and fertilizers) are the primary sources of phosphorus (about 70%) in the Missisquoi basin, runoff from developed land and suburbs is estimated to contribute about 46% of the phosphorus runoff basin-wide to Lake Champlain, and agricultural lands contributed about 38%.

In 2002, the cleanup plan noted that the lake had the capacity to absorb of phosphorus each year. In 2009, a judge noted that were still flowing in annually, more than twice what the lake could handle. Sixty municipal and industrial sewage plants discharge processed waste from the Vermont side.

In 2008, the EPA expressed concerns to the State of Vermont that the Lake's cleanup was not progressing fast enough to meet the original cleanup goal of 2016. The state, however, cites its Clean and Clear Action Plan as a model that will produce positive results for Lake Champlain.

In 2007, Vermont banned phosphates for dishwasher use starting in 2010. This will prevent an estimated from flowing into the lake. While this represents 0.6% of the phosphate pollution, it took US$1.9 million to remove the pollutant from treated wastewater, an EPA requirement.

Despite concerns about pollution, Lake Champlain is safe for swimming, fishing, and boating. It is considered a world-class fishery for salmonid species (Lake trout and Atlantic salmon) and bass. About 81 fish species live in the lake, and more than 300 bird species rely on it for habitat and as a resource during migrations.

By 2008, at least six institutions were monitoring lake water health:

In 2001, scientists estimated that farming contributed 38% of the phosphorus runoff. By 2010, results of environmentally conscious farming practices, enforced by law, had made any positive contribution to lake cleanliness. A federally funded study was started to analyze this problem and to arrive at a solution.

Biologists have been trying to control lampreys in the lake since 1985 or earlier. Lampreys are native to the area but have expanded in population to such an extent that they wounded nearly all lake trout in 2006 and 70–80% of salmon. The use of pesticides against the lamprey has reduced their casualties of other fish to 35% of salmon and 31% of lake trout. The goal was 15% of salmon and 25% of lake trout.

The federal and state governments originally budgeted US$18 million for lake programs for 2010. This was later supplemented by an additional US$6.5 million from the federal government.

In 2010, the estimate of cormorant population, now classified as a nuisance species because they take so much of the lake fish, ranged from 14,000 to 16,000. A Fish and Wildlife commissioner said the ideal population would be 3,300 or about . Cormorants had disappeared from the lake (and all northern lakes) due to the use of DDT in the 1940s and 1950s, which made their eggs more fragile and reduced breeding populations.

Ring-billed gulls are also considered a nuisance, and measures have been taken to reduce their population. Authorities are trying to encourage the return of black crowned night herons, cattle egrets, and great blue herons, which disappeared during the time DDT was being widely used.

In 1989, UNESCO designated the area around Lake Champlain as the Champlain-Adirondack Biosphere Reserve.

The Alburgh Peninsula (also known as the Alburgh Tongue), extending south from the Quebec shore of the lake into Vermont, and Province Point, the southernmost tip of a small promontory approximately in size a few miles (kilometres) to the northeast of the town of East Alburgh, Vermont, are connected by land to the rest of the state only via Canada. This is a distinction shared with the state of Alaska, Point Roberts, Washington, and the Northwest Angle in Minnesota. All of these are practical exclaves of the United States contiguous with Canada. Unlike the other cases, highway bridges across the lake provide direct access to the Alburgh peninsula from within the United States (from three directions). 

Two roadways cross over the lake, connecting Vermont and New York:


In 2009, the bridge had been used by 3,400 drivers per day, and driving around the southern end of the lake added two hours to the trip. Ferry service was re-established to take some of the traffic burden. On December 28, 2009, the bridge was destroyed by a controlled demolition. A new bridge was rapidly constructed by a joint state commitment, opening on November 7, 2011.


North of Ticonderoga, New York, the lake widens appreciably; ferry service is operated by the Lake Champlain Transportation Company at:

While the old bridge was being demolished and the new one constructed, Lake Champlain Transportation
Company operated a free, 24-hour ferry from just south of the bridge to Chimney
Point in Vermont at the expense of the states of New York and Vermont at a cost to the states of about $10 per car.

The most southerly crossing is the Fort Ticonderoga Ferry, connecting Ticonderoga, New York with Shoreham, Vermont, just north of the historic fort.

Four significant railroad crossings were built over the lake. As of 2016, only one remains.

Now called Colchester Park, the main three-mile (5 km) causeway has been adapted and preserved as a recreation area for cyclists, runners, and anglers. Two smaller marble rock-landfill causeways were also erected as part of this line that connected Grand Isle to North Hero, and spanned from North Hero to Alburgh.


Lake Champlain has been connected to the Erie Canal via the Champlain Canal since the canal's official opening September 9, 1823, the same day as the opening of the Erie Canal from Rochester on Lake Ontario to Albany. It connects to the St. Lawrence River via the Richelieu River, with the Chambly Canal bypassing rapids on the river since 1843. Together with these waterways the lake is part of the Lakes to Locks Passage. The Lake Champlain Seaway, a project to use the lake to bring ocean-going ships from New York City to Montreal, was proposed in the late 19th century and considered as late as the 1960s, but rejected for various reasons. The lake is also part of the 740-mile Northern Forest Canoe Trail, which begins in Old Forge, New York, and ends in Fort Kent, Maine.

Burlington, Vermont (pop. 42,217, 2010 Census) is the largest city on the lake. The 2nd and 3rd most populated cities/towns are Plattsburgh, New York, and South Burlington, Vermont, respectively. The fourth-largest community is the town of Colchester.

Lake Champlain contains roughly 80 islands, three of which comprise four entire Vermont towns (most of Grand Isle County). The largest islands:


All active navigational aids on the American portion of the lake are maintained by USCG Burlington station, along with those on international Lake Memphremagog to the east.
Aids to navigation on the Canadian portion of the lake are maintained by the Canadian Coast Guard.

There are a number of parks in the Lake Champlain region in both New York and Vermont.

Those on the New York side of the lake include: Point Au Roche State Park, which park grounds have hiking and cross country skiing trails, and a public beach; and the Ausable Point State Park. The Cumberland Bay State Park is located on Cumberland Head, with a campground, city beach, and sports fields.

There are various parks along the lake on the Vermont side, including Sand Bar State Park in Milton, featuring a natural sand beach, swimming, canoe and kayak rentals, food concession, picnic grounds and a play area. At , Grand Isle State Park contains camping facilities, a sand volleyball court, a nature walk trail, a horseshoe pit and a play area. Button Bay State Park in Ferrisburgh features campsites, picnic areas, a nature center and a swimming pool. Burlington's Waterfront Park is a revitalized industrial area.

Coast Guard Station Burlington provides "Search and Rescue, Law Enforcement and Ice Rescue services 24 hours a day, 365 days a year." Services are also provided by local, and state, and federal governments bordering on the lake, including the U.S. Border Patrol, Royal Canadian Mounted Police, Vermont State Police, New York State Police Marine Detail, and Vermont Fish and Wildlife wardens.




</doc>
<doc id="18203" url="https://en.wikipedia.org/wiki?curid=18203" title="Lambda calculus">
Lambda calculus

Lambda calculus (also written as λ-calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution. It is a universal model of computation that can be used to simulate any Turing machine. It was introduced by the mathematician Alonzo Church in the 1930s as part of his research into the foundations of mathematics.

Lambda calculus consists of constructing lambda terms and performing reduction operations on them. In the simplest form of lambda calculus, terms are built using only the following rules:
producing expressions such as: (λ"x".λ"y".(λ"z".(λ"x"."z x") (λ"y"."z y")) ("x y")). Parentheses can be dropped if the expression is unambiguous. For some applications, terms for logical and mathematical constants and operations may be included.

The reduction operations include:

If De Bruijn indexing is used, then α-conversion is no longer required as there will be no name collisions. If repeated application of the reduction steps eventually terminates, then by the Church–Rosser theorem it will produce a β-normal form.

Lambda calculus is Turing complete, that is, it is a universal model of computation that can be used to simulate any Turing machine. Its namesake, the Greek letter lambda (λ), is used in lambda expressions and lambda terms to denote binding a variable in a function.

Lambda calculus may be "untyped" or "typed". In typed lambda calculus, functions can be applied only if they are capable of accepting the given input's "type" of data. Typed lambda calculi are "weaker" than the untyped lambda calculus, which is the primary subject of this article, in the sense that "typed lambda calculi can express less" than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proved; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate. One reason there are many different typed lambda calculi has been the desire to do more (of what the untyped calculus can do) without giving up on being able to prove strong theorems about the calculus.

Lambda calculus has applications in many different areas in mathematics, philosophy, linguistics, and computer science. Lambda calculus has played an important role in the development of the theory of programming languages. Functional programming languages implement the lambda calculus. Lambda calculus is also a current research topic in Category theory.

The lambda calculus was introduced by mathematician Alonzo Church in the 1930s as part of an investigation into the foundations of mathematics. The original system was shown to be logically inconsistent in 1935 when Stephen Kleene and J. B. Rosser developed the Kleene–Rosser paradox.

Subsequently, in 1936 Church isolated and published just the portion relevant to computation, what is now called the untyped lambda calculus. In 1940, he also introduced a computationally weaker, but logically consistent system, known as the simply typed lambda calculus.

Until the 1960s when its relation to programming languages was clarified, the lambda calculus was only a formalism. Thanks to Richard Montague and other linguists' applications in the semantics of natural language, the lambda calculus has begun to enjoy a respectable place in both linguistics and computer science.

There is a bit of controversy over the reason for Church's use of the Greek letter lambda (λ) as the notation for function-abstraction in the lambda calculus, perhaps in part due to conflicting explanations by Church himself. According to Cardone and Hindley (2006):

By the way, why did Church choose the notation “λ”? In [an unpublished 1964 letter to Harald Dickson] he stated clearly that it came from the notation “formula_1” used for class-abstraction by Whitehead and Russell, by first modifying “formula_1” to “∧formula_3” to distinguish function-abstraction from class-abstraction, and then changing “∧” to “λ” for ease of printing.

This origin was also reported in [Rosser, 1984, p.338]. On the other hand, in his later years Church told two enquirers that the choice was more accidental: a symbol was needed and λ just happened to be chosen.

Dana Scott has also addressed this controversy in various public lectures.
Scott recounts that he once posed a question about the origin of the lambda symbol to Church's son-in-law John Addison, who then wrote his father-in-law a postcard:

Dear Professor Church,

Russell had the iota operator, Hilbert had the epsilon operator. Why did you choose lambda for your operator?

According to Scott, Church's entire response consisted of returning the postcard with the following annotation: "eeny, meeny, miny, moe".

Computable functions are a fundamental concept within computer science and mathematics. The lambda calculus provides a simple semantics for computation, enabling properties of computation to be studied formally. The lambda calculus incorporates two simplifications that make this semantics simple.
The first simplification is that the lambda calculus treats functions "anonymously", without giving them explicit names. For example, the function 
can be rewritten in "anonymous form" as 
(read as "a tuple of and is mapped to formula_6"). Similarly, 
can be rewritten in anonymous form as
where the input is simply mapped to itself.

The second simplification is that the lambda calculus only uses functions of a single input. An ordinary function that requires two inputs, for instance the formula_9 function, can be reworked into an equivalent function that accepts a single input, and as output returns "another" function, that in turn accepts a single input. For example, 
can be reworked into 
This method, known as currying, transforms a function that takes multiple arguments into a chain of functions each with a single argument.

Function application of the formula_9 function to the arguments (5, 2), yields at once
whereas evaluation of the curried version requires one more step
to arrive at the same result.

The lambda calculus consists of a language of lambda terms, which is defined by a certain formal syntax, and a set of transformation rules, which allow manipulation of the lambda terms. These transformation rules can be viewed as an equational theory or as an operational definition.

As described above, all functions in the lambda calculus are anonymous functions, having no names. They only accept one input variable, with currying used to implement functions with several variables.

The syntax of the lambda calculus defines some expressions as valid lambda calculus expressions and some as invalid, just as some strings of characters are valid C programs and some are not. A valid lambda calculus expression is called a "lambda term".

The following three rules give an inductive definition that can be applied to build all syntactically valid lambda terms:
Nothing else is a lambda term. Thus a lambda term is valid if and only if it can be obtained by repeated application of these three rules. However, some parentheses can be omitted according to certain rules. For example, the outermost parentheses are usually not written. See "Notation", below.

An abstraction formula_31 is a definition of an anonymous function that is capable of taking a single input formula_3 and substituting it into the expression formula_25. 
It thus defines an anonymous function that takes formula_3 and returns formula_25. For example, formula_36 is an abstraction for the function formula_37 using the term formula_38 for formula_25. The definition of a function with an abstraction merely "sets up" the function but does not invoke it. The abstraction binds the variable formula_3 in the term formula_25.

An application formula_42 represents the application of a function formula_25 to an input formula_29, that is, it represents the act of calling function formula_25 on input formula_29 to produce formula_47.

There is no concept in lambda calculus of variable declaration. In a definition such as formula_48 (i.e. formula_49), the lambda calculus treats formula_21 as a variable that is not yet defined. The abstraction formula_48 is syntactically valid, and represents a function that adds its input to the yet-unknown formula_21.

Bracketing may be used and may be needed to disambiguate terms. For example, formula_53 and formula_54 denote different terms (although they coincidentally reduce to the same value). Here, the first example defines a function whose lambda term is the result of applying x to the child function, while the second example is the application of the outermost function to the input x, which returns the child function. Therefore, both examples evaluate to the identity function formula_55.

In lambda calculus, functions are taken to be 'first class values', so functions may be used as the inputs, or be returned as outputs from other functions.

For example, formula_55 represents the identity function, formula_8, and formula_58 represents the identity function applied to formula_21. Further, formula_60 represents the constant function formula_61, the function that always returns formula_21, no matter the input. In lambda calculus, function application is regarded as left-associative, so that formula_63 means formula_64.

There are several notions of "equivalence" and "reduction" that allow lambda terms to be "reduced" to "equivalent" lambda terms.

A basic form of equivalence, definable on lambda terms, is alpha equivalence. It captures the intuition that the particular choice of a bound variable, in an abstraction, does not (usually) matter.
For instance, formula_55 and formula_66 are alpha-equivalent lambda terms, and they both represent the same function (the identity function). 
The terms formula_3 and formula_21 are not alpha-equivalent, because they are not bound in an abstraction.
In many presentations, it is usual to identify alpha-equivalent lambda terms.

The following definitions are necessary in order to be able to define β-reduction:

The free variables of a term are those variables not bound by an abstraction. The set of free variables of an expression is defined inductively:

For example, the lambda term representing the identity formula_55 has no free variables, but the function formula_78 has a single free variable, formula_21.

Suppose formula_25, formula_29 and formula_82 are lambda terms and formula_3 and formula_21 are variables.
The notation formula_85 indicates substitution of formula_82 for formula_3 in formula_25 in a "capture-avoiding" manner. This is defined so that:

For example, formula_100, and formula_101.

The freshness condition (requiring that formula_21 is not in the free variables of formula_82) is crucial in order to ensure that substitution does not change the meaning of functions.
For example, a substitution is made that ignores the freshness condition: formula_104. This substitution turns the constant function formula_105 into the identity formula_55 by substitution.

In general, failure to meet the freshness condition can be remedied by alpha-renaming with a suitable fresh variable.
For example, switching back to our correct notion of substitution, in formula_107 the abstraction can be renamed with a fresh variable formula_108, to obtain formula_109, and the meaning of the function is preserved by substitution.

The β-reduction rule states that an application of the form formula_110 reduces to the term formula_111. The notation formula_112 is used to indicate that formula_113 β-reduces to formula_114.
For example, for every formula_29, formula_116. This demonstrates that formula_117 really is the identity.
Similarly, formula_118, which demonstrates that formula_119 is a constant function.

The lambda calculus may be seen as an idealised version of a functional programming language, like Haskell or Standard ML.
Under this view, β-reduction corresponds to a computational step. This step can be repeated by additional β-reductions until there are no more applications left to reduce. In the untyped lambda calculus, as presented here, this reduction process may not terminate.
For instance, consider the term formula_120.
Here formula_121.
That is, the term reduces to itself in a single β-reduction, and therefore the reduction process will never terminate.

Another aspect of the untyped lambda calculus is that it does not distinguish between different kinds of data.
For instance, it may be desirable to write a function that only operates on numbers. However, in the untyped lambda calculus, there is no way to prevent a function from being applied to truth values, strings, or other non-number objects.

Lambda expressions are composed of:


The set of lambda expressions, Λ, can be defined inductively:


Instances of rule 2 are known as "abstractions" and instances of rule 3 are known as "applications".

To keep the notation of lambda expressions uncluttered, the following conventions are usually applied:

The abstraction operator, λ, is said to bind its variable wherever it occurs in the body of the abstraction. Variables that fall within the scope of an abstraction are said to be "bound". In an expression λ"x"."M", the part λ"x" is often called "binder", as a hint that the variable "x" is getting bound by appending λ"x" to "M". All other variables are called "free". For example, in the expression λ"y"."x x y", "y" is a bound variable and "x" is a free variable. Also a variable is bound by its nearest abstraction. In the following example the single occurrence of "x" in the expression is bound by the second lambda: λ"x"."y" (λ"x"."z x").

The set of "free variables" of a lambda expression, "M", is denoted as FV("M") and is defined by recursion on the structure of the terms, as follows:

An expression that contains no free variables is said to be "closed". Closed lambda expressions are also known as "combinators" and are equivalent to terms in combinatory logic.

The meaning of lambda expressions is defined by how expressions can be reduced.

There are three kinds of reduction:

We also speak of the resulting equivalences: two expressions are "α-equivalent", if they can be α-converted into the same expression. β-equivalence and η-equivalence are defined similarly.

The term "redex", short for "reducible expression", refers to subterms that can be reduced by one of the reduction rules. For example, (λ"x"."M") "N" is a β-redex in expressing the substitution of "N" for "x" in "M". The expression to which a redex reduces is called its "reduct"; the reduct of (λ"x"."M") "N" is "M"["x" := "N"].

If "x" is not free in "M", λ"x"."M x" is also an η-redex, with a reduct of "M".

α-conversion, sometimes known as α-renaming, allows bound variable names to be changed. For example, α-conversion of λ"x"."x" might yield λ"y"."y". Terms that differ only by α-conversion are called "α-equivalent". Frequently, in uses of lambda calculus, α-equivalent terms are considered to be equivalent.

The precise rules for α-conversion are not completely trivial. First, when α-converting an abstraction, the only variable occurrences that are renamed are those that are bound to the same abstraction. For example, an α-conversion of λ"x".λ"x"."x" could result in λ"y".λ"x"."x", but it could "not" result in λ"y".λ"x"."y". The latter has a different meaning from the original. This is analogous to the programming notion of variable shadowing.

Second, α-conversion is not possible if it would result in a variable getting captured by a different abstraction. For example, if we replace "x" with "y" in λ"x".λ"y"."x", we get λ"y".λ"y"."y", which is not at all the same.

In programming languages with static scope, α-conversion can be used to make name resolution simpler by ensuring that no variable name masks a name in a containing scope (see α-renaming to make name resolution trivial).

In the De Bruijn index notation, any two α-equivalent terms are syntactically identical.

Substitution, written "M"["V" := "N"], is the process of replacing all "free" occurrences of the variable "V" in the expression "M" with expression "N". Substitution on terms of the lambda calculus is defined by recursion on the structure of terms, as follows (note: x and y are only variables while M and N are any lambda expression):

To substitute into an abstraction, it is sometimes necessary to α-convert the expression. For example, it is not correct for (λ"x"."y")["y" := "x"] to result in λ"x"."x", because the substituted "x" was supposed to be free but ended up being bound. The correct substitution in this case is λ"z"."x", up to α-equivalence. Substitution is defined uniquely up to α-equivalence.

β-reduction captures the idea of function application. β-reduction is defined in terms of substitution: the β-reduction of (λ"V"."M") "N" is "M"["V" := "N"].

For example, assuming some encoding of 2, 7, ×, we have the following β-reduction: (λ"n"."n" × 2) 7 → 7 × 2.

β-reduction can be seen to be the same as the concept of "local reducibility" in natural deduction, via the Curry–Howard isomorphism.

η-reduction expresses the idea of extensionality, which in this context is that two functions are the same if and only if they give the same result for all arguments. η-reduction converts between λ"x"."f" "x" and "f" whenever "x" does not appear free in "f".

η-reduction can be seen to be the same as the concept of "local completeness" in natural deduction, via the Curry–Howard isomorphism.

For the untyped lambda calculus, β-reduction as a rewriting rule is neither strongly normalising nor weakly normalising.

However, it can be shown that β-reduction is confluent when working up to α-conversion (i.e. we consider two normal forms to be equal if it is possible to α-convert one into the other).

Therefore, both strongly normalising terms and weakly normalising terms have a unique normal form. For strongly normalising terms, any reduction strategy is guaranteed to yield the normal form, whereas for weakly normalising terms, some reduction strategies may fail to find it.

The basic lambda calculus may be used to model booleans, arithmetic, data structures and recursion, as illustrated in the following sub-sections.

There are several possible ways to define the natural numbers in lambda calculus, but by far the most common are the Church numerals, which can be defined as follows:
and so on. Or using the alternative syntax presented above in "Notation":

A Church numeral is a higher-order function—it takes a single-argument function "f", and returns another single-argument function. The Church numeral "n" is a function that takes a function "f" as argument and returns the "n"-th composition of "f", i.e. the function "f" composed with itself "n" times. This is denoted "f" and is in fact the "n"-th power of "f" (considered as an operator); "f" is defined to be the identity function. Such repeated compositions (of a single function "f") obey the laws of exponents, which is why these numerals can be used for arithmetic. (In Church's original lambda calculus, the formal parameter of a lambda expression was required to occur at least once in the function body, which made the above definition of 0 impossible.)

One way of thinking about the Church numeral "n", which is often useful when analysing programs, is as an instruction 'repeat "n" times'. For example, using the PAIR and NIL functions defined below, one can define a function that constructs a (linked) list of "n" elements all equal to "x" by repeating 'prepend another "x" element' "n" times, starting from an empty list. The lambda term is
By varying what is being repeated, and varying what argument that function being repeated is applied to, a great many different effects can be achieved.

We can define a successor function, which takes a Church numeral "n" and returns "n" + 1 by adding another application of "f", where '(mf)x' means the function 'f' is applied 'm' times on 'x':
Because the "m"-th composition of "f" composed with the "n"-th composition of "f" gives the "m"+"n"-th composition of "f", addition can be defined as follows:
PLUS can be thought of as a function taking two natural numbers as arguments and returning a natural number; it can be verified that
and
are β-equivalent lambda expressions. Since adding "m" to a number "n" can be accomplished by adding 1 "m" times, an alternative definition is:
Similarly, multiplication can be defined as
Alternatively
since multiplying "m" and "n" is the same as repeating the add "n" function "m" times and then applying it to zero.
Exponentiation has a rather simple rendering in Church numerals, namely
The predecessor function defined by PRED "n" = "n" − 1 for a positive integer "n" and PRED 0 = 0 is considerably more difficult. The formula
can be validated by showing inductively that if "T" denotes (λ"g".λ"h"."h" ("g" "f")), then T(λ"u"."x") = (λ"h"."h"("f"("x"))) for "n" > 0. Two other definitions of PRED are given below, one using conditionals and the other using pairs. With the predecessor function, subtraction is straightforward. Defining
SUB "m" "n" yields "m" − "n" when "m" > "n" and 0 otherwise.

By convention, the following two definitions (known as Church booleans) are used for the boolean values TRUE and FALSE:
Then, with these two lambda terms, we can define some logic operators (these are just possible formulations; other expressions are equally correct):
We are now able to compute some logic functions, for example:

and we see that AND TRUE FALSE is equivalent to FALSE.

A "predicate" is a function that returns a boolean value. The most fundamental predicate is ISZERO, which returns TRUE if its argument is the Church numeral 0, and FALSE if its argument is any other Church numeral:
The following predicate tests whether the first argument is less-than-or-equal-to the second:
and since "m" = "n", if LEQ "m" "n" and LEQ "n" "m", it is straightforward to build a predicate for numerical equality.

The availability of predicates and the above definition of TRUE and FALSE make it convenient to write "if-then-else" expressions in lambda calculus. For example, the predecessor function can be defined as:
which can be verified by showing inductively that "n" (λ"g".λ"k".ISZERO ("g" 1) "k" (PLUS ("g" "k") 1)) (λ"v".0) is the add "n" − 1 function for "n" > 0.

A pair (2-tuple) can be defined in terms of TRUE and FALSE, by using the Church encoding for pairs. For example, PAIR encapsulates the pair ("x","y"), FIRST returns the first element of the pair, and SECOND returns the second.

A linked list can be defined as either NIL for the empty list, or the PAIR of an element and a smaller list. The predicate NULL tests for the value NIL. (Alternatively, with NIL := FALSE, the construct "l" (λ"h".λ"t".λ"z".deal_with_head_"h"_and_tail_"t") (deal_with_nil) obviates the need for an explicit NULL test).

As an example of the use of pairs, the shift-and-increment function that maps ("m", "n") to ("n", "n" + 1) can be defined as
which allows us to give perhaps the most transparent version of the predecessor function:

There is a considerable body of programming idioms for lambda calculus. Many of these were originally developed in the context of using lambda calculus as a foundation for programming language semantics, effectively using lambda calculus as a low-level programming language. Because several programming languages include the lambda calculus (or something very similar) as a fragment, these techniques also see use in practical programming, but may then be perceived as obscure or foreign.

In lambda calculus, a library would take the form of a collection of previously defined functions, which as lambda-terms are merely particular constants. The pure lambda calculus does not have a concept of named constants since all atomic lambda-terms are variables, but one can emulate having named constants by setting aside a variable as the name of the constant, using abstraction to bind that variable in the main body, and apply that abstraction to the intended definition. Thus to use "f" to mean "M" (some explicit lambda-term) in "N" (another lambda-term, the "main program"), one can say
Authors often introduce syntactic sugar, such as let, to permit writing the above in the more intuitive order
By chaining such definitions, one can write a lambda calculus "program" as zero or more function definitions, followed by one lambda-term using those functions that constitutes the main body of the program.

A notable restriction of this let is that the name "f" is not defined in "M", since "M" is outside the scope of the abstraction binding "f"; this means a recursive function definition cannot be used as the "M" with let. The more advanced letrec syntactic sugar construction that allows writing recursive function definitions in that naive style instead additionally employs fixed-point combinators.

Recursion is the definition of a function using the function itself. Lambda calculus cannot express this as directly as some other notations: all functions are anonymous in lambda calculus, so we can't refer to a value which is yet to be defined, inside the lambda term defining that same value. However, recursion can still be achieved by arranging for a lambda expression to receive itself as its argument value, for example in  (λ"x"."x" "x") "E".

Consider the factorial function F("n") recursively defined by

In the lambda expression which is to represent this function, a "parameter" (typically the first one) will be assumed to receive the lambda expression itself as its value, so that calling it – applying it to an argument – will amount to recursion. Thus to achieve recursion, the intended-as-self-referencing argument (called "r" here) must always be passed to itself within the function body, at a call point:

The self-application achieves replication here, passing the function's lambda expression on to the next invocation as an argument value, making it available to be referenced and called there.

This solves it but requires re-writing each recursive call as self-application. We would like to have a generic solution, without a need for any re-writes:

Given a lambda term with first argument representing recursive call (e.g. G here), the "fixed-point" combinator FIX will return a self-replicating lambda expression representing the recursive function (here, F). The function does not need to be explicitly passed to itself at any point, for the self-replication is arranged in advance, when it is created, to be done each time it is called. Thus the original lambda expression (FIX G) is re-created inside itself, at call-point, achieving self-reference.

In fact, there are many possible definitions for this FIX operator, the simplest of them being:

In the lambda calculus, Y "g"  is a fixed-point of "g", as it expands to:

Now, to perform our recursive call to the factorial function, we would simply call (Y G) "n",  where "n" is the number we are calculating the factorial of. Given "n" = 4, for example, this gives:

Every recursively defined function can be seen as a fixed point of some suitably defined function closing over the recursive call with an extra argument, and therefore, using Y, every recursively defined function can be expressed as a lambda expression. In particular, we can now cleanly define the subtraction, multiplication and comparison predicate of natural numbers recursively.

Certain terms have commonly accepted names:
Several of these have direct applications in the "elimination of abstraction" that turns lambda terms into combinator calculus terms.

If "N" is a lambda-term without abstraction, but possibly containing named constants (combinators), then there exists a lambda-term "T"("x","N") which is equivalent to λ"x"."N" but lacks abstraction (except as part of the named constants, if these are considered non-atomic). This can also be viewed as anonymising variables, as "T"("x","N") removes all occurrences of "x" from "N", while still allowing argument values to be substituted into the positions where "N" contains an "x". The conversion function "T" can be defined by:
In either case, a term of the form "T"("x","N") "P" can reduce by having the initial combinator I, K, or S grab the argument "P", just like β-reduction of (λ"x"."N") "P" would do. I returns that argument. K throws the argument away, just like (λ"x"."N") would do if "x" has no free occurrence in "N". S passes the argument on to both subterms of the application, and then applies the result of the first to the result of the second.

The combinators B and C are similar to S, but pass the argument on to only one subterm of an application (B to the "argument" subterm and C to the "function" subterm), thus saving a subsequent K if there is no occurrence of "x" in one subterm. In comparison to B and C, the S combinator actually conflates two functionalities: rearranging arguments, and duplicating an argument so that it may be used in two places. The W combinator does only the latter, yielding the B, C, K, W system as an alternative to SKI combinator calculus.

A typed lambda calculus is a typed formalism that uses the lambda-symbol (formula_122) to denote anonymous function abstraction. In this context, types are usually objects of a syntactic nature that are assigned to lambda terms; the exact nature of a type depends on the calculus considered (see kinds below). From a certain point of view, typed lambda calculi can be seen as refinements of the untyped lambda calculus but from another point of view, they can also be considered the more fundamental theory and "untyped lambda calculus" a special case with only one type.

Typed lambda calculi are foundational programming languages and are the base of typed functional programming languages such as ML and Haskell and, more indirectly, typed imperative programming languages. Typed lambda calculi play an important role in the design of type systems for programming languages; here typability usually captures desirable properties of the program, e.g. the program will not cause a memory access violation.

Typed lambda calculi are closely related to mathematical logic and proof theory via the Curry–Howard isomorphism and they can be considered as the internal language of classes of categories, e.g. the simply typed lambda calculus is the language of Cartesian closed categories (CCCs).

A function "F": N → N of natural numbers is a computable function if and only if there exists a lambda expression "f" such that for every pair of "x", "y" in N, "F"("x")="y" if and only if "f" "x" = "y",  where "x" and "y" are the Church numerals corresponding to "x" and "y", respectively and = meaning equivalence with β-reduction. This is one of the many ways to define computability; see the Church–Turing thesis for a discussion of other approaches and their equivalence.

There is no algorithm that takes as input any two lambda expressions and outputs TRUE or FALSE depending on whether or not the two expressions are equivalent. More precisely, no computable function can decide the equivalence. This was historically the first problem for which undecidability could be proven. As usual for such a proof, "computable" means computable by any model of computation that is Turing complete.

Church's proof first reduces the problem to determining whether a given lambda expression has a "normal form". A normal form is an equivalent expression that cannot be reduced any further under the rules imposed by the form. Then he assumes that this predicate is computable, and can hence be expressed in lambda calculus. Building on earlier work by Kleene and constructing a Gödel numbering for lambda expressions, he constructs a lambda expression "e" that closely follows the proof of Gödel's first incompleteness theorem. If "e" is applied to its own Gödel number, a contradiction results.

As pointed out by Peter Landin's 1965 paper "A Correspondence between ALGOL 60 and Church's Lambda-notation", sequential procedural programming languages can be understood in terms of the lambda calculus, which provides the basic mechanisms for procedural abstraction and procedure (subprogram) application.

For example, in Lisp the "square" function can be expressed as a lambda expression as follows:

The above example is an expression that evaluates to a first-class function. The symbol codice_1 creates an anonymous function, given a list of parameter names, codice_2 – just a single argument in this case, and an expression that is evaluated as the body of the function, codice_3. Anonymous functions are sometimes called lambda expressions.

For example, Pascal and many other imperative languages have long supported passing subprograms as arguments to other subprograms through the mechanism of function pointers. However, function pointers are not a sufficient condition for functions to be first class datatypes, because a function is a first class datatype if and only if new instances of the function can be created at run-time. And this run-time creation of functions is supported in Smalltalk, JavaScript, and more recently in Scala, Eiffel ("agents"), C# ("delegates") and C++11, among others.

Whether a term is normalising or not, and how much work needs to be done in normalising it if it is, depends to a large extent on the reduction strategy used. The distinction between reduction strategies relates to the distinction in functional programming languages between eager evaluation and lazy evaluation.


Applicative order is not a normalising strategy. The usual counterexample is as follows: define Ω = ωω where ω = λ"x"."xx". This entire expression contains only one redex, namely the whole expression; its reduct is again Ω. Since this is the only available reduction, Ω has no normal form (under any evaluation strategy). Using applicative order, the expression KIΩ = (λ"x".λ"y"."x") (λ"x"."x")Ω is reduced by first reducing Ω to normal form (since it is the rightmost redex), but since Ω has no normal form, applicative order fails to find a normal form for KIΩ.

In contrast, normal order is so called because it always finds a normalising reduction, if one exists. In the above example, KIΩ reduces under normal order to "I", a normal form. A drawback is that redexes in the arguments may be copied, resulting in duplicated computation (for example, (λ"x"."xx") ((λ"x"."x")"y") reduces to ((λ"x"."x")"y") ((λ"x"."x")"y") using this strategy; now there are two redexes, so full evaluation needs two more steps, but if the argument had been reduced first, there would now be none).

The positive tradeoff of using applicative order is that it does not cause unnecessary computation, if all arguments are used, because it never substitutes arguments containing redexes and hence never needs to copy them (which would duplicate work). In the above example, in applicative order (λ"x"."xx") ((λ"x"."x")"y") reduces first to (λ"x"."xx")"y" and then to the normal order "yy", taking two steps instead of three.

Most "purely" functional programming languages (notably Miranda and its descendants, including Haskell), and the proof languages of theorem provers, use "lazy evaluation", which is essentially the same as call by need. This is like normal order reduction, but call by need manages to avoid the duplication of work inherent in normal order reduction using "sharing". In the example given above, (λ"x"."xx") ((λ"x"."x")"y") reduces to ((λ"x"."x")"y") ((λ"x"."x")"y"), which has two redexes, but in call by need they are represented using the same object rather than copied, so when one is reduced the other is too.

While the idea of β-reduction seems simple enough, it is not an atomic step, in that it must have a non-trivial cost when estimating computational complexity. To be precise, one must somehow find the location of all of the occurrences of the bound variable "V" in the expression "E", implying a time cost, or one must keep track of these locations in some way, implying a space cost. A naïve search for the locations of "V" in "E" is "O"("n") in the length "n" of "E". This has led to the study of systems that use explicit substitution. Sinot's director strings offer a way of tracking the locations of free variables in expressions.

The Church–Rosser property of the lambda calculus means that evaluation (β-reduction) can be carried out in "any order", even in parallel. This means that various nondeterministic evaluation strategies are relevant. However, the lambda calculus does not offer any explicit constructs for parallelism. One can add constructs such as Futures to the lambda calculus. Other process calculi have been developed for describing communication and concurrency.

In Lévy's 1988 paper "Sharing in the Evaluation of lambda Expressions", he defines a notion of optimal sharing, such that no work is "duplicated". For example, performing a β-reduction in normal order on (λ"x"."xx") (II) reduces it to II (II). The argument II is duplicated by the application to the first lambda term. If the reduction was done in an applicative order first, we save work because work is not duplicated: (λ"x"."xx") (II) reduces to (λ"x"."xx") I. On the other hand, using applicative order can result in redundant reductions or even possibly never reduce to normal form. For example, performing a β-reduction in normal order on (λ"f".f I) (λy.(λ"x"."xx") (y I)) yields (λy.(λ"x"."xx") (y I)) I, (λ"x"."xx") (II) which we know we can do without duplicating work. Doing the same but in applicative order yields (λ"f".f I) (λy.y I (y I)), (λy.y I (y I)) I, I I (I I), and now work is duplicated.

Lévy shows the existence of lambda terms where there "does not exist" a sequence of reductions which reduces them without duplicating work. The below lambda term is such an example.

It is composed of three similar terms, x=((λg. ... ) (λh.y)) and y=((λf. ...) (λw.z) ), and finally z=λw.(h(w(λy.y))). There are only two possible β-reductions to be done here, on x and on y. Reducing the outer x term first results in the inner y term being duplicated, and each copy will have to be reduced, but reducing the inner y term first will duplicate its argument z, which will cause work to be duplicated when the values of h and w are made known. Incidentally, the above term reduces to the identity function (λy.y), and is constructed by making wrappers which make the identity function available to the binders g=λh..., f=λw..., h=λx.x (at first), and w=λz.z (at first), all of which are applied to the innermost term λy.y.

The precise notion of duplicated work relies on noticing that after the first reduction of I I is done, the value of the other I I can be determined, because they have the same structure (and in fact they have exactly the same values), and result from a common ancestor. Such similar structures can each be assigned a label that can be tracked across reductions. If a name is assigned to the redex that produces all the resulting II terms, and then all duplicated occurrences of II can be tracked and reduced in one go. However, it is not obvious that a redex will produce the II term. Identifying the structures that are similar in different parts of a lambda term can involve a complex algorithm and can possibly have a complexity equal to the history of the reduction itself.

While Lévy defines the notion of optimal sharing, he does not provide an algorithm to do it. In Vincent van Oostrom, Kees-Jan van de Looij, and Marijn Zwitserlood's paper "Lambdascope: Another optimal implementation of the lambda-calculus", they provide such an algorithm by transforming lambda terms into interaction nets, which are then reduced. Roughly speaking, the resulting reduction is optimal because every term that would have the same labels as per Lévy's paper would also be the same graph in the interaction net. In the paper, they mention that their prototype implementation of Lambdascope performs as well as the "optimised" version of the reference optimal higher order machine BOHM.

More details can be found in the short article About the efficient reduction of lambda terms.

The fact that lambda calculus terms act as functions on other lambda calculus terms, and even on themselves, led to questions about the semantics of the lambda calculus. Could a sensible meaning be assigned to lambda calculus terms? The natural semantics was to find a set "D" isomorphic to the function space "D" → "D", of functions on itself. However, no nontrivial such "D" can exist, by cardinality constraints because the set of all functions from "D" to "D" has greater cardinality than "D", unless "D" is a singleton set.

In the 1970s, Dana Scott showed that, if only continuous functions were considered, a set or domain "D" with the required property could be found, thus providing a model for the lambda calculus.

This work also formed the basis for the denotational semantics of programming languages.

These extensions are in the lambda cube:

These formal systems are extensions of lambda calculus that are not in the lambda cube:

These formal systems are variations of lambda calculus:

These formal systems are related to lambda calculus:


Monographs/textbooks for graduate students:

"Some parts of this article are based on material from FOLDOC, used with ."



</doc>
<doc id="18208" url="https://en.wikipedia.org/wiki?curid=18208" title="Lossy compression">
Lossy compression

In information technology, lossy compression or irreversible compression is the class of data encoding methods that uses inexact approximations and partial data discarding to represent the content. These techniques are used to reduce data size for storing, handling, and transmitting content. The different versions of the photo of the cat to the right show how higher degrees of approximation create coarser images as more details are removed. This is opposed to lossless data compression (reversible data compression) which does not degrade the data. The amount of data reduction possible using lossy compression is much higher than through lossless techniques.

Well-designed lossy compression technology often reduces file sizes significantly before degradation is noticed by the end-user. Even when noticeable by the user, further data reduction may be desirable (e.g., for real-time communication, to reduce transmission times, or to reduce storage needs). The most widely used lossy compression algorithm is the discrete cosine transform (DCT), first published by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974. Recently, a new family of sinusoidal-hyperbolic transform functions, which have comparable properties and performance with DCT, have been proposed for lossy compression.

Lossy compression is most commonly used to compress multimedia data (audio, video, and images), especially in applications such as streaming media and internet telephony. By contrast, lossless compression is typically required for text and data files, such as bank records and text articles. It can be advantageous to make a master lossless file which can then be used to produce additional copies from. This allows one to avoid basing new compressed copies off of a lossy source file, which would yield additional artifacts and further unnecessary information loss.

It is possible to compress many types of digital data in a way that reduces the size of a computer file needed to store it, or the bandwidth needed to transmit it, with no loss of the full information contained in the original file. A picture, for example, is converted to a digital file by considering it to be an array of dots and specifying the color and brightness of each dot. If the picture contains an area of the same color, it can be compressed without loss by saying "200 red dots" instead of "red dot, red dot, ...(197 more times)..., red dot."

The original data contains a certain amount of information, and there is a lower limit to the size of file that can carry all the information. Basic information theory says that there is an absolute limit in reducing the size of this data. When data is compressed, its entropy increases, and it cannot increase indefinitely. As an intuitive example, most people know that a compressed ZIP file is smaller than the original file, but repeatedly compressing the same file will not reduce the size to nothing. Most compression algorithms can recognize when further compression would be pointless and would in fact increase the size of the data.

In many cases, files or data streams contain more information than is needed for a particular purpose. For example, a picture may have more detail than the eye can distinguish when reproduced at the largest size intended; likewise, an audio file does not need a lot of fine detail during a very loud passage. Developing lossy compression techniques as closely matched to human perception as possible is a complex task. Sometimes the ideal is a file that provides exactly the same perception as the original, with as much digital information as possible removed; other times, perceptible loss of quality is considered a valid trade-off for the reduced data.

The terms 'irreversible' and 'reversible' are preferred over 'lossy' and 'lossless' respectively for some applications, such as medical image compression, to circumvent the negative implications of 'loss'. The type and amount of loss can affect the utility of the images. Artifacts or undesirable effects of compression may be clearly discernible yet the result still useful for the intended purpose. Or lossy compressed images may be 'visually lossless', or in the case of medical images, so-called Diagnostically Acceptable Irreversible Compression (DAIC) may have been applied.

Some forms of lossy compression can be thought of as an application of transform coding, which is a type of data compression used for digital images, digital audio signals, and digital video. The transformation is typically used to enable better (more targeted) quantization. Knowledge of the application is used to choose information to discard, thereby lowering its bandwidth. The remaining information can then be compressed via a variety of methods. When the output is decoded, the result may not be identical to the original input, but is expected to be close enough for the purpose of the application.

The most common form of lossy compression is a transform coding method, the discrete cosine transform (DCT), which was first published by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974. DCT is the most widely used form of lossy compression, for popular image compression formats (such as JPEG), video coding standards (such as MPEG and H.264/AVC) and audio compression formats (such as MP3 and AAC).

In the case of audio data, a popular form of transform coding is perceptual coding, which transforms the raw data to a domain that more accurately reflects the information content. For example, rather than expressing a sound file as the amplitude levels over time, one may express it as the frequency spectrum over time, which corresponds more accurately to human audio perception. While data reduction (compression, be it lossy or lossless) is a main goal of transform coding, it also allows other goals: one may represent data more accurately for the original amount of space – for example, in principle, if one starts with an analog or high-resolution digital master, an MP3 file of a given size should provide a better representation than a raw uncompressed audio in WAV or AIFF file of the same size. This is because uncompressed audio can only reduce file size by lowering bit rate or depth, whereas compressing audio can reduce size while maintaining bit rate and depth. This compression becomes a selective loss of the least significant data, rather than losing data across the board. Further, a transform coding may provide a better domain for manipulating or otherwise editing the data – for example, equalization of audio is most naturally expressed in the frequency domain (boost the bass, for instance) rather than in the raw time domain.

From this point of view, perceptual encoding is not essentially about "discarding" data, but rather about a "better representation" of data. Another use is for backward compatibility and graceful degradation: in color television, encoding color via a luminance-chrominance transform domain (such as YUV) means that black-and-white sets display the luminance, while ignoring the color information. Another example is chroma subsampling: the use of color spaces such as YIQ, used in NTSC, allow one to reduce the resolution on the components to accord with human perception – humans have highest resolution for black-and-white (luma), lower resolution for mid-spectrum colors like yellow and green, and lowest for red and blues – thus NTSC displays approximately 350 pixels of luma per scanline, 150 pixels of yellow vs. green, and 50 pixels of blue vs. red, which are proportional to human sensitivity to each component.

Lossy compression formats suffer from generation loss: repeatedly compressing and decompressing the file will cause it to progressively lose quality. This is in contrast with lossless data compression, where data will not be lost via the use of such a procedure. Information-theoretical foundations for lossy data compression are provided by rate-distortion theory. Much like the use of probability in optimal coding theory, rate-distortion theory heavily draws on Bayesian estimation and decision theory in order to model perceptual distortion and even aesthetic judgment.

There are two basic lossy compression schemes:


In some systems the two techniques are combined, with transform codecs being used to compress the error signals generated by the predictive stage.

The advantage of lossy methods over lossless methods is that in some cases a lossy method can produce a much smaller compressed file than any lossless method, while still meeting the requirements of the application. Lossy methods are most often used for compressing sound, images or videos. This is because these types of data are intended for human interpretation where the mind can easily "fill in the blanks" or see past very minor errors or inconsistencies – ideally lossy compression is transparent (imperceptible), which can be verified via an ABX test. Data files using lossy compression are smaller in size and thus cost less to store and to transmit over the Internet, a crucial consideration for streaming video services such as Netflix and streaming audio services such as Spotify.

A study conducted by the Audio Engineering Library concluded that lossy compression formats such as MP3s have distinct effects on timbral and emotional characteristics, tending to strengthen negative emotional qualities and weaken positive ones. The study further noted that the trumpet is the instrument most affected by compression, while the horn is least.

When a user acquires a lossily compressed file, (for example, to reduce download time) the retrieved file can be quite different from the original at the bit level while being indistinguishable to the human ear or eye for most practical purposes. Many compression methods focus on the idiosyncrasies of human physiology, taking into account, for instance, that the human eye can see only certain wavelengths of light. The psychoacoustic model describes how sound can be highly compressed without degrading perceived quality. Flaws caused by lossy compression that are noticeable to the human eye or ear are known as compression artifacts.

The compression ratio (that is, the size of the compressed file compared to that of the uncompressed file) of lossy video codecs is nearly always far superior to that of the audio and still-image equivalents.


An important caveat about lossy compression (formally transcoding), is that editing lossily compressed files causes digital generation loss from the re-encoding. This can be avoided by only producing lossy files from (lossless) originals and only editing (copies of) original files, such as images in raw image format instead of JPEG. If data which has been compressed lossily is decoded and compressed losslessly, the size of the result can be comparable with the size of the data before lossy compression, but the data already lost cannot be recovered. When deciding to use lossy conversion without keeping the original, one should remember that format conversion may be needed in the future to achieve compatibility with software or devices (format shifting), or to avoid paying patent royalties for decoding or distribution of compressed files.

By modifying the compressed data directly without decoding and re-encoding, some editing of lossily compressed files without degradation of quality is possible. Editing which reduces the file size as if it had been compressed to a greater degree, but without more loss than this, is sometimes also possible.

The primary programs for lossless editing of JPEGs are codice_1, and the derived codice_2 (which also preserves Exif information), and Jpegcrop (which provides a Windows interface).

These allow the image to be
While unwanted information is destroyed, the quality of the remaining portion is unchanged.

Some other transforms are possible to some extent, such as joining images with the same encoding (composing side by side, as on a grid) or pasting images (such as logos) onto existing images (both via Jpegjoin), or scaling.

Some changes can be made to the compression without re-encoding:

The freeware Windows-only IrfanView has some lossless JPEG operations in its codice_3 plugin.

Metadata, such as ID3 tags, Vorbis comments, or Exif information, can usually be modified or removed without modifying the underlying data.

One may wish to downsample or otherwise decrease the resolution of the represented source signal and the quantity of data used for its compressed representation without re-encoding, as in bitrate peeling, but this functionality is not supported in all designs, as not all codecs encode data in a form that allows less important detail to simply be dropped. Some well-known designs that have this capability include JPEG 2000 for still images and H.264/MPEG-4 AVC based Scalable Video Coding for video. Such schemes have also been standardized for older designs as well, such as JPEG images with progressive encoding, and MPEG-2 and MPEG-4 Part 2 video, although those prior schemes had limited success in terms of adoption into real-world common usage. Without this capacity, which is often the case in practice, to produce a representation with lower resolution or lower fidelity than a given one, one needs to start with the original source signal and encode, or start with a compressed representation and then decompress and re-encode it (transcoding), though the latter tends to cause digital generation loss.

Another approach is to encode the original signal at several different bitrates, and then either choose which to use (as when streaming over the internet – as in RealNetworks' "SureStream" – or offering varying downloads, as at Apple's iTunes Store), or broadcast several, where the best that is successfully received is used, as in various implementations of hierarchical modulation. Similar techniques are used in mipmaps, pyramid representations, and more sophisticated scale space methods. Some audio formats feature a combination of a lossy format and a lossless correction which when combined reproduce the original signal; the correction can be stripped, leaving a smaller, lossily compressed, file. Such formats include MPEG-4 SLS (Scalable to Lossless), WavPack, OptimFROG DualStream, and DTS-HD Master Audio in lossless (XLL) mode).





Researchers have (semi-seriously) performed lossy compression on text by either using a thesaurus to substitute short words for long ones, or generative text techniques, although these sometimes fall into the related category of lossy data conversion.

A general kind of lossy compression is to lower the resolution of an image, as in image scaling, particularly decimation. One may also remove less "lower information" parts of an image, such as by seam carving. Many media transforms, such as Gaussian blur, are, like lossy compression, irreversible: the original signal cannot be reconstructed from the transformed signal. However, in general these will have the same size as the original, and are not a form of compression. Lowering resolution has practical uses, as the NASA New Horizons craft will transmit thumbnails of its encounter with Pluto-Charon before it sends the higher resolution images. Another solution for slow connections is the usage of Image interlacing which progressively defines the image. Thus a partial transmission is enough to preview the final image, in a lower resolution version, without creating a scaled and a full version too.


(Wayback Machine copy)


</doc>
<doc id="18209" url="https://en.wikipedia.org/wiki?curid=18209" title="Lossless compression">
Lossless compression

Lossless compression is a class of data compression algorithms that allows the original data to be perfectly reconstructed from the compressed data. By contrast, lossy compression permits reconstruction only of an approximation of the original data, though usually with greatly improved compression rates (and therefore reduced media sizes).

Lossless data compression is used in many applications. For example, it is used in the ZIP file format and in the GNU tool gzip. It is also often used as a component within lossy data compression technologies (e.g. lossless mid/side joint stereo preprocessing by MP3 encoders and other lossy audio encoders).

Lossless compression is used in cases where it is important that the original and the decompressed data be identical, or where deviations from the original data would be unfavourable. Typical examples are executable programs, text documents, and source code. Some image file formats, like PNG or GIF, use only lossless compression, while others like TIFF and MNG may use either lossless or lossy methods. Lossless audio formats are most often used for archiving or production purposes, while smaller lossy audio files are typically used on portable players and in other cases where storage space is limited or exact replication of the audio is unnecessary.

Most lossless compression programs do two things in sequence: the first step generates a "statistical model" for the input data, and the second step uses this model to map input data to bit sequences in such a way that "probable" (e.g. frequently encountered) data will produce shorter output than "improbable" data.

The primary encoding algorithms used to produce bit sequences are Huffman coding (also used by DEFLATE) and arithmetic coding. Arithmetic coding achieves compression rates close to the best possible for a particular statistical model, which is given by the information entropy, whereas Huffman compression is simpler and faster but produces poor results for models that deal with symbol probabilities close to 1.

There are two primary ways of constructing statistical models: in a "static" model, the data is analyzed and a model is constructed, then this model is stored with the compressed data. This approach is simple and modular, but has the disadvantage that the model itself can be expensive to store, and also that it forces using a single model for all data being compressed, and so performs poorly on files that contain heterogeneous data. "Adaptive" models dynamically update the model as the data is compressed. Both the encoder and decoder begin with a trivial model, yielding poor compression of initial data, but as they learn more about the data, performance improves. Most popular types of compression used in practice now use adaptive coders.

Lossless compression methods may be categorized according to the type of data they are designed to compress. While, in principle, any general-purpose lossless compression algorithm ("general-purpose" meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress. Many of the lossless compression techniques used for text also work reasonably well for indexed images.

These techniques take advantage of the specific characteristics of images such as the common phenomenon of contiguous 2-D areas of similar tones.
Every pixel but the first is replaced by the difference to its left neighbor. This leads to small values having a much higher probability than large values.
This is often also applied to sound files, and can compress files that contain mostly low frequencies and low volumes.
For images, this step can be repeated by taking the difference to the top pixel, and then in videos, the difference to the pixel in the next frame can be taken.

A hierarchical version of this technique takes neighboring pairs of data points, stores their difference and sum, and on a higher level with lower resolution continues with the sums. This is called discrete wavelet transform. JPEG2000 additionally uses data points from other pairs and multiplication factors to mix them into the difference. These factors must be integers, so that the result is an integer under all circumstances. So the values are increased, increasing file size, but hopefully the distribution of values is more peaked. 

The adaptive encoding uses the probabilities from the previous sample in sound encoding, from the left and upper pixel in image encoding, and additionally from the previous frame in video encoding. In the wavelet transformation, the probabilities are also passed through the hierarchy.

Many of these methods are implemented in open-source and proprietary tools, particularly LZW and its variants. Some algorithms are patented in the United States and other countries and their legal usage requires licensing by the patent holder. Because of patents on certain kinds of LZW compression, and in particular licensing practices by patent holder Unisys that many developers considered abusive, some open source proponents encouraged people to avoid using the Graphics Interchange Format (GIF) for compressing still image files in favor of Portable Network Graphics (PNG), which combines the LZ77-based deflate algorithm with a selection of domain-specific prediction filters. However, the patents on LZW expired on June 20, 2003.

Many of the lossless compression techniques used for text also work reasonably well for indexed images, but there are other techniques that do not work for typical text that are useful for some images (particularly simple bitmaps), and other techniques that take advantage of the specific characteristics of images (such as the common phenomenon of contiguous 2-D areas of similar tones, and the fact that color images usually have a preponderance of a limited range of colors out of those representable in the color space).

As mentioned previously, lossless sound compression is a somewhat specialized area. Lossless sound compression algorithms can take advantage of the repeating patterns shown by the wave-like nature of the data – essentially using autoregressive models to predict the "next" value and encoding the (hopefully small) difference between the expected value and the actual data. If the difference between the predicted and the actual data (called the "error") tends to be small, then certain difference values (like 0, +1, −1 etc. on sample values) become very frequent, which can be exploited by encoding them in few output bits.

It is sometimes beneficial to compress only the differences between two versions of a file (or, in video compression, of successive images within a sequence). This is called delta encoding (from the Greek letter Δ, which in mathematics, denotes a difference), but the term is typically only used if both versions are meaningful outside compression and decompression. For example, while the process of compressing the error in the above-mentioned lossless audio compression scheme could be described as delta encoding from the approximated sound wave to the original sound wave, the approximated version of the sound wave is not meaningful in any other context.

By operation of the pigeonhole principle, no lossless compression algorithm can efficiently compress all possible data. For this reason, many different algorithms exist that are designed either with a specific type of input data in mind or with specific assumptions about what kinds of redundancy the uncompressed data are likely to contain.

Some of the most common lossless compression algorithms are listed below.





See this list of lossless video codecs.

Cryptosystems often compress data (the "plaintext") "before" encryption for added security. When properly implemented, compression greatly increases the unicity distance by removing patterns that might facilitate cryptanalysis. However, many ordinary lossless compression algorithms produce headers, wrappers, tables, or other predictable output that might instead make cryptanalysis easier. Thus, cryptosystems must utilize compression algorithms whose output does not contain these predictable patterns.

Genetics compression algorithms (not to be confused with genetic algorithms) are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and specific algorithms adapted to genetic data. In 2012, a team of scientists from Johns Hopkins University published the first genetic compression algorithm that does not rely on external genetic databases for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression much faster than leading general-purpose compression utilities.

Genomic sequence compression algorithms, also known as DNA sequence compressors, explore the fact that DNA sequences have characteristic properties, such as inverted repeats. The most successful compressors are XM and GeCo. For eukaryotes XM is slightly better in compression ratio, though for sequences larger than 100 MB its computational requirements are impractical.

Self-extracting executables contain a compressed application and a decompressor. When executed, the decompressor transparently decompresses and runs the original application. This is especially often used in demo coding, where competitions are held for demos with strict size limits, as small as 1k.
This type of compression is not strictly limited to binary executables, but can also be applied to scripts, such as JavaScript.

Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks. There are a number of better-known compression benchmarks. Some benchmarks cover only the data compression ratio, so winners in these benchmarks may be unsuitable for everyday use due to the slow speed of the top performers. Another drawback of some benchmarks is that their data files are known, so some program writers may optimize their programs for best performance on a particular data set. The winners on these benchmarks often come from the class of context-mixing compression software.

Matt Mahoney, in his February 2010 edition of the free booklet "Data Compression Explained", additionally lists the following:

The Compression Ratings website published a chart summary of the "frontier" in compression ratio and time.

The Compression Analysis Tool is a Windows application that enables end users to benchmark the performance characteristics of streaming implementations of LZF4, DEFLATE, ZLIB, GZIP, BZIP2 and LZMA using their own data. It produces measurements and charts with which users can compare the compression speed, decompression speed and compression ratio of the different compression methods and to examine how the compression level, buffer size and flushing operations affect the results.

Lossless data compression algorithms cannot guarantee compression for all input data sets. In other words, for any lossless data compression algorithm, there will be an input data set that does not get smaller when processed by the algorithm, and for any lossless data compression algorithm that makes at least one file smaller, there will be at least one file that it makes larger. This is easily proven with elementary mathematics using a counting argument, as follows:


Any lossless compression algorithm that makes some files shorter must necessarily make some files longer, but it is not necessary that those files become "very much" longer. Most practical compression algorithms provide an "escape" facility that can turn off the normal coding for files that would become longer by being encoded. In theory, only a single additional bit is required to tell the decoder that the normal coding has been turned off for the entire input; however, most encoding algorithms use at least one full byte (and typically more than one) for this purpose. For example, DEFLATE compressed files never need to grow by more than 5 bytes per 65,535 bytes of input.

In fact, if we consider files of length N, if all files were equally probable, then for any lossless compression that reduces the size of some file, the expected length of a compressed file (averaged over all possible files of length N) must necessarily be "greater" than N. So if we know nothing about the properties of the data we are compressing, we might as well not compress it at all. A lossless compression algorithm is useful only when we are more likely to compress certain types of files than others; then the algorithm could be designed to compress those types of data better.

Thus, the main lesson from the argument is not that one risks big losses, but merely that one cannot always win. To choose an algorithm always means implicitly to select a "subset" of all files that will become usefully shorter. This is the theoretical reason why we need to have different compression algorithms for different kinds of files: there cannot be any algorithm that is good for all kinds of data.

The "trick" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger. Algorithms are generally quite specifically tuned to a particular type of file: for example, lossless audio compression programs do not work well on text files, and vice versa.

In particular, files of random data cannot be consistently compressed by any conceivable lossless data compression algorithm: indeed, this result is used to "define" the concept of randomness in algorithmic complexity theory.

It's provably impossible to create an algorithm that can losslessly compress any data. While there have been many claims through the years of companies achieving "perfect compression" where an arbitrary number "N" of random bits can always be compressed to "N" − 1 bits, these kinds of claims can be safely discarded without even looking at any further details regarding the purported compression scheme. Such an algorithm contradicts fundamental laws of mathematics because, if it existed, it could be applied repeatedly to losslessly reduce any file to length 0. Allegedly "perfect" compression algorithms are often derisively referred to as "magic" compression algorithms for this reason.

On the other hand, it has also been proven that there is no algorithm to determine whether a file is incompressible in the sense of Kolmogorov complexity. Hence it's possible that any particular file, even if it appears random, may be significantly compressed, even including the size of the decompressor. An example is the digits of the mathematical constant "pi", which appear random but can be generated by a very small program. However, even though it cannot be determined whether a particular file is incompressible, a simple theorem about incompressible strings shows that over 99% of files of any given length cannot be compressed by more than one byte (including the size of the decompressor).

Abstractly, a compression algorithm can be viewed as a function on sequences (normally of octets). Compression is successful if the resulting sequence is shorter than the original sequence (and the instructions for the decompression map). For a compression algorithm to be lossless, the compression map must form an injection from "plain" to "compressed" bit sequences.

The pigeonhole principle prohibits a bijection between the collection of sequences of length "N" and any subset of the collection of sequences of length "N"−1. Therefore, it is not possible to produce a lossless algorithm that reduces the size of every possible input sequence.

Most everyday files are relatively 'sparse' in an information entropy sense, and thus, most lossless algorithms a layperson is likely to apply on regular files compress them relatively well. This may, through misapplication of intuition, lead some individuals to conclude that a well-designed compression algorithm can compress "any" input, thus, constituting a "magic compression algorithm".

Real compression algorithm designers accept that streams of high information entropy cannot be compressed, and accordingly, include facilities for detecting and handling this condition. An obvious way of detection is applying a raw compression algorithm and testing if its output is smaller than its input. Sometimes, detection is made by heuristics; for example, a compression application may consider files whose names end in ".zip", ".arj" or ".lha" uncompressible without any more sophisticated detection. A common way of handling this situation is quoting input, or uncompressible parts of the input in the output, minimizing the compression overhead. For example, the zip data format specifies the 'compression method' of 'Stored' for input files that have been copied into the archive verbatim.

Mark Nelson, in response to claims of magic compression algorithms appearing in comp.compression, has constructed a 415,241 byte binary file of highly entropic content, and issued a public challenge of $100 to anyone to write a program that, together with its input, would be smaller than his provided binary data yet be able to reconstitute it without error.

The FAQ for the comp.compression newsgroup contains a challenge by Mike Goldman offering $5,000 for a program that can compress random data. Patrick Craig took up the challenge, but rather than compressing the data, he split it up into separate files all of which ended in the number "5", which was not stored as part of the file. Omitting this character allowed the resulting files (plus, in accordance with the rules, the size of the program that reassembled them) to be smaller than the original file. However, no actual compression took place, and the information stored in the names of the files was necessary to reassemble them in the correct order in the original file, and this information was not taken into account in the file size comparison. The files themselves are thus not sufficient to reconstitute the original file; the file names are also necessary. Patrick Craig agreed that no meaningful compression had taken place, but argued that the wording of the challenge did not actually require this. A full history of the event, including discussion on whether or not the challenge was technically met, is on Patrick Craig's web site.




</doc>
<doc id="18210" url="https://en.wikipedia.org/wiki?curid=18210" title="Larry Niven">
Larry Niven

Laurence van Cott Niven (; born April 30, 1938) is an American science fiction writer. His best-known works are "Ringworld" (1970), which received Hugo, Locus, Ditmar, and Nebula awards, and, with Jerry Pournelle, "The Mote in God's Eye" (1974) and "Lucifer's Hammer" (1977). The Science Fiction and Fantasy Writers of America named him the 2015 recipient of the Damon Knight Memorial Grand Master Award. His work is primarily hard science fiction, using big science concepts and theoretical physics. It also often includes elements of detective fiction and adventure stories. His fantasy includes the series "The Magic Goes Away", rational fantasy dealing with magic as a non-renewable resource.

Niven was born in Los Angeles. He is a great-grandson of Edward L. Doheny, an oil tycoon who had drilled the first successful well in the Los Angeles City Oil Field in 1892, and also was subsequently implicated in the Teapot Dome scandal. He briefly attended the California Institute of Technology and graduated with a Bachelor of Arts in mathematics (with a minor in psychology) from Washburn University in Topeka, Kansas in 1962. He also completed a year of graduate work in mathematics at the University of California, Los Angeles. On September 6, 1969, he married Marilyn Joyce "Fuzzy Pink" Wisowaty, a science fiction and Regency literature fan. He is an agnostic.

Niven is the author of numerous science fiction short stories and novels, beginning with his 1964 story "The Coldest Place". In this story, the coldest place concerned is the dark side of Mercury, which at the time the story was written was thought to be tidally locked with the Sun (it was found to rotate in a 2:3 resonance after Niven received payment for the story, but before it was published).

Algis Budrys said in 1968 that Niven becoming a top writer despite the New Wave was evidence that "trends are for second-raters". In addition to the Nebula award in 1970 and the Hugo and Locus awards in 1971 for "Ringworld", Niven won the Hugo Award for Best Short Story for "Neutron Star" in 1967. He won the same award in 1972, for "Inconstant Moon", and in 1975 for "The Hole Man". In 1976, he won the Hugo Award for Best Novelette for "The Borderland of Sol".

Niven has written scripts for three science fiction television series: the original "Land of the Lost" series; "", for which he adapted his early story "The Soft Weapon"; and "The Outer Limits", for which he adapted his story "Inconstant Moon" into an episode of the same name.

Niven has also written for the DC Comics character Green Lantern, including in his stories hard science fiction concepts such as universal entropy and the redshift effect.

He has included limited psi gifts (mind over matter) in some characters in his stories; like Gil Hamilton's psychic arm which can only reach as far as a corporeal arm could, though it can, for example, reach through solid materials and manipulate objects on the other side, and through videophone screens, or Matt Keller's ability to make people not notice him.

Several of his stories predicted the black market in transplant organs ("organlegging").

Many of Niven's stories—sometimes called the Tales of Known Space—take place in his Known Space universe, in which humanity shares the several habitable star systems nearest to the Sun with over a dozen alien species, including the aggressive feline Kzinti and the very intelligent but cowardly Pierson's Puppeteers, which are frequently central characters. The "Ringworld" series is part of the Tales of Known Space, and Niven has shared the setting with other writers since a 1988 anthology, "The Man-Kzin Wars" (Baen Books, jointly edited with Jerry Pournelle and Dean Ing). There have been several volumes of short stories and novellas.

Niven has also written a logical fantasy series "The Magic Goes Away", which utilizes an exhaustible resource called "mana" to power a rule-based "technological" magic. "The Draco Tavern" series of short stories take place in a more light-hearted science fiction universe, and are told from the point of view of the proprietor of an omni-species bar. The whimsical "Svetz" series consists of a collection of short stories, "The Flight of the Horse", and a novel, "Rainbow Mars", which involve a nominal time machine sent back to retrieve long-extinct animals, but which travels, in fact, into alternative realities and brings back mythical creatures such as a Roc and a Unicorn. Much of his writing since the 1970s has been in collaboration, particularly with Jerry Pournelle and Steven Barnes, but also Brenda Cooper and Edward M. Lerner.

One of Niven's best known humorous works is "Man of Steel, Woman of Kleenex", in which he uses real-world physics to underline the difficulties of Superman and a human woman (Lois Lane or Lana Lang) mating.

Niven appeared in the 1980 science documentary film "Target... Earth?"

Niven's most famous contribution to the SF genre comes from his novel "Ringworld", in which he envisions a Ringworld: a band of material, roughly a million miles wide, of approximately the same diameter as Earth's orbit, rotating around a star. The idea originated in Niven's attempts to imagine a more efficient version of a Dyson sphere, which could produce the effect of surface gravity through rotation. Given that spinning a Dyson sphere would result in the atmosphere pooling around the equator, the Ringworld removes all the extraneous parts of the structure, leaving a spinning band landscaped on the sun-facing side, with the atmosphere and inhabitants kept in place through centrifugal force and high perimeter walls (rim walls). After publication of "Ringworld", Dan Alderson and Ctein, two fannish friends of Niven, analyzed the structure and told Niven that the Ringworld was dynamically unstable such that if the center of rotation drifts away from the central sun, gravitational forces will not "re-center" it, thus allowing the ring to eventually contact the sun and be destroyed. Niven used this as a core plot element in the sequel novel, "The Ringworld Engineers".

This idea proved influential, serving as an alternative to a full Dyson sphere that required fewer assumptions (such as artificial gravity) and allowed a day/night cycle to be introduced (through the use of a smaller ring of "shadow squares", rotating between the ring and its sun). This was further developed by Iain M. Banks in his Culture series, which features about ringworld–size megastructures called Orbitals that orbit a star rather than encircling it entirely (actual "Rings" and Dyson "Spheres" are also mentioned but are much rarer). Alastair Reynolds also uses ringworlds in his 2008 novel "House of Suns". The Ringworld-like namesake of the "Halo" video game series is the eponymous Halo megastructure/superweapon.

The original release of "" paid homage to Larry Niven on a card called "Nevinyrral's Disk", with Nevinyrral being "Larry Niven" spelled backwards. Subsequent sets have featured no new cards featuring Nevinyrral, although the character is sporadically quoted on the flavor text of various cards. "Netrunner" paid a similar homage to Larry Niven with the card "Nevinyrral".

According to author Michael Moorcock, in 1967, Niven was among those Science Fiction Writers of America members who voiced opposition to the Vietnam War. However, in 1968 Niven's name appeared in a pro-war ad in "Galaxy Science Fiction".

Niven was an adviser to Ronald Reagan on the creation of the Strategic Defense Initiative antimissile policy, as part of the Citizens' Advisory Council on National Space Policy – as covered in the BBC documentary "Pandora's Box" by Adam Curtis. The council also convinced Vice President Dan Quayle to support the single-stage-to-orbit concept for a reusable space ship that led to the building of the DC-X.

In 2007, Niven, in conjunction with a group of science fiction writers known as SIGMA, led by Pournelle, began advising the U.S. Department of Homeland Security as to future trends affecting terror policy and other topics.

Larry Niven is also known in science fiction fandom for "Niven's Law": "There is no cause so right that one cannot find a fool following it." Over the course of his career Niven has added to this first law a list of Niven's Laws which he describes as "how the Universe works" as far as he can tell.




</doc>
<doc id="18212" url="https://en.wikipedia.org/wiki?curid=18212" title="Linux distribution">
Linux distribution

A Linux distribution (often abbreviated as distro) is an operating system made from a software collection that is based upon the Linux kernel and, often, a package management system. Linux users usually obtain their operating system by downloading one of the Linux distributions, which are available for a wide variety of systems ranging from embedded devices (for example, OpenWrt) and personal computers (for example, Linux Mint) to powerful supercomputers (for example, Rocks Cluster Distribution).

A typical Linux distribution comprises a Linux kernel, GNU tools and libraries, additional software, documentation, a window system (the most common being the X Window System), a window manager, and a desktop environment. Most of the included software is free and open-source software made available both as compiled binaries and in source code form, allowing modifications to the original software. Usually, Linux distributions optionally include some proprietary software that may not be available in source code form, such as binary blobs required for some device drivers.
A Linux distribution may also be described as a particular assortment of application and utility software (various GNU tools and libraries, for example), packaged together with the Linux kernel in such a way that its capabilities meet the needs of many users. The software is usually adapted to the distribution and then packaged into software packages by the distribution's maintainers. The software packages are available online in so-called repositories, which are storage locations usually distributed around the world. Beside glue components, such as the distribution installers (for example, Debian-Installer and Anaconda) or the package management systems, there are only very few packages that are originally written from the ground up by the maintainers of a Linux distribution.

Almost six hundred Linux distributions exist, with close to five hundred out of those in active development. Because of the huge availability of software, distributions have taken a wide variety of forms, including those suitable for use on desktops, servers, laptops, netbooks, mobile phones and tablets, as well as minimal environments typically for use in embedded systems. There are commercially-backed distributions, such as Fedora (Red Hat), openSUSE (SUSE) and Ubuntu (Canonical Ltd.), and entirely community-driven distributions, such as Debian, Slackware, Gentoo and Arch Linux. Most distributions come ready to use and pre-compiled for a specific instruction set, while some distributions (such as Gentoo) are distributed mostly in source code form and compiled locally during installation.

Linus Torvalds developed the Linux kernel and distributed its first version, 0.01, in 1991. Linux was initially distributed as source code only, and later as a pair of downloadable floppy disk images one bootable and containing the Linux kernel itself, and the other with a set of GNU utilities and tools for setting up a file system. Since the installation procedure was complicated, especially in the face of growing amounts of available software, distributions sprang up to simplify this.

Early distributions included the following:

The two oldest and still active distribution projects started in 1993. The SLS distribution was not well maintained, so in July 1993 a new distribution, called Slackware and based on SLS, was released by Patrick Volkerding. Also dissatisfied with SLS, Ian Murdock set to create a free distribution by founding Debian, which had its first release in December 1993.

Users were attracted to Linux distributions as alternatives to the DOS and Microsoft Windows operating systems on IBM PC compatible computers, Mac OS on the Apple Macintosh, and proprietary versions of Unix. Most early adopters were familiar with Unix from work or school. They embraced Linux distributions for their low (if any) cost, and availability of the source code for most or all of the software included.

As of 2017, Linux has become more popular in server and embedded devices markets than in the desktop market. For example, Linux is used on over 50% of web servers, whereas its desktop market share is about 3.7%.

Many Linux distributions provide an installation system akin to that provided with other modern operating systems. On the other hand, some distributions, including Gentoo Linux, provide only the binaries of a basic kernel, compilation tools, and an installer; the installer compiles all the requested software for the specific architecture of the user's computer, using these tools and the provided source code.

Distributions are normally segmented into "packages". Each package contains a specific application or service. Examples of packages are a library for handling the PNG image format, a collection of fonts or a web browser.

The package is typically provided as compiled code, with installation and removal of packages handled by a package management system (PMS) rather than a simple file archiver. Each package intended for such a PMS contains meta-information such as a package description, version, and "dependencies". The package management system can evaluate this meta-information to allow package searches, to perform an automatic upgrade to a newer version, to check that all dependencies of a package are fulfilled, and/or to fulfill them automatically.

Although Linux distributions typically contain much more software than proprietary operating systems, it is normal for local administrators to also install software not included in the distribution. An example would be a newer version of a software application than that supplied with a distribution, or an alternative to that chosen by the distribution (for example, KDE Plasma Workspaces rather than GNOME or vice versa for the user interface layer). If the additional software is distributed in source-only form, this approach requires local compilation. However, if additional software is locally added, the "state" of the local system may fall out of synchronization with the state of the package manager's database. If so, the local administrator will be required to take additional measures to ensure the entire system is kept up to date. The package manager may no longer be able to do so automatically.

Most distributions install packages, including the kernel and other core operating system components, in a predetermined configuration. Few now require or even permit configuration adjustments at first install time. This makes installation less daunting, particularly for new users, but is not always acceptable. For specific requirements, much software must be carefully configured to be useful, to work correctly with other software, or to be secure, and local administrators are often obliged to spend time reviewing and reconfiguring assorted software.

Some distributions go to considerable lengths to specifically adjust and customize most or all of the software included in the distribution. Not all do so. Some distributions provide configuration tools to assist in this process.

By replacing "everything" provided in a distribution, an administrator may reach a "distribution-less" state: everything was retrieved, compiled, configured, and installed locally. It is possible to build such a system from scratch, avoiding a distribution altogether. One needs a way to generate the first binaries until the system is "self-hosting". This can be done via compilation on another system capable of building binaries for the intended target (possibly by cross-compilation). For example, see Linux From Scratch.

In broad terms, Linux distributions may be:

The diversity of Linux distributions is due to technical, organizational, and philosophical variation among vendors and users. The permissive licensing of free software means that any user with sufficient knowledge and interest can customize an existing distribution or design one to suit his or her own needs.

Rolling Linux distributions are kept updated using small and frequent updates. Software contained in a rolling distribution's software stack is usually standard release, though.

Rolling releases can be either:


The terms "partially rolling" and "partly rolling" (along with synonyms "semi-rolling" and "half-rolling"), "fully rolling", "truly rolling" and "optionally rolling" are all standard terms used by software developers and users.

Repositories of rolling distributions usually contains very recent software releases – often the latest stable software releases available. They have pseudo-releases and installation media that are simply a snapshot of the software distribution at the time of the release of the installation image. Typically, a rolling release operating system installed from an older installation medium can be fully updated post-installation to a current state.

There are pros and cons to both standard release and rolling release software development methodologies.

In terms of the software development process, standard releases require significant development effort being spent on keeping old versions up to date due to propagating bug fixes back to the newest branch, versus focusing more on the newest development branch. Also, unlike rolling releases, standard releases require more than one code branch to be developed and maintained, which increases the software development and software maintenance workload of the software developers and software maintainers.

On the other hand, software features and technology planning are easier in standard releases due to a better understanding of upcoming features in the next version(s) rather than simply the whim of the developers at any given time. Software release cycles can also be synchronized with those of major upstream software projects, such as desktop environments.

As far as the user experience, standard releases are often viewed as more stable and bug-free since software conflicts can be more easily addressed and the software stack more thoroughly tested and evaluated, during the software development cycle. For this reason, they tend to be the preferred choice in enterprise environments and mission-critical tasks.

However, rolling releases offer more current software which can also provide increased stability and fewer software bugs along with the additional benefits of new features, greater functionality, faster running speeds, and improved system and application security. Regarding software security, the rolling release model can have advantages in timely security updates, fixing system or application security bugs and vulnerabilities, that standard releases may have to wait till the next release for or patch in various versions. In a rolling release distribution, where the user has "chosen" to run it as a highly dynamic system, the constant flux of software packages can introduce new unintended vulnerabilities.

A "live" distribution is a Linux distribution that can be booted from removable storage media such as optical discs or USB flash drives, instead of being installed on and booted from a hard disk drive. The portability of installation-free distributions makes them advantageous for applications such as demonstrations, borrowing someone else's computer, rescue operations, or as installation media for a standard distribution.

When the operating system is booted from a read-only medium such as a CD or DVD, any user data that needs to be retained between sessions cannot be stored on the boot device but must be written to another storage device, such as a USB flash drive or a hard disk drive.

Many Linux distributions provide a "live" form in addition to their conventional form, which is a network-based or removable-media image intended to be used only for installation; such distributions include SUSE, Ubuntu, Linux Mint, MEPIS and Fedora. Some distributions, including Knoppix, Puppy Linux, Devil-Linux, SuperGamer, SliTaz GNU/Linux and , are designed primarily for live use. Additionally, some minimal distributions can be run directly from as little space as one floppy disk without the need to change the contents of the system's hard disk drive.

The website DistroWatch lists many Linux distributions, and displays some of the ones that have the most web traffic on the site. The Wikimedia Foundation released an analysis of the browser User Agents of visitors to WMF websites until 2015, which includes details of the most popular Operating System identifiers, including some Linux distributions. Many of the popular distributions are listed below.



Other distributions target specific niches, such as:


Whether Google's Android counts as a Linux distribution is a matter of definition. It uses the Linux kernel, so the Linux Foundation and Chris DiBona, Google's open source chief, agree that Android is a Linux distribution; others, such as Google engineer Patrick Brady, disagree by noting the lack of support for many GNU tools in Android, including glibc.

Other non-GNU distributions include Cyanogenmod, its fork LineageOS, Android-x86 and recently Tizen and Mer/Sailfish OS.

The Free Standards Group is an organization formed by major software and hardware vendors that aims to improve interoperability between different distributions. Among their proposed standards are the Linux Standard Base, which defines a common ABI and packaging system for Linux, and the Filesystem Hierarchy Standard which recommends a standard filenaming chart, notably the basic directory names found on the root of the tree of any Linux filesystem. Those standards, however, see limited use, even among the distributions developed by members of the organization.

The diversity of Linux distributions means that not all software runs on all distributions, depending on what libraries and other system attributes are required. Packaged software and software repositories are usually specific to a particular distribution, though cross-installation is sometimes possible on closely related distributions.

The process of constantly switching between distributions is often referred to as "distro hopping". Virtual machines such as VirtualBox and VMware Workstation virtualize hardware allowing users to test live media on a virtual machine. Some websites like DistroWatch offer lists of popular distributions, and link to screenshots of operating systems as a way to get a first impression of various distributions.

There are tools available to help people select an appropriate distribution, such as several versions of the Linux Distribution Chooser, and the universal package search tool "whohas". There are easy ways to try out several Linux distributions before deciding on one: Multi Distro is a Live CD that contains nine space-saving distributions.

There are several ways to install a Linux distribution. Nowadays, the most common method of installing Linux is by booting from a live USB memory stick, which can be created by using an USB image writer application and the ISO image, which can be downloaded from the various Linux distribution websites. DVD disks, CD disks, network installations and even other hard drives can also be used as "installation media".

Early Linux distributions were installed using sets of floppies but this has been abandoned by all major distributions. Nowadays most distributions offer CD and DVD sets with the vital packages on the first disc and less important packages on later ones. They usually also allow installation over a network after booting from either a set of floppies or a CD with only a small amount of data on it.

New users tend to begin by partitioning a hard drive in order to keep their previously installed operating system. The Linux distribution can then be installed on its own separate partition without affecting previously saved data.

In a Live CD setup, the computer boots the entire operating system from CD without first installing it on the computer's hard disk. Some distributions have a Live CD "installer", where the computer boots the operating system from the disk, and then proceeds to install it onto the computer's hard disk, providing a seamless transition from the OS running from the CD to the OS running from the hard disk.

Both servers and personal computers that come with Linux already installed are available from vendors including Hewlett-Packard, Dell and System76.

On embedded devices, Linux is typically held in the device's firmware and may or may not be consumer-accessible. 

Anaconda, one of the more popular installers, is used by Red Hat Enterprise Linux, Fedora (which uses the Fedora Media Writer) and other distributions to simplify the installation process. Debian, Ubuntu and many others use Debian-Installer.

Some distributions let the user install Linux on top of their current system, such as WinLinux or coLinux. Linux is installed to the Windows hard disk partition, and can be started from inside Windows itself.

Virtual machines (such as VirtualBox or VMware) also make it possible for Linux to be run inside another OS. The VM software simulates a separate computer onto which the Linux system is installed. After installation, the virtual machine can be booted as if it were an independent computer.

Various tools are also available to perform full dual-boot installations from existing platforms without a CD, most notably:


Some specific proprietary software products are not available in any form for Linux. As of September 2015, the Steam gaming service has 1,500 games available on Linux, compared to 2,323 games for Mac and 6,500 Windows games. Emulation and API-translation projects like Wine and CrossOver make it possible to run non-Linux-based software on Linux systems, either by emulating a proprietary operating system or by translating proprietary API calls (e.g., calls to Microsoft's Win32 or DirectX APIs) into native Linux API calls. A virtual machine can also be used to run a proprietary OS (like Microsoft Windows) on top of Linux.

Computer hardware is usually sold with an operating system other than Linux already installed by the original equipment manufacturer (OEM). In the case of IBM PC compatibles the OS is usually Microsoft Windows; in the case of Apple Macintosh computers it has always been a version of Apple's OS, currently macOS; Sun Microsystems sold SPARC hardware with the Solaris installed; video game consoles such as the Xbox, PlayStation, and Wii each have their own proprietary OS. This limits Linux's market share: consumers are unaware that an alternative exists, they must make a conscious effort to use a different operating system, and they must either perform the actual installation themselves, or depend on support from a friend, relative, or computer professional.

However, it is possible to buy hardware with Linux already installed. Lenovo, Hewlett-Packard, Dell, Affordy, Purism, and System76 all sell general-purpose Linux laptops, and custom-order PC manufacturers will also build Linux systems (but possibly with the Windows key on the keyboard). Fixstars Solutions (formerly Terra Soft) sells Macintosh computers and PlayStation 3 consoles with Yellow Dog Linux installed.

It is more common to find embedded devices sold with Linux as the default manufacturer-supported OS, including the Linksys NSLU2 NAS device, TiVo's line of personal video recorders, and Linux-based cellphones (including Android smartphones), PDAs, and portable music players. 

The current Microsoft Windows license lets the manufacturer determine the refund policy. With previous versions of Windows, it was possible to obtain a refund if the manufacturer failed to provide the refund by litigation in the small claims courts. On 15 February 1999, a group of Linux users in Orange County, California held a "Windows Refund Day" protest in an attempt to pressure Microsoft into issuing them refunds. In France, the Linuxfrench and AFUL (French speaking Libre Software Users' Association) organizations along with free software activist Roberto Di Cosmo started a "Windows Detax" movement, which led to a 2006 petition against "racketiciels" (translation: Racketware) with 39,415 signatories and the DGCCRF branch of the French government filing several complaints against bundled software. On March 24, 2014, a new international petition was launched by AFUL on the Avaaz platform, translated into several languages and supported by many organizations around the world.

There are no official figures on popularity, adoption, downloads or installed base of Linux distributions.

There are also no official figures for the total number of Linux systems, partly due to the difficulty of quantifying the number of PCs running Linux (see Desktop Linux#Measuring adoption), since many users download Linux distributions. Hence, the sales figures for Linux systems and commercial Linux distributions indicate a much lower number of Linux systems and level of Linux adoption than is the case; this is mainly due to Linux being free and open source software that can be downloaded free of charge. A Linux Counter Project had kept track of a running guesstimate of the number of Linux systems, but did not distinguish between rolling release and standard release distributions. It ceased operation in August of 2018, though a few related blog posts were created through October 2018.




</doc>
<doc id="18213" url="https://en.wikipedia.org/wiki?curid=18213" title="Los Angeles Dodgers">
Los Angeles Dodgers

The Los Angeles Dodgers are an American professional baseball team based in Los Angeles, California. They compete in Major League Baseball (MLB) as a member club of the National League (NL) West division. Established in 1883 in Brooklyn, New York, the team moved to Los Angeles before the 1958 season. They played for four seasons at the Los Angeles Memorial Coliseum before moving to their current home of Dodger Stadium in .

The Dodgers have won six World Series championships and twenty three National League pennants. Eleven NL MVP award winners have played for the Dodgers, winning a total of thirteen MVP Awards; eight Cy Young Award winners have also pitched for the Dodgers, winning a total of twelve Cy Young Awards. The team has eighteen Rookie of the Year Award winners, more than twice as many as the second place New York Yankees 8. The Dodgers have had four consecutive Rookies of the Year from 1979 to 1982 and five in a row from 1992 to 1996.

Although they were winners of the National League pennant in the 2017 and 2018 seasons, the Dodgers lost in both the 2017 and 2018 World Series.

In the early 20th century, the team, then known as the Brooklyn Robins, won league pennants in 1916 and 1920, losing the World Series both times, first to Boston and then Cleveland. In the 1930s, the team changed its name to the Dodgers, after the Brooklyn pedestrians who dodged the streetcars in the city. 

In 1941, the Dodgers captured their third National League pennant, only to lose to the New York Yankees. This marked the onset of the Dodgers–Yankees rivalry, as the Dodgers would face them in their next six World Series appearances. Led by Jackie Robinson, the first black Major League Baseball player of the modern era; and three-time National League Most Valuable Player Roy Campanella, also signed out of the Negro Leagues, the Dodgers captured their first World Series title in 1955 by defeating the Yankees for the first time, a story notably described in the 1972 book "The Boys of Summer".

Following the 1957 season the team left Brooklyn. In just their second season in Los Angeles, the Dodgers won their second World Series title, beating the Chicago White Sox in six games in 1959. Spearheaded by the dominant pitching style of Sandy Koufax and Don Drysdale, the Dodgers captured three pennants in the 1960s and won two more World Series titles, sweeping the Yankees in four games in 1963, and edging the Minnesota Twins in seven in 1965. The 1963 sweep was their second victory against the Yankees, and their first against them as a Los Angeles team. The Dodgers won four more pennants in 1966, 1974, 1977 and 1978, but lost in each World Series appearance. They went on to win the World Series again in 1981, thanks in part to pitching sensation Fernando Valenzuela. 

The early 1980s were affectionately dubbed "Fernandomania." In 1988, another pitching hero, Orel Hershiser, again led them to a World Series victory, aided by one of the most memorable home runs of all time, by their injured star outfielder Kirk Gibson coming off the bench to pinch hit with two outs in the bottom of the ninth inning of game 1, in his only appearance of the series. The Dodgers won the pennant in 2017 and 2018, but lost the World Series to the Houston Astros and Boston Red Sox respectively. 

The Dodgers share a fierce rivalry with the San Francisco Giants,dating back to when the two franchises played in New York City. Both teams moved west for the 1958 season. Both the Brooklyn/Los Angeles Dodgers and the New York/San Francisco Giants have appeared in the World Series 20 times. The Giants have won two more World Series (8); when the two teams were based in New York, the Giants won five World Series championships, and the Dodgers one. After the move to California, the Dodgers have won five 5 World Series to the Giants have won 3.

The Dodgers were founded in 1883 as the Brooklyn Atlantics, taking the name of a defunct team that had played in Brooklyn before them. The team joined the American Association in 1884 and won the AA championship in 1889 before joining the National League in 1890. They promptly won the NL Championship their first year in the League. The team was known alternatively as the Bridegrooms, Grooms, Superbas, Robins, and Trolley Dodgers before officially becoming the Brooklyn Dodgers in the 1930s.

In Brooklyn, the Dodgers won the NL pennant twelve times (1890, 1899, 1900, 1916, 1920, 1941, 1947, 1949, 1952, 1953, 1955, 1956) and the World Series in 1955. After moving to Los Angeles, the team won National League pennants in 1959, 1963, 1965, 1966, 1974, 1977, 1978, 1981, 1988, 2017, and 2018, with World Series championships in 1959, 1963, 1965, 1981 and 1988. In all, the Dodgers have appeared in 20 World Series: 9 in Brooklyn and 11 in Los Angeles.

For most of the first half of the 20th century, no Major League Baseball team employed an African American player. Jackie Robinson became the first African American to play for a Major League Baseball team when he played his first major league game on April 15, 1947, as a member of the Brooklyn Dodgers. This was mainly due to general manager Branch Rickey's efforts. The deeply religious Rickey's motivation appears to have been primarily moral, although business considerations were also a factor. Rickey was a member of The Methodist Church, the antecedent denomination to The United Methodist Church of today, which was a strong advocate for social justice and active later in the American Civil Rights Movement.

This event was the harbinger of the integration of professional sports in the United States, the concomitant demise of the Negro Leagues, and is regarded as a key moment in the history of the American Civil Rights Movement. Robinson was an exceptional player, a speedy runner who sparked the team with his intensity. He was the inaugural recipient of the Rookie of the Year award, which is now named the Jackie Robinson Award in his honor. The Dodgers' willingness to integrate, when most other teams refused to, was a key factor in their 1947–1956 success. They won six pennants in those 10 years with the help of Robinson, three-time MVP Roy Campanella, Cy Young Award winner Don Newcombe, Jim Gilliam and Joe Black. Robinson would eventually go on to become the first African-American elected to the Baseball Hall of Fame in 1962.

Real estate investor Walter O'Malley acquired majority ownership of the Dodgers in 1950, when he bought the 25 percent share of co-owner Branch Rickey and became allied with the widow of the another equal partner, Mrs. John L. Smith. Before long, he was working to buy new land in Brooklyn to build a more accessible and profitable ballpark than the aging Ebbets Field. Beloved as it was, Ebbets Field was no longer well-served by its aging infrastructure and the Dodgers could no longer sell out the park even in the heat of a pennant race, despite largely dominating the National League from 1946 to 1957.

O'Malley wanted to build a new, state of the art stadium in Brooklyn. But City Planner Robert Moses and New York politicians refused to grant him the eminent domain authority required to build pursuant to O'Malley's plans. To put pressure on the city, during the 1955 season, O'Malley announced that the team would play seven regular season games and one exhibition game at Jersey City's Roosevelt Stadium in 1956. Moses and the City considered this an empty threat, and did not believe O'Malley would go through with moving the team from New York City.

After teams began to travel to and from games by air instead of train, it became possible to include locations in the far west. Los Angeles officials attended the 1956 World Series looking to the Washington Senators to move to the West Coast. When O'Malley heard that LA was looking for a club, he sent word to the Los Angeles officials that he was interested in talking. LA offered him what New York would not: a chance to buy land suitable for building a ballpark, and own that ballpark, giving him complete control over all revenue streams. When the news came out, NYC Mayor Robert F. Wagner, Jr. and Moses made an offer to build a ballpark on the World's Fair Grounds in Queens that would be shared by the Giants and Dodgers. However, O'Malley was interested in his park only under his conditions, and the plans for a new stadium in Brooklyn seemed like a pipe dream. O'Malley decided to move the Dodgers to California, convincing Giants owner Horace Stoneham to move to San Francisco instead of Minneapolis to keep the Giants-Dodgers rivalry alive on the West Coast.

The Dodgers played their final game at Ebbets Field on September 24, 1957, which the Dodgers won 2–0 over the Pittsburgh Pirates.

New York would remain a one-team town with the New York Yankees until 1962, when Joan Payson founded the New York Mets and brought National League baseball back to the city. The blue background used by the Dodgers, would be adopted by the Mets, honoring their New York NL forebears with a blend of Dodgers blue and Giants orange.

The Dodgers were the first Major League Baseball team to ever play in Los Angeles. On April 18, 1958, the Dodgers played their first LA game, defeating the former New York and now new San Francisco Giants, 6–5, before 78,672 fans at the Los Angeles Memorial Coliseum. Catcher Roy Campanella, left partially paralyzed in an off-season accident, was never able to play in Los Angeles.
Construction on Dodger Stadium was completed in time for Opening Day 1962. With its clean, simple lines and its picturesque setting amid hills and palm trees, the ballpark quickly became an icon of the Dodgers and their new California lifestyle. O'Malley was determined that there would not be a bad seat in the house, achieving this by cantilevered grandstands that have since been widely imitated. More importantly for the team, the stadium's spacious dimensions, along with other factors, gave defense an advantage over offense and the Dodgers moved to take advantage of this by assembling a team that would excel with its pitching.

Since moving to Los Angeles, the Dodgers have won 11 more National League Championships and five World Series rings.


The Dodgers' official history reports that the term "Trolley Dodgers" was attached to the Brooklyn ballclub due to the complex maze of trolley cars that weaved its way through the borough of Brooklyn.

In 1892, the city of Brooklyn (Brooklyn was an independent city until annexed by New York City in 1898) began replacing its slow-moving, horse-drawn trolley lines with the faster, more powerful electric trolley lines. Within less than three years, by the end of 1895, electric trolley accidents in Brooklyn had resulted in more than 130 deaths and maimed well over 500 people. Brooklyn's high profile, the significant number of widely reported accidents, and a trolley strike in early 1895, combined to create a strong association in the public's mind between Brooklyn and trolley dodging.

Sportswriters started using the name "Trolley Dodgers" to refer to the Brooklyn team early in the 1895 season. The name was shortened to, on occasion, the "Brooklyn Dodgers" as early as 1898.

Sportswriters in the early 20th century began referring to the Dodgers as the "Bums", in reference to the team's fans and possibly because of the "street character" nature of Jack Dawkins, the "Artful Dodger" in Charles Dickens' "Oliver Twist". Newspaper cartoonist Willard Mullin used a drawing of famous clown Emmett Kelly to depict "Dem Bums": the team would later use "Weary Willie" in promotional images, and Kelly himself was a club mascot during the 1950s.

Other team names used by the franchise were the Atlantics, Grays, Grooms, Bridegrooms, Superbas and Robins. All of these nicknames were used by fans and sportswriters to describe the team, but not in any official capacity. The team's legal name was the Brooklyn Base Ball Club. However, the Trolley Dodger nickname was used throughout this period, simultaneously with these other nicknames, by fans and sportswriters of the day. The team did not use the name in any formal sense until 1932, when the word "Dodgers" appeared on team jerseys. The "conclusive shift" came in 1933, when both home and road jerseys for the team bore the name "Dodgers".

Examples of how the many popularized names of the team were used are available from newspaper articles before 1932. A New York Times article describing a game in 1916 starts out: "Jimmy Callahan, pilot of the Pirates, did his best to wreck the hopes the Dodgers have of gaining the National League pennant", but then goes on to comment: "the only thing that saved the Superbas from being toppled from first place was that the Phillies lost one of the two games played". What is interesting about the use of these two nicknames is that most baseball statistics sites and baseball historians generally now refer to the pennant-winning 1916 Brooklyn team as the Robins. A 1918 New York Times article uses the nickname in its title: "Buccaneers Take Last From Robins", but the subtitle of the article reads: "Subdue The Superbas By 11 To 4, Making Series An Even Break".

Another example of the use of the many nicknames is found on the program issued at Ebbets Field for the 1920 World Series, which identifies the matchup in the series as "Dodgers vs. Indians" despite the fact that the Robins nickname had been in consistent use for around six years. The "Robins" nickname was derived from the name of their Hall of Fame manager, Wilbert Robinson, who led the team from 1914 to 1931.

The Dodgers' uniform has remained relatively unchanged since the 1930s. The home jersey is white with "Dodgers" written in script across the chest in royal. The road jersey is gray with "Los Angeles" written in script across the chest in royal. The word "Dodgers" was first used on the front of the team's home jersey in 1933; the uniform was then white with red pinstripes and a stylized "B" on the left shoulder. The Dodgers also wore green outlined uniforms and green caps throughout the 1937 season but reverted to blue the following year.

The current design was created in 1939, and has remained the same ever since with only cosmetic changes. Originally intended for the 1951 World Series for which the ballclub failed to qualify, red numbers under the "Dodgers" script were added to the home uniform in 1952. The road jersey also has a red uniform number under the script. When the franchise moved from Brooklyn to Los Angeles, the city name on the road jersey changed, and the stylized "B" was replaced with the interlocking "LA" on the caps in 1958. In 1970, the Dodgers removed the city name from the road jerseys and had "Dodgers" on both the home and away uniforms. The city script returned to the road jerseys in 1999, and the tradition-rich Dodgers flirted with an alternate uniform for the first time since 1944 (when all-blue satin uniforms were introduced). These 1999 alternate jerseys had a royal top with the "Dodgers" script in white across the chest, and the red number on the front. These were worn with white pants and a new cap with silver brim, top button and Dodger logo. These alternates proved unpopular and the team abandoned them after only one season. In 2014, the Dodgers introduced an alternate road jersey: a gray version with the "Dodgers" script instead of the city name. In 2018, the Dodgers wore their 60th anniversary patch to honor the 60 years of being in Los Angeles.

The Dodgers have been groundbreaking in their signing of players from Asia; mainly Japan, South Korea, and Taiwan. Former owner Peter O'Malley began reaching out in 1980 by starting clinics in China and South Korea, building baseball fields in two Chinese cities, and in 1998 becoming the first major league team to open an office in Asia. The Dodgers were the second team to start a Japanese player in recent history, pitcher Hideo Nomo, the first team to start a South Korean player, pitcher Chan Ho Park, and the first Taiwanese player, Chin-Feng Chen. In addition, they were the first team to send out three Asian pitchers, from different Asian countries, in one game: Park, Hong-Chih Kuo of Taiwan, and Takashi Saito of Japan. In the 2008 season, the Dodgers had the most Asian players on its roster of any major league team with five. They included Japanese pitchers Takashi Saito and Hiroki Kuroda; South Korean pitcher Chan Ho Park; and Taiwanese pitcher Hong-Chih Kuo and infielder Chin-Lung Hu. In 2005, the Dodgers' Hee Seop Choi became the first Asian player to compete in the Home Run Derby. For the 2013 season, the Dodgers signed starting pitcher Hyun-Jin Ryu with a six-year, $36 million contract, after posting a bid of nearly $27 million to acquire him from the KBO's Hanhwa Eagles. For the 2016 season, the Dodgers signed starting pitcher Kenta Maeda with an eight-year, $25 million contract, after posting a bid of $20 million to acquire him from the NPB's Hiroshima Toyo Carp.

The Dodgers' rivalry with the San Francisco Giants dates back to the 19th century, when the two teams were based in New York; the rivalry with the New York Yankees took place when the Dodgers were based in New York, but was revived with their East Coast/West Coast World Series battles in 1963, 1977, 1978, and 1981. The Dodgers rivalry with the Philadelphia Phillies also dates back to their days in New York, but was most fierce during the 1970s, 1980s, and 2000s. The Dodgers also had a heated rivalry with the Cincinnati Reds during the 1970s, 1980s and early 1990s. The rivalry with the Los Angeles Angels and the San Diego Padres dates back to the Angels' and Padres' respective inaugural seasons (Angels in 1961, Padres in 1969). Regional proximity is behind the rivalries with both the Angels and the Padres.

The Dodgers–Giants rivalry is one of the longest-standing rivalries in U.S. baseball.

The feud between the Dodgers and the San Francisco Giants began in the late 19th century when both clubs were based in New York City, with the Dodgers playing in Brooklyn and the Giants playing at the Polo Grounds in Manhattan. After the 1957 season, Dodgers owner Walter O'Malley moved the team to Los Angeles for financial and other reasons. Along the way, he managed to convince Giants owner Horace Stoneham—who was considering moving his team to Minnesota—to preserve the rivalry by bringing his team to California as well. New York baseball fans were stunned and heartbroken by the move. Given that the cities of Los Angeles and San Francisco have been bitter rivals in economic, cultural, and political arenas for over a century and a half, the new venue in California became fertile ground for its transplantation.

Each team's ability to endure for over a century while moving across an entire continent, as well as the rivalry's leap from a cross-city to a cross-state engagement, have led to the rivalry being considered one of the greatest in American sports history.

Unlike many other historic baseball match-ups in which one team remains dominant for most of their history, the Dodgers–Giants rivalry has exhibited a persistent balance in the respective successes of the two teams. While the Giants have more wins in franchise history, the Dodgers and Giants are tied for most National League Pennants at 23, though the Giants have won eight World Series titles, while the Dodgers have won six. The 2010 World Series was the Giants' first championship since moving to California, while the Dodgers had won five World Series titles since their move, their last title coming in the 1988 World Series.. 

This rivalry refers to a series of games played with the Los Angeles Angels. The Freeway Series takes its name from the massive freeway system in the greater Los Angeles metropolitan area, the home of both teams; one could travel from one team's stadium to the other simply by traveling along Interstate 5. The term is akin to "Subway Series" which refers to meetings between New York City baseball teams. The term ""Freeway Series"" also inspired the official name of the region's NHL rivalry: the "Freeway Face-Off."

The Dodgers–Yankees rivalry is one of the most well-known rivalries in Major League Baseball. The two teams have met eleven times in the World Series, more times than any other pair from the American and National Leagues. The initial significance was embodied in the two teams' proximity in New York City, when the Dodgers initially played in Brooklyn. After the Dodgers moved to Los Angeles in 1958, the rivalry retained its significance as the two teams represented the dominant cities on each coast of the United States, and since the 1980s, the two largest cities in the United States.

Although the rivalry's significance arose from the two teams' numerous World Series meetings, the Yankees and Dodgers have not met in the World Series since . They would not play each other in a non-exhibition game until 2004, when they played a three-game interleague series. Their last meeting was in August 2019, when the Yankees won two out of three games in Los Angeles.

The Dodgers have a loyal fanbase, evidenced by the fact that the Dodgers were the first MLB team to attract more than 3 million fans in a season (in 1978), and accomplished that feat six more times before any other franchise did it once. The Dodgers drew at least 3 million fans for 15 consecutive seasons from 1996 to 2010, the longest such streak in all of MLB. On July 3, 2007, Dodgers management announced that total franchise attendance, dating back to 1901, had reached 175 million, a record for all professional sports. In 2007, the Dodgers set a franchise record for single-season attendance, attracting over 3.8 million fans. In 2009, the Dodgers led MLB in total attendance. The Dodger baseball cap is consistently in the top three in sales. During the 2011–2012 season, Frank McCourt, the owner of the Dodgers at that time, was going through a rough divorce with his wife over who should be the owner of the Dodger team. Instead, Frank McCourt paid $131 million to his wife as part of the divorce settlement. As a result, the team payroll was financially low for a big-budget team crippling the Dodgers in the free-agent market. Collectively, the team performance waned due to the distracting drama in the front office resulting in low attendance numbers.

Given the team's proximity to Hollywood, numerous celebrities can often be seen attending home games at Dodger Stadium. Celebrities such as co-owner Magic Johnson, Mary Hart, Larry King, Tiger Woods, Alyssa Milano and Shia LaBeouf are known to sit at field box seats behind home plate where they sign autographs for fellow Dodger fans. Actor Bryan Cranston is a lifelong Dodger fan.

The Dodgers set the world record for the largest attendance for a single baseball game during an exhibition game against the Boston Red Sox on March 28, 2008 at the Los Angeles Memorial Coliseum in honor of the Dodgers 50th anniversary, with 115,300 fans in attendance. All proceeds from the game benefited the official charity of the Dodgers, ThinkCure! which supports cancer research at Children's Hospital Los Angeles and City of Hope. Primarily Dodgers fans are from their own location in southern California and also parts of southern Nevada; however there are also strong pockets of Dodger support in Mexico and throughout Asia, and their away games throughout the US will usually attract substantial numbers of expat and traveling fans.

Vin Scully called Dodgers games from 1950 to 2016. His longtime partners were Jerry Doggett (1956–1987) and Ross Porter (1977–2004). In 1976, he was selected by Dodgers fans as the Most Memorable Personality (on the field or off) in the team's history. He is also a recipient of the Baseball Hall of Fame's Ford C. Frick Award for broadcasters (inducted in 1982). Unlike the modern style in which multiple sportscasters have an on-air conversation (usually with one functioning as play-by-play announcer and the other[s] as color commentator), Scully, Doggett and Porter generally called games solo, trading with each other inning-by-inning. In the 1980s and 1990s, Scully would call the entire radio broadcast except for the third and seventh inning, allowing the other Dodger commentators to broadcast an inning.

When Doggett retired after the 1987 season, he was replaced by Hall-of-Fame Dodgers pitcher Don Drysdale, who previously broadcast games for the California Angels and Chicago White Sox. Drysdale died in his hotel room following a heart attack before a game in Montreal in 1993. This was a difficult broadcast for Scully and Porter who could not mention it on-air until Drysdale's family had been notified and the official announcement made. He was replaced by former Dodgers outfielder Rick Monday. Porter's tenure ended after the 2004 season, after which the format of play-by-play announcers and color commentators was installed, led by Monday and newcomer Charley Steiner. Scully, however, continued to announce solo.

Scully called roughly 100 games per season (all home games and road games in California and Arizona) for both flagship radio station KLAC and on television for SportsNet LA. Scully was simulcast for the first three innings of each of his appearances, then announced only for the TV audience. If Scully was calling the game, Steiner took over play-by-play on radio beginning with the fourth inning, with Monday as color commentator. If Scully was not calling the game, Steiner and Orel Hershiser called the entire game on television while Monday and Kevin Kennedy did the same on radio. In the event the Dodgers were in post-season play, Scully called the first three and last three innings of the radio broadcast alone and Steiner and Monday handled the middle innings. Vin Scully retired from calling games in 2016. His tenure with the Dodgers was the longest with any single sports team at 67 years. Youthful announcer Joe Davis was selected in 2017 by Dodgers management to handle play by play on television with Orel Hershiser as his colorman.

The Dodgers also broadcast on radio in Spanish, and the play-by-play is voiced by another Frick Award winner, Jaime Jarrín, who has been with the Dodgers since 1959. The color analyst for some games is former Dodger pitcher Fernando Valenzuela, for whom Jarrin once translated post-game interviews. The Spanish-language radio flagship station is KTNQ.




Koufax, Campanella, and Robinson were the first Dodgers to have their numbers retired, in a ceremony at Dodger Stadium on June 4, 1972. This was the year in which Koufax was inducted into the Baseball Hall of Fame; Robinson and Campanella were already Hall-of-Famers.

Alston's number was retired in the year following his retirement as the Dodgers manager, six years before he was inducted into the Hall of Fame.

Gilliam died suddenly in 1978 after a 28-year career with the Dodgers organization. The Dodgers retired his number two days after his death, prior to Game 1 of the 1978 World Series. As of 2018, he is the only non-Hall-of-Famer to have his number retired by the Dodgers (Alston's number was retired before he was elected to the Hall of Fame).

Beginning in 1980, the Dodgers have retired the numbers of longtime Dodgers (Snider, Reese, Drysdale, Lasorda, and Sutton) during the seasons in which each was inducted into the Hall of Fame.

In 1997, 50 years after he broke the color barrier and 25 years after the Dodgers retired his number, Robinson's No. 42 was retired throughout Major League Baseball. Robinson is the only major league baseball player to have this honor bestowed upon him. Starting in the 2007 season, Jackie Robinson Day (April 15, commemorating Opening Day of Robinson's rookie season of 1947) has featured many or all players and coaches wearing the number 42 as a tribute to Robinson.

The Dodgers have not issued the number 34 since the departure of Fernando Valenzuela in 1991, although it has not been officially retired.


Since 1884, the Dodgers have used a total of 31 Managers, the most current being Dave Roberts, who was appointed following the 2015 postseason, after the departure of Don Mattingly.

Over the nearly 43 years from 1954 to mid-1996, the Dodgers employed only two managers, Walter Alston and Tommy Lasorda, both of whom are in the Hall of Fame. During this entire time period of extraordinary stability, the Dodgers were family owned by Walter O'Malley and then his son Peter O'Malley. It was during this era that the Dodgers won 11 of their 21 pennants, and all six of their World Series championships.

The managers of the Los Angeles Dodgers (1958–present) are as follows:


During their time in Brooklyn, stadium organist Gladys Goodding became so well known that fans would joke that she was "the only Dodger who played every game without an error".

From the Dodgers' move to Los Angeles from Brooklyn in 1958, the Dodgers employed a handful of well-known public address announcers; the most famous of which was John Ramsey, who served as the PA voice of the Dodgers from 1958 until his retirement in 1982; he was also well known for announcing at other venerable Los Angeles venues, including the Los Angeles Memorial Coliseum and Sports Arena, and the Forum. Ramsey died in 1990.

From 1958 to 1982, Doug Moore, Philip Petty, and Dennis Packer served as back-up voices for John Ramsey for the Dodgers, California Angels, Los Angeles Chargers, USC football and Los Angeles Rams. Packer was Ramsey's primary backup for the Los Angeles Lakers and Los Angeles Kings until Ramsey's retirement from the Forum in 1978. Thereafter, Packer became the public address announcer for the Lakers, Kings, indoor soccer and indoor tennis events at the Forum.

Nick Nickson, a radio broadcaster for the Los Angeles Kings, replaced John Ramsey as the Dodger Stadium public address announcer in 1983 and served in that capacity through the 1989 season to work with the Kings full-time.

Dennis Packer and Pete Arbogast were emulators of John Ramsey, using the same stentorian style of announcing Ramsey was famous for. Packer and Arbogast shared the stadium announcing chores for the 1994 FIFA World Cup matches at the Rose Bowl. Arbogast won the Dodgers job on the day that Ramsey died on January 25, 1990, by doing a verbatim imitation of Ramsey's opening and closing remarks that were standard at each game. His replacement, in 1994 was Mike Carlucci, who remained as the Dodgers' PA voice announcer until he resigned in 2001 to concentrate on his voiceover and acting career along with his Olympics announcing duties.

From 2002 to 2014, the Dodgers public address announcer was Eric Smith, who also announces for the Los Angeles Clippers and USC Trojans.

On April 3, 2015 the Dodgers announced that former radio broadcaster Todd Leitz was hired to become their new public address announcer. Leitz was an anchor and news reporter in Los Angeles at KNX 1070 AM for 10 years, and a news reporter at KABC 790 for two years.

From 1988 to 2015, Nancy Bea enjoyed popularity behind the Dodger Stadium keyboard similar to Gladys Goodding. Since retirement in 2015, Beal's replacement and current organist is Dieter Ruehle, who also plays at Staples Center for Los Angeles Kings games.

Vin Scully is permanently honored in the Baseball Hall of Fame's "Scribes & Mikemen" exhibit as a result of winning the Ford C. Frick Award in 1982. Frick Award recipients are not official members of the Hall.

Sue Falsone, was the first female physical therapist in Major League baseball, and from 2012 to 2013, was the first female head athletic trainer.




</doc>
<doc id="18214" url="https://en.wikipedia.org/wiki?curid=18214" title="Louis Andriessen">
Louis Andriessen

Louis Andriessen (; born 6 June 1939) is a Dutch composer and pianist based in Amsterdam. He is a lecturer at the Royal Conservatory of The Hague. He was recipient of the Gaudeamus International Composers Award in 1959.

Andriessen was born in Utrecht into a musical family, the son of the composer Hendrik Andriessen (1892–1981), brother of composers Jurriaan Andriessen (1925–1996) and Caecilia Andriessen (1931–2019) and nephew of Willem Andriessen (1887–1964).

Andriessen originally studied with his father and Kees van Baaren at the Royal Conservatory of The Hague, before embarking upon two years of study with Italian composer Luciano Berio in Milan and Berlin. He later joined the faculty of the Royal Conservatory.

In 1969 Andriessen co-founded STEIM in Amsterdam. He also helped found the instrumental groups Orkest de Volharding and Hoketus, both of which performed compositions of the same names. He later became closely involved in the ongoing Schonberg and Asko ensembles and inspired the formation of the British ensemble Icebreaker.

Andriessen was married to guitarist Jeanette Yanikian (1935–2008). They were a couple for over 40 years and were married in 1996.

His current wife is violinist Monica Germino.

Andriessen's early works show experimentation with various contemporary trends: post war serialism ("Series", 1958), pastiche ("Anachronie I", 1966–67), and tape ("Il Duce", 1973). His reaction to what he perceived as the conservatism of much of the Dutch contemporary music scene quickly moved him to form a radically alternative musical aesthetic of his own. Since the early 1970s he has refused to write for conventional symphony orchestras and has instead opted to write for his own idiosyncratic instrumental combinations, which often retain some traditional orchestral instruments alongside electric guitars, electric basses, and congas.

Andriessen's mature music combines the influences of jazz, American minimalism, Igor Stravinsky and Claude Vivier. His harmonic writing eschews the consonant modality of much minimalism, preferring post war European dissonance, often crystallised into large blocks of sound. Large scale pieces such as "De Staat" ['Republic'] (1972–76), for example, are influenced by the energy of the big band music of Count Basie and Stan Kenton and the repetitive procedures of Steve Reich, both combined with bright, clashing dissonances. Andriessen's music is thus anti-Germanic and anti-Romantic, and marks a departure from post war European serialism and its offshoots. He has also played a role in providing alternatives to traditional performance practice techniques, often specifying forceful, rhythmic articulations, and amplified, non-vibrato, singing.

Other notable works include "Workers Union" (1975), a melodically indeterminate piece "for any loud sounding group of instruments"; "Mausoleum" (1979) for 2 baritones and large ensemble; "De Tijd" ['Time'] (1979–81) for female singers and ensemble; "De Snelheid" ['Velocity'] (1982–83), for 3 amplified ensembles; "De Materie" ['Matter'] (1984–88), a large four-part work for voices and ensemble; collaborations with filmmaker and librettist Peter Greenaway on the film "M is for Man, Music, Mozart" and the operas "Rosa: A Horse Drama" (1994) and "Writing to Vermeer" (1998); and "La Passione" (2000–02) for female voice, violin and ensemble.


Andriessen's primary publishers are Boosey & Hawkes and Donemus.
Complete list of works: 




</doc>
<doc id="18217" url="https://en.wikipedia.org/wiki?curid=18217" title="Leonard Peltier">
Leonard Peltier

Leonard Peltier (born September 12, 1944) is an indigenous rights activist who was convicted of murdering two FBI agents in a June 26, 1975, shooting on the Pine Ridge Reservation in South Dakota. Peltier is an enrolled member of the Turtle Mountain Chippewa, who is also of Lakota and Dakota descent. He is a member of the American Indian Movement (AIM). In 1977, he was convicted and sentenced to two consecutive terms of life imprisonment for first-degree murder in the shooting of two Federal Bureau of Investigation (FBI) agents during a 1975 shootout on the Pine Ridge Indian Reservation.

Peltier's indictment and conviction have been the subject of much controversy; Amnesty International placed his case under the "Unfair Trials" category of its "Annual Report: USA 2010". In his 1999 memoir, Peltier admitted to involvement in the shootout but denied killing the FBI agents.

Peltier is incarcerated at the United States Penitentiary, Coleman in Florida. Peltier became eligible for parole in 1993; his next scheduled parole hearing will be in July 2024, when Peltier will be 79. On January 18, 2017, the Office of the Pardon Attorney announced that President Barack Obama had denied Peltier's application for clemency. Peltier was next eligible for commutation in 2018. Barring appeals, parole, or presidential clemency, Peltier will remain in prison for the rest of his life.

Peltier was born on September 12, 1944, at the Turtle Mountain Indian Reservation of the Turtle Mountain Chippewa near Belcourt, North Dakota, in a family of thirteen children. Peltier's parents divorced when he was four years old. Therefore, Leonard and his sister Betty Ann lived with their paternal grandparents Alex and Mary Dubois-Peltier in the Turtle Mountain Indian Reservation. In September 1953, at the age of nine, Leonard was enrolled at the Wahpeton Indian School in Wahpeton, North Dakota, an Indian boarding school run by the Bureau of Indian Affairs (BIA). Leonard remained away from his home at Wahpeton Indian School through the ninth grade; the school forced assimilation to white American culture by requiring English and forbidding the inclusion of Native American culture. He graduated from Wahpeton in May 1957, and attended the Flandreau Indian School in Flandreau, South Dakota. After finishing the ninth grade, he returned to the Turtle Mountain Reservation to live with his father. Peltier later obtained a general equivalency degree.

In 1965, Peltier relocated to Seattle, Washington. Peltier was a welder, construction worker, and the co-owner of an auto shop in Seattle in his twenties. The co-owners of the shop in Seattle used the upper level of building as a stopping place for American Indians who had alcohol addiction issues or recently finished their prison sentences. However, the halfway house took a financial toll on the shop, so it closed down after some time.

In Seattle, Peltier became involved in a variety of causes championing Native American civil rights. In the early 1970s, he learned about the factional tensions at the Pine Ridge Indian Reservation in South Dakota between supporters of Richard Wilson, elected tribal chairman in 1972, and traditionalist members of the tribe. Consequently, Peltier became an official member of the American Indian Movement (AIM) in 1972. Wilson had created a private militia, known as the Guardians of the Oglala Nation (GOON), whose members were reputed to have attacked political opponents. Protests over a failed impeachment hearing of Wilson contributed to the AIM and Lakota armed takeover of Wounded Knee in February 1973, which resulted in a 71-day siege by federal forces, known as the Wounded Knee incident. They demanded the resignation of Wilson. Peltier, however, spent most of the occupation in a Milwaukee jail charged with attempted murder. When Peltier secured bail at the end of April, he took part in an AIM protest outside the federal building in Milwaukee and was on his way to Wounded Knee with the group to deliver supplies when the incident ended.

In 1975, Peltier traveled to the Pine Ridge Indian Reservation as a member of AIM to try to help reduce the continuing violence among political opponents. At the time, he was a fugitive, with a warrant issued in Milwaukee, Wisconsin. It charged him with unlawful flight to avoid prosecution for the attempted murder of an off-duty Milwaukee police officer, a crime of which he was acquitted in February 1978. During this time period, Peltier had seven children from two marriages and adopted two children.

On June 26, 1975, Special Agents Jack R. Coler and Ronald A. Williams of the Federal Bureau of Investigation (FBI) were on the Pine Ridge Indian Reservation searching for a young man named Jimmy Eagle, who was wanted for questioning in connection with the recent assault and robbery of two local ranch hands. Eagle had been involved in a physical altercation with a friend, during which he had stolen a pair of leather cowboy boots. At approximately 11:50 a.m., Williams and Coler, driving two separate unmarked cars, spotted, reported, and followed a red pick-up truck which matched the description of Eagle's.

Soon after his initial report, Williams radioed into a local dispatch that he and Coler had come under fire from the occupants of the vehicle. Williams radioed that they would be killed if reinforcements did not arrive. He next radioed that they both had been shot. FBI Special Agent Gary Adams was the first to respond to Williams' call for assistance, and he also came under gunfire; Adams was unable to reach Coler and Williams in time, and both agents died within the first ten minutes of gunfire. At about 4:25 p.m., authorities recovered the bodies of Williams and Coler from their vehicles.

The FBI reported that Williams had received a defensive wound to his right hand (as he attempted to shield his face) from a bullet which passed through his hand into his head, killing him instantly. Williams received two gunshot injuries, to his body and foot, prior to the contact shot that killed him. Coler, incapacitated from earlier bullet wounds, had been shot twice in the head. In total, 125 bullet holes were found in the agents' vehicles, many from a .223 Remington (5.56 mm) rifle. The shooters took apart Williams's car and stole four guns belonging to the agents.

Leonard Peltier provided numerous alibis, to different people, about his activities on the morning of the attacks. In an interview with the author Peter Matthiessen ("In the Spirit of Crazy Horse" 1983), Peltier described working on a car in Oglala, claiming to have driven back to the Jumping Bull Compound about an hour before the shooting started. In an interview with Lee Hill, he described being awakened in the tent city at the ranch by the sound of gunshots. To Harvey Arden, for "Prison Writings", he described enjoying a beautiful morning before he heard the firing.

On September 5, 1975, Agent Coler's .308 rifle and handgun and Agent Williams's handgun were recovered from an automobile in the vicinity of Darrelle Butler's arrest location. The FBI forwarded a description of a recreational vehicle (RV) and the Plymouth station wagon recently purchased by Peltier to law enforcement during the hunt for the suspects. The RV was stopped by an Oregon State Trooper, but the driver, later discovered to be Peltier, fled on foot following a small shootout. Both Peltier's thumbprint and Agent Coler's handgun were discovered under the RV's front seat.

On September 10, 1975, AIM members Robert Robideau, Norman Charles, and Michael Anderson were injured in the explosion of a station wagon on the Kansas Turnpike close to Wichita. Agent Coler's .308 rifle and an AR-15 rifle were found in the burned vehicle.

On December 22, 1975, Peltier was named to the FBI Ten Most Wanted Fugitives list. On February 6, 1976, Peltier was arrested after being found in a friend's cabin in Hinton, Alberta. In December 1976, he was extradited from Canada based on documents submitted by the FBI that Warren Allmand, Canada's Solicitor General at the time, would later state contained false information.

One of those documents was an affidavit signed by Myrtle Poor Bear, a local Native American woman. While Poor Bear stated that she was Peltier's girlfriend during that time and watched the killings, Peltier and others at the scene claimed that Poor Bear did not know Peltier and was not present during the murders. Poor Bear admitted to lying to the FBI, but emphasized that the agents interviewing her coerced her into making the claims above. When Poor Bear tried to testify against the FBI, the judge barred her testimony because of mental incompetence.

Peltier fought extradition to the United States, even as Bob Robideau and Darrelle "Dino" Butler, AIM members also present on the Jumping Bull compound at the time of the shootings, were found not guilty on the grounds of self-defense by a federal jury in Cedar Rapids, Iowa. Peltier returned too late to be tried with Robideau and Butler and he was subsequently tried separately.

Peltier's trial was held in Fargo, North Dakota, where a jury convicted Peltier of the murders of Coler and Williams. Unlike the trial for Butler and Robideau, the jury was informed that the two FBI agents were killed by close-range shots to their heads, when they were already defenseless due to previous gunshot wounds. Consequently, Peltier could not submit a self-defense testimony that could have led to an acquittal. They also saw autopsy and crime scene photographs of the two agents, which had not been shown to the jury at Cedar Rapids. In April 1977, Peltier was convicted and sentenced to two consecutive life sentences.

On July 20, 1979, Peltier and two other inmates escaped from Federal Correctional Institution, Lompoc. One inmate was shot dead by a guard outside the prison and the other was captured 90 minutes later approximately away. Peltier remained at large until he was captured by a search party three days later near Santa Maria, California, after robbing a farmer who notified authorities. He was in possession of a Ruger Mini-14 rifle at the time of his capture, but was apprehended without incident. On December 22, 1979, Peltier was convicted and sentenced to serve a consecutive five-year sentence for escape and a consecutive two-year sentence for being a felon in possession of a firearm.

Peltier has made a number of appeals against his murder convictions.

In 1986, Federal Appeals Judge Gerald W. Heaney, concluded, "When all is said and done ... a few simple but very important facts remain. The casing introduced into evidence had in fact been extracted from the Wichita AR-15." In his 1999 memoir, Peltier admitted that he fired at the agents, but denies that he fired the fatal shots that killed them.

A cartridge case from the Wichita AR-15 was found in the trunk of Agent Coler's car, and admitted as evidence at Peltier's trial in Fargo, North Dakota. Also admitted as evidence was the fact that Peltier was the only person in possession of an AR-15 rifle during the shooting.

The journalist Scott Anderson said that in a 1995 interview with Peltier, he sought answers to the contradictions he had found in Peltier's accounts of the incident on June 26, 1975. When asked about the guns he carried that day, Peltier listed a .30-30, a .303, a .306, a .250 and a .22, but he did not remember the AR-15.

The former United States Attorney General Ramsey Clark has served "pro bono" as one of Peltier's lawyers and has aided in filing a series of appeals on Peltier's behalf. Clark identifies the evidence used against Peltier as "fabricated, circumstantial ... mis-used, concealed, and perverted." In all appeals, the conviction and sentence have been affirmed by the 8th Circuit Court of Appeals. The last two appeals were "Peltier v. Henman", 997 F. 2d 461 in July 1993 and "United States v. Peltier", 446 F.3d 911 (8th Cir. 2006) (Peltier IV) in 2006.

Numerous doubts have been raised over Peltier's guilt and the fairness of his trial, based on allegations and inconsistencies regarding the FBI and prosecution's handling of this case:


Peltier's conviction sparked great controversy and has drawn criticism from a number of sources. Numerous appeals have been filed on his behalf; none of the resulting rulings has been made in his favor. Peltier is considered by the AIM to be a political prisoner and has received support from individuals and groups including Nelson Mandela, Rigoberta Menchú, Soviet Peace Committee, Amnesty International, the United Nations High Commissioner for Human Rights, the Zapatista Army of National Liberation, Tenzin Gyatso (the 14th Dalai Lama), Mikhail Gorbachev, Zack de la Rocha, Rage Against the Machine, the European Parliament, the Belgian Parliament, the Italian Parliament, the Kennedy Memorial Center for Human Rights, Archbishop Desmond Tutu, and Rev. Jesse Jackson.

Peltier's supporters have asserted that he did not commit the murders, and that he either had no knowledge of the murders (as he told CNN in 1999), or that he has knowledge implicating others which he will never reveal, or (as told in Peter Matthiessen's "In the Spirit of Crazy Horse", 1983) that he approached and searched the agents, but did not execute them.

The film "Incident at Oglala" (1992) included the AIM activist Robert Robideau saying the FBI agents had been shot by a 'Mr X'. When Peltier was interviewed about 'Mr X', he said he knew who the man was. Dino Butler, in a 1995 interview with E.K. Caldwell of "News From Indian Country", said that 'Mr X' had been invented as the murderer in an attempt to achieve Peltier's release. In a 2001 interview with "News From Indian Country", Bernie Lafferty said that she had witnessed Peltier's referring to his murder of one of the agents.

In 1999, Peltier filed a habeas corpus petition, but it was rejected by the 10th Circuit Court on November 4, 2003. Near the end of the Clinton administration in 2001, rumors began circulating that Bill Clinton was considering granting Peltier clemency. Opponents of Peltier campaigned against his possible clemency; about 500 FBI agents and families protested outside the White House, and FBI director Louis Freeh sent a letter opposing Peltier's clemency to the White House. Clinton did not grant Peltier clemency. In 2002, Peltier filed a civil rights lawsuit in the U.S. District Court for the District of Columbia against the FBI, Louis Freeh and FBI agents who had participated in the campaign against his clemency petition, alleging that they "engaged in a systematic and officially sanctioned campaign of misinformation and disinformation." On March 22, 2004, the suit was dismissed. In January 2009, President George W. Bush denied Peltier's clemency petition before leaving office.

In 2016, Peltier's attorney's filed a clemency application with the White House's Office of the Pardon Attorney, and his supporters organized a campaign to convince President Barack Obama to commute Peltier's sentence, a campaign which included an appeal by Pope Francis, as well as James Reynolds, a senior attorney and former US Attorney who supervised the prosecution against Peltier in the appeal period following his initial trial. In a letter to the United States Department of Justice, Reynolds wrote that clemency was "in the best interest of justice in considering the totality of all matters involved". In a subsequent letter to the "Chicago Tribune", Reynolds added that the case against Peltier "was a very thin case that likely would not be upheld by courts today. It is a gross overstatement to label Peltier a 'cold-blooded murderer' on the basis of the minimal proof that survived the appeals in his case." On January 18, 2017, two days before President Obama left office, the Office of the Pardon Attorney announced that Obama had denied Peltier's application for clemency. On June 8, 2018, KFGO Radio in Fargo, N.D., reported that Peltier filed a formal clemency request with President Trump. KFGO obtained and published a letter that was sent by Peltier's attorney to the White House.

In January 2002 in the "News from Indian Country", the publisher Paul DeMain wrote an editorial that an "unnamed delegation" told him that Peltier murdered the FBI agents. DeMain described the delegation as "grandfathers and grandmothers, AIM activists, Pipe carriers and others who have carried a heavy unhealthy burden within them that has taken its toll." DeMain said he was told the motive for the execution-style murder of the AIM activist Anna Mae Aquash in December 1975 "allegedly was her knowledge that Leonard Peltier had shot the two agents, as he was convicted." DeMain did not accuse Peltier of participation in the Aquash murder. In 2003 two Native American men were indicted and later convicted for the murder.

On May 1, 2003, Peltier sued DeMain for libel for similar statements about the case published on March 10, 2003, in "News from Indian Country". On May 25, 2004, Peltier withdrew the suit after he and DeMain settled the case. DeMain issued a statement saying he did not think Peltier was given a fair trial for the two murder convictions nor did he think Peltier was connected to Anna Mae Aquash's death. DeMain did not retract his allegations that Peltier was guilty of the murders of the FBI agents and that the motive for Aquash's murder was the fear that she might inform on the activist.

Bruce Ellison, Leonard Peltier's lawyer since the 1970s, invoked his Fifth Amendment rights against self-incrimination and refused to testify at the 2003 federal grand jury hearings on charges against Arlo Looking Cloud and John Graham for the murder of Aquash. Ellison also refused to testify at Looking Cloud's trial in 2004. During the trial, the federal prosecutor named Ellison as a co-conspirator in the Aquash case. Witnesses said that Ellison participated in interrogating Aquash about being an informant on December 11, 1975, shortly before her murder.

In February 2004, Fritz Arlo Looking Cloud, an Oglala Sioux, was tried and convicted for the murder of Aquash. In Looking Cloud's trial, the federal prosecution argued that AIM's suspicion of Aquash stemmed from her having heard Peltier admit to the murders. Darlene "Kamook" Nichols, former wife of the AIM leader Dennis Banks, was a witness for the prosecution. She testified that in late 1975, Peltier told her and a small group of AIM fugitive activists about shooting the FBI agents. At the time, all were fleeing law enforcement after the Pine Ridge shootout. The other fugitives included her sister Bernie Nichols, her husband Dennis Banks, and Anna Mae Aquash, among several others. Bernie Nichols-Lafferty testified with a similar account of Peltier's statement.

Earlier in 1975, the AIM member Douglass Durham had been revealed to be an FBI agent and dismissed from the organization. AIM leaders were fearful of infiltration. Other witnesses have testified that, once Aquash was suspected of being an informant, Peltier interrogated her while holding a gun to her head. Peltier and David Hill were said to have Aquash participate in bomb-making so that her fingerprints would be on the bombs. Prosecutors alleged in court documents that the trio planted these bombs at two power plants on the Pine Ridge Indian Reservation on Columbus Day 1975.

During the trial, Nichols acknowledged receiving $42,000 from the FBI in connection with her cooperation on the case. She said it was compensation for travel expenses to collect evidence and moving expenses to be farther from her ex-husband Dennis Banks, whom she feared because she had implicated him as a witness. Peltier has claimed that Kamook Nichols committed perjury with her testimony.

On June 26, 2007, the Supreme Court of British Columbia ordered the extradition of John Graham to the United States to stand trial for his alleged role in the murder of Aquash. He was eventually tried by the state of South Dakota in 2010. During his trial, Darlene "Kamook" Ecoffey said Peltier told both her and Aquash that he had killed the FBI agents in 1975. Ecoffey testified under oath, "He (Peltier) held his hand like this," she said, pointing her index finger like a gun, "and he said 'that (expletive) was begging for his life but I shot him anyway.'" Graham was convicted of murdering Aquash and sentenced to life in prison.

Peltier was the candidate for the Peace and Freedom Party in the 2004 election for President of the United States. While numerous states have laws that prohibit prison inmates convicted of felonies from voting (Maine and Vermont are exceptions), the United States Constitution has no prohibition against felons being elected to federal offices, including President. The Peace and Freedom Party secured ballot status for Peltier only in California, where his presidential candidacy received 27,607 votes, approximately 0.2% of the vote in that state.

He is running for Vice President in the 2020 election as the running mate of Gloria La Riva with the Party for Socialism and Liberation.

In a February 27, 2006, decision, U.S. District Judge William Skretny ruled that the FBI did not have to release five of 812 documents relating to Peltier and held at their Buffalo field office. He ruled that the particular documents were exempted on the grounds of "national security and FBI agent/informant protection". In his opinion, Judge Skretny wrote, "Plaintiff has not established the existence of bad faith or provided any evidence contradicting (the FBI's) claim that the release of these documents would endanger national security or would impair this country's relationship with a foreign government." In response, Michael Kuzma, a member of Peltier's defense team, said, "We're appealing. It's incredible that it took him 254 days to render a decision." Kuzma further said, "The pages we were most intrigued about revolved around a teletype from Buffalo ... a three-page document that seems to indicate that a confidential source was being advised by the FBI not to engage in conduct that would compromise attorney-client privilege." Peltier's supporters have tried to obtain more than 100,000 pages of documents from FBI field offices, claiming that the files should have been turned over at the time of his trial or following a Freedom of Information Act (FOIA) request filed soon after.

On January 13, 2009, Peltier was beaten by inmates at the United States Penitentiary, Canaan, where he had been transferred from USP Lewisburg. He was sent back to Lewisburg, where he remained until the fall of 2011 when he was transferred to a federal penitentiary in Florida. As of 2016, Leonard Peltier is housed at Coleman Federal Correctional Complex in Coleman, Florida.

A controversial statue of Peltier was created by political artist Rigo 23. After it was installed on the grounds of American University, officials removed it following outcry.



It was reported by Joseph Corré that the last words of his father, Malcolm McLaren, were "Free Leonard Peltier".





 


</doc>
<doc id="18221" url="https://en.wikipedia.org/wiki?curid=18221" title="LambdaMOO">
LambdaMOO

LambdaMOO is an online community of the variety called a MOO. It is the oldest MOO today.

"LambdaMOO" was founded in late 1990 or early 1991 by Pavel Curtis at Xerox PARC. Now hosted in the state of Washington, it is operated and administered entirely on a volunteer basis. Guests are allowed, and membership is free to anyone with an e-mail address.

"LambdaMOO" gained some notoriety when Julian Dibbell wrote a book called "My Tiny Life" describing his experiences there. Over its history, "LambdaMOO" has been highly influential in the examination of virtual-world social issues.

LambdaMOO has its roots in the 1978–1980 work by Roy Trubshaw and Richard Bartle to create and expand the concept of Multi-User Dungeon (MUD) – virtual communities. Around 1987–1988, the expansion of the global internet allowed more users to experience the MUD. Pavel Curtis at Xerox Parc noted that they were "almost exclusively for recreational purposes." Curtis determined to explore whether the MUD could be non-recreational. He developed "LambdaMOO" software to run on the LambdaMOO server, which implements the MOO programming language. This software was subsequently made available to the public. Several starter databases, known as cores, are available for MOOs; "LambdaMOO" itself uses the LambdaCore database. The "Lambda" name is from Curtis's own username on earlier MUD systems.

LambdaMOO can refer to the software, the server, or the community of users.

"LambdaMOO" central geography was based on Pavel Curtis's California home. New players and guests traditionally connected in "The Coat Closet", but a second area, "The Linen Closet" (specially programmed as a silent area) was later added as an alternative connection point. The coat closet opens onto the center of the house in The Living Room, a common hangout and place for conversation; its fixtures include a fireplace (where things can be roasted), The Living Room Couch (which periodically causes players' objects to 'fall through' to underneath the couch), and a pet Cockatoo who repeats overheard phrases (which is often found with its beak gagged). From time to time the Cockatoo is replaced with a more seasonal creature: a Turkey near Thanksgiving, a Raven near Halloween, et cetera.

To the north of the Living Room is the Entrance Hall, the Front Yard, and a limited residential area along LambdaStreet. There is an extensive subterranean complex located down the manhole, including a sewage system. Players walking to the far west along LambdaStreet may be given the option to 'jump off the end of the world', which disables access to their account for three months.

To the south of the Living Room is a pool deck, a hot tub, and some of the extensive grounds of the mansion, featuring gardens, hot air balloon landing pads, open fields, fishing holes, and the like.

To the northwest of the living room are the laundry room, garage, dining room, smoking room, drawing room, housekeeper's quarters, and kitchen; a popular command allows players in the living room to push others into the kitchen and ask them to "fetch me a cup of tea"; since players can prevent themselves from being moved in such a fashion, this command is more often used on new users, who may have difficulty finding their way back to the Living Room. (There is direct access to the kitchen leading northwest from the living room, but as with the actual house you must head north, east, and then south from the Kitchen to return.)

To the east of the entry hall, hallways provide access to some individual rooms, the Linen Closet, and to the eastern wing of the house. In the eastern wing can be found the Library of online books, the Museum of generic objects (which account-holders may create instances of), and an extensive area for the "LambdaMOO" RPG.

Since the creation of the original LambdaMOO map, many users have expanded the MOO by making additional rooms with the command "@dig."

While most MOOs are run by administrative fiat, in summer of 1993 "LambdaMOO" implemented a petition/ballot mechanism, allowing the community to propose and vote on new policies and other administrative actions. A petition may be created by anyone eligible to participate in politics (those who have maintained accounts at the MOO for at least 30 days), can be signed by other players, and may then be submitted for administrative 'vetting'. Once vetted, the petition has a limited time to collect enough signatures to become valid and be made into a ballot. Ballots are subsequently voted on; those with a 66% approval rating are passed and will be implemented. This system suffered quite a lot of evolution and eventually passed into a state where wizards took back the power they'd passed into the hands of the people, but still maintain the ballot system as a way for the community to express its opinions.

The population of "LambdaMOO" numbered close to 10,000 around 1994, with over 300 actively connected at any time.




</doc>
<doc id="18223" url="https://en.wikipedia.org/wiki?curid=18223" title="Lorica segmentata">
Lorica segmentata

The lorica segmentata () is a type of personal armour that was used by soldiers of the Roman Empire, consisting of metal strips ("girth hoops" fashioned into circular bands), fastened to internal leather straps. The Latin name translates to "segmented cuirass" and was first used in the 16th century; the Roman appellation is unknown.

The plates of "lorica segmentata" armour were soft iron inside and (some at least) were mild steel on the outside, making the plates hardened against damage without becoming brittle. This case hardening was done deliberately by packing organic matter tightly around them and heating them in a forge, transferring carbon from the burnt materials into the surface of the metal. 
The strips were arranged horizontally on the body, overlapping downwards, and they surrounded the torso in two halves, being fastened at the front and back. The upper body and shoulders were protected by additional strips ("shoulder guards") and breast- and backplates. The form of the armour allowed it to be stored very compactly, since it was possible to separate it into four sections, each of which would collapse on itself into a compact mass. The fitments that closed the various plate sections together (buckles, lobate hinges, hinged straps, tie-hooks, tie-rings, etc.) were made of brass. In later variants dating from around 75–80 A.D., the fastenings of the armour were simplified. Bronze hinges were removed in favour of simple rivets, belt fastenings utilised small hooks, and the lowest two girdle plates were replaced by one broad plate.

During the time of their use, this style of armour evolved and changed, the currently recognised types being the Dangestetten-Kalkriese-Vindonissa type from 9 BC to AD 43, the Corbridge-Carnuntum type from 69 to 100 and the Newstead type from 164 to 180, named after their places of discovery. There was, however, a considerable overlap between these types in use, and the Corbridge and Newstead types are often found at the same sites (e.g. at Caerleon in Wales, Carnuntum in Austria, Carlisle in England and León in Spain). It is possible that there was a fourth type, covering the body with segmented armour joined to scale shoulder defences. However, this is only known from one badly-damaged statue originating at Alba Iulia in Romania. The currently accepted range for the use of the armour is from about 14 B.C. (depiction on the arch of Susa) to the late 3rd century A.D. (León). Its use was geographically widespread, but mail ("lorica hamata") may have been more common at all times.

The question as to precisely who used the armour is debated. There is a clear difference in armour between the two corps shown on Trajan's Column. This is a monument erected in 113 in Rome to commemorate the conquest of Dacia by Emperor Trajan (ruled 98–117): its bas-reliefs are a key source for Roman military equipment. "Auxilia" are generally shown wearing mail, cuirasses, and carrying oval shields. Legionaries are uniformly depicted wearing the "lorica segmentata" and carrying the curved rectangular shield. On this basis, it has been supposed that "lorica segmentata" was used by legionaries only. However, some historians consider Trajan's Column to be inaccurate as a historical source due to its inaccurate and stylised portrayal of Roman armour: "it is probably safest to interpret the Column reliefs as ‘impressions’, rather than accurate representations." 

The view that "auxilia" were light troops originates from Vegetius' comment that ""auxilia" are always joined as light troops with the legions in the line". It is true that some specialist units in the "auxilia", such as Syrian archers and Numidian cavalry wore light armour (or none). But they were a small minority of the "auxilia". Most auxiliary "cohortes" contained heavy infantry similar to legionaries.

However, on another Trajanic monument (the Adamclisi "Tropaeum") the "lorica segmentata" does not appear at all, and legionaries and "auxilia" alike are depicted wearing either mail or scales ("lorica squamata"). Some experts are of the opinion that the Adamclisi monument is a more accurate portrayal of the situation, the "segmentata" used rarely, maybe only for set-piece battles and parades. This viewpoint considers the figures in Trajan's Column to be highly stereotyped, in order to distinguish clearly between different types of troops. In any event, both corps were equipped with the same weapons: "gladius" (a close-combat stabbing sword) and javelins, although the type of javelin known as "pilum" seems to have been provided to legionaries only. Goldsworthy points out that the equipment of both corps were roughly equal in weight.

In recent years archaeologists have found fittings of "loricae segmentatae" in many fort sites that are thought to have been garrisoned by only auxiliary troops, "i.e.", where the legions were "not" based. If the legions were, indeed, broken up and distributed around all these small bases, then it implies a tactical use of the legions that has not previously been considered. Hitherto, the legions were regarded as shock troops employed only "en masse" and not broken up into detachments. M.C. Bishop, however, has argued that there is a need to examine the way in which the various troop types were armed and deduce from this what their battle roles were, rather than trying to consider who wore what. The legions were armed and trained for close-order combat while the auxiliary forces, just as numerous, were more accustomed to open order fighting, although they could be employed as the legions were (e.g. at Mons Graupius) if circumstances demanded this.

During the 3rd century, all "peregrini" were granted Roman citizenship, and therefore legionaries lost their social superiority. The "lorica segmentata" eventually disappeared from Roman use, although it appears to have still been in use into the early 4th century, being depicted in the Arch of Constantine erected in 315 during the reign of Constantine I to commemorate his military achievements. (However, it has been argued that these depictions are from an earlier monument by Marcus Aurelius, from which Constantine incorporated portions into his Arch.)

The "lorica segmentata" has come to be viewed as iconic of the Roman legions in popular culture. The tendency to portray Roman legionaries clad in this type of armour often extends to periods of time that are too early or too late in history.





</doc>
<doc id="18224" url="https://en.wikipedia.org/wiki?curid=18224" title="Known Space">
Known Space

Known Space is the fictional setting of about a dozen science fiction novels and several collections of short stories written by Larry Niven. It has also become a shared universe in the spin-off "Man-Kzin Wars" anthologies. ISFDB catalogs all works set in the fictional universe that includes Known Space under the series name Tales of Known Space, which was the title of a 1975 collection of Niven's short stories. The first-published work in the series, which was Niven's first published piece was "The Coldest Place", in the December 1964 issue of "If" magazine, edited by Frederik Pohl. This was the first-published work in the 1975 collection.

The stories span approximately one thousand years of future history, from the first human explorations of the Solar System to the colonization of dozens of nearby systems. Late in the series, Known Space is an irregularly shaped "bubble" about 60 light-years across.

Within the Tales of Known Space, the epithet "Known Space" refers to a relatively small region in the Milky Way galaxy, one centered on Earth. In the future that the series depicts, spanning roughly the third millennium, humans have explored this region and colonized many of its worlds. Contact has been made with other species, such as the two-headed Pierson's Puppeteers and the aggressive felinoid Kzinti. Stories in the Known Space series include events and places outside of the region called "Known Space" such as the Ringworld, the Pierson's Puppeteers' Fleet of Worlds and the Pak homeworld.

The Tales were originally conceived as two separate series, the "Belter" stories set roughly from 2000 to 2350 CE and the "Neutron Star" / "Ringworld" stories set in 2651 CE and later. The earlier, Belter period features solar-system colonization and slower-than-light travel with fusion-powered and Bussard ramjet ships. The later, Neutron Star period features faster-than-light ships using "hyperdrive". Niven implicitly joined the two settings as a single fictional universe in the short story "A Relic of the Empire" ("If", December 1966), by using background elements of the Slaver civilization from the "Belter" series as a plot element in the faster-than-light setting. In the late 1980s—having written almost no Tales of Known Space in more than a decade—Niven opened the 300-year gap in the Known Space timeline as a shared universe, and the stories of the "Man-Kzin Wars" volumes fill in that history, bridging the two settings.

One aspect of the "Known Space" universe is that most of the early human colonies are on planets suboptimal for "Homo sapiens". During the first phase of human interstellar colonization (i.e. before humanity acquired FTL), simple robotic probes were sent to nearby stars to assess their planets for habitation. The programming of these probes was flawed: they sent back a "good for colonization" message if they found a habitable "point", rather than a habitable "planet". Sleeper ships containing human colonists were sent to the indicated star systems. Too often, those colonists had to make the best of a bad situation.


The series features a number of "superscience" inventions which figure as plot devices. Stories earlier in the timeline feature technology such as Bussard ramjets, Drouds (wires capable of directly stimulating the pleasure centers of the brain) and explore how organ transplantation technology enables the new crime of "organlegging" (as well as the general sociological effects of widespread transplant technology), while later stories feature hyperdrive, invulnerable starship hulls, stasis fields, molecular monofilaments, transfer booths (teleporters used only on planetary surfaces), the lifespan-extending drug boosterspice, and the tasp which is an extension of the wirehead development which works without direct contact.

Boosterspice is a compound that increases the longevity and reverses aging of human beings. With the use of boosterspice, humans can easily live hundreds of years and, theoretically, indefinitely.

Developed by the Institute of Knowledge on Jinx, it is said to be made from genetically engineered ragweed (although early stories have it ingested in the form of edible seeds). In "Ringworld's Children", it is suggested boosterspice may actually be adapted from Tree-of-Life, without the symbiotic virus that enabled hominids to metamorphose from Pak Breeder stage to Pak Protector stage (mutated Pak breeders were the ancestors of both "Homo sapiens" and the hominids of the Ringworld).

On the Ringworld, there is an analogous (and apparently more potent) compound developed from Tree-of-Life, but they are mutually incompatible; in "The Ringworld Engineers", Louis Wu learns that the character Halrloprillalar died when in ARM custody after leaving the Ringworld, as a result of having taken boosterspice after having used the Ringworld equivalent. Boosterspice only works on "Homo sapiens", whereas the Tree-of-Life compound will work on any hominid descended from the Pak.

Faster-than-light (FTL) propulsion, or hyperdrive, was obtained from the Outsiders at the end of the First Man-Kzin War. In addition to winning the war for humanity, it allowed the re-integration of all the human colonies, which were previously separated by distance. Standard hyperdrive covers a distance of one light-year every three days (121.75 x c). A more advanced Quantum II Hyperdrive introduced later is able to cover the same distance in one and a quarter minutes (420,768 x c).

In Niven's first novel, "World of Ptavvs", the hyperdrive used by the Thrintun required a ship to be going faster than 93% of the speed of light. However, this is the only time that Hyperdrive is described this way.

In the vast majority of "Known Space" material, hyperdrive requires that a ship be outside a star's gravity well to use. Ships which activate hyperdrive close to a star are likely to disappear without a trace. This effect is regarded as a limitation based on the laws of physics. In Niven's novel "Ringworld's Children" the Ringworld itself is converted into a gigantic Quantum II hyperdrive and launched into hyperspace while within its star's gravity well. "Ringworld's Children" reveals that there is life in hyperspace around gravity wells and that hyperspace predators eat spaceships which appear in hyperspace close to large masses, thus explaining why a structure as large as the Ringworld can safely engage the hyperdrive in a star's gravity well.

One phenomenon travellers in hyperspace can experience is the so-called 'blind spot' should they look through a porthole or camera screen, giving the impression that the walls around the porthole or sides of the camera view screen are expanding to 'cover up the outside'. The phenomenon is the result of hyperspace being so fundamentally different from 'normal/Einstein' space that a traveller's senses can not truly comprehend it, and instead the observer 'sees' a form of nothingness that can be hypnotic and dangerous.
Staring too long into the 'blind' spot can be insanity inducing, so as a precaution all view ports on ships are blinded when a ship enters hyperspace.

The Puppeteer firm, General Products, produces an invulnerable starship hull, known simply as a General Products Hull. The hulls are impervious to any type of matter or energy, with the exception of antimatter (which destroys the hull), gravitation, and visible light (which passes through the hull). While invulnerable themselves, this is no guarantee that the contents are likewise protected. For example, though a high speed impact with the surface of a planet or star may cause no harm to the hull, the occupants will be crushed if they are not protected by additional measures such as a stasis field or a gravity compensating field.

In "Fleet of Worlds", the characters tour a General Products factory and receive clues that allow them to destroy a General Products hull from the inside using only a high-powered interstellar communications laser. In "Juggler of Worlds", the Puppeteers, attempting to surmise how this was done without antimatter, identify another technique which can be used to destroy the otherwise invulnerable hulls, one which does suggest some potential defense options.

On Earth in the mid-21st century, it became possible to transplant any organ from any person to another, with the exception of brain and central nervous system tissue. Individuals were categorized according to their so-called "rejection spectrum" which allowed doctors to counter any immune system responses to the new organs, allowing transplants to "take" for life. It also enabled the crime of "organlegging" which lasted well into the 24th century.

A Slaver stasis field creates a bubble of space/time disconnected from the entropy gradient of the rest of the universe. Time slows effectively to a stop for an object in stasis, at a ratio of some billions of years outside to a second inside. An object in stasis is invulnerable to anything occurring outside the field, as well as being preserved indefinitely. A stasis field may be recognized by its perfectly reflecting surface, so perfect that it reflects 100% of all radiation and particles, including neutrinos. However one stasis field cannot exist inside another. This is used in "World of Ptavvs" where humans develop a stasis field technology and realize that a mirrored artifact known as the "Sea Statue" must be actually an alien in a stasis field. They place it with a human envoy, who is a telepath, and envelop both in field. By doing this, they unleash the last living member of the Slaver species on the world.

Stepping disks are a fictional teleportation technology. They were invented by the Pierson's Puppeteers, and their existence is not generally known to other races until the events of "The Ringworld Engineers".

The stepping disks are an outgrowth and improvement of the transfer booth technology used by humans and other Known Space races. Unlike the booths, the disks do not require an enclosed chamber, and somehow can differentiate between solid masses and air, for example. They also have a far greater range than transfer booths, extending several astronomical units.

Several limitations to stepping disks are mentioned in the Ringworld novels. If there is a difference in velocity between two disks, any matter transferred between them must be accelerated by the disk accordingly. If there is not enough energy to do so, the transfer cannot take place. This becomes a problem with disks that are a significant distance apart on the Ringworld surface, as they will have different velocities: same speed, different direction.

Transfer booths are an inexpensive form of teleportation. Short-range booths are similar in appearance to an old style telephone booth: one enters, "dials" one's desired destination, and is immediately deposited in a corresponding booth at the destination. Longer-range booths operate similarly, but are housed in former airports due to requiring "equipment to compensate for the difference in rotational velocity between different points on the Earth". They are inexpensive: a trip anywhere on Earth costs only a "tenth-star" (presumably equivalent to a dime). Introduced by one of Gregory Pelton's ancestors, apparently bought from, and based on, Puppeteer technology.

Some individuals in the stories display limited paranormal or "psionic" abilities. Gil Hamilton can move objects with his mind using his phantom arm, which he gained after losing an arm in an asteroid mining accident. When he finally had the arm replaced from an organ bank on Earth, the ability persisted. "Plateau Eyes" (introduced in "A Gift From Earth") is an ability to hide in plain sight, by causing others not to notice you. Population control is tight on Earth, but these abilities can gain the possessor a license to have more children. The Pierson's Puppeteers engineer a lottery for child licenses on Earth to increase the occurrence of "Luck", which they think is a paranormal ability humans have that has enabled them to defeat races such as the Kzinti. In "Ringworld", the character Teela Brown is said to have this ability (although possibly not to the same extent as others who avoided being included in the expedition.)

The ARM is the police force of the United Nations. ARM originated as an acronym for "Amalgamation of Regional Militia", though this is not a term in current usage by the time of the "Known Space" novels. An agent of the ARM, Gil Hamilton, is the protagonist of Niven's sci-fi detective stories, a series-within-a-series gathered in the collection "Flatlander". (Confusingly, "Flatlander" is also the name of an unrelated "Known Space" story.)

Their basic function is to enforce mandatory birth control on overcrowded Earth, and restrict research which might lead to dangerous weapons. In short, the ARM hunts down women who have illegal pregnancies and suppresses all new technologies. They also hunt organleggers, especially in the era of the "organ bank problem". Among the many technologies they control and outlaw are all trained forms of armed and unarmed combat. By the 25th century, ARM agents were kept in an artificially induced state of paranoid schizophrenia to enhance their usefulness as law enforcement officials, which led to them sometimes being referred to as ""Schizes"". Agents with natural tendencies toward paranoia were medicated into docility during their off duty hours, through the aforementioned science of psychistry (see "Madness Has Its Place" and "Juggler of Worlds").

Their jurisdiction is limited to the Earth-Moon system; other human colonies have their own militia. Nevertheless, in many "Known Space" stories, ARM agents operate or exert influence in other human star systems through the "Bureau of Alien Affairs" (see "In the Hall of the Mountain King", "Procrustes", "The Borderland of Sol", and "Neutron Star"). These interventions begin following the Man-Kzin Wars and the introduction of hyperdrive, presumably as part of a general re-integration of human societies.

The Tales of Known Space were first published primarily as short stories or serials in science fiction magazines. Generally the short fiction was subsequently released in one or more collections and the serial novels as books. Some of the shorter novels (novellas) published in magazines were expanded as, or incorporated in, book-length novels. There are also two or three short stories which share common themes and some background elements with "Known Space" stories, but which are not considered a part of the "Known Space" universe: "One Face" (1965) and "Bordered in Black" (1966) —both in the 1979 collection "Convergent Series"—and possibly "The Color of Sunfire", published online and listed here.

In the "Known Space" stories, Niven had created a number of technological devices (GP hull, stasis field, Ringworld material) which, combined with the "Teela Brown gene", made it very difficult to construct engaging stories beyond a certain date—the combination of factors made it tricky to produce any kind of creditable threat/problem without complex contrivances. Niven demonstrated this, to his own satisfaction, with "Safe at Any Speed" (1967). He used the setting for much less short fiction after 1968 and much less for novels after two published in 1980. Late in that decade, Niven invited other authors to participate in a series of shared-universe novels, with the Man-Kzin Wars as their setting. The first volume was published in 1988.

"Ringworld" (1970) won the annual Nebula, Hugo, and Locus best novel awards.
"Protector" (1973) and "The Ringworld Engineers" (1980) were nominated for the Hugo and Locus Awards.

Niven has described his fiction as "playground equipment", encouraging fans to speculate and extrapolate on the events described. Debates have been made, for example, on who built the Ringworld (Pak Protectors and the Outsiders being the traditional favorites, but see "Ringworld's Children" for a possibly definitive answer), and what happened to the Tnuctipun. Niven also states that this is not an invitation to violate his copyrights, warning potential publishers and editors not to proceed without permission.

Niven was also reported to have said that "Known Space should be seen as a possible future history told by people that may or may not have all their facts right."

The author also published an "outline" for a story which would "destroy" the Known Space Series (or more precisely, reveal much of the Known Space background to be an in-universe hoax), in an article entitled "Down in Flames". Although the article is written as though Niven intended to write the story, he later wrote that the article was only an elaborate joke, and he never intended to write such a novel. The article itself notes that the outline was made obsolete by the publication of "Ringworld". "Down in Flames" was a result of a conversation between Norman Spinrad and Niven in 1968, but at the time of its first publication in 1977 some of the concepts were invalidated by Niven's writings between '68 and '77. (A further edited version of the outline was published in "N-Space" in 1990.)




</doc>
<doc id="18225" url="https://en.wikipedia.org/wiki?curid=18225" title="LeRoy Homer Jr.">
LeRoy Homer Jr.

LeRoy Wilton Homer Jr. (August 27, 1965 – September 11, 2001) was the First Officer of United Airlines Flight 93, which was hijacked as part of the September 11 attacks in 2001, and crashed into a field near Shanksville, Pennsylvania, killing all 37 passengers and seven crewmembers, including LeRoy.

Homer, son of a West German woman and an American soldier who was stationed in West Germany, grew up on Long Island in New York, where he always dreamed of flying. As a child, he assembled model airplanes, collected aviation memorabilia and read books on aviation. He was 15 years old when he started flight instruction in a Cessna 152. Working part-time jobs after school to pay for flying lessons, he completed his first solo trip at the age of 16 and obtained his private pilot's certificate in 1983.

Homer was graduated from Ss. Cyril and Methodius School in 1979 and St. John the Baptist Diocesan High School in 1983.

He entered the United States Air Force Academy as a member of the class of 1987. As an upperclassman, he was a member of Cadet Squadron 31. He graduated on May 27, 1987, and was commissioned as a second lieutenant in the U.S. Air Force.

After completing his USAF pilot training in 1988, he was assigned to McGuire Air Force Base in New Jersey, flying a Lockheed C-141 Starlifter. While on active duty, he served in the Gulf War and later supported operations in Somalia. He received many commendations, awards and medals during his military career. In 1993, he was named the Twenty-First Air Force "Aircrew Instructor of the Year". Homer achieved the rank of captain before his honorable discharge from active duty in 1995 and his acceptance of a Reserve Commission in order to continue his career as an Air Force officer.

Homer continued his military career as a member of the U.S. Air Force Reserve, initially as a C-141 instructor pilot with the 356th Airlift Squadron at Wright-Patterson Air Force Base in Ohio, then subsequently as an Academy Liaison Officer, recruiting potential candidates for both the Air Force Academy and the Air Force Reserve Officer Training Corps. During his time in the Air Force Reserve, he achieved the rank of major.

He continued his flying career by joining United Airlines in May 1995. His first assignment was Second Officer on the Boeing 727. He then upgraded to First Officer on the Boeing 757/Boeing 767 in 1996, where he remained until September 11, 2001.

He married his wife, Melodie, on May 24, 1998, and his first child, Laurel, was born in late November 2000. They resided together in Marlton, New Jersey.
On September 11, 2001, Homer was flying with Captain Jason M. Dahl on United Airlines Flight 93 from Newark, New Jersey, to San Francisco. The plane was hijacked by four al-Qaeda terrorists as part of the September 11 attacks. Homer and Dahl struggled with the hijackers, which was transmitted to Air Traffic Control.

After learning of the earlier crashes at the World Trade Center and the Pentagon, the crew and passengers attempted to foil the hijacking and reclaim the aircraft. Given the uprising of crew and passengers, and knowing they would not make it to their intended target, which was the US Capitol, they instead chose to crash the plane into a field near Shanksville, Pennsylvania.
Homer received many awards and citations posthumously, including honorary membership in the historic Tuskegee Airmen; the Congress of Racial Equality's Dr. Martin Luther King Jr. Award; the Southern Christian Leadership Conference Drum Major for Justice Award; and the Westchester County Trailblazer Award.

He is survived by his wife, Melodie, and his only daughter, Laurel. Other family members include his mother, seven sisters, and his brother. His widow Melodie Homer established the LeRoy W. Homer Jr. Foundation, which awards scholarships related to aviation.

At the National 9/11 Memorial, Homer Jr. is memorialized at the South Pool, on Panel S-67, along with other crew and passengers on Flight 93.




</doc>
<doc id="18227" url="https://en.wikipedia.org/wiki?curid=18227" title="LGB">
LGB

LGB may refer to:




</doc>
<doc id="18230" url="https://en.wikipedia.org/wiki?curid=18230" title="La Jetée">
La Jetée

La Jetée () ("The Jetty", here referring to the publicly accessible top of an infrastructural pier or jetty at an airport) is a 1962 French Left Bank science fiction featurette by Chris Marker. Constructed almost entirely from still photos, it tells the story of a post-nuclear war experiment in time travel. It is 28 minutes long and shot in black and white. 

It won the Prix Jean Vigo for short film. The 1995 science fiction film "12 Monkeys" was inspired by and borrows several concepts directly from "La Jetée", as does the 2015 "12 Monkeys" television series developed from the film.

A man (Davos Hanich) is a prisoner in the aftermath of World War III in post-apocalyptic Paris, where survivors live underground in the "Palais de Chaillot" galleries. Scientists research time travel, hoping to send test subjects to different time periods "to call past and future to the rescue of the present". They have difficulty finding subjects who can mentally withstand the shock of time travel. The scientists eventually settle upon the prisoner; his key to the past is a vague but obsessive memory from his pre-war childhood of a woman (Hélène Chatelain) he had seen on the observation platform ("the jetty") at Orly Airport shortly before witnessing a startling incident there. He did not understand exactly what happened, but knew he had seen a man die.

After several attempts, he reaches the pre-war period. He meets the woman from his memory, and they develop a romantic relationship. After his successful passages to the past, the experimenters attempt to send him into the far future. In a brief meeting with the technologically advanced people of the future, he is given a power unit sufficient to regenerate his own destroyed society.

Upon his return, with his mission accomplished, he discerns that he is to be executed by his jailers. He is contacted by the people of the future, who offer to help him escape to their time permanently; but he asks instead to be returned to the pre-war time of his childhood, hoping to find the woman again. He is returned to the past, placed on the jetty at the airport, and it occurs to him that the child version of himself is probably also there at the same time. He is more concerned with locating the woman, and quickly spots her. However, as he rushes to her, he notices an agent of his jailers who has followed him and realizes the agent is about to kill him. In his final moments, he comes to understand that the incident he witnessed as a child, which has haunted him ever since, was his own death.


"La Jetée" is constructed almost entirely from optically printed photographs playing out as a photomontage of varying rhythm. It contains only one brief shot (of the woman mentioned above sleeping and suddenly waking up) originating on a motion-picture camera, this due to the fact that Marker could only afford to hire one for an afternoon. The stills were taken with a Pentax Spotmatic and the motion-picture segment was shot with a 35 mm Arriflex. The film has no dialogue aside from small sections of muttering in German and people talking in an airport terminal. The story is told by a voice-over narrator. The scene in which the hero and the woman look at a cut-away trunk of a tree is a reference to Alfred Hitchcock's 1958 film "Vertigo" which Marker also references in his 1983 film "Sans soleil".

The editing of "La Jetée," adds to the intensity of the film. With the use of cut-ins and fade-outs, it produces the eerie and unsettling nature adding to the theme of the apocalyptic destruction of World World III. Director of "12 Monkeys", Terry Gilliam, describes the editing as "simply poetic" in the combination of editing and soundtrack that is used in the short film. 

As the film plays out as a photomontage, the only continuous variable is the sound. The sound used in this production is minimal, showing up in the form of narration, Orchestral score and sound effect. The rhythmic patterns of the soundtrack act as a framework to add to the intensity of the film. This is seen as "The dissolve is synchronized with the sound. As the story moves from the past to the present, La Jetee creates mental continuity." The soundtrack adds to the Illusion of movement within the film and the change of time.

In "Black and Blue", her study of postwar French fiction, Carol Mavor describes "La Jetée" as taking "place in a no-place (u-topia) in no-time (u-chronia)" which she connects to the time and place of the fairy tale. She goes on to say "even the sound of the title resonates with the fairy-tale surprise of finding oneself in another world: La Jetée evokes 'là j'étais' (there I was)". By "u-topia", Mavor does not refer to "utopia" as the word is commonly used; she also describes an ambiguity of dystopia/utopia in the film: "It is dystopia with the hope of utopia, or is it utopia cut by the threat of dystopia."

Tor Books blogger Jake Hinkson summed up his interpretation in the title of an essay about the film, "There's No Escape Out of Time". He elaborated:

Hinkson also addresses the symbolic use of imagery: "The Man is blindfolded with some kind of padded device and he sees images. The Man is chosen for this assignment because ... he has maintained a sharp mind because of his attachment to certain images. Thus a film told through the use of still photos becomes about looking at images." He further observes that Marker himself did not refer to "La Jetée" as a film, but as photo novel.

In 2010, "Time" ranked "La Jetée" first in its list of "Top 10 time-travel movies". In 2012, in correspondence with the "Sight & Sound" Poll, the British Film Institute deemed "La Jetée" as the 50th greatest film of all time.

In 1963, Prix Jean Vigo awarded "La Jetée" for "Best Short Film." 

In 1963, "La Jetée" was part of the Locarno International Film Festival. 

In 2009, the films was featured in "Buenos Aires Festival Internacional de Cine Independiente.

"La Jetée" was featured in the "Cine//B Film Festival" in 2011. 

The International Documentary Film Festival Amsterdam had "La Jetée" as a featured film in 2019. 

Science fiction writer William Gibson considers the film one of his main influences.

The video for Sigue Sigue Sputnik's 1989 single "Dancerama" is also an homage to "La Jetée".

The film is one of the influences in the video for David Bowie's "Jump They Say" (1993).

Terry Gilliam's "12 Monkeys" (1995) was inspired by and takes several concepts directly from "La Jetée" (acknowledging this debt in the opening credits).

The 2003 short film "La puppé" is both an homage to and a parody of "La Jetée".

The 2007 Mexican film "Year of the Nail", which is told entirely through still photographs, was inspired by "La Jetée".

Kode9 in collaboration with Ms. Haptic, Marcel Weber (aka MFO), and Lucy Benson created an homage to "La Jetée" in 2011, for the Unsound Festival.

Northern Irish rock band Two Door Cinema Club screened the film at the launch party for their 2016 album "Gameshow". The final track on the album, "Je viens de la", is inspired by "La Jetée" and describes the journey of the film's protagonist.

The film was included in the "1001 Movies You Must See Before You Die<nowiki>"</nowiki> by producer, Steven Schneider. 

In 1996, Zone Books released a book which reproduced the film's original images along with the script in both English and French.

In Region 2, the film is available with English subtitles in the "La Jetée/Sans soleil" digipack released by Arte Video. In Region 1, the Criterion Collection has released a "La Jetée/Sans soleil" combination DVD / Blu-ray, which features the option of hearing the English or French narration.




</doc>
<doc id="18232" url="https://en.wikipedia.org/wiki?curid=18232" title="Little penguin">
Little penguin

The little penguin ("Eudyptula minor") is the smallest species of penguin. It grows to an average of in height and in length, though specific measurements vary by subspecies. It is found on the coastlines of southern Australia and New Zealand, with possible records from Chile. In Australia, they are often called fairy penguins because of their small size. In New Zealand, they are more commonly known as little blue penguins or blue penguins owing to their slate-blue plumage; they are also known by their Māori name: kororā.

The little penguin was first described by German naturalist Johann Reinhold Forster in 1781. Several subspecies are known, but a precise classification of these is still a matter of dispute. The holotypes of the subspecies "E. m. variabilis" and "Eudyptula minor chathamensis" are in the collection of the Museum of New Zealand Te Papa Tongarewa. The white-flippered penguin is sometimes considered a subspecies, sometimes a distinct species, and sometimes a morph. 

Genetic analyses indicate that the Australian and Otago (southeastern coast of South Island) little penguins may constitute a distinct species. In this case the specific name "minor" would devolve on it, with the specific name "novaehollandiae" suggested for the other populations. This interpretation suggests that "E. novaehollandiae" individuals arrived in New Zealand between AD 1500 and 1900 while the local "E. minor" population had declined, leaving a genetic opening for a new species.

Mitochondrial and nuclear DNA evidence suggests the split between "Eudyptula" and "Spheniscus" occurred around 25 million years ago, with the ancestors of the white-flippered and little penguins diverging about 2.7 million years ago.

Like those of all penguins, the little penguin's wings have developed into flippers used for swimming. The little penguin typically grows to between tall and usually weighs about 1.5 kg on average (3.3 lb). The head and upper parts are blue in colour, with slate-grey ear coverts fading to white underneath, from the chin to the belly. Their flippers are blue in colour. The dark grey-black beak is 3–4 cm long, the irises pale silvery- or bluish-grey or hazel, and the feet pink above with black soles and webbing. An immature individual will have a shorter bill and lighter upperparts.

Like most seabirds, they have a long lifespan. The average for the species is 6.5 years, but flipper ringing experiments show in very exceptional cases up to 25 years in captivity.

The little penguin breeds along the entire coastline of New Zealand (including the Chatham Islands), and southern Australia (including roughly 20,000 pairs on Babel Island). Australian colonies exist in New South Wales, Victoria, Tasmania, South Australia, and Western Australia. Little penguins have also been reported from Chile (where they are known as "pingüino pequeño" or "pingüino azul") (Isla Chañaral 1996, Playa de Santo Domingo, San Antonio, 16 March 1997) and South Africa, but it is unclear whether these birds were vagrants. As new colonies continue to be discovered, rough estimates of the world population are around 350,000-600,000 animals.

Overall, little penguin populations in New Zealand have been decreasing. Some colonies have become extinct and others continue to be at risk. Some new colonies have been established in urban areas. The species is not considered endangered in New Zealand, with the exception of the white-flippered subspecies found only on Banks Peninsula and nearby Motunau Island. Since the 1960s, the mainland population has declined by 60-70%; though a small increase has occurred on Motunau Island.

Australian little penguin colonies primarily exist on offshore islands, where they are protected from feral terrestrial predators and human disturbance. Colonies are found from Port Stephens in northern New South Wales around the southern coast to Fremantle, Western Australia.

An endangered population of little penguins exists at Manly, in Sydney's North Harbour. The population is protected under the NSW Threatened Species Conservation Act 1995 and has been managed in accordance with a Recovery Plan since the year 2000. The population once numbered in the hundreds, but has decreased to around 60 pairs of birds. The decline is believed to be mainly due to loss of suitable habitat, attacks by foxes and dogs and disturbance at nesting sites.

The largest colony in New South Wales is on Montague Island. Up to 8000 breeding pairs are known to nest there each year.

A population of about 5,000 breeding pairs exists on Bowen Island. The colony has increased from 500 pairs in 1979 and 1500 pairs in 1985. During this time, the island was privately leased. The island was vacated in 1986 and is currently controlled by the federal government.

In South Australia, many little penguin colony declines have been identified across the state. In some cases, colonies have declined to extinction (including the Neptune Islands, West Island, Wright Island, Pullen Island and several colonies on western Kangaroo Island), while others have declined from thousands of animals to few (Granite Island and Kingscote). A report released in 2011 presented evidence supporting the listing of the statewide population or the more closely monitored sub-population from Gulf St. Vincent as Vulnerable under South Australia's "National Parks & Wildlife Act 1972". As of 2014, the little penguin is not listed as a species of conservation concern, despite ongoing declines at many colonies.

Tasmanian little penguin population estimates range from 110,000–190,000 breeding pairs of which less than 5% are found on mainland Tasmania. Ever-increasing human pressure is predicted to result in the extinction of colonies on mainland Tasmania.

The largest colony of little penguins in Victoria is located at Phillip Island, where the nightly 'parade' of penguins across Summerland Beach has been a major tourist destination, and more recently a major conservation effort, since the 1920s. Phillip Island is home to an estimated 32,000 breeding adults. Little penguins can also be seen in the vicinity of the St Kilda, Victoria pier and breakwater. The breakwater is home to a colony of little penguins which have been the subject of a conservation study since 1986.

Little penguin habitats also exist at a number of other locations, including London Arch and The Twelve Apostles along the Great Ocean Road, Wilson's Promontory and Gabo Island.

The largest colony of little penguins in Western Australia is believed to be located on Penguin Island, where an estimated 1,000 pairs nest during winter. Penguins are also known to nest on Garden Island and Carnac Island which lie north of Penguin Island. Many islands along Western Australia's southern coast are likely to support little penguin colonies, though the status of these populations is largely unknown. An account of little penguins on Bellinger Island published in 1928 numbered them in their thousands. Visiting naturalists in November 1986 estimated the colony at 20 breeding pairs. The account named another substantial colony 12 miles from Bellinger Island and the same distance from Cape Pasley. Little penguins are known to breed on some islands of the Recherche Archipelago, including Woody Island where day-tripping tourists can view the animals. A penguin colony exists on Mistaken Island in King George Sound near Albany. Historical accounts of little penguins on Newdegate Island at the mouth of Deep River and on Breaksea Island near Torbay also exist.

In 1930 in Tasmania, it was believed that little penguins were competing with mutton-birds, which were being commercially exploited. An "open season" in which penguins would be permitted to be killed was planned in response to requests from members of the mutton-birding industry.

The impacts of human habitation in proximity to little penguin colonies include collisions with vehicles, direct harassment, burning and clearing of vegetation and housing development.

Penguins are vulnerable to interference by humans, especially while they are ashore during molt or nesting periods. In 1949, penguins on Phillip Island in Victoria became victims of human cruelty, with some kicked and others thrown off a cliff and shot at. These acts of cruelty prompted the state government to fence off the rookeries. More recent examples of destructive interference can be found at Granite island, where in 1994 a penguin chick was taken from a burrow and abandoned on the mainland, a burrow containing penguin chicks was trampled and litter was discarded down active burrows. In 1998, two incidents in six months resulted in penguin deaths. The latter, which occurred in May, saw 13 penguins apparently kicked to death. In March 2016, two little penguins were kicked and attacked by humans during separate incidents at the St Kilda colony, Victoria.

In 2018, 20-year-old Tasmanian man Joshua Leigh Jeffrey was fined $82.50 in court costs and sentenced to 49 hours of community service at Burnie Magistrates Court on 25 June 2018 after killing nine little penguins at Sulfur Creek in North West Tasmania on 1 January 2016 by beating them with a stick. Dr Eric Woehler from conservation group Birds Tasmania denounced the perceived leniency of the sentence which he said placed minimal value on Tasmania's wildlife and set an "unwelcome precedent". Following an appeal by prosecutors, Jeffrey had his sentence doubled on 15 October 2018. The office of the Director of Public Prosecutions said it considered the original sentence to be manifestly inadequate. The original sentence was set aside, and Jeffrey was sentenced to two months in prison, suspended on the condition of him committing no offences for a year that are punishable by imprisonment. His community order was also doubled to 98 hours.

Also in 2018, a dozen little penguin carcasses were found in a garbage bin at Low Head, Tasmania prompting an investigation into the causes of death.

Some little penguins are drowned when amateur fishermen set gill nets near penguin colonies. Discarded fishing line can also present an entanglement risk and contact can result in physical injury, reduced mobility or drowning. In 2014, a group of 25 dead little penguins was found on Altona Beach in Victoria. Necropsies concluded that the animals had died after becoming entangled in net fishing equipment, prompting community calls for a ban on net fishing in Port Phillip Bay.

In the 20th century, little penguins were intentionally shot or caught by fishermen to use as bait in pots for catching crayfish (Southern rock lobster) or by line fishermen. Colonies were targeted for this purpose in various parts of Tasmania including Bruny Island and West Island, South Australia.

A study in Perth from 2003 to 2012 found that the main cause of mortality was trauma, most likely from watercraft, leading to a recommendation for management strategies to avoid watercraft strikes.

Oil spills can be lethal for penguins and other sea birds. Oil is toxic when ingested and penguins' buoyancy and the insulative quality of their plumage is damaged by contact with oil. Little penguin populations have been significantly affected during two major oil spills at sea: the Iron Baron oil spill off Tasmania's north coast in 1995 and the grounding of the Rena off New Zealand in 2011.

Plastics are swallowed by little penguins, who mistake them for prey items. They present a choking hazard and also occupy space in the animal's stomach. Indigestible material in a penguin's stomach can contribute to malnutrition or starvation. Other larger plastic items, such as bottle packaging rings, can become entangled around penguins' necks, affecting their mobility.

Threats to little penguin populations include predation (both adult and nest predation) by a variety of terrestrial animals including cats, dogs, rats, foxes, large reptiles, ferrets and stoats. Due to their diminutive size and the introduction of new predators, some colonies have been reduced in size by as much as 98% in just a few years, such as the small colony on Middle Island, near Warrnambool, Victoria, which was reduced from approximately 600 penguins in 2001 to less than 10 in 2005. Because of this threat of colony collapse, conservationists successfully pioneered an experimental technique using Maremma Sheepdogs to protect the colony and fend off would-be predators, with numbers reaching 100 by 2017.

Uncontrolled dogs or feral cats can have sudden and severe impacts on penguin colonies (more than the penguin's natural predators) and may kill many individuals. Examples of colonies affected by dog attacks include Manly, New South Wales, Penneshaw, South Australia, Red Chapel Beach, Tasmania, Low Head, Tasmania, Penguin Island, Western Australia and Little Kaiteriteri Beach, New Zealand.

A suspected stoat or ferret attack at Doctor's Point near Dunedin, New Zealand claimed the lives of 29 little blue penguins in November 2014.

A fox was believed responsible for the deaths of 53 little penguins over several nights on Granite Island in 1994. In June 2015, 26 penguins from the Manly colony were killed in 11 days. A fox believed responsible was eventually shot in the area and an autopsy is expected to prove or disprove its involvement. In November 2015 a fox entered the little penguin enclosure at the Melbourne Zoo and killed 14 penguins, prompting measures to further "fox proof" the enclosure.

Variation in prey abundance and distribution from year to year causes young birds to be washed up dead from starvation or in weak condition.

Little penguins in the wild are sometimes preyed upon by long-nosed fur seals. A study conducted by researchers from the South Australian Research and Development Institute found that roughly 40 percent of seal droppings in South Australia's Granite Island area contained little penguin remains.

They are also preyed upon by white-bellied sea eagles. These large birds-of-prey are endangered in South Australia and not considered a threat to colony viability.

On land, little penguins are vulnerable to attack from domestic and feral dogs and cats. Attacks on Kangaroo Island, at Manly in Tasmania and in New Zealand have resulted in significant impacts to several populations. Management strategies to mitigate the risk of attack include establishing dog-free zones near penguin colonies and introducing regulations to ensure dogs to remain on leashes at all times in adjacent areas.

Little penguins on Middle Island off Warrnambool, Victoria were subject to heavy predation by foxes, which were able to reach the island at low tide by a tidal sand bridge. The deployment of Maremma sheepdogs to protect the penguin colony has deterred the foxes and enabled the penguin population to rebound. This is in addition to the support from groups of volunteers who work to protect the penguins from attack at night. The first Maremma sheepdog to prove the concept was Oddball, whose story inspired a feature film of the same name, released in 2015. In December 2015, the BBC reported, "The current dogs patrolling Middle Island are Eudy and Tula, named after the scientific term for the fairy penguin: Eudyptula. They are the sixth and seventh dogs to be used and a new puppy is being trained up [...] to start work in 2016.

In Sydney, snipers have been deployed to protect a colony of little penguins. This effort is in addition to support from local volunteers who work to protect the penguins from attack at night.

Little penguins are diurnal and like many penguin species, spend the largest part of their day swimming and foraging at sea. During the breeding and chick-rearing seasons, little penguins leave their nest at sunrise, forage for food throughout the day and return to their nests just after dusk. Thus, sunlight, moonlight and artificial lights can affect the behaviour of attendance to the colony. Also, increased wind speeds negatively affect the little penguins' efficiency in foraging for chicks, but for reasons not yet understood. Little penguins preen their feathers to keep them waterproof. They do this by rubbing a tiny drop of oil onto every feather from a special gland above the tail.

These birds feed by hunting small clupeoid fish, cephalopods and crustaceans, for which they travel and dive quite extensively. In New Zealand, important prey items include arrow squid, slender sprat, Graham's gudgeon, red cod and ahuru. Since the year 2000, the little penguins of Port Phillip Bay's diet has consisted mainly of barracouta, anchovy, and arrow squid. Sardines previously featured more prominently in southern Australian little penguin diets prior to mass sardine mortality events of the 1990s. These mass mortality events affected sardine stocks over 5,000 kilometres of coastline. Jellyfish including species in the genera "Chrysaora" and "Cyanea" were found to be actively sought-out food items, while they previously had been thought to be only accidentally ingested. Similar preferences were found in the Adélie penguin, yellow-eyed penguin and Magellanic penguin.

The little penguins are generally inshore feeders. The use of data loggers has provided information of the diving behaviour of little penguins. 50% of their dives go no deeper than 2 m and the mean diving time is 21 seconds. Yet, they are able to dive as deep as 66.7 m and remained submerged as long as 90 seconds. Little penguins play an important role in the ecosystem as not only a predator to parasites but also a host. Recent studies have shown a new species of feather mite that feeds on the preening oil on the feathers of the penguin.

Little penguins mature at different ages. The female matures at 2 years old. The male, however, matures at 3 years old. Little penguins only remain faithful to their partner in breeding seasons and whilst hatching eggs. At other times of the year they do tend to swap burrows. They exhibit site fidelity to their nesting colonies and nesting sites over successive years.

Little penguins can breed as isolated pairs, in colonies, or semi-colonially. Nests are situated close to the sea in burrows excavated by the birds or other species, or in caves, rock crevices, under logs or in or under a variety of man-made structures including nest boxes, pipes, stacks of wood or timber, and buildings. They are monogamous within a breeding season, and share incubating and chick-rearing duties. They are the only species of penguin capable of producing more than one clutch of eggs per breeding season, but few populations do so.

The timing of breeding seasons varies across the species' range. Eastern Australian populations (including at Phillip Island, Victoria) lay their eggs from July through December. In South Australia's Gulf St. Vincent, eggs are laid between April and October.

The one or two white or lightly mottled brown eggs are laid with rarer second (or even third) clutches following. Incubation takes up to 36 days. Chicks are brooded for 18–38 days and fledge after 7–8 weeks. On Australia's east coast, chicks are raised from August through March. In Gulf St. Vincent, chicks are raised from June through November.

Little penguins typically return to their colonies to feed their chicks at dusk. The birds tend to come ashore in small groups to provide some defence against predators, which might pick off individuals one by one. In Australia, the strongest colonies are usually on cat-free and fox-free islands. However, the population on Granite Island (which is a fox, cat and dog-free island) has been severely depleted, from around 2000 penguins in 2001 down to 146 in 2009.

Little penguins have long been a curiosity to humans, and to children in particular. Captive animals are often exhibited in zoos. Historically, the animals have also been used as bait to catch Southern rock lobster, captured for amusement and eaten by ship-wrecked sailors and castaways to avoid starvation. They have also been the victims of malicious attacks by humans and incidental bycatch by fishermen using nets. The sites of many breeding colonies have developed into tourist destinations which provide an economic boost for coastal and island communities in Australia and New Zealand. These locations also often provide facilities and volunteer staff to support population surveys, habitat improvement works and little penguin research programs.

At Phillip Island, Victoria, a viewing area has been established at the Phillip Island Nature Park to allow visitors to view the nightly "penguin parade". Lights and concrete stands have been erected to allow visitors to see but not photograph or film the birds (this is because it can blind or scare them) interacting in their colony.

In Bicheno, Tasmania, evening penguin viewing tours are offered by a local tour operator at a rookery on private land. A similar sunset tour is offered at Low Head, near the mouth of the Tamar River on Tasmania's north coast. Observation platforms exist near some of Tasmania's other little penguin colonies, including Bruny Island and Lillico Beach near Devonport.

South of Perth, Western Australia, visitors to Penguin Island are able to view penguin feeding within a penguin rehabilitation centre and may also encounter wild penguins ashore in their natural habitat. The island is accessible via a short passenger ferry ride, and visitors depart the island before dusk to protect the colony from disturbance.

Visitors to Kangaroo Island, South Australia, have nightly opportunities to observe penguins at the Kangaroo Island Marine Centre in Kingscote and at the Penneshaw Penguin Centre. Granite Island at Victor Harbor, South Australia continues to offer guided tours at dusk, despite its colony dropping from thousands in the 1990s to dozens in 2014. There is also a Penguin Centre located on the island where the penguins can be viewed in captivity.

In the Otago, New Zealand town of Oamaru, visitors may view the birds returning to their colony at dusk. In Oamaru it is not uncommon for penguins to nest within the cellars and foundations of local shorefront properties, especially in the old historic precinct of the town. More recently, little penguin viewing facilities have been established at Pilots Beach on the Otago Peninsula in Dunedin, New Zealand. Here visitors are guided by volunteer wardens to watch penguins returning to their burrows at dusk.

Several efforts have been made to improve breeding sites on Kangaroo Island, including augmenting habitat with artificial burrows and revegetation work. The Knox School's habitat restoration efforts were filmed and broadcast in 2008 by "Totally Wild".

Exhibits currently exist at the Adelaide Zoo, Melbourne Zoo, the National Zoo & Aquarium in Canberra, Perth Zoo, Caversham Wildlife Park (Perth), Sea Life Sydney Aquarium and the Taronga Zoo in Sydney.

A colony of little penguins is also exhibited at Sea World, on the Gold Coast, Queensland, Australia. In early March, 2007, 25 of the 37 penguins died from an unknown toxin following a change of gravel in their enclosure. It is still not known what caused the deaths of the little penguins, and it was decided not to return the 12 surviving penguins to the same enclosure in which the penguins became ill. A new enclosure for the little penguin colony was opened at Sea World in 2008.

Exhibits currently exist at the Auckland Zoo, the Wellington Zoo and the National Aquarium of New Zealand. The National Aquarium of New Zealand, since 2017, has featured a monthly "Penguin of the Month" board, declaring two of their resident animals the "Naughty" and "Nice" penguin for that month. Photos of the board have gone viral and gained the aquarium a large worldwide social media following.

A colony of little blue penguins exists at the New England Aquarium in Boston, Massachusetts. The penguins are one of three species on exhibit and are part of the Association of Zoos and Aquariums' Species Survival Plan for little blue penguins.

Linus Torvalds, the original creator of Linux (a popular operating system kernel), was once pecked by a little penguin while on holiday in Australia. Reportedly, this encounter encouraged Torvalds to select Tux as the official Linux mascot.

A Linux kernel programming challenge called the Eudyptula Challenge has attracted thousands of persons; its creator(s) use the name "Little Penguin".

Penny the Little Penguin was the mascot for the 2007 FINA World Swimming Championships held in Melbourne, Victoria.



</doc>
<doc id="18233" url="https://en.wikipedia.org/wiki?curid=18233" title="Lake Balaton">
Lake Balaton

Lake Balaton (Hungarian IPA , , , , ) is a freshwater lake in the Transdanubian region of Hungary. It is the largest lake in Central Europe, and one of the region's foremost tourist destinations. The Zala River provides the largest inflow of water to the lake, and the canalised Sió is the only outflow.

The mountainous region of the northern shore is known both for its historic character and as a major wine region, while the flat southern shore is known for its resort towns. Balatonfüred and Hévíz developed early as resorts for the wealthy, but it was not until the late 19th century when landowners, ruined by "Phylloxera" attacking their grape vines, began building summer homes to rent out to the burgeoning middle classes.

In distinction to all other endonyms for lakes, which universally bear the identifying suffix "-tó" (“lake”), Lake Balaton is referred to in Hungarian with a definite article, ie. "a Balaton" (the Balaton). It was called "lacus Pelsodis" or "Pelso" by the Romans. The name is Indo-European in origin (cf. Czech "pleso" ‘sinkhole, deep end of a lake’), later replaced by the Slavic *"bolto" (Czech "bláto", Slovak "blato", Polish "błoto") meaning 'mud, swamp' (from earlier Proto-Slavic "boltьno", , ). 
In January 846 Slavic prince Pribina began to build a fortress as his seat of power and several churches in the region of Lake Balaton, in a territory of modern Zalavár surrounded by forests and swamps along the river Zala. His well fortified castle and capital of Balaton Principality that became known as "Blatnohrad" or "Moosburg" ("Swamp Fortress") served as a bulwark both against the Bulgarians and the Moravians.

The German name for the lake is '. It is unlikely that the Germans named the lake so for being shallow since the adjective ' is a Greek loanword that was borrowed via French and entered the general German vocabulary in the 17th century. It is also noteworthy that the average depth of Balaton () is not extraordinary for the area (cf. the average depth of the neighbouring Neusiedler See, which is roughly ).

Lake Balaton affects the local area precipitation. The area receives approximately more precipitation than most of Hungary, resulting in more cloudy days and less extreme temperatures. The lake's surface freezes during winters. The microclimate around Lake Balaton has also made the region ideal for viticulture. The Mediterranean-like climate, combined with the soil (containing volcanic rock), has made the region notable for its production of wines since the Roman period two thousand years ago.

While a few settlements on Lake Balaton, including Balatonfüred and Hévíz, have long been resort centres for the Hungarian aristocracy, it was only in the late 19th century that the Hungarian middle class began to visit the lake. The construction of railways in 1861 and 1909 increased tourism substantially, but the post-war boom of the 1950s was much larger.

By the turn of the 20th century, Balaton had become a center of research by Hungarian biologists, geologists, hydrologists, and other scientists, leading to the country's first biological research institute being built on its shore in 1927.

The last major German offensive of World War II, Operation Frühlingserwachen, was conducted in the region of Lake Balaton in March 1945, being referred to as "the Lake Balaton Offensive" in many British histories of the war. The battle was a German attack by Sepp Dietrich's Sixth Panzer Army and the Hungarian Third Army between 6 March and 16 March 1945, and in the end, resulted in a Red Army victory. Several Ilyushin Il-2 wrecks have been pulled out of the lake after having been shot down during the later months of the war.

During the 1960s and 1970s, Balaton became a major tourist destination due to focused government efforts, causing the number of overnight guests in local hotels and campsites to increase from 700,000 in July 1965 to two million in July 1975. Weekend visitors to the region, including tens of thousands from Budapest, reached more than 600,000 by 1975. It was visited by ordinary working Hungarians and especially for subsidised holiday excursions for labor union members. It also attracted many East Germans and other residents of the Eastern Bloc. West Germans could also visit, making Balaton a common meeting place for families and friends separated by the Berlin Wall until 1989. The collapse of the Soviet Union after 1991 and the dismantling of the labor unions caused the gradual but steady reduction in numbers of lower-paid Hungarian visitors.

The major resorts around the lake are Siófok, Keszthely, and Balatonfüred. Zamárdi, another resort town on the southern shore, has been the site of Balaton Sound, a notable electronic music festival since 2007. Balatonkenese has hosted numerous traditional gastronomic events. Siófok is known for attracting young people to it because of its large clubs. Keszthely is the site of the Festetics Palace and Balatonfüred is a historical bathing town which hosts the annual Anna Ball.

The peak tourist season extends from June until the end of August. The average water temperature during the summer is , which makes bathing and swimming popular on the lake. Most of the beaches consist of either grass, rocks, or the silty sand that also makes up most of the bottom of the lake. Many resorts have artificial sandy beaches and all beaches have step access to the water. Other tourist attractions include sailing, fishing, and other water sports, as well as visiting the countryside and hills, wineries on the north coast, and nightlife on the south shore. The Tihany Peninsula is a historical district. Badacsony is a volcanic mountain and wine-growing region as well as a lakeside resort. The lake is almost completely surrounded by separated bike lanes to facilitate bicycle tourism.
Although the peak season at the lake is the summer, Balaton is also frequented during the winter, when visitors go ice-fishing or even skate, sledge, or ice-sail on the lake if it freezes over.

Sármellék International Airport provides air service to Balaton (although most service is only seasonal).

Other resort towns include: Balatonalmádi, Balatonboglár, Balatonlelle, Fonyód and Vonyarcvashegy.

From east to west:

Balatonfőkajár - Balatonakarattya - Balatonkenese - Balatonfűzfő - Balatonalmádi - Alsóörs - Paloznak - Csopak - Balatonarács - Balatonfüred - Tihany - Aszófő - Örvényes - Balatonudvari - Fövenyes - Balatonakali - Zánka - Balatonszepezd - Szepezdfürdő - Révfülöp - Pálköve - Ábrahámhegy - Balatonrendes - Badacsonytomaj - Badacsony - Badacsonytördemic - Szigliget - Balatonederics - Balatongyörök - Vonyarcvashegy - Gyenesdiás - Keszthely

From east to west:

Balatonakarattya - Balatonaliga - Balatonvilágos - Sóstó - Szabadifürdő - Siófok - Széplak - Zamárdi - Szántód - Balatonföldvár - Balatonszárszó - Balatonszemes - Balatonlelle - Balatonboglár - Fonyód - Fonyód–Alsóbélatelep - Bélatelep - Balatonfenyves - Balatonmáriafürdő - Balatonkeresztúr - Balatonberény - Fenékpuszta




</doc>
<doc id="18234" url="https://en.wikipedia.org/wiki?curid=18234" title="Libro de los juegos">
Libro de los juegos

The Libro de los Juegos ("Book of games"), or Libro de axedrez, dados e tablas ("Book of chess, dice and tables", in Old Spanish), was commissioned by Alfonso X of Castile, Galicia and León and completed in his scriptorium in Toledo in 1283, is an exemplary piece of Alfonso's medieval literary legacy.

The book consists of ninety-seven leaves of parchment, many with color illustrations, and contains 150 miniatures. The text is a treatise that addresses the playing of three games: a game of skill, or chess; a game of chance, or dice; and a third game, backgammon, which combines elements of both skill and chance. The book contains the earliest known description of these games. These games are discussed in the final section of the book at both an astronomical and astrological level. Examining further, the text can also be read as an allegorical initiation tale and as a metaphysical guide for leading a balanced, prudent, and virtuous life. In addition to the didactic, although not overly moralistic, aspect of the text, the manuscript's illustrations reveal a rich cultural, social, and religious complexity.

It is one of the most important documents for researching the history of board games. The only known original is held in the library of the monastery of El Escorial near Madrid in Spain. The book is bound in sheepskin and is 40 cm high and 28 cm wide (16 in × 11 in). A 1334 copy is held in the library of the Spanish Royal Academy of History in Madrid.

Alfonso was likely influenced by his contact with scholars in the Arab world. Unlike many contemporary texts on the topic, he does not engage the games in the text with moralistic arguments; instead, he portrays them in an astrological context. He conceives of gaming as a dichotomy between the intellect and chance. The book is divided into three parts reflecting this: the first on chess (a game purely of abstract strategy), the second on dice (with outcomes controlled strictly by chance), and the last on tables (combining elements of both). The text may have been influenced by Frederick II's text on falconry.

The Libro de juegos contains an extensive collection of writings on chess, with over 100 chess problems and variants. Among its more notable entries is a depiction of what Alfonso calls the "ajedrex de los quatro tiempos" ("chess of the four seasons"). This game is a chess variant for four players, described as representing a conflict between the four elements and the four humors. The chessmen are marked correspondingly in green, red, black, and white, and pieces are moved according to the roll of dice. Alfonso also describes a game entitled "astronomical chess", played on a board of seven concentric circles, divided radially into twelve areas, each associated with a constellation of the Zodiac.

The book describes the rules for a number of games in the tables family. One notable entry is "todas tablas", which has an identical starting position to modern backgammon and follows the same rules for movement and bearoff. Alfonso also describes a variant played on a board with seven points in each table. Players rolled seven-sided dice to determine the movement of pieces, an example of Alfonso's preference for the number seven.

The miniatures in the "Libro de juegos" vary between half- and full-page illustrations. The half-page miniatures typically occupy the upper half of a folio, with text explaining the game "problem" solved in the image occupying the bottom half. The back or second (verso) side of Folio 1, in a half-page illustration, depicts the initial stages of the creation of the "Libro de juegos", accompanied by text on the bottom half of the page, and the front or first (recto) side of Folio 2 depicts the transmission of the game of chess from an Indian Philosopher-King to three followers. The full-page illustrations are almost exclusively on the verso side of later folios and are faced by accompanying text on the recto side of the following folio. The significance of the change in miniature size and placement may indicate images of special emphasis, could merely function as a narrative or didactic technique, or could indicate different artisans at work in Alfonso's scriptorium as the project developed over time.

Having multiple artisans working on the "Libro de juegos" would have been a typical practice for medieval chanceries and scriptoria, where the labor of producing a manuscript was divided amongst individuals of varying capacities, for example the positions of scribe, draftsman, and apprentice cutting pages. But in addition to performing different tasks, various artisans could have labored at the same job, such as the work of illustration in the "Libro de juegos", thereby revealing a variety hands or styles. The "Libro de Juegos" offers such evidence in the difference in size between the half- and full-page illustrations in addition to changes in framing techniques amongst the folios: geometrical frames with embellished corners, architectural frames established by loosely perspectival rooftops and colonnades, and games played under tents. Other stylistic variances are found in figural representation, in facial types, and in a repertoire of different postures assumed by the players in different folios in the manuscript.

For example, in a comparison of two miniatures, found on Folios 53v and 76r, examples of these different styles are apparent, although the trope of a pair of gamers is maintained. In Folio 53v, two men are playing chess, both wearing turbans and robes. Although they may be seated on rugs on the ground, as suggested by the ceramic containers that are placed on or front of the rug near the man on the right side of the board, the figures’ seated positions, which are full frontal with knees bent at right angles, suggests that they are seated on stools or perhaps upholstered benches. The figures’ robes display a Byzantine conservatism, with their modeled three-dimensionality and allusion to a Classical style, yet the iconic hand gestures are reminiscent of a Romanesque energy and theatricality. Although the figures are seated with their knees and torsos facing front, their shoulders and heads rotate in three-quarter profile toward the center of the page, the chess board, and each other. The proximal, inner arm of each player (the arm that is closest to the board) is raised in a speaking gesture; the distal, outside arms of the players are also raised and are bent at the elbows, creating a partial crossing of each player's torso as the hands lift in speaking gestures. The faces reveal a striking specificity of subtle detail, particular to a limited number of miniatures throughout the "Libro de juegos", perhaps indicative of a particular artist's hand. These details include full cheeks, realistic wrinkles around the eyes and across the brow, and a red, full-lipped mouth that hints at the Gothic affectations in figural representation coming out of France during the late twelfth and early thirteenth centuries.

The style in the miniature in Folio 76v is markedly different from the style in Folio 53v. In this case, the framed miniature contains two men, perhaps Spanish, with uncovered wavy light brown hair that falls to the jaw line. The men seem young, as the player on the left has no facial hair and his face is unlined. In both folios, both pairs of players are playing backgammon and seem to be well-dressed, although there is no addition of gold detailing to their robes as seen in the wardrobes of aristocratic players in other miniatures. These players are seated on the ground, leaning on pillows that are placed next to a backgammon board. In this miniature, the figure on the left side of the board faces the reader, while the figure on the right leans in to the board with his back to the reader. In other words, each player is leaning on his left elbow, using his right hand to reach across his body to play. In the miniatures of this style, the emphasis seems to be more on the posture of the player than the detail of their faces; this crossed, lounging style is only found in the folios of the "Libro de tablas", the third section of the "Libro de juegos" which explains the game of backgammon, again perhaps indicative of the work of a particular artist.

Other visual details contemporaneous of Alfonso's court and social and cultural milieu infuse the "Libro de juegos". Although some of the miniatures are framed by simple rectangles with corners embellished by the golden castles and lions of Castile and León, other are framed by medieval Spanish architectural motifs, including Gothic and Mudéjar arcades of columns and arches. At times, the figural depictions are hierarchical, especially in scenes with representations of Alfonso, where the king is seated on a raised throne while dictating to scribes or meting out punishments to gamblers. Yet a contemporary atmosphere of Spanish "convivencia" is evoked by the inclusion nobility, rogues, vagrants, young and old, men, women, Christian, Muslim, and Jewish characters. Alfonso himself is depicted throughout the text, both as participant and spectator and as an older man and as a younger. The pages are filled with many social classes and ethnicities in various stages of solving the challenges presented by games.

The "Libro de juegos" can be divided into three parts: the games and problems it explores textually, the actual illuminations themselves, and the metaphysical allegories, where an analysis of the texts and illuminations reveals the movements of the macrocosmos of the universe and the microcosmos of man. The symbolism within the medieval illuminations, as explained by the accompanying texts, reveal allusions to medieval literature, art, science, law and philosophy. Intended as a didactic text, the manuscript functions as a manual that documents and explains how and why one plays games ranging from pure, intellectual strategy (chess), to games of pure chance (dice), to games that incorporate both elements (backgammon). Conceivably, Alfonso hoped to elucidate for himself how to better play the game of life, while also providing a teaching tool for others. The game of "ajedrex", or chess, is not the only game explained in the "Libro de Juegos", but it does occupy the primary position in the text and is given the most attention to detail.

In the thirteenth century, chess had been played in Europe for almost two hundred years, having been introduced into Europe by Arabs around the year 1000. The Arabs had become familiar with the game as early as the eighth century when the Islamic empire conquered Persia, where the game of chess was alleged to have been originated. It is said that a royal advisor had invented the game in order to teach his king prudence without having to overtly correct him. As Arab contact with the West expanded, so too did the game and its various permutations, and by the twelfth century, chess was becoming an entertaining diversion among a growing population of Europeans, including some scholars, clergy, the aristocracy, and the merchant classes; thus, by the thirteenth century, the iconography and symbolism associated with chess would have been accessible and familiar to Alfonso and his literate court culture, who may have had access to the private library, and manuscripts, of Alfonso, including the "Libro de juegos".

The "Libro de juegos" manuscript was a Castilian translation of Arabic texts, which were themselves translations of Persian manuscripts. The visual trope portrayed in the "Libro de juegos" miniatures is seen in other European transcriptions of the Arabic translations, most notably the German Carmina Burana Manuscript: two figures, one on either side of the board, with the board tilted up to reveal to the readers the moves made by the players. The juxtaposition of chess and dice in Arabic tradition, indicating the opposing values of skill (chess) and ignorance (dice), was given a different spin in Alfonso's manuscript, however. As Alfonso elucidates in the opening section of the "Libro de Juegos", the "Libro de ajedrex" (Book of chess) demonstrates the value of the intellect, the "Libro de los dados" (Book of dice) illustrates that chance has supremacy over pure intellect, and the" Libro de las tablas" (Book of tables) celebrates a conjoined use of both intellect and chance. Further, the iconographic linkage between chess and kingship in the Western tradition continued to evolve and became symbolic of kingly virtues, including skill, prudence, and intelligence.

Most of the work accomplished in Alfonso's scriptorium consisted of translations into the Castilian vernacular from Arabic translations of Greek texts or classical Jewish medicinal texts. As a result, very few original works were produced by this scholar-king, relative to the huge amount of work that was translated under his auspices. This enormous focus on translation was perhaps an attempt by Alfonso to continue the legacy of academic openness in Castile, initiated by Islamic rulers in Córdoba, where the emirates had also employed armies of translators in order to fill their libraries with Arabic translations of classic Greek texts. Alfonso was successful in promoting Castilian society and culture through his emphasis on the use of Galaico-Portuguese and Castilian, in academic, juridical, diplomatic, literary, and historical works. This emphasis also had the effect of reducing the universality of his translated works and original academic writings, as Latin was the "lingua franca" in both Iberia and Europe; yet Alfonso never desisted in his promotion of the Castilian vernacular.

In 1217, Alfonso had captured the Kingdom of Murcia, on the Mediterranean coast south of Valencia, for his father, King Alfonso IX, thereby unifying the kingdoms of Castile and León, bringing together the northern half of the Iberian Peninsula under one Christian throne. With the Christian re-conquest of the Peninsula underway, inroads into Islamic territories were successfully incorporating lands previously held by the "taifa" kingdoms. The arts and sciences prospered in the Kingdom of Castile under the confluence of Latin and Arabic traditions of academic curiosity as Alfonso sponsored scholars, translators, and artists of all three religions of the Book (Jewish, Christian, and Muslim) in his chanceries and scriptoria. Clerical and secular scholars from Europe turned their eyes to Iberian Peninsula as the arts and sciences prospered in an early Spanish "renaissance" under the patronage of Alfonso X, who was continuing the tradition of (relatively) enlightened and tolerant "convivencia" established by the Muslim emirate several centuries earlier.

As an inheritor of a dynamic mixture of Arabic and Latin culture, Alfonso was steeped in the rich heritage of humanistic philosophy, and the production of his "Libro de juegos" reveals the compendium of world views that comprised the eclectic thirteenth century admixture of faith and science. According to this approach, man's actions could be traced historically and his failures and successes could be studied as lessons to be applied to his future progress. These experiences can be played out and studied as they are lived, or as game moves played and analyzed in the pages of the "Libro de juegos". It is a beautiful and luxurious document, rich not only in workmanship but also in the amount of scholarship of multiple medieval disciplines that are integrated in its pages.





</doc>
<doc id="18236" url="https://en.wikipedia.org/wiki?curid=18236" title="Lithium citrate">
Lithium citrate

Lithium citrate (LiCHO) is a chemical compound of lithium and citrate that is used as a mood stabilizer in psychiatric treatment of manic states and bipolar disorder. There is extensive pharmacology of lithium, the active component of this salt.

Lithia water contains various lithium salts, including the citrate. An early version of Coca-Cola available in pharmacies' soda fountains called Lithia Coke was a mixture of Coca-Cola syrup and lithia water. The soft drink 7Up was originally named "Bib-Label Lithiated Lemon-Lime Soda" when it was formulated in 1929 because it contained lithium citrate. The beverage was a patent medicine marketed as a cure for hangover. Lithium citrate was removed from 7Up in 1948.


</doc>
<doc id="18237" url="https://en.wikipedia.org/wiki?curid=18237" title="Lithium carbonate">
Lithium carbonate

Lithium carbonate is an inorganic compound, the lithium salt of carbonate with the formula . This white salt is widely used in the processing of metal oxides and treatment of mood disorders.

For the treatment of bipolar disorder, it is on the World Health Organization's List of Essential Medicines, the most important medications needed in a basic health system.

Lithium carbonate is an important industrial chemical. It forms low-melting fluxes with silica and other materials. Glasses derived from lithium carbonate are useful in ovenware. Lithium carbonate is a common ingredient in both low-fire and high-fire ceramic glaze. Its alkaline properties are conducive to changing the state of metal oxide colorants in glaze particularly red iron oxide (). Cement sets more rapidly when prepared with lithium carbonate, and is useful for tile adhesives. When added to aluminium trifluoride, it forms LiF which gives a superior electrolyte for the processing of aluminium. It is also used in the manufacture of most lithium-ion battery cathodes, which are made of lithium cobalt oxide.

In 1843, lithium carbonate was used as a new solvent for stones in the bladder. In 1859, some doctors recommended a therapy with lithium salts for a number of ailments, including gout, urinary calculi, rheumatism, mania, depression, and headache. In 1948, John Cade discovered the antimanic effects of lithium ions. This finding led lithium, specifically lithium carbonate, to be used to treat mania associated with bipolar disorder.

Lithium carbonate is used to treat mania, the elevated phase of bipolar disorder. Lithium ions interfere with ion transport processes (see “sodium pump”) that relay and amplify messages carried to the cells of the brain. Mania is associated with irregular increases in protein kinase C (PKC) activity within the brain. Lithium carbonate and sodium valproate, another drug traditionally used to treat the disorder, act in the brain by inhibiting PKC's activity and help to produce other compounds that also inhibit the PKC. Lithium carbonate's mood-controlling properties are not fully understood.

Taking lithium salts has risks and side effects. Extended use of lithium to treat various mental disorders has been known to lead to acquired nephrogenic diabetes insipidus. Lithium intoxication can affect the central nervous system and renal system and can be lethal.

Unlike sodium carbonate, which forms at least three hydrates, lithium carbonate exists only in the anhydrous form. Its solubility in water is low relative to other lithium salts. The isolation of lithium from aqueous extracts of lithium ores capitalizes on this poor solubility. Its apparent solubility increases 10-fold under a mild pressure of carbon dioxide; this effect is due to the formation of the metastable bicarbonate, which is more soluble:
The extraction of lithium carbonate at high pressures of and its precipitation upon depressuring is the basis of the Quebec process.

Lithium carbonate can also be purified by exploiting its diminished solubility in hot water. Thus, heating a saturated aqueous solution causes crystallization of .

Lithium carbonate, and other carbonates of group 1, do not decarboxylate readily. decomposes at temperatures around 1300 °C.

Lithium is extracted from primarily two sources: pegmatite crystals and lithium salt from brine pools. About 30,000 tons were produced in 1989. It also exists as the rare mineral zabuyelite.

Lithium carbonate is generated by combining lithium peroxide with carbon dioxide. This reaction is the basis of certain air purifiers, e.g., in spacecraft, used to absorb carbon dioxide: 

In recent years many junior mining companies have begun exploration of lithium projects throughout North America, South America and Australia to identify economic deposits that can potentially bring new supplies of lithium carbonate online to meet the growing demand for the product.
In April 2017 MGX Minerals reported it had received independent confirmation of its rapid lithium extraction process to recover lithium and other valuable minerals from oil and gas wastewater brine.
Natural lithium carbonate is known as zabuyelite. This mineral is connected with deposits of some salt lakes and some pegmatites.



</doc>
<doc id="18238" url="https://en.wikipedia.org/wiki?curid=18238" title="Lunar Roving Vehicle">
Lunar Roving Vehicle

The Lunar Roving Vehicle (LRV) is a battery-powered four-wheeled rover used on the Moon in the last three missions of the American Apollo program (15, 16, and 17) during 1971 and 1972. They are popularly known as "Moon buggies", a play on the words "dune buggy".

Built by Boeing, each LRV weighs (on Earth) without payload. It could carry a maximum payload mass of including two astronauts, equipment, and lunar samples; and was designed for a top speed of , although it actually achieved a top speed of on its last mission, Apollo 17. They were transported to the Moon folded up in the Lunar Module's Quadrant 1 Bay. After being unpacked, they were driven an average distance of 30 km on each of the three missions, without major incident.

These three LRVs remain on the Moon.

The concept of a lunar rover predated Apollo, with a 1952–1954 series in "Collier's Weekly" magazine by Wernher von Braun and others, "Man Will Conquer Space Soon!" In this, von Braun described a six-week stay on the Moon, featuring 10-ton tractor trailers for moving supplies.

In 1956, Mieczysław G. Bekker published two books on land locomotion. At the time, Bekker was a University of Michigan professor and a consultant to the U.S. Army Tank-Automotive Command's Land Locomotion Laboratory. The books provided much of the theoretical base for future lunar vehicle development.

In the February 1964 issue of "Popular Science", von Braun, then director of NASA's Marshall Space Flight Center (MSFC), discussed the need for a lunar surface vehicle, and revealed that studies had been underway at Marshall in conjunction with Lockheed, Bendix, Boeing, General Motors, Brown Engineering, Grumman, and Bell Aerospace.

Beginning in the early 1960s, a series of studies centering on lunar mobility were conducted under Marshall. This began with the lunar logistics system (LLS), followed by the mobility laboratory (MOLAB), then the lunar scientific survey module (LSSM), and finally the mobility test article (MTA). In early planning for the Apollo program, it had been assumed that two Saturn V launch vehicles would be used for each lunar mission: one for sending the crew aboard a Lunar Surface Module (LSM) to lunar orbit, landing, and returning, and a second for sending an LSM-Truck (LSM-T) with all of the equipment, supplies, and transport vehicle for use by the crew while on the surface. All of the first Marshall studies were based on this dual-launch assumption, allowing a large, heavy, roving vehicle.

Grumman and Northrop, in the fall of 1962, began to design pressurized-cabin vehicles, with electric motors for each wheel. At about this same time Bendix and Boeing started their own internal studies on lunar transportation systems. Mieczysław Bekker, now with General Motors Defense Research Laboratories at Santa Barbara, California, was completing a study for NASA's Jet Propulsion Laboratory on a small, uncrewed lunar roving vehicle for the Surveyor program. Ferenc Pavlics, originally from Hungary, used a wire-mesh design for "resilient wheels," a design that would be followed in future small rovers.

In early 1963, NASA selected Marshall for studies in an Apollo Logistics Support System (ALSS). Following reviews of all earlier efforts, this resulted in a 10-volume report. Included was the need for a pressurized vehicle in the weight range, accommodating two men with their expendables and instruments for traverses up to two weeks in duration. In June 1964, Marshall awarded contracts to Bendix and to Boeing, with GM's lab designated as the vehicle technology subcontractor. Bell Aerospace was already under contract for studies of Lunar Flying Vehicles.

Even as the Bendix and Boeing studies were underway, Marshall was examining a less ambitious surface exploration activity, the LSSM. This would be composed of a fixed, habitable shelter–laboratory with a small lunar-traversing vehicle that could either carry one man or be remotely controlled. This mission would still require a dual launch with the moon vehicle carried on the "lunar truck”. Marshall's Propulsion and Vehicle Engineering (P&VE) lab contracted with Hayes International to make a preliminary study of the shelter and its related vehicle. Because of the potential need for an enclosed vehicle for enlarged future lunar explorations, those design efforts continued for some time, and resulted in several full-scale test vehicles.

With pressure from Congress to hold down Apollo costs, Saturn V production was reduced, allowing only a single launch per mission. Any roving vehicle would have to fit on the same lunar module as the astronauts. In November 1964, two-rocket models were put on indefinite hold, but Bendix and Boeing were given study contracts for small rovers. The name of the lunar excursion module was changed to simply the lunar module, indicating that the capability for powered "excursions" away from a lunar-lander base did not yet exist. There could be no mobile lab — the astronauts would work out of the LM. Marshall continued to also examine uncrewed robotic rovers that could be controlled from the Earth.

From the beginnings at Marshall, the Brown Engineering Company of Huntsville, Alabama had participated in all of the lunar mobility efforts. In 1965, Brown became the prime support contractor for Marshall's P&VE Laboratory. With an urgent need to determine the feasibility of a two-man self-contained lander, von Braun bypassed the usual procurement process and had P&VE's Advanced Studies Office directly task Brown to design, build, and test a prototype vehicle. While Bendix and Boeing would continue to refine concepts and designs for a lander, test model rovers were vital for Marshall human factors studies involving spacesuit-clad astronauts interfacing with power, telemetry, navigation, and life-support rover equipment.

Brown's team made full use of the earlier small-rover studies, and commercially available components were incorporated wherever possible. The selection of wheels was of great importance, and almost nothing was known at that time about the lunar surface. The Marshall Space Sciences Laboratory (SSL) was responsible for predicting surface properties, and Brown was also prime support contractor for this lab; Brown set up a test area to examine a wide variety of wheel-surface conditions. To simulate Pavlics' "resilient wheel," a four-foot-diameter inner tube wrapped with nylon ski rope was used. On the small test rover, each wheel had a small electric motor, with overall power provided by standard truck batteries. A roll bar gave protection from overturn accidents.

In early 1966, Brown's vehicle became available for examining human factors and other testing. Marshall built a small test track with craters and rock debris where the several different mock-ups were compared; it became obvious that a small rover would be best for the proposed missions. The test vehicle was also operated in remote mode to determine characteristics that might be dangerous to the driver, such as acceleration, bounce-height, and turn-over tendency as it traveled at higher speeds and over simulated obstacles. The test rover's performance under one-sixth gravity was obtained through flights on a KC-135A aircraft in a Reduced Gravity parabolic maneuver; among other things, the need for a very soft wheel and suspension combination was shown. Although Pavlics' wire-mesh wheels were not initially available for the reduced gravity tests, the mesh wheels were tested on various soils at the Waterways Experiment Station of the U.S. Army Corps of Engineers at Vicksburg, Mississippi. Later, when wire-mesh wheels were tested on low-g flights, the need for wheel fenders to reduce dust contamination was found. The model was also extensively tested at the U.S. Army's Yuma Proving Ground in Arizona, as well as the Army's Aberdeen Proving Ground in Maryland.

During 1965 and 1967, the Summer Conference on Lunar Exploration and Science brought together leading scientists to assess NASA's planning for exploring the Moon and to make recommendations. One of their findings was that the LSSM was critical to a successful program and should be given major attention. At Marshall, von Braun established a Lunar Roving Task Team, and in May 1969, NASA approved the Manned Lunar Rover Vehicle Program as a Marshall hardware development. Saverio F. "Sonny" Morea was named Lunar Roving Vehicle Project Manager.

On 11 July 1969, just before the successful Moon landing of Apollo 11, a request for proposal for the final development and building the Apollo LRV was released by Marshall. Boeing, Bendix, Grumman, and Chrysler submitted proposals. Following three months of proposal evaluation and negotiations, Boeing was selected as the Apollo LRV prime contractor on 28 October 1969. Boeing would manage the LRV project under Henry Kudish in Huntsville, Alabama. As a major subcontractor, the General Motors' Defense Research Laboratories in Santa Barbara, California, would furnish the mobility system (wheels, motors, and suspension); this effort would be led by GM Program Manager Samuel Romano andFerenc Pavlics. Boeing in Seattle, Washington, would furnish the electronics and navigation system. Vehicle testing would take place at the Boeing facility in Kent, Washington, and the chassis manufacturing and overall assembly would be at the Boeing facility in Huntsville.

The first cost-plus-incentive-fee contract to Boeing was for $19,000,000 and called for delivery of the first LRV by 1 April 1971. Cost overruns, however, led to a final cost of $38,000,000, which was about the same as NASA's original estimate. Four lunar rovers were built, one each for Apollo missions 15, 16, and 17; and one used for spare parts after the cancellation of further Apollo missions. Other LRV models were built: a static model to assist with human factors design; an engineering model to design and integrate the subsystems; two one-sixth gravity models for testing the deployment mechanism; a one-gravity trainer to give the astronauts instruction in the operation of the rover and allow them to practice driving it; a mass model to test the effect of the rover on the LM structure, balance, and handling; a vibration test unit to study the LRV's durability and handling of launch stresses; and a qualification test unit to study integration of all LRV subsystems. A paper by Saverio Morea gives details of the LRV system and its development.

LRVs were used for greater surface mobility during the Apollo J-class missions, Apollo 15, Apollo 16, and Apollo 17. The rover was first used on 31 July 1971, during the Apollo 15 mission. This greatly expanded the range of the lunar explorers. Previous teams of astronauts were restricted to short walking distances around the landing site due to the bulky space suit equipment required to sustain life in the lunar environment. The range, however, was operationally restricted to remain within walking distance of the lunar module, in case the rover broke down at any point. The rovers were designed with a top speed of about , although Eugene Cernan recorded a maximum speed of , giving him the (unofficial) lunar land-speed record.

The LRV was developed in only 17 months and performed all its functions on the Moon with no major anomalies. Scientist-astronaut Harrison Schmitt of Apollo 17 said, "The Lunar Rover proved to be the reliable, safe and flexible lunar exploration vehicle we expected it to be. Without it, the major scientific discoveries of Apollo 15, 16, and 17 would not have been possible; and our current understanding of lunar evolution would not have been possible."

The LRVs experienced some minor problems. The rear fender extension on the Apollo 16 LRV was lost during the mission's second extra-vehicular activity (EVA) at station 8 when John Young bumped into it while going to assist Charles Duke. The dust thrown up from the wheel covered the crew, the console, and the communications equipment. High battery temperatures and resulting high power consumption ensued. No repair attempt was mentioned.

The fender extension on the Apollo 17 LRV broke when accidentally bumped by Eugene Cernan with a hammer handle. Cernan and Schmitt taped the extension back in place, but due to the dusty surfaces, the tape did not adhere and the extension was lost after about one hour of driving, causing the astronauts to be covered with dust. For their second EVA, a replacement "fender" was made with some EVA maps, duct tape, and a pair of clamps from inside the Lunar Module that were nominally intended for the moveable overhead light. This repair was later undone so that the clamps could be taken inside for the return launch. The maps were brought back to Earth and are now on display at the National Air and Space Museum. The abrasion from the dust is evident on some portions of the makeshift fender.
The color TV camera mounted on the front of the LRV could be remotely operated by Mission Control in pan and tilt axes as well as zoom. This allowed far better television coverage of the EVA than the earlier missions. On each mission, at the conclusion of the astronauts' stay on the surface, the commander drove the LRV to a position away from the Lunar Module so that the camera could record the ascent stage launch. The camera operator in Mission Control experienced difficulty in timing the various delays so that the LM ascent stage was in frame through the launch. On the third and final attempt (Apollo 17), the launch and ascent were successfully tracked.

NASA's rovers, left behind, are among the artificial objects on the Moon, as are the Soviet Union's uncrewed rovers, "Lunokhod 1" and "Lunokhod 2".

The Apollo Lunar Roving Vehicle was an electric-powered vehicle designed to operate in the low-gravity vacuum of the Moon and to be capable of traversing the lunar surface, allowing the Apollo astronauts to extend the range of their surface extravehicular activities. Three LRVs were used on the Moon, one on Apollo 15 by astronauts David Scott and Jim Irwin, one on Apollo 16 by John Young and Charles Duke, and one on Apollo 17 by Eugene Cernan and Harrison Schmitt. The mission commander served as the driver, occupying the left-hand seat of each LRV. Features are available in papers by Morea, Baker, and Kudish.

The Lunar Roving Vehicle had a mass of , and was designed to hold a payload of . This resulted in weights in the approximately one-sixth g on the lunar surface of empty (curb weight) and fully loaded (gross vehicle weight). The frame was long with a wheelbase of . The height of the vehicle was . The frame was made of 2219 aluminium alloy tubing welded assemblies and consisted of a three-part chassis that was hinged in the center so it could be folded up and hung in the Lunar Module Quadrant 1 bay, which was kept open to space by omission of the outer skin panel. It had two side-by-side foldable seats made of tubular aluminium with nylon webbing and aluminum floor panels. An armrest was mounted between the seats, and each seat had adjustable footrests and a Velcro-fastened seat belt. A large mesh dish antenna was mounted on a mast on the front center of the rover. The suspension consisted of a double horizontal wishbone with upper and lower torsion bars and a damper unit between the chassis and upper wishbone. Fully loaded, the LRV had a ground clearance of .

The wheels were designed and manufactured by General Motors Defense Research Laboratories in Santa Barbara, California. Ferenc Pavlics was given special recognition by NASA for developing the "resilient wheel". They consisted of a spun aluminum hub and a diameter, wide tire made of zinc-coated woven diameter steel strands attached to the rim and discs of formed aluminum. Titanium chevrons covered 50% of the contact area to provide traction. Inside the tire was a diameter bump stop frame to protect the hub. Dust guards were mounted above the wheels. Each wheel had its own electric drive made by Delco, a direct current (DC) series-wound motor capable of at 10,000 rpm, attached to the wheel via an 80:1 harmonic drive, and a mechanical brake unit. Each wheel could free-wheel in case of drive failure.

Maneuvering capability was provided through the use of front and rear steering motors. Each series-wound DC steering motor was capable of . The front and rear wheels could pivot in opposite directions to achieve a tight turning radius of , or could be decoupled so only front or rear would be used for steering.

Power was provided by two 36-volt silver-zinc potassium hydroxide non-rechargeable batteries with a charge capacity of 121 A·h each (a total of 242 A·h), yielding a range of . These were used to power the drive and steering motors and also a 36-volt utility outlet mounted on the front of the LRV to power the communications relay unit or the TV camera. LRV batteries and electronics were passively cooled, using change-of-phase wax thermal capacitor packages and reflective, upward-facing radiating surfaces. While driving, radiators were covered with mylar blankets to minimize dust accumulation. When stopped, the astronauts would open the blankets, and manually remove excess dust from the cooling surfaces with hand brushes.

A T-shaped hand controller situated between the two seats controlled the four drive motors, two steering motors, and brakes. Moving the stick forward powered the LRV forward, left and right turned the vehicle left or right, and pulling backwards activated the brakes. Activating a switch on the handle before pulling back would put the LRV into reverse. Pulling the handle all the way back activated a parking brake. The control and display modules were situated in front of the handle and gave information on the speed, heading, pitch, and power and temperature levels.

Navigation was based on continuously recording direction and distance through use of a directional gyro and odometer and feeding this data to a computer that would keep track of the overall direction and distance back to the LM. There was also a Sun-shadow device that could give a manual heading based on the direction of the Sun, using the fact that the Sun moved very slowly in the sky.

Each rover was used on three traverses, one per day over the three-day course of each mission, with the individual performances logged as follows:
An operational constraint on the use of the LRV was that the astronauts must be able to walk back to the LM if the LRV were to fail at any time during the EVA (called the "Walkback Limit"). Thus, the traverses were limited in the distance they could go at the start and at any time later in the EVA. Therefore, they went to the farthest point away from the LM and worked their way back to it so that, as the life support consumables were depleted, their remaining walk back distance was equally diminished. This constraint was relaxed during the longest traverse on Apollo 17, based on the demonstrated reliability of the LRV and spacesuits on previous missions. A paper by Burkhalter and Sharp provides details on usage.

Astronaut deployment of the LRV from the LM's open Quadrant 1 bay was achieved with a system of pulleys and braked reels using ropes and cloth tapes. The rover was folded and stored in the bay with the underside of the chassis facing out. One astronaut would climb the egress ladder on the LM and release the rover, which would then be slowly tilted out by the second astronaut on the ground through the use of reels and tapes. As the rover was let down from the bay, most of the deployment was automatic. The rear wheels folded out and locked in place. When they touched the ground, the front of the rover could be unfolded, the wheels deployed, and the entire frame let down to the surface by pulleys.

The rover components locked into place upon opening. Cabling, pins, and tripods would then be removed and the seats and footrests raised. After switching on all the electronics, the vehicle was ready to back away from the LM.

Four flight-ready LRVs were manufactured, as well as several others for testing and training. Three were transported to and left on the Moon via the Apollo 15, 16, and 17 missions, with the fourth rover used for spare parts on the first three following the cancellation of Apollo 18. Since only the upper stages of the lunar excursion modules could return to lunar orbit from the surface, the vehicles, along with the lower stages were abandoned. As a result, the only lunar rovers on display are test vehicles, trainers, and mock-ups. The rover used on Apollo 15 was left at Hadley-Apennine (

). The rover used on Apollo 16 was left at Descartes (

). The rover used on Apollo 17 was left at Taurus-Littrow (

) and was seen by the Lunar Reconnaissance Orbiter during passes in 2009 and 2011.
Several rovers were created for testing, training, or validation purposes. The engineering mockup is on display at the Museum of Flight in Seattle, Washington. The Qualification Test Unit is on display at the National Air and Space Museum in Washington, D.C. The rover used for vibration testing is on display in the Davidson Saturn V Center at the U.S. Space & Rocket Center in Huntsville, Alabama. Additional test units are on display at the Johnson Space Center in Houston, Texas, and the Kennedy Space Center Visitors Complex in Cape Canaveral, Florida. Replicas of rovers are on display at the National Museum of Naval Aviation in Pensacola, Florida, the Evergreen Aviation & Space Museum in McMinnville, Oregon, and the Kansas Cosmosphere and Space Center in Hutchinson, Kansas. A replica on loan from the Smithsonian Institution is on display at the attraction at Epcot at the Walt Disney World Resort near Orlando, Florida.




</doc>
<doc id="18240" url="https://en.wikipedia.org/wiki?curid=18240" title="Lake Kickapoo">
Lake Kickapoo

Lake Kickapoo is a reservoir in Archer County, Texas. Created in 1947. It has a surface area of . Named after the Kickapoo tribe native to the area.

One of the nine Air Force Space Surveillance System (formerly NAVSPASUR) sites is located at Lake Kickapoo (). It is the master transmitter and the most powerful continuous wave (CW) station in the world, at 768 kW radiated power.



</doc>
<doc id="18243" url="https://en.wikipedia.org/wiki?curid=18243" title="Land (disambiguation)">
Land (disambiguation)

Land is the solid surface of the Earth that is not covered by water. It may also refer to:

In music:

As a synonym for a region belonging to a people:

As a geographical place:

As a division of a country:

Other usages:


</doc>
<doc id="18245" url="https://en.wikipedia.org/wiki?curid=18245" title="Labyrinth">
Labyrinth

In Greek mythology, the Labyrinth ( "labúrinthos") was an elaborate, confusing structure designed and built by the legendary artificer Daedalus for King Minos of Crete at Knossos. Its function was to hold the Minotaur, the monster eventually killed by the hero Theseus. Daedalus had so cunningly made the Labyrinth that he could barely escape it after he built it.

Although early Cretan coins occasionally exhibit branching (multicursal) patterns, the single-path (unicursal) seven-course "Classical" design without branching or dead ends became associated with the Labyrinth on coins as early as 430 BC, and similar non-branching patterns became widely used as visual representations of the Labyrinth – even though both logic and literary descriptions make it clear that the Minotaur was trapped in a complex branching maze. Even as the designs became more elaborate, visual depictions of the mythological Labyrinth from Roman times until the Renaissance are almost invariably unicursal. Branching mazes were reintroduced only when hedge mazes became popular during the Renaissance.

In English, the term "labyrinth" is generally synonymous with "maze". As a result of the long history of unicursal representation of the mythological Labyrinth, however, many contemporary scholars and enthusiasts observe a distinction between the two. In this specialized usage "maze" refers to a complex branching multicursal puzzle with choices of path and direction, while a unicursal "labyrinth" has only a single path to the center. A labyrinth in this sense has an unambiguous route to the center and back and presents no navigational challenge.

Unicursal labyrinths appeared as designs on pottery or basketry, as body art, and in etchings on walls of caves or churches. The Romans created many primarily decorative unicursal designs on walls and floors in tile or mosaic. Many labyrinths set in floors or on the ground are large enough that the path can be walked. Unicursal patterns have been used historically both in group ritual and for private meditation, and are increasingly found for therapeutic use in hospitals and hospices.

"Labyrinth" is a word of pre-Greek origin, which the Greeks associated with the palace of Knossos in Crete, excavated by Arthur Evans early in the 20th century. The word appears in a Linear B inscription as da-pu-ri-to. As early as 1892 Maximilian Mayer suggested that "labyrinthos" might derive from "labrys", a Lydian word for "double-bladed axe". Evans suggested that the palace at Knossos was the original labyrinth, and since the double axe motif appears in the palace ruins,
he asserted that "labyrinth" could be understood to mean "the house of the double axe". This designation may not have been limited to Knossos, since the same symbols were discovered in other palaces in Crete. However Nilsson observes that in Crete the "double axe" is not a weapon and always accompanies goddesses or women and not a male god. 
Beekes finds the relation with "labrys" speculative, and suggests instead the relation with "lavra" (λαύρα), narrow street. The original Minoan word appears to refer to labyrinthine grottoes, such as seen at Gortyn. Pliny the Elder's four examples of labyrinths are all complex underground structures, and this appears to have been the standard Classical understanding of the word. It is also possible that the word labyrinth is derived from the Egyptian "loperohunt", meaning palace or temple by the lake. The Egyptian labyrinth near Lake Moeris is described by Herodotus and Strabo. By the 4th century BC, Greek vase painters also represented the Labyrinth by the familiar "Greek key" patterns of endlessly running meanders.

When the Bronze Age site at Knossos was excavated by explorer Arthur Evans, the complexity of the architecture prompted him to suggest that the palace had been the Labyrinth of Daedalus. Evans found various bull motifs, including an image of a man leaping over the horns of a bull, as well as depictions of a labrys carved into the walls. On the strength of a passage in the "Iliad", it has been suggested that the palace was the site of a dancing-ground made for Ariadne by the craftsman Daedalus,
where young men and women, of the age of those sent to Crete as prey for the Minotaur, would dance together. By extension, in popular legend the palace is associated with the myth of the Minotaur.

In the 2000s, archaeologists explored other potential sites of the labyrinth. Oxford University geographer Nicholas Howarth believes that 'Evans's hypothesis that the palace of Knossos is also the Labyrinth must be treated sceptically.' Howarth and his team conducted a search of an underground complex known as the Skotino cave but concluded that it was formed naturally. Another contender is a series of tunnels at Gortyn, accessed by a narrow crack but expanding into interlinking caverns. Unlike the Skotino cave, these caverns have smooth walls and columns, and appear to have been at least partially man-made. This site corresponds to an unusual labyrinth symbol on a 16th-century map of Crete contained in a book of maps in the library of Christ Church, Oxford. A map of the caves themselves was produced by the French in 1821. The site was also used by German soldiers to store ammunition during the Second World War. Howarth's investigation was shown on a documentary produced for the National Geographic Channel.

More generally, "labyrinth" might be applied to any extremely complicated maze-like structure. Herodotus, in Book II of his "Histories", describes as a "labyrinth" a building complex in Egypt, "near the place called the City of Crocodiles," that he considered to surpass the pyramids:
During the 19th century, the remains of this structure were discovered by Flinders Petrie at the foot of the pyramid of Amenemhat III at Hawara in the Faiyum Oasis. The Classical accounts of various authors (Herodotus, Strabo, Pliny the Elder, among others) are not entirely consistent, perhaps due to degradation of the structure during Classical times. In origin, the structure was likely a collection of funerary temples such as are commonly found near Egyptian pyramids.

In 1898, the "Harpers Dictionary of Classical Antiquities" described the structure as "the largest of all the temples of Egypt, the so-called Labyrinth, of which, however, only the foundation stones have been preserved."

Herodotus' description of the Egyptian Labyrinth inspired some central scenes in Bolesław Prus' 1895 historical novel, "Pharaoh".

Pliny the Elder's "Natural History" (36.90) lists the legendary Smilis, reputed to be a contemporary of Daedalus, together with the historical mid-sixth-century BC architects and sculptors Rhoikos and Theodoros as two of the makers of the Lemnian labyrinth, which Andrew Stewart regards as "evidently a misunderstanding of the Samian temple's location "en limnais" ['in the marsh']."

According to Pliny, the tomb of the great Etruscan general Lars Porsena contained an underground maze. Pliny's description of the exposed portion of the tomb is intractable; Pliny, it seems clear, had not observed this structure himself, but is quoting the historian and Roman antiquarian Varro.

A design essentially identical to the 7-course "classical" pattern appeared in Native American culture, the Tohono O'odham people labyrinth which features I'itoi, the "Man in the Maze." The Tonoho O'odham pattern has two distinct differences from the classical: it is radial in design, and the entrance is at the top, where traditional labyrinths have the entrance at the bottom (see below). The earliest appearances cannot be dated securely; the oldest is commonly dated to the 17th century.

A prehistoric petroglyph on a riverbank in Goa shows a maze-like pattern and has been dated to circa 2500 BC. Other examples have been found among cave art in northern India and on a dolmen shrine in the Nilgiri Mountains, but are difficult to date accurately. Early labyrinths in India typically follow the Classical pattern or a local variant of it; some have been described as plans of forts or cities.

Labyrinths appear in Indian manuscripts and Tantric texts from the 17th century onward. They are often called "Chakravyuha" in reference to an impregnable battle formation described in the ancient Mahabharata epic. Lanka, the capital city of mythic Rāvana, is described as a labyrinth in the 1910 translation of Al-Beruni's "India" (c. 1030 AD) p. 306 (with a diagram on the following page).

By the White Sea, notably on the Solovetsky Islands, there have been preserved more than 30 stone labyrinths. The most remarkable monument is the Stone labyrinths of Bolshoi Zayatsky Island - a group of 13–14 stone labyrinths on 0.4 km area of one small island. These labyrinths are thought to be 2,000–3,000 years old.

The 7-course "Classical" or "Cretan" pattern known from Cretan coins (ca 400–200 BC) appears in several examples from antiquity, some perhaps as early as the late Stone Age or early Bronze Age. Roman floor mosaics typically unite four copies of the classical labyrinth (or a similar pattern) interlinked around the center, squared off as the medium requires, but still recognisable. An image of the Minotaur or an allusion to the legend of the Minotaur appears at the center of many of these mosaic labyrinths. The four-axis medieval patterns may have developed from the Roman model, but are more varied in how the four quadrants of the design are traced out. The Minotaur or other danger is retained in the center of several medieval examples. The Chartres pattern (named for its appearance in Chartres Cathedral) is the most common medieval design; it appears in manuscripts as early as the 9th century.

When the early humanist Benzo d'Alessandria visited Verona before 1310, he noted the ""Laberinthum" which is now called the Arena"; perhaps he was seeing the "cubiculi" beneath the arena's missing floor.
The full flowering of the medieval labyrinth came about from the twelfth through fourteenth centuries with the grand pavement labyrinths of the gothic cathedrals, notably Chartres, Reims and Amiens in northern France. These labyrinths may have originated as symbolic allusion to the Holy City; and some modern thinkers have theorized that prayers and devotions may have accompanied the perambulation of their intricate paths. Although some books (in particular guidebooks) suggest that the mazes on cathedral floors served as substitutes for pilgrimage paths, the earliest attested use of the phrase "chemin de Jerusalem" (path to Jerusalem) dates to the late 18th century when it was used to describe mazes at Reims and Saint-Omer. The accompanying ritual, supposedly involving pilgrims following the maze on their knees while praying, may have been practiced at Chartres during the 17th century. However, no contemporary evidence supports the idea that labyrinths had such a purpose for early Christians. The cathedral labyrinths are thought to be the inspiration for the many turf mazes in the UK, such as survive at Wing, Hilton, Alkborough, and Saffron Walden.

Over the same general period, some 500 or more non-ecclesiastical labyrinths were constructed in Scandinavia. These labyrinths, generally in coastal areas, are marked out with stones, most often in the simple 7- or 11-course classical forms. They often have names which translate as "Troy Town." They are thought to have been constructed by fishing communities: trapping malevolent trolls or winds in the labyrinth's coils might ensure a safe fishing expedition. There are also stone labyrinths on the Isles of Scilly, although none is known to date from before the nineteenth century.

There are examples of labyrinths in many disparate cultures. The symbol has appeared in various forms and media (petroglyphs, classic-form, medieval-form, pavement, turf, and basketry) at some time throughout most parts of the world, from Native North and South America to Australia, Java, India, and Nepal.

In recent years, there has been a resurgence of interest in labyrinths and a revival in labyrinth building, of both unicursal and multicursal patterns. In modern imagery, the labyrinth of Daedalus is often represented by a multicursal maze, in which one may become lost.

The Argentine writer Jorge Luis Borges was entranced with the idea of the labyrinth, and used it extensively in his short stories (such as "The House of Asterion" in "The Aleph"). His use of it has inspired other authors (e.g. Umberto Eco's "The Name of the Rose", Mark Z. Danielewski's "House of Leaves"). Additionally, Roger Zelazny's fantasy series, "The Chronicles of Amber", features a labyrinth, called "the Pattern," which grants those who walk it the power to move between parallel worlds. The avant-garde multi-screen film, "In the Labyrinth", presents a search for meaning in a symbolic modern labyrinth. In Rick Riordan's series Percy Jackson & the Olympians, the events of the fourth novel "The Battle of the Labyrinth" predominantly take place within the labyrinth of Daedalus, which has followed the heart of the West to settle beneath the United States. Australian author Sara Douglass incorporated some labyrinthine ideas in her series The Troy Game, in which the Labyrinth on Crete is one of several in the ancient world, created with the cities as a source of magical power. Lawrence Durrell's "The Dark Labyrinth" depicts travelers trapped underground in Crete. A magical labyrinth, based on the original myth, appears in the third episode of "The Librarians" ("And The Horns of a Dilemma").

The labyrinth is also treated in contemporary fine arts. Examples include Piet Mondrian's "Dam and Ocean" (1915), Joan Miró's "Labyrinth" (1923), Pablo Picasso's "Minotauromachia" (1935), M. C. Escher's "Relativity" (1953), Friedensreich Hundertwasser's "Labyrinth" (1957), Jean Dubuffet's "Logological Cabinet" (1970), Richard Long's "Connemara sculpture" (1971), Joe Tilson's "Earth Maze" (1975), Richard Fleischner's "Chain Link Maze" (1978), István Orosz's "Atlantis Anamorphosis" (2000), Dmitry Rakov's "Labyrinth" (2003), and drawings by contemporary American artist Mo Morales employing what the artist calls "Labyrinthine projection." The Italian painter Davide Tonato has dedicated many of his artistic works to the labyrinth theme.

Mark Wallinger has created a set of 270 enamel plaques of unicursal labyrinth designs, one for every tube station in the London Underground, to mark the 150th anniversary of the Underground. The plaques were installed over a 16-month period in 2013 and 2014, and each is numbered according to its position in the route taken by the contestants in the 2009 Guinness World Record Tube Challenge.

Labyrinths and mazes have been embraced by the video game industry, and countless video games include such a feature.

Prehistoric labyrinths may have served as traps for malevolent spirits or as paths for ritual dances. Many Roman and Christian labyrinths appear at the entrances of buildings, suggesting that they may have served a similar apotropaic purpose. In their cross-cultural study of signs and symbols, "Patterns that Connect", Carl Schuster and Edmund Carpenter present various forms of the labyrinth and suggest various possible meanings, including not only a sacred path to the home of a sacred ancestor, but also, perhaps, a representation of the ancestor him/herself: ."..many [New World] Indians who make the labyrinth regard it as a sacred symbol, a beneficial ancestor, a deity. In this they may be preserving its original meaning: the ultimate ancestor, here evoked by two continuous lines joining its twelve primary joints." Schuster also observes the common theme of the labyrinth being a refuge for a trickster; in India, the demon Ravana has dominion over labyrinths, the trickster Djonaha lives in a labyrinth according to Sumatran Bataks, and Europeans say it is the home of a rogue.

One can think of labyrinths as symbolic of pilgrimage; people can walk the path, ascending toward salvation or enlightenment. Author Ben Radford conducted an investigation into some of the claims of spiritual and healing effects of labyrinths, reporting on his findings in his book Mysterious New Mexico.

Many labyrinths have been constructed recently in churches, hospitals, and parks. These are often used for contemplation; walking among the turnings, one loses track of direction and of the outside world, and thus quiets the mind. The Labyrinth Society provides a locator for modern labyrinths all over the world.

In addition, the labyrinth can serve as a metaphor for situations that are difficult to be extricated from, as an image that suggests getting lost in a subterranean dungeon-like world. Octavio Paz titled his book on Mexican identity "The Labyrinth of Solitude", describing the Mexican condition as orphaned and lost.

Labyrinths have on various occasions been used in Christian tradition as a part of worship. The earliest known example is from a fourth-century pavement at the Basilica of St Reparatus, at Orleansville, Algeria, with the words "Sancta Eclesia" at the center, though it is unclear how it might have been used in worship.

In medieval times, labyrinths began to appear on church walls and floors around 1000 C.E.. The most famous medieval labyrinth, with great influence on later practice, was created in Chartres Cathedral. The purpose of the labyrinths is not clear, though there are surviving descriptions of French clerics performing a ritual Easter dance along the path on Easter Sunday. Some books (guidebooks in particular) suggest that mazes on cathedral floors originated in the medieval period as alternatives to pilgrimage to the Holy Land, but the earliest attested use of the phrase "chemin de Jerusalem" (path to Jerusalem) dates to the late 18th century when it was used to describe mazes at Reims and Saint-Omer. The accompanying ritual, depicted in Romantic illustrations as involving pilgrims following the maze on their knees while praying, may have been practiced at Chartres during the 17th century.

The use of labyrinths has recently been revived in some contexts of Christian worship. Many churches in Europe and North America have constructed permanent, typically unicursal, labyrinths, or employ temporary ones (e.g., painted on canvas or outlined with candles). For example, a labyrinth was set up on the floor of St Paul's Cathedral for a week in March 2000. Some conservative Christians disapprove of labyrinths, considering them pagan practices or "new age" fads.





</doc>
<doc id="18246" url="https://en.wikipedia.org/wiki?curid=18246" title="Lyon &amp; Healy">
Lyon &amp; Healy

Lyon & Healy Harps, Inc. is an American musical instrument manufacturer based in Chicago, Illinois and is a subsidiary of Salvi Harps. Today best known for concert harps, the company's Chicago headquarters and manufacturing facility contains a showroom and concert hall. George W. Lyon and Patrick J. Healy began the company in 1864 as a sheet music shop. By the end of the 19th century, they manufactured a wide range of musical instruments—including not only harps, but guitars, mandolins, banjos, ukuleles and various brass and percussion instruments.

Today, Lyon & Healy harps are widely played by professional musicians, since they are one of the few makers of harps for orchestral use—which are known as "concert harps" or "pedal harps". Lyon & Healy also makes smaller "folk harps" or lever harps (based on traditional Irish and Scottish instruments) that use levers to change string pitch instead of pedals. In the 1980s, Lyon & Healy also began to manufacture electroacoustic harps and, later, solid body electric harps.

George W. Lyon, a native of Northborough, Massachusetts; and Patrick J. Healy, born in Mallow, Ireland, founded the company in 1864, after they moved from Boston to start a sheet music shop for music publisher Oliver Ditson. Determining Lyon & Healy's history is complicated because its building and company records were destroyed in two fires, including the Great Chicago Fire of 1871. Two smaller fires did little damage to the firm and did not result in data loss.

Company letters and trade catalogs don't provide exact dates that would reveal when Lyon & Healy began manufacturing instruments. An article in the "Musical Courier" states that Lyon & Healy began manufacturing instruments in 1885. Clearly, Lyon & Healy was making fretted string instruments in the 1880s, with Washburn (guitars, mandolins, banjos, and zithers) as their premier line. By the 1900s, if not earlier, Lyon & Healy might well have been manufacturing bowed string instruments.

According to Vintage Guitar magazine, "Circa 1900, the firm was so large it manufactured under a host of sub-brands; Washburn is perhaps the most recognized, though Leland, Lakeside, and American Conservatory are still seen." 

Lyon & Healy also made various percussion instruments. Later, Lyon & Healy began manufacturing brass instruments, possibly as early as the 1890s. Lyon & Healy also repaired instruments, and offered engraving services. Complicating matters still further, Lyon & Healy engraved instruments that it retailed but did not actually manufacture. In its 1892 catalog, it claimed that it manufactured 100,000 instruments annually.

The company is known to have made other instruments, including reed organs and pianos. Lyon & Healy evidently began manufacturing these instruments around 1876 in its factories in Chicago and nearby cities. George W. Lyon patented his cottage upright in 1878 and it was sold under the Lyon & Healy name.

Lyon retired in 1889 and Healy became the company's first president. That year, Lyon & Healy built their first harp. Healy wanted to develop a harp better suited to the rigors of the American climate than available European models. They successfully produced a harp notable for its strength, pitch reliability, and freedom from unwanted vibration. Previously, most harps in North America were made by small groups of craftsmen in France, England, Ireland, or Italy.

In 1890, Lyon & Healy introduced the Style 23 Harp, still a popular and recognizable design. It has 47 strings, highly decorative floral carving on the top of the column, base, and feet, and a fleur de lis pattern at the bottom of the column. It is available in a gold version. It is tall, and weighs about . Lyon & Healy produces one of the most ornate and elaborate harps in the world, the Louis XV, which includes carvings of leaves, flowers, scrolls, and shells along its neck and kneeblock, as well the soundboard edges.

Lyon would later form a new company with E.A. Potter called Lyon & Potter, and remained there until his death on January 12, 1894. Healy died of pneumonia on April 3, 1905.

In the 1890s the company—which used the slogan,"Everything in music"—began building pipe organs. In 1894 Robert J. Bennett came to Lyon & Healy from the Hutchings company of Boston to head their organ department. The largest surviving Lyon & Healy pipe organ is at the Our Lady of Sorrows Basilica in Chicago. It is a large organ of four manuals and 57 ranks of pipes.

They also made small pipe organs. An example survives at St. Mary's Catholic Church in Aspen Colorado. It is a two manual tracker with a 30 note straight pedalboard and 7 ranks. It is believed to have been built around 1900, and can still be pumped by hand.

By the 1900s, Lyon & Healy was one of the largest music publishers in the world, and was a major producer of musical instruments. However, In late 1920s, Lyon & Healy sold its brass musical instrument manufacturing branch (see "New Langwill Index"). In the 1970s, the firm concentrated solely upon making and selling harps.

In 1928, Lyon & Healy introduced one of the most unusual harps ever mass-produced, the "Salzedo Model". The company designed it in collaboration with the harpist Carlos Salzedo. It an Art Deco style instrument that incorporates bold red and white lines on the soundboard to create a stylized and distinct appearance.

In the 1960s, Lyon & Healy introduced a smaller lever harp, the "Troubadour", a 36-string harp for young beginners with smaller hands, and for casual players. This harp stands , and weighs .

In the late 1970s, Steinway & Sons (then owned by CBS) purchased Lyon & Healy and soon after closed all retail stores, which sold sheet music and musical instruments, to focus on harp production.

By 1985, Lyon & Healy also made folk harps, also known as "Irish harps", which are even smaller than the Troubadour. The ""Shamrock model folk harp"" has 34 strings. It stands tall with its legs. The legs can be removed so the player can hold the instrument lap—style on the knees. It weighs about . It features Celtic designs on the soundboard. An Irish or folk harp player is sometimes called a "harper" rather than "harpist". 
DePaul University now owns the Wabash building. Lyon & Healy harps are still in Chicago, Illinois, at 168 North Ogden Avenue. The building was once home to the recording studios of Orlando R. Marsh.

Wood in harp construction varies by instrument, but Sitka Spruce (Picea sitchensis) is the most common soundboard wood. Various Lyon & Healy guitars, mandolins, and many other instrument types reside in major musical instrument museums in the U.S. and Europe.

Lyon and Healy now primarily manufactures four types of harps—the "lever harp", "petite pedal harp", "semi-grande pedal harp", and "concert grand harp". They also make limited numbers of "special harps" called "concert grands". Lyon & Healy makes electric lever harps in nontraditional colors such as pink, green, blue, and red.

Lyon & Healy Corporation is a musical product distribution company in North America representing brands such as Delta, Relish Guitars, SIM1, Paoletti Guitars and Acus Sound Engineering. Lyon & Healy Corporation aims to become the leading provider of premium quality musical instruments and accessories. 




</doc>
<doc id="18247" url="https://en.wikipedia.org/wiki?curid=18247" title="Index of philosophy articles (A–C)">
Index of philosophy articles (A–C)


</doc>
<doc id="18271" url="https://en.wikipedia.org/wiki?curid=18271" title="Lamborghini">
Lamborghini

Automobili Lamborghini S.p.A. () is an Italian brand and manufacturer of luxury sports cars and SUVs based in Sant'Agata Bolognese. The company is owned by the Volkswagen Group through its subsidiary Audi.

Ferruccio Lamborghini, an Italian manufacturing magnate, founded Automobili Ferruccio Lamborghini S.p.A. in 1963 to compete with established marques, including Ferrari. The company gained wide acclaim in 1966 for the Miura sports coupé, which established rear mid-engine, rear-wheel drive as the standard layout for high-performance cars of the era. Lamborghini grew rapidly during its first decade, but sales plunged in the wake of the 1973 worldwide financial downturn and the oil crisis. The firm's ownership changed three times after 1973, including a bankruptcy in 1978. American Chrysler Corporation took control of Lamborghini in 1987 and sold it to Malaysian investment group Mycom Setdco and Indonesian group V'Power Corporation in 1994. In 1998, Mycom Setdco and V'Power sold Lamborghini to the Volkswagen Group where it was placed under the control of the group's Audi division.

New products and model lines were introduced to the brand's portfolio and brought to the market and saw an increased productivity for the brand. In the late 2000s, during the worldwide financial crisis and the subsequent economic crisis, Lamborghini's sales saw a drop of nearly 50 percent.

Lamborghini currently produces the V12-powered Aventador and the V10-powered Huracán, along with the Urus SUV powered by a twin-turbo V8 engine. In addition, the company produces V12 engines for offshore powerboat racing. Lamborghini Trattori, founded in 1948 by Ferruccio Lamborghini, is headquartered in Pieve di Cento, Italy and continues to produce tractors.

Manufacturing magnate Italian Ferruccio Lamborghini founded the company in 1963 with the objective of producing a refined grand touring car to compete with offerings from established marques such as Ferrari. The company's first models, such as the 350 GT, were released in the mid 1960s and were noted for their refinement, power and comfort. Lamborghini gained wide acclaim in 1966 for the Miura sports coupé, which established rear mid-engine, rear wheel drive as the standard layout for high-performance cars of the era.

Lamborghini grew rapidly during its first ten years, but sales plunged in the wake of the 1973 worldwide financial downturn and the oil crisis. Ferruccio Lamborghini sold ownership of the company to Georges-Henri Rossetti and René Leimer and retired in 1974. The company went bankrupt in 1978, and was placed in the receivership of brothers Jean-Claude and Patrick Mimran in 1980. The Mimrans purchased the company out of receivership by 1984 and invested heavily in the company's expansion. Under the Mimrans' management, Lamborghini's model line was expanded from the Countach to include the Jalpa sports car and the LM002 high performance off-road vehicle.

The Mimrans sold Lamborghini to the Chrysler Corporation in 1987. After replacing the Countach with the Diablo and discontinuing the Jalpa and the LM002, Chrysler sold Lamborghini to Malaysian investment group Mycom Setdco and Indonesian group V'Power Corporation in 1994. In 1998, Mycom Setdco and V'Power sold Lamborghini to the Volkswagen Group where it was placed under the control of the group's Audi division. New products and model lines were introduced to the brand's portfolio and brought to the market and saw an increased productivity for the brand Lamborghini. In the late 2000s, during the worldwide financial crisis and the subsequent economic crisis, Lamborghini's sales saw a drop of nearly 50 percent.

As of the 2018 model year, Lamborghini's automobile product range consists of three model lines, two of which are mid-engine two-seat sports cars while the third one is a front engined, all-wheel drive SUV. The V12-powered Aventador line consists of the LP 740–4 Aventador S coupé and roadster. The V10-powered Huracán line currently includes the all-wheel-drive LP 610-4 coupé and spyder, the low cost rear-wheel-drive LP 580-2 coupé and spyder and the most powerful, track oriented LP 640-4 Performanté coupé and spyder. With the intention of doubling its sales volume by 2019, Lamborghini also added an SUV named Urus in its line-up which is powered by a twin-turbo V8 engine and utilises a front engine, all-wheel drive layout.

Motori Marini Lamborghini produces a large V12 marine engine block for use in World Offshore Series Class 1 powerboats. A Lamborghini branded marine engine displaces approximately and outputs approximately .

In the mid-1980s, Lamborghini produced a limited-production run of a 1,000 cc sports motorcycle. UK weekly newspaper "Motor Cycle News" reported in 1994 – when featuring an example available through an Essex motorcycle retailer – that 24 examples were produced with a Lamborghini alloy frame having adjustable steering head angle, Kawasaki GPz1000RX engine/transmission unit, Ceriani front forks and Marvic wheels. The bodywork was plastic and fully integrated with front fairing merged into fuel tank and seat cover ending in a rear tail-fairing. The motorcycles were designed by Lamborghini stylists and produced by French business Boxer Bikes.

Lamborghini licenses its brand to manufacturers that produce a variety of Lamborghini-branded consumer goods including scale models, clothing, accessories, bags, electronics and laptop computers.

In contrast to his rival Enzo Ferrari, Ferruccio Lamborghini had decided early on that there would be no factory-supported racing of Lamborghinis, viewing motorsport as too expensive and too draining on company resources. This was unusual for the time, as many sports car manufacturers sought to demonstrate the speed, reliability, and technical superiority through motorsport participation. Enzo Ferrari in particular was known for considering his road car business mostly a source of funding for his participation in motor racing. Ferruccio's policy led to tensions between him and his engineers, many of whom were racing enthusiasts; some had previously worked at Ferrari. When Dallara, Stanzani, and Wallace began dedicating their spare time to the development of the P400 prototype, they designed it to be a road car with racing potential, one that could win on the track and also be driven on the road by enthusiasts. When Ferruccio discovered the project, he allowed them to go ahead, seeing it as a potential marketing device for the company, while insisting that it would not be raced. The P400 went on to become the Miura. The closest the company came to building a true race car under Lamborghini's supervision were a few highly modified prototypes, including those built by factory test driver Bob Wallace, such as the Miura SV-based "Jota" and the Jarama S-based "Bob Wallace Special".

In the mid-1970s, while Lamborghini was under the management of Georges-Henri Rossetti, Lamborghini entered into an agreement with BMW to develop, then manufacture 400 cars for BMW in order to meet Group 4 homologation requirements. BMW lacked experience developing a mid-engined vehicle and believed that Lamborghini's experience in that area would make Lamborghini an ideal choice of partner. Due to Lamborghini's shaky finances, Lamborghini fell behind schedule developing the car's structure and running gear. When Lamborghini failed to deliver working prototypes on time, BMW took the program in house, finishing development without Lamborghini. BMW contracted with Baur to produce the car, which BMW named the M1, delivering the first vehicle in October 1978.
In 1985, Lamborghini's British importer developed the Countach QVX, in conjunction with Spice Engineering, for the 1986 Group C championship season. One car was built, but lack of sponsorship caused it to miss the season. The QVX competed in only one race, the non-championship 1986 Southern Suns 500 km race at Kyalami in South Africa, driven by Tiff Needell. Despite the car finishing better than it started, sponsorship could once again not be found and the programme was cancelled.

Lamborghini was an engine supplier in Formula One for the 1989 through 1993 Formula One seasons. It supplied engines to Larrousse (1989–1990,1992–1993), Lotus (1990), Ligier (1991), Minardi (1992), and to the Modena team in 1991. While the latter is commonly referred to as a factory team, the company saw themselves as a supplier, not a backer. The 1992 Larrousse–Lamborghini was largely uncompetitive but noteworthy in its tendency to spew oil from its exhaust system. Cars following closely behind the Larrousse were commonly coloured yellowish-brown by the end of the race. Lamborghini's best result was achieved with Larrousse at the 1990 Japanese Grand Prix, when Aguri Suzuki finished third on home soil.

In late 1991, a Lamborghini Formula One motor was used in the Konrad KM-011 Group C sports car, but the car only lasted a few races before the project was canceled. The same engine, re-badged a Chrysler, Lamborghini's then-parent company, was tested by McLaren towards the end of the 1993 season, with the intent of using it during the 1994 season. Although driver Ayrton Senna was reportedly impressed with the engine's performance, McLaren pulled out of negotiations, choosing a Peugeot engine instead, and Chrysler ended the project.
Two racing versions of the Diablo were built for the Diablo Supertrophy, a single-model racing series held annually from 1996 to 1999. In the first year, the model used in the series was the Diablo SVR, while the Diablo 6.0 GTR was used for the remaining three years. Lamborghini developed the Murciélago R-GT as a production racing car to compete in the FIA GT Championship, the Super GT Championship and the American Le Mans Series in 2004. The car's highest placing in any race that year was the opening round of the FIA GT Championship at Valencia, where the car entered by Reiter Engineering finished third from a fifth-place start. In 2006, during the opening round of the Super GT championship at Suzuka, a car run by the Japan Lamborghini Owners Club garnered the first victory (in class) by an R-GT. A GT3 version of the Gallardo has been developed by Reiter Engineering. A Murciélago R-GT entered by All-Inkl.com racing, driven by Christophe Bouchut and Stefan Mücke, won the opening round of the FIA GT Championship held at Zhuhai International Circuit, achieving the first major international race victory for Lamborghini.

() (results in bold indicate pole position) 

The world of bullfighting is a key part of Lamborghini's identity. In 1962, Ferruccio Lamborghini visited the Seville ranch of Don Eduardo Miura, a renowned breeder of Spanish fighting bulls. Lamborghini, a Taurus himself, was so impressed by the majestic Miura animals that he decided to adopt a raging bull as the emblem for the automaker he would open shortly.

After producing two cars with alphanumeric designations, Lamborghini once again turned to the bull breeder for inspiration. Don Eduardo was filled with pride when he learned that Ferruccio had named a car for his family and their line of bulls; the fourth Miura to be produced was unveiled to him at his ranch in Seville.

The automaker would continue to draw upon the bullfighting connection in future years. The Islero was named for the Miura bull that killed the famed bullfighter Manolete in 1947. "Espada" is the Spanish word for sword, sometimes used to refer to the bullfighter himself. The Jarama's name carried a special double meaning; though it was intended to refer only to the historic bullfighting region in Spain, Ferruccio was concerned about confusion with the also historic Jarama motor racing track.

After christening the Urraco after a bull breed, in 1974, Lamborghini broke from tradition, naming the not for a bull, but for (), a Piedmontese expletive. Legend has it that stylist Nuccio Bertone uttered the word in surprise when he first saw the Countach prototype, "Project 112". The LM002 (LM for Lamborghini Militaire) sport utility vehicle and the Silhouette (named after the popular racing category of the time) were other exceptions to the tradition.

The Jalpa of 1982 was named for a bull breed; Diablo, for the Duke of Veragua's ferocious bull famous for fighting an epic battle against El Chicorro in Madrid in 1869; Murciélago, the legendary bull whose life was spared by El Lagartijo for his performance in 1879; Gallardo, named for one of the five ancestral castes of the Spanish fighting bull breed; and Reventón, the bull that defeated young Mexican "torero" Félix Guzmán in 1943. The Estoque concept of 2008 was named for the estoc, the sword traditionally used by matadors during bullfights.

Throughout its history, Lamborghini has envisioned and presented a variety of concept cars, beginning in 1963 with the very first Lamborghini prototype, the 350GTV. Other famous models include Bertone's 1967 Marzal, 1974 Bravo, and 1980 Athon, Chrysler's 1987 Portofino, the Italdesign-styled Cala from 1995, the Zagato-built Raptor from 1996.

A retro-styled Lamborghini Miura concept car, the first creation of chief designer Walter de'Silva, was presented in 2006. President and CEO Stephan Winkelmann denied that the concept would be put into production, saying that the Miura concept was "a celebration of our history, but Lamborghini is about the future. Retro design is not what we are here for. So we won’t do the [new] Miura.”

At the 2008 Paris Motor Show, Lamborghini revealed the Estoque, a four-door sedan concept. Although there had been much speculation regarding the Estoque's eventual production, Lamborghini management has not made a decision regarding production of what might be the first four-door car to roll out of the Sant'Agata factory.

At the 2010 Paris Motor Show, Lamborghini unveiled the Sesto Elemento. The concept car is made almost entirely of carbon fibre making it extremely light, with a weight of . The Sesto Elemento shares the same V10 engine found in the Lamborghini Gallardo. Lamborghini hopes to signal a shift in the company's direction from making super cars focused on top speed to producing more agile, track focused cars with the Sesto Elemento. The concept car can reach 0–62 mph (100 km/h) in 2.5 seconds and can reach a top speed of over 180 mph.

At the 2012 Geneva Motor Show, Lamborghini unveiled the Aventador J – a roofless, windowless version of the Lamborghini Aventador. The Aventador J uses the same 700 hp engine and seven-speed transmission as the standard Aventador.

At the 2012 Beijing Motor Show, Lamborghini unveiled the Urus SUV. This is the first SUV built by Lamborghini since the LM002.

As part of the celebration of 50 years of Lamborghini, the company created the Egoista. Egoista is for one person's driving and only one Egoista is to be made.

At the 2014 Paris Motor Show, Lamborghini unveiled the Asterion LPI910-4 hybrid concept car. Named after the half-man, half-bull hybrid (Minotaur) of Greek legend, it is the first hybrid Lamborghini in the history of the company. Utilizing the Huracán's 5.2 litre V10 producing , along with one electric motor mounted on the transaxle and an additional two on the front axle, developing an additional . This puts the power at a combined figure of . The 0–100 km/h (62 mph) time is claimed to be just above 3 seconds, with a claimed top speed of .

As of 2011, Lamborghini is structured as a wholly owned subsidiary of AUDI AG named Automobili Lamborghini S.p.A.

Automobili Lamborghini S.p.A. controls five principal subsidiaries: Ducati Motor Holding S.p.A., a manufacturer of motorcycles; Italdesign Giugiaro S.p.A., a 90.1%-owned design and prototyping firm that provides services to the entire Volkswagen Group; MML S.p.A. (Motori Marini Lamborghini), a manufacturer of marine engine blocks; and Volkswagen Group Italia S.p.A. (formerly Autogerma S.p.A.), which sells Audi and other Volkswagen Group vehicles in Italy.

By sales, the most important markets in 2004 for Lamborghini's sports cars were the U.S. (41%), Germany (13%), Great Britain (9%) and Japan (8%). Prior to the launch of the Gallardo in 2003, Lamborghini produced approximately 400 vehicles per year; in 2011 Lamborghini produced 1,711 vehicles.

Automóviles Lamborghini Latinoamérica S.A. de C.V. (Lamborghini Automobiles of Latin America Public Limited Company) is an authorized distributor and manufacturer of Lamborghini-branded vehicles and merchandise in Latin America and South America.

In 1995, Indonesian corporation MegaTech, Lamborghini's owner at the time, entered into distribution and license agreements with Mexican businessman Jorge Antonio Fernandez Garcia. The agreements give Automóviles Lamborghini Latinoamérica S.A. de C.V. the exclusive distributorship of Lamborghini vehicles and branded merchandise in Latin America and South America. Under the agreements, Automóviles Lamborghini is also allowed to manufacture Lamborghini vehicles and market them worldwide under the Lamborghini brand.

Automóviles Lamborghini has produced two rebodied versions of the Diablo called the Eros and the Coatl. In 2015, Automóviles Lamborghini transferred the IP-rights to the Coatl foundation (chamber of commerce no. 63393700) in The Netherlands in order to secure these rights and to make them more marketable. The company has announced the production of a speedboat called the Lamborghini Glamour.
This two-storey museum is attached to the headquarters, and covers the history of Lamborghini cars and sport utility vehicles, showcasing a variety of modern and vintage models. The museum uses displays of cars, engines and photos to provide a history and review important milestones of Lamborghini.

A 9,000 square-foot museum about Ferruccio Lamborghini houses several cars, industrial prototypes, sketches, personal objects and family photos from Ferruccio's early life.






</doc>
<doc id="18272" url="https://en.wikipedia.org/wiki?curid=18272" title="LaGrand case">
LaGrand case

The LaGrand case was a legal action heard before the International Court of Justice (ICJ) which concerned the Vienna Convention on Consular Relations. In the case, the ICJ found that its own temporary court orders were legally binding and that the rights contained in the convention could not be denied by the application of domestic legal procedures.

On January 7, 1982, brothers Karl-Heinz (October 20, 1963 - February 24, 1999) and Walter Bernhard LaGrand (January 26, 1962 - March 3, 1999) bungled an armed bank robbery in Marana, Arizona, United States, killing a man and severely injuring a woman in the process. They were subsequently charged and convicted of murder and sentenced to death. The LaGrands were German nationals, having been born from a German mother in Germany. While they had both lived in the United States since they were four and five, respectively, neither had officially obtained U.S. citizenship. As foreigners the LaGrands should have been informed of their right to consular assistance, under the Vienna Convention, from their state of nationality, Germany. However the Arizona authorities failed to do this even after they became aware that the LaGrands were German nationals. The LaGrand brothers later contacted the German consulate of their own accord, having learned of their right to consular assistance. They appealed their sentences and convictions on the grounds that they were not informed of their right to consular assistance, and that with consular assistance they might have been able to mount a better defense. The federal courts rejected their argument on grounds of procedural default, which provides that issues cannot be raised in federal court appeals unless they have first been raised in state courts.

Diplomatic efforts, including pleas by German ambassador Jürgen Chrobog and German Member of Parliament Claudia Roth, and the recommendation of Arizona's clemency board, failed to sway Arizona Governor Jane Dee Hull, who insisted that the executions were carried out. Karl LaGrand was subsequently executed by the state of Arizona on February 24, 1999, by lethal injection. Walter LaGrand was executed March 3, 1999, by lethal gas, and currently remains the last person executed by that method in the United States.

Germany then initiated legal action in the International Court of Justice against the United States regarding Walter LaGrand. Hours before Walter LaGrand was due to be executed, Germany applied for the Court to grant a provisional court order, requiring the United States to delay the execution of Walter LaGrand, which the court granted.

Germany then initiated action in the U.S. Supreme Court for enforcement of the provisional order. In its judgment, the U.S. Supreme Court held that it lacked jurisdiction with respect to Germany's complaint against Arizona due to the Eleventh Amendment of the U.S. constitution, which prohibits federal courts from hearing lawsuits of foreign states against a U.S. state. With respect to Germany's case against the United States, it held that the doctrine of procedural default was not incompatible with the Vienna Convention, and that even if procedural default did conflict with the Vienna Convention it had been overruled by later federal law – the Antiterrorism and Effective Death Penalty Act of 1996, which explicitly legislated the doctrine of procedural default. (Subsequent federal legislation overrides prior self-executing treaty provisions, "Whitney v. Robertson", ).

The U.S. Solicitor General sent a letter to the Supreme Court, as part of these proceedings, arguing that provisional measures of the International Court of Justice are not legally binding. The United States Department of State also conveyed the ICJ's provisional measure to the Governor of Arizona without comment. The Arizona clemency board recommended a stay to the governor, on the basis of the pending ICJ case; but the Governor of Arizona ignored the recommendation. 

Germany then modified its complaint in the case before the ICJ, alleging furthermore that the U.S. violated international law by failing to implement the provisional measures. In opposition to the German submissions, the United States argued that the Vienna Convention did not grant rights to individuals, only to states; that the convention was meant to be exercised subject to the laws of each state party, which in the case of the United States meant subject to the doctrine of procedural default; and that Germany was seeking to turn the ICJ into an international court of criminal appeal.

On June 27, 2001, the ICJ, rejecting all of the United States' arguments, ruled in favor of Germany. The ICJ held that the Vienna Convention on Consular Relations of April 24, 1963, granted rights to individuals on the basis of its plain meaning, and that domestic laws could not limit the rights of the accused under the convention, but only specify the means by which those rights were to be exercised. The ICJ also found that its own provisional measures were legally binding. The nature of provisional measures has been a subject of great dispute in international law; the English text of the Statute of the International Court of Justice implies they are not binding, while the French text implies that they are. Faced with a contradiction between two equally authentic texts of the statute, the court considered which interpretation better served the objects and purposes of the statute, and hence found that they are binding. This was the first time in the court's history it had ruled as such.

The court also found that the United States violated the Vienna Convention through its application of procedural default. The court was at pains to point out that it was not passing judgment on the doctrine itself, but only its application to cases involving the Vienna Convention.




</doc>
<doc id="18273" url="https://en.wikipedia.org/wiki?curid=18273" title="Lotus 1-2-3">
Lotus 1-2-3

Lotus 1-2-3 is a discontinued spreadsheet program from Lotus Software (later part of IBM). It was the IBM PC's first killer application, was hugely popular in the 1980s and contributed significantly to the success of the IBM PC.

The first spreadsheet, VisiCalc, had helped launch the Apple II as one of the earliest personal computers in business use. With IBM's entry into the market, VisiCalc was slow to respond, and when they did, they launched what was essentially a straight port of their existing system in spite of the greatly expanded hardware capabilities. Lotus' solution was marketed as a three-in-one integrated solution, which handled spreadsheet calculations, database functionality, and graphical charts, hence the name "1-2-3", though how much database capability was debatable given Lotus' sparse memory. 1-2-3 quickly overtook VisiCalc, as well as Multiplan and SuperCalc, two VisiCalc competitors.

1-2-3 was the spreadsheet standard throughout the 1980s and into the 1990s, part of an unofficial set of three stand-alone office automation products that included dBase and WordPerfect, to build a complete business platform. With the acceptance of Windows 3.0, the market for desktop software grew even more. None of the major spreadsheet developers had seriously considered the graphical user interface to supplement their DOS offerings, and so they responded slowly to Microsoft's own graphical-based products, Excel and Word. Lotus was surpassed by Microsoft in the early 1990s and never recovered. IBM purchased Lotus in 1995 and continued to sell Lotus offerings, only officially ending sales in 2013.

VisiCalc was launched in 1979 on the Apple II and immediately became a best-seller. Compared to earlier programs, VisiCalc allowed one to easily construct free-form calculation systems for practically any purpose, the limitations being primarily memory and speed related. The application was so compelling that there were numerous stories of people buying Apple II machines to run the program. VisiCalc's runaway success on the Apple led to direct bug compatible ports to other platforms, including the Atari 8-bit family, Commodore PET and many others. This included the IBM PC when it launched in 1981, where it quickly became another best-seller, with an estimated 300,000 sales in the first six months on the market.

There were well known problems with VisiCalc, and several competitors appeared to address some of these issues. One early example was 1980's SuperCalc, which solved the problem of circular references, while a slightly later example was Microsoft Multiplan from 1981, which offered larger sheets and other improvements. In spite of these, and others, VisiCalc continued to outsell them all.

The Lotus Development Corporation was founded by Mitchell Kapor, a friend of the developers of VisiCalc. 1-2-3 was originally written by Jonathan Sachs, who had written two spreadsheet programs previously while working at Concentric Data Systems, Inc. To aid its growth, in the UK, and possibly elsewhere, Lotus 1-2-3 was the very first computer software to use television consumer advertising.

Lotus 1-2-3 was released on 26 January 1983, and immediately overtook Visicalc in sales. Unlike Microsoft Multiplan, it stayed very close to the model of VisiCalc, including the "A1" letter and number cell notation, and slash-menu structure. It was cleanly programmed, relatively bug-free, gained speed from being written completely in x86 assembly language (this remained the case for all DOS versions until 3.0, when Lotus switched to C) and wrote directly to video memory rather than use the slow DOS and/or BIOS text output functions.

Among other novelties that Lotus introduced was a graph maker that could display several forms of graphs (including pie charts, bar graphics, or line charts) but required the user to have a graphics card. At this early stage, the only video boards available for the PC were IBM's Color/Graphics Adapter and Monochrome Display and Printer Adapter while the latter did not support any graphics. However, because the two video boards used different RAM and port addresses, both could be installed in the same machine and so Lotus took advantage of this by supporting a "split" screen mode whereby the user could display the worksheet portion of 1-2-3 on the sharper monochrome video and the graphics on the CGA display.

The initial release of 1-2-3 supported only three video setups, CGA, MDA (in which case the graph maker was not available) or dual monitor mode. However, a few months later support was added for Hercules Computer Technology's Hercules Graphics Adapter which was a clone of the MDA that allowed bitmap mode. The ability to have high-resolution text and graphics capabilities (at the expense of color) proved extremely popular and Lotus 1-2-3 is credited with popularizing the Hercules graphics card.

Subsequent releases of Lotus 1-2-3 supported more video standards as time went on, including EGA, AT&T/Olivetti, and VGA. Significantly, support for the PCjr/Tandy modes was never added and users of those machines were limited to CGA graphics.

The early versions of 1-2-3 also had a key disk copy protection. While the program was hard disk installable, the user had to insert the original floppy disk when starting 1-2-3 up. This protection scheme was easily cracked and a minor inconvenience for home users, but proved a serious nuisance in an office setting. Starting with Release 3.0, Lotus no longer used copy protection. However, it was then necessary to "initialize" the System disk with one's name and company name so as to customize the copy of the program. Release 2.2 and higher had this requirement. This was an irreversible process unless one had made an exact copy of the original disk so as to be able to change names to transfer the program to someone else.

The reliance on the specific hardware of the IBM PC led to 1-2-3 being utilized as one of the two stress test applications, along with Microsoft Flight Simulator, for true 100% compatibility when PC clones appeared in the early 1980s. 1-2-3 required two disk drives and at least 192K of memory, which made it incompatible with the IBM PCjr; Lotus produced a version for the PCjr that was on two cartridges but otherwise identical.

By early 1984 the software was a killer app for the IBM PC and compatibles, while hurting sales of computers that could not run it. "They're looking for 1-2-3. Boy, are they looking for 1-2-3!" "InfoWorld" wrote. Noting that computer purchasers did not want PC compatibility as much as compatibility with certain PC software, the magazine suggested "let's tell it like it is. Let's not say 'PC compatible,' or even 'MS-DOS compatible.' Instead, let's say '1-2-3 compatible.'" PC clones' advertising did often prominently state that they were compatible with 1-2-3. An Apple II software company promised that its spreadsheet had "the power of 1-2-3". Because spreadsheets use large amounts of memory, 1‐2‐3 helped popularize greater RAM capacities in PCs, and especially the advent of expanded memory, which allowed greater than 640k to be accessed.

Lotus 1-2-3 inspired imitators, the first of which was Mosaic Software's "The Twin", written in the fall of 1985 largely in the C language, followed by VP-Planner, which was backed by Adam Osborne. These were able to not only read 1-2-3 files, but also execute many or most macro programs by incorporating the same command structure. Copyright law had first been understood to only cover the source code of a program. After the success of lawsuits which claimed that the very "look and feel" of a program were covered, Lotus sought to ban any program which had a compatible command and menu structure. Program commands had not been considered to be covered before, but the commands of 1-2-3 were embedded in the words of the menu displayed on the screen. 1-2-3 won its 3-year long court battle against Paperback Software International and Mosaic Software Inc. in 1990. However, when it sued Borland over its Quattro Pro spreadsheet in Lotus v. Borland, a 6-year battle that ended at the Supreme Court in 1996, the final ruling appeared to support narrowing the applicability of copyright law to software; this is because the lower court's decision that it was not a copyright violation to merely have a compatible command menu or language was upheld, but only via stalemate. In 1995, the First Circuit found that command menus are an uncopyrightable "method of operation" under section 102(b) of the Copyright Act. The 1-2-3 menu structure (example, slash File Erase) was itself an advanced version of single letter menus introduced in VisiCalc. When the case came before the Supreme Court, the justices would end up deadlocked 4-4. This meant that Borland had emerged victorious, but the extent to which copyright law would be applicable to computer software went unaddressed and undefined.

Microsoft's early spreadsheet Multiplan eventually gave way to Excel, which debuted on the Macintosh in 1985. It arrived on PCs with the release of Windows 2.x in 1987, but as Windows was not yet popular, it posed no serious threat to Lotus' stranglehold on spreadsheet sales. However, Lotus suffered technical setbacks in this period. Version 3 of Lotus 1-2-3, fully converted from its original macro assembler to the more portable C language, was delayed by more than a year as the totally new 1-2-3 had to be made portable across platforms and fully compatible with existing macro sets and file formats. The inability to fit the larger code size of compiled C into lower-powered machines forced the company to split its spreadsheet offerings, with 1-2-3 release 3 only for higher-end machines, and a new version 2.2, based on the 2.01 assembler code base, available for PCs without extended memory. By the time these versions were released in 1989, Microsoft had eroded much of Lotus' market share.

During the early 1990s, Windows grew in popularity and along with it Excel, which gradually displaced Lotus from its leading position. A planned total revamp of 1-2-3 for Windows fell apart and all that the company could manage was a Windows adaptation of their existing spreadsheet with no changes except using a graphical interface. Additionally, several versions of 1-2-3 had different features and slightly different interfaces.

1-2-3's intended successor, Lotus Symphony, was Lotus' entry into the anticipated "integrated software" market. It intended to expand the rudimentary all-in-one 1-2-3 into a fully-fledged spreadsheet, graph, database and word processor for DOS, but none of the integrated packages ever really succeeded. 1-2-3 migrated to the Windows platform, as part of Lotus SmartSuite.

IBM's continued development and marketing of Lotus SmartSuite and OS/2 during the 1990s placed it in direct competition with Microsoft Office and Microsoft Windows, respectively. As a result, Microsoft "punished the IBM PC Company with higher prices, a late license for Windows 95, and the withholding of technical and marketing support." IBM wasn't granted OEM rights for Windows 95 until 15 minutes prior to the release of Windows 95, 24 August 1995. Because of this uncertainty, IBM machines were sold without Windows 95, while Compaq, HP, and other companies sold machines with Windows 95 from day one.

On 11 June 2013, IBM announced it would withdraw the Lotus brand: IBM Lotus 123 Millennium Edition V9.x, IBM Lotus SmartSuite 9.x V9.8.0, and Organizer V6.1.0. IBM stated, "Customers will no longer be able to receive support for these offerings after 30 September 2014. No service extensions will be offered. There will be no replacement programs."

The name "1-2-3" stemmed from the product's integration of three main capabilities. Along with being a spreadsheet, it also offered integral charting/graphing and rudimentary database operations.

Data features included sorting data in any defined rectangle, by order of information in one or two columns in the rectangular area. Justifying text in a range into paragraphs allowed it to be used as a primitive word processor.

It had keyboard-driven pop-up menus as well as one-key commands, making it fast to operate. It was also user-friendly, introducing an early instance of context-sensitive help accessed by the F1 key.

Macros in version one and add-ins (introduced in version 2.0) contributed much to 1-2-3's popularity, allowing dozens of outside vendors to sell macro packages and add-ins ranging from dedicated financial worksheets like F9 to full-fledged word processors. In the single-tasking MS-DOS, 1-2-3 was sometimes used as a complete office suite. All major graphics standards were supported; initially CGA and Hercules, and later EGA, AT&T, and VGA. Early versions used the filename extension "WKS". In version 2.0, the extension changed first to "WK1", then "WK2". This later became "WK3" for version 3.0 and "WK4" for version 4.0.

Version 2 introduced macros with syntax and commands similar in complexity to an advanced BASIC interpreter, as well as string variable expressions. Later versions supported multiple worksheets and were written in C. The charting/graphing routines were written in Forth by Jeremy Sagan (son of Carl Sagan) and the printing routines by Paul Funk (founder of Funk Software).

These editions of 1-2-3 for DOS were primarily written in x86 assembly language.

These editions of 1-2-3 for DOS were primarily written in C.





After previewing "1-2-3" on the IBM PC in 1982, "BYTE" called it "modestly revolutionary" for elegantly combining spreadsheet, database, and graphing functions. It praised the application's speed and ease of use, stating that with the built-in help screens and tutorial "1-2-3 is one of the few pieces of software that can literally be used by anybody. You can buy 1-2-3 and [an IBM PC] and be running the two together the same day". "PC Magazine" in 1983 called 1-2-3 "a powerful and impressive program ... as a spreadsheet, it's excellent", and attributed its very fast performance to being written in assembly language.




</doc>
<doc id="18274" url="https://en.wikipedia.org/wiki?curid=18274" title="List of memorials to Lyndon B. Johnson">
List of memorials to Lyndon B. Johnson

This is a list of memorials to Lyndon B. Johnson, 36th president of the United States.







</doc>
<doc id="18278" url="https://en.wikipedia.org/wiki?curid=18278" title="Liberation Day (Netherlands)">
Liberation Day (Netherlands)

In the Netherlands, Liberation Day () is celebrated each year on May the 5th to mark the end of the occupation by Nazi Germany during World War II.

The nation was liberated by Canadian forces, British infantry divisions, the British I Corps, the 1st Polish Armoured Division, American, Belgian, Dutch and Czechoslovak troops. Parts of the country, in particular the south-east, were liberated by the British Second Army which included American and Polish airborne forces (see Operation Market Garden) and French airbornes (see Operation Amherst). On 5 May 1945 the Canadian General Charles Foulkes and the German Commander-in-Chief Johannes Blaskowitz reached an agreement on the capitulation of German forces in the Netherlands in Hotel de Wereld in Wageningen. One day later the capitulation document was signed in the auditorium of Wageningen University located next door.

After liberation in 1945 Liberation Day was celebrated every five years. In 1990 the day was declared a national holiday when liberation would be remembered and celebrated every year.

On May 4 the Dutch hold "Dodenherdenking" Remembrance of the Dead for the people who fought and died during World War II and in wars in general. There are remembrance gatherings all over cities and in the country, the better-known at the National Monument on Dam Square in Amsterdam and at the Waalsdorpervlakte in the dunes near The Hague, one of the infamous Nazi execution places. Throughout the country two minutes of silence is observed at 8 pm. On May 5 the liberation is celebrated and festivals are held at most places in the Netherlands with parades of veterans and 14 musical festivals through the whole country.



</doc>
<doc id="18279" url="https://en.wikipedia.org/wiki?curid=18279" title="Light pollution">
Light pollution

Light pollution, also known as photo pollution, is the presence of anthropogenic and artificial light in the night environment. It is exacerbated by excessive, misdirected or obtrusive use of light, but even carefully used light fundamentally alters natural conditions. As a major side-effect of urbanization, it is blamed for compromising health, disrupting ecosystems and spoiling aesthetic environments.

Light pollution is the adding-of/added light itself, in analogy to added sound, carbon dioxide, etc. Adverse consequences are multiple; some of them may not be known yet. Scientific definitions thus include the following:

The first three of the above four scientific definitions describe the state of the environment. The fourth one describes the process of polluting by light.

Light pollution competes with starlight in the night sky for urban residents, interferes with astronomical observatories, and, like any other form of pollution, disrupts ecosystems and has adverse health effects.

Light pollution is a side-effect of industrial civilization. Its sources include building exterior and interior lighting, advertising, outdoor area lighting (e.g. car parks/parking lots), offices, factories, streetlights, and illuminated sporting venues. It is most severe in highly industrialized, densely populated areas of North America, Europe, and Japan and in major cities in the Middle East and North Africa like Tehran and Cairo, but even relatively small amounts of light can be noticed and create problems. Awareness of the deleterious effects of light pollution began early in the 20th century (see e.g. Beston), but efforts to address effects did not begin until the 1950s. In the 1980s a global dark-sky movement emerged with the founding of the International Dark-Sky Association (IDA). There are now such educational and advocacy organizations in many countries worldwide.

Energy conservation advocates contend that light pollution must be addressed by changing the habits of society, so that lighting is used more efficiently, with less waste and less creation of unwanted or unneeded illumination. Several industry groups also recognize light pollution as an important issue. For example, the Institution of Lighting Engineers in the United Kingdom provides its members with information about light pollution, the problems it causes, and how to reduce its impact. Although, recent research point that the energy efficiency is not enough to reduce the light pollution because of the rebound effect.

Since not everyone is irritated by the same lighting sources, it is common for one person's light "pollution" to be light that is desirable for another. One example of this is found in advertising, when an advertiser wishes for particular lights to be bright and visible, even though others find them annoying. Other types of light pollution are more certain. For instance, light that "accidentally" crosses a property boundary and annoys a neighbour is generally wasted and pollutive light.

Disputes are still common when deciding appropriate action; and differences in opinion over what light is considered reasonable, and who should be responsible, mean that negotiation must sometimes take place between parties. Where objective measurement is desired, light levels can be quantified by field measurement or mathematical modeling, with results typically displayed as an isophote map or light contour map. Authorities have also taken a variety of measures for dealing with light pollution, depending on the interests, beliefs and understandings of the society involved. Measures range from doing nothing at all, to implementing strict laws and regulations about how lights may be installed and used.

Light pollution is caused by inefficient, unappealing, or (arguably) unnecessary use of artificial light. Specific categories of light pollution include light trespass, over-illumination, glare, light clutter, and skyglow. A single offending light source often falls into more than one of these categories.

Light trespass occurs when unwanted light enters one's property, for instance, by shining over a neighbor's fence. A common light trespass problem occurs when a strong light enters the window of one's home from the outside, causing problems such as sleep deprivation. A number of cities in the U.S. have developed standards for outdoor lighting to protect the rights of their citizens against light trespass. To assist them, the International Dark-Sky Association has developed a set of model lighting ordinances.

The Dark-Sky Association was started to reduce the light going up into the sky which reduces visibility of stars (see Skyglow below). This is any light which is emitted more than 90° above nadir. By limiting light at this 90° mark they have also reduced the light output in the 80–90° range which creates most of the light trespass issues.
U.S. federal agencies may also enforce standards and process complaints within their areas of jurisdiction. For instance, in the case of light trespass by white strobe lighting from communication towers in excess of FAA minimum lighting requirements the Federal Communications Commission maintains an Antenna Structure Registration database information which citizens may use to identify offending structures and provides a mechanism for processing citizen inquiries and complaints. The U.S. Green Building Council (USGBC) has also incorporated a credit for reducing the amount of light trespass and sky glow into their environmentally friendly building standard known as LEED.

Light trespass can be reduced by selecting light fixtures which limit the amount of light emitted more than 80° above the nadir. The IESNA definitions include full cutoff (0%), cutoff (10%), and semi-cutoff (20%). (These definitions also include limits on light emitted above 90° to reduce sky glow.)

Over-illumination is the excessive use of light. Specifically within the United States, over-illumination is responsible for approximately two million barrels of oil per day in energy wasted. This is based upon U.S. consumption of equivalent of of petroleum. It is further noted in the same U.S. Department of Energy (DOE) source that over 30% of all primary energy is consumed by commercial, industrial and residential sectors. Energy audits of existing buildings demonstrate that the lighting component of residential, commercial and industrial uses consumes about 20–40% of those land uses, variable with region and land use. (Residential use lighting consumes only 10–30% of the energy bill while commercial buildings' major use is lighting.) Thus lighting energy accounts for about four or five million barrels of oil (equivalent) per day. Again energy audit data demonstrates that about 30–60% of energy consumed in lighting is unneeded or gratuitous.

An alternative calculation starts with the fact that commercial building lighting consumes in excess of 81.68 terawatts (1999 data) of electricity, according to the DOE. Thus commercial lighting alone consumes about four to five million barrels per day (equivalent) of petroleum, in line with the alternate rationale above to estimate U.S. lighting energy consumption. Even among developed countries there are large differences in patterns of light use. American cities emit three to five times more light to space per capita compared to German cities.

Over-illumination stems from several factors:


Most of these issues can be readily corrected with available, inexpensive technology, and with resolution of landlord/tenant practices that create barriers to rapid correction of these matters. Most importantly, public awareness would need to improve for industrialized countries to realize the large payoff in reducing over-illumination.

In certain cases an over-illumination lighting technique may be needed. For example, indirect lighting is often used to obtain a "softer" look, since hard direct lighting is generally found less desirable for certain surfaces, such as skin. The indirect lighting method is perceived as more cozy and suits bars, restaurants and living quarters. It is also possible to block the direct lighting effect by adding softening filters or other solutions, though intensity will be reduced.

Glare can be categorized into different types. One such classification is described in a book by Bob Mizon, coordinator for the British Astronomical Association's Campaign for Dark Skies, as follows:

According to Mario Motta, president of the Massachusetts Medical Society, "...glare from bad lighting is a public-health hazard—especially the older you become. Glare light scattering in the eye causes loss of contrast and leads to unsafe driving conditions, much like the glare on a dirty windshield from low-angle sunlight or the high beams from an oncoming car." In essence bright and/or badly shielded lights around roads can partially blind drivers or pedestrians and contribute to accidents.

The blinding effect is caused in large part by reduced contrast due to light scattering in the eye by excessive brightness, or to reflection of light from dark areas in the field of vision, with luminance similar to the background luminance. This kind of glare is a particular instance of disability glare, called veiling glare. (This is not the same as loss of accommodation of night vision which is caused by the direct effect of the light itself on the eye.)

Light clutter refers to excessive groupings of lights. Groupings of lights may generate confusion, distract from obstacles (including those that they may be intended to illuminate), and potentially cause accidents. Clutter is particularly noticeable on roads where the street lights are badly designed, or where brightly lit advertisements surrounds the roadways. Depending on the motives of the person or organization that installed the lights, their placement and design can even be intended to distract drivers, and can contribute to accidents.

Another source of light pollution are artificial satellites. With future increase in numbers of satellite constellations, like SpaceX's Starlink, it is feared especially by the astronomical community, such as the IAU that light pollution will increase significantly, beside other problems of satellite overcrowding.

Measuring the effect of sky glow on a global scale is a complex procedure. The natural atmosphere is not completely dark, even in the absence of terrestrial sources of light and illumination from the Moon. This is caused by two main sources: "airglow" and "scattered light".

At high altitudes, primarily above the mesosphere, there is enough UV radiation from the sun of very short wavelength to cause ionization. When the ions collide with electrically neutral particles they recombine and emit photons in the process, causing airglow. The degree of ionization is sufficiently large to allow a constant emission of radiation even during the night when the upper atmosphere is in the Earth's shadow. Lower in the atmosphere all the solar photons with energies above the ionization potential of N and O have already been absorbed by the higher layers and thus no appreciable ionization occurs.

Apart from emitting light, the sky also scatters incoming light, primarily from distant stars and the Milky Way, but also the zodiacal light, sunlight that is reflected and backscattered from interplanetary dust particles.

The amount of airglow and zodiacal light is quite variable (depending, amongst other things on sunspot activity and the Solar cycle) but given optimal conditions the darkest possible sky has a brightness of about 22 magnitude/square arc second. If a full moon is present, the sky brightness increases to about 18 magnitude/sq. arc second depending on local atmospheric transparency, 40 times brighter than the darkest sky. In densely populated areas a sky brightness of 17 magnitude/sq. arc second is not uncommon, or as much as 100 times brighter than is natural.

To precisely measure how bright the sky gets, night time satellite imagery of the earth is used as raw input for the number and intensity of light sources. These are put into a physical model of scattering due to air molecules and aerosoles to calculate cumulative sky brightness. Maps that show the enhanced sky brightness have been prepared for the entire world.

Inspection of the area surrounding Madrid reveals that the effects of light pollution caused by a single large conglomeration can be felt up to away from the center.
Global effects of light pollution are also made obvious. The entire area consisting of southern England, Netherlands, Belgium, west Germany, and northern France have a sky brightness of at least two to four times normal (see above right). The only places in continental Europe where the sky can attain its natural darkness are in northern Scandinavia and in islands far from the continent.

In North America the situation is comparable. There is a significant problem with light pollution ranging from the Canadian Maritime Provinces to the American Southwest. The International Dark-Sky Association works to designate areas that have high quality night skies. These areas are supported by communities and organizations that are dedicated to reducing light pollution (e.g. Dark-sky preserve). The National Park Service Natural Sounds and Night Skies Division has measured night sky quality in national park units across the U.S. Sky quality in the U.S. ranges from pristine (Capitol Reef National Park and Big Bend National Park) to severely degraded (Santa Monica Mountains National Recreation Area and Biscayne National Park). The National Park Service Night Sky Program monitoring database is available online (2015).

The Bortle scale is a nine-level measuring system used to track how much light pollution there is in the sky. Five or less is the amount required to see the Milky Way whilst one is "pristine", the darkest possible.

Light pollution in Hong Kong was declared the 'worst on the planet' in March 2013.

In June 2016, it was estimated that one third of the world's population could no longer see the Milky Way, including 80% of Americans and 60% of Europeans. Singapore was found to be the most light-polluted country in the world.

Medical research on the effects of excessive light on the human body suggests that a variety of adverse health effects may be caused by light pollution or excessive light exposure, and some lighting design textbooks use human health as an explicit criterion for proper interior lighting. Health effects of over-illumination or improper spectral composition of light may include: increased headache incidence, worker fatigue, medically defined stress, decrease in sexual function and increase in anxiety. Likewise, animal models have been studied demonstrating unavoidable light to produce adverse effect on mood and anxiety. For those who need to be awake at night, light at night also has an acute effect on alertness and mood.

In 2007, "shift work that involves circadian disruption" was listed as a probable carcinogen by the World Health Organization's International Agency for Research on Cancer. (IARC Press release No. 180). Multiple studies have documented a correlation between night shift work and the increased incidence of breast and prostate cancer. One study which examined the link between exposure to artificial light at night (ALAN) and levels of breast cancer in South Korea found that regions which had the highest levels of ALAN reported the highest number of cases of breast cancer. Seoul, which had the highest levels of light pollution, had 34.4% more cases of breast cancer than Ganwon-do, which had the lowest levels of light pollution. This suggested a high correlation between ALAN and the prevalence of breast cancer. It was also found that there was no correlation between other types of cancer such as cervical or lung cancer and ALAN levels.

A more recent discussion (2009), written by Professor Steven Lockley, Harvard Medical School, can be found in the CfDS handbook "Blinded by the Light?". Chapter 4, "Human health implications of light pollution" states that "...light intrusion, even if dim, is likely to have measurable effects on sleep disruption and melatonin suppression. Even if these effects are relatively small from night to night, continuous chronic circadian, sleep and hormonal disruption may have longer-term health risks". The New York Academy of Sciences hosted a meeting in 2009 on Circadian Disruption and Cancer. Red light suppresses melatonin the least.

In June 2009, the American Medical Association developed a policy in support of control of light pollution. News about the decision emphasized glare as a public health hazard leading to unsafe driving conditions. Especially in the elderly, glare produces loss of contrast, obscuring night vision.

When artificial light affects organisms and ecosystems it is called ecological light pollution. While light at night can be beneficial, neutral, or damaging for individual species, its presence invariably disturbs ecosystems. For example, some species of spiders avoid lit areas, while other species are happy to build their spider web directly on a lamp post. Since lamp posts attract many flying insects, the spiders that don't mind light gain an advantage over the spiders that avoid it. This is a simple example of the way in which species frequencies and food webs can be disturbed by the introduction of light at night.

Light pollution poses a serious threat in particular to nocturnal wildlife, having negative impacts on plant and animal physiology. It can confuse animal navigation, alter competitive interactions, change predator-prey relations, and cause physiological harm. The rhythm of life is orchestrated by the natural diurnal patterns of light and dark, so disruption to these patterns impacts the ecological dynamics.

Studies suggest that light pollution around lakes prevents zooplankton, such as "Daphnia", from eating surface algae, causing algal blooms that can kill off the lakes' plants and lower water quality. Light pollution may also affect ecosystems in other ways. For example, lepidopterists and entomologists have documented that nighttime light may interfere with the ability of moths and other nocturnal insects to navigate. Night-blooming flowers that depend on moths for pollination may be affected by night lighting, as there is no replacement pollinator that would not be affected by the artificial light. This can lead to species decline of plants that are unable to reproduce, and change an area's longterm ecology. Among nocturnal insects, fireflies (Coleoptera: Lampyridae, Phengodidae and Elateridae) are especially interesting study objects for light pollution, once they depend on their own light to reproduce and, consequently, are very sensitive to environmental levels of light. Fireflies are charismatic (which is a rare quality among insects) and are easily spotted by nonexperts, and, due to their sensibility and rapid response to environmental changes, good bioindicators for artificial night lighting. Massive insect declines have been suggested as being at least partially mediated by artificial lights at night.
A 2009 study also suggests deleterious impacts on animals and ecosystems because of perturbation of polarized light or artificial polarization of light (even during the day, because direction of natural polarization of sun light and its reflection is a source of information for a lot of animals). This form of pollution is named polarized light pollution (PLP). Unnatural polarized light sources can trigger maladaptive behaviors in polarization-sensitive taxa and alter ecological interactions.

Lights on tall structures can disorient migrating birds. Estimates by the U.S. Fish and Wildlife Service of the number of birds killed after being attracted to tall towers range from four to five million per year to an order of magnitude higher. The Fatal Light Awareness Program (FLAP) works with building owners in Toronto, Ontario, Canada and other cities to reduce mortality of birds by turning out lights during migration periods.

Similar disorientation has also been noted for bird species migrating close to offshore production and drilling facilities. Studies carried out by Nederlandse Aardolie Maatschappij b.v. (NAM) and Shell have led to development and trial of new lighting technologies in the North Sea. In early 2007, the lights were installed on the Shell production platform L15. The experiment proved a great success since the number of birds circling the platform declined by 50 to 90%.

Sea turtle hatchlings emerging from nests on beaches are another casualty of light pollution. It is a common misconception that hatchling sea turtles are attracted to the moon. Rather, they find the ocean by moving away from the dark silhouette of dunes and their vegetation, a behavior with which artificial lights interfere. The breeding activity and reproductive phenology of toads, however, are cued by moonlight. Juvenile seabirds may also be disoriented by lights as they leave their nests and fly out to sea. Amphibians and reptiles are also affected by light pollution. Introduced light sources during normally dark periods can disrupt levels of melatonin production. Melatonin is a hormone that regulates photoperiodic physiology and behaviour. Some species of frogs and salamanders utilize a light-dependent "compass" to orient their migratory behaviour to breeding sites. Introduced light can also cause developmental irregularities, such as retinal damage, reduced juvenile growth, premature metamorphosis, reduced sperm production, and genetic mutation.

In September 2009, the 9th European Dark-Sky Symposium in Armagh, Northern Ireland had a session on the environmental effects of light at night (LAN). It dealt with bats, turtles, the "hidden" harms of LAN, and many other topics. The environmental effects of LAN were mentioned as early as 1897, in a "Los Angeles Times" article. The following is an excerpt from that article, called "Electricity and English songbirds":

Astronomy is very sensitive to light pollution. The night sky viewed from a city bears no resemblance to what can be seen from dark skies. Skyglow (the scattering of light in the atmosphere at night) reduces the contrast between stars and galaxies and the sky itself, making it much harder to see fainter objects. This is one factor that has caused newer telescopes to be built in increasingly remote areas.

Some astronomers use narrow-band "nebula filters", which allow only specific wavelengths of light commonly seen in nebulae, or broad-band "light pollution filters", which are designed to reduce (but not eliminate) the effects of light pollution by filtering out spectral lines commonly emitted by sodium- and mercury-vapor lamps, thus enhancing contrast and improving the view of dim objects such as galaxies and nebulae. Unfortunately, these light pollution reduction (LPR) filters are not a cure for light pollution. LPR filters reduce the brightness of the object under study and this limits the use of higher magnifications. LPR filters work by blocking light of certain wavelengths, which alters the color of the object, often creating a pronounced green cast. Furthermore, LPR filters work only on certain object types (mainly emission nebulae) and are of little use on galaxies and stars. No filter can match the effectiveness of a dark sky for visual or photographic purposes.

Light pollution affects the visibility of diffuse sky objects like nebulae and galaxies more than stars, due to their low surface brightness. Most such objects are rendered invisible in heavily light-polluted skies above major cities. A simple method for estimating the darkness of a location is to look for the Milky Way, which from truly dark skies appears bright enough to cast a shadow.
In addition to skyglow, light trespass can impact observations when artificial light directly enters the tube of the telescope and is reflected from non-optical surfaces until it eventually reaches the eyepiece. This direct form of light pollution causes a glow across the field of view, which reduces contrast. Light trespass also makes it hard for a visual observer to become sufficiently adapted to the dark. The usual measures to reduce this glare, if reducing the light directly is not an option, include flocking the telescope tube and accessories to reduce reflection, and putting a light shield (also usable as a dew shield) on the telescope to reduce light entering from angles other than those near the target. Under these conditions, some astronomers prefer to observe under a black cloth to ensure maximum adaptation to the dark.

A study presented at the American Geophysical Union meeting in San Francisco found that light pollution destroys nitrate radicals thus preventing the normal night time reduction of atmospheric smog produced by fumes emitted from cars and factories. The study was presented by Harald Stark from the National Oceanic and Atmospheric Administration.

In the night, the polarization of the moonlit sky is very strongly reduced in the presence of urban light pollution, because scattered urban light is not strongly polarized. Polarized moonlight can't be seen by humans, but is believed to be used by many animals for navigation.

Reducing light pollution implies many things, such as reducing sky glow, reducing glare, reducing light trespass, and reducing clutter. The method for best reducing light pollution, therefore, depends on exactly what the problem is in any given instance. Possible solutions include:

The use of "full cutoff" lighting fixtures, as much as possible, is advocated by most campaigners for the reduction of light pollution. It is also commonly recommended that lights be spaced appropriately for maximum efficiency, and that number of luminaires being used as well as the wattage of each luminaire match the needs of the particular application (based on local lighting design standards).

Full cutoff fixtures first became available in 1959 with the introduction of General Electric's M100 fixture.

A full cutoff fixture, when correctly installed, reduces the chance for light to escape above the plane of the horizontal. Light released above the horizontal may sometimes be lighting an intended target, but often serves no purpose. When it enters into the atmosphere, light contributes to sky glow. Some governments and organizations are now considering, or have already implemented, full cutoff fixtures in street lamps and stadium lighting.

The use of full cutoff fixtures help to reduce sky glow by preventing light from escaping above the horizontal. Full cutoff typically reduces the visibility of the lamp and reflector within a luminaire, so the effects of glare are also reduced. Campaigners also commonly argue that full cutoff fixtures are more efficient than other fixtures, since light that would otherwise have escaped into the atmosphere may instead be directed towards the ground. However, full cutoff fixtures may also trap more light in the fixture than other types of luminaires, corresponding to lower luminaire efficiency, suggesting a re-design of some luminaires may be necessary.

The use of full cutoff fixtures can allow for lower wattage lamps to be used in the fixtures, producing the same or sometimes a better effect, due to being more carefully controlled. In every lighting system, some sky glow also results from light reflected from the ground. This reflection can be reduced, however, by being careful to use only the lowest wattage necessary for the lamp, and setting spacing between lights appropriately. Assuring luminaire setback is greater than 90° from highly reflective surfaces also diminishes reflectance.

A common criticism of full cutoff lighting fixtures is that they are sometimes not as aesthetically pleasing to look at. This is most likely because historically there has not been a large market specifically for full cutoff fixtures, and because people typically like to see the source of illumination. Due to the specificity with their direction of light, full cutoff fixtures sometimes also require expertise to install for maximum effect.

The effectiveness of using full cutoff roadway lights to combat light pollution has also been called into question. According to design investigations, luminaires with full cutoff distributions (as opposed to "cutoff" or "semi cutoff", compared here) have to be closer together to meet the same light level, uniformity and glare requirements specified by the IESNA. These simulations optimized the height and spacing of the lights while constraining the overall design to meet the IESNA requirements, and then compared total uplight and energy consumption of different luminaire designs and powers. Cutoff designs performed better than full cutoff designs, and semi-cutoff performed better than either cutoff or full cutoff. This indicates that, in roadway installations, over-illumination or poor uniformity produced by full cutoff fixtures may be more detrimental than direct uplight created by fewer cutoff or semi-cutoff fixtures. Therefore, the overall performance of existing systems could be improved more by reducing the number of luminaires than by switching to full cutoff designs.
However, using the definition of "light pollution" from some Italian regional bills (i.e., "every irradiance of artificial light outside competence areas and particularly upward the sky") only full cutoff design prevents light pollution. The Italian Lombardy region, where only full cutoff design is allowed (Lombardy act no. 17/2000, promoted by Cielobuio-coordination for the protection of the night sky), in 2007 had the lowest per capita energy consumption for public lighting in Italy. The same legislation also imposes a minimum distance between street lamps of about four times their height, so full cut off street lamps are the best solution to reduce both light pollution and electrical power usage.

Several different types of light sources exist, each having different properties that affect their appropriateness for certain tasks, particularly efficiency and spectral power distribution. It is often the case that inappropriate light sources have been selected for a task, either due to ignorance or because more sophisticated light sources were unavailable at the time of installation. Therefore, badly chosen light sources often contribute unnecessarily to light pollution and energy waste. By re-assessing and changing the light sources used, it is often possible to reduce energy use and pollutive effects while simultaneously greatly improving efficiency and visibility.

Some types of light sources are listed in order of energy efficiency in the table below (figures are approximate maintained values), and include relative visual skyglow impacts.

Many astronomers request that nearby communities use low pressure sodium lights or amber Aluminium gallium indium phosphide LED as much as possible, because the principal wavelength emitted is comparably easy to work around or in rare cases filter out. The low cost of operating sodium lights is another feature. In 1980, for example, San Jose, California, replaced all street lamps with low pressure sodium lamps, whose light is easier for nearby Lick Observatory to filter out. Similar programs are now in place in Arizona and Hawaii. Such yellow light sources also have significantly less visual skyglow impact, so reduce visual sky brightness and improve star visibility for everyone.

Disadvantages of low pressure sodium lighting are that fixtures must usually be larger than competing fixtures, and that color cannot be distinguished, due to its emitting principally a single wavelength of light (see security lighting). Due to the substantial size of the lamp, particularly in higher wattages such as 135 W and 180 W, control of light emissions from low pressure sodium luminaires is more difficult. For applications requiring more precise direction of light (such as narrow roadways) the native lamp efficacy advantage of this lamp type is decreased and may be entirely lost compared to high pressure sodium lamps. Allegations that this also leads to higher amounts of light pollution from luminaires running these lamps arise principally because of older luminaires with poor shielding, still widely in use in the UK and in some other locations. Modern low-pressure sodium fixtures with better optics and full shielding, and the decreased skyglow impacts of yellow light preserve the luminous efficacy advantage of low-pressure sodium and result in most cases is less energy consumption and less visible light pollution. Unfortunately, due to continued lack of accurate information, many lighting professionals continue to disparage low-pressure sodium, contributing to its decreased acceptance and specification in lighting standards and therefore its use. Another disadvantage of low-pressure sodium lamps is that some people find the characteristic yellow light very displeasing aesthetically.

Because of the increased sensitivity of the human eye to blue and green wavelengths when viewing low-luminances (the Purkinje effect) in the night sky, different sources produce dramatically different amounts of visible skyglow from the same amount of light sent into the atmosphere.

In some cases, evaluation of existing plans has determined that more efficient lighting plans are possible. For instance, light pollution can be reduced by turning off unneeded outdoor lights, and lighting stadiums only when there are people inside. Timers are especially valuable for this purpose. One of the world's first coordinated "legislative" efforts to reduce the adverse effect of this pollution on the environment began in Flagstaff, Arizona, in the U.S. There, more than three decades of ordinance development has taken place, with the full support of the population, often with government support, with community advocates, and with the help of major local observatories, including the United States Naval Observatory Flagstaff Station. Each component helps to educate, protect and enforce the imperatives to intelligently reduce detrimental light pollution.

One example of a lighting plan assessment can be seen in a report originally commissioned by the Office of the Deputy Prime Minister in the United Kingdom, and now available through the Department for Communities and Local Government. The report details a plan to be implemented throughout the UK, for designing lighting schemes in the countryside, with a particular focus on preserving the environment.

In another example, the city of Calgary has recently replaced most residential street lights with models that are comparably energy efficient. The motivation is primarily operation cost and environmental conservation. The costs of installation are expected to be regained through energy savings within six to seven years.

The Swiss Agency for Energy Efficiency (SAFE) uses a concept that promises to be of great use in the diagnosis and design of road lighting, ""consommation électrique spécifique" ("CES")", which can be translated into English as "specific electric power consumption (SEC)". Thus, based on observed lighting levels in a wide range of Swiss towns, SAFE has defined target values for electric power consumption per metre for roads of various categories. Thus, SAFE currently recommends an SEC of two to three watts per meter for roads less than ten metres wide (four to six for wider roads). Such a measure provides an easily applicable environmental protection constraint on conventional "norms", which usually are based on the recommendations of lighting manufacturing interests, who may not take into account environmental criteria. In view of ongoing progress in lighting technology, target SEC values will need to be periodically revised downwards.
A newer method for predicting and measuring various aspects of light pollution was described in the journal Lighting Research & Technology (September 2008). Scientists at Rensselaer Polytechnic Institute's Lighting Research Center have developed a comprehensive method called Outdoor Site-Lighting Performance (OSP), which allows users to quantify, and thus optimize, the performance of existing and planned lighting designs and applications to minimize excessive or obtrusive light leaving the boundaries of a property. OSP can be used by lighting engineers immediately, particularly for the investigation of glow and trespass (glare analyses are more complex to perform and current commercial software does not readily allow them), and can help users compare several lighting design alternatives for the same site.

In the effort to reduce light pollution, researchers have developed a "Unified System of Photometry," which is a way to measure how much or what kind of street lighting is needed. The Unified System of Photometry allows light fixtures to be designed to reduce energy use while maintaining or improving perceptions of visibility, safety, and security. There was a need to create a new system of light measurement at night because the biological way in which the eye's rods and cones process light is different in nighttime conditions versus daytime conditions. Using this new system of photometry, results from recent studies have indicated that replacing traditional, yellowish, high-pressure sodium (HPS) lights with "cool" white light sources, such as induction, fluorescent, ceramic metal halide, or LEDs can actually reduce the amount of electric power used for lighting while maintaining or improving visibility in nighttime conditions.

The International Commission on Illumination, also known as the CIE from its French title, la Commission Internationale de l'Eclairage, will soon be releasing its own form of unified photometry for outdoor lighting.





</doc>
<doc id="18285" url="https://en.wikipedia.org/wiki?curid=18285" title="Lagrangian point">
Lagrangian point

In celestial mechanics, the Lagrangian points ( also Lagrange points, L-points, or libration points) are the points near two large bodies in orbit where a smaller object will maintain its position relative to the large orbiting bodies. At other locations, a small object would go into its own orbit around one of the large bodies, but at the Lagrangian points the gravitational forces of the two large bodies, the centripetal force of orbital motion, and (for certain points) the Coriolis acceleration all match up in a way that cause the small object to maintain a stable or nearly stable position relative to the large bodies.

There are five such points, labeled L to L, all in the orbital plane of the two large bodies, for each given combination of two orbital bodies. For instance, there are five Lagrangian points L to L for the Sun–Earth system, and in a similar way there are five "different" Lagrangian points for the Earth–Moon system. L, L, and L are on the line through the centers of the two large bodies. L and L each form an equilateral triangle with the centers of the large bodies. L and L are stable, which implies that objects can orbit around them in a rotating coordinate system tied to the two large bodies.

Several planets have trojan satellites near their L and L points with respect to the Sun. Jupiter has more than a million of these trojans. Artificial satellites have been placed at L and L with respect to the Sun and Earth, and with respect to the Earth and the Moon. The Lagrangian points have been proposed for uses in space exploration.

The three collinear Lagrange points (L, L, L) were discovered by Leonhard Euler a few years before Joseph-Louis Lagrange discovered the remaining two.

In 1772, Lagrange published an "Essay on the three-body problem". In the first chapter he considered the general three-body problem. From that, in the second chapter, he demonstrated two special constant-pattern solutions, the collinear and the equilateral, for any three masses, with circular orbits.

The five Lagrangian points are labeled and defined as follows:

The point lies on the line defined by the two large masses "M" and "M", and between them. It is the point where the gravitational attraction of "M" partially cancels "M"'s gravitational attraction. An object that orbits the Sun more closely than Earth would normally have a shorter orbital period than Earth, but that ignores the effect of Earth's own gravitational pull. If the object is directly between Earth and the Sun, then Earth's gravity counteracts some of the Sun's pull on the object, and therefore increases the orbital period of the object. The closer to Earth the object is, the greater this effect is. At the point, the orbital period of the object becomes exactly equal to Earth's orbital period. is about 1.5 million kilometers from Earth, or 0.01 au, 1/100th the distance to the Sun.

The point lies on the line through the two large masses, beyond the smaller of the two. Here, the gravitational forces of the two large masses balance the centrifugal effect on a body at . On the opposite side of Earth from the Sun, the orbital period of an object would normally be greater than that of Earth. The extra pull of Earth's gravity decreases the orbital period of the object, and at the point that orbital period becomes equal to Earth's. Like L, L is about 1.5 million kilometers or 0.01 au from Earth.

The point lies on the line defined by the two large masses, beyond the larger of the two. Within the Sun–Earth system, the point exists on the opposite side of the Sun, a little outside Earth's orbit and slightly further from the Sun than Earth is. This placement occurs because the Sun is also affected by Earth's gravity and so orbits around the two bodies' barycenter, which is well inside the body of the Sun. An object at Earth's distance from the Sun would have an orbital period of one year if only the Sun's gravity is considered. But an object on the opposite side of the Sun from Earth and directly in line with both "feels" Earth's gravity adding slightly to the Sun's and therefore must orbit a little further from the Sun in order to have the same 1-year period. It is at the point that the combined pull of Earth and Sun causes the object to orbit with the same period as Earth, in effect orbiting an Earth+Sun mass with the Earth-Sun barycenter at one focus of its orbit.

The and points lie at the third corners of the two equilateral triangles in the plane of orbit whose common base is the line between the centers of the two masses, such that the point lies behind () or ahead () of the smaller mass with regard to its orbit around the larger mass.

The triangular points ( and ) are stable equilibria, provided that the ratio of is greater than 24.96. This is the case for the Sun–Earth system, the Sun–Jupiter system, and, by a smaller margin, the Earth–Moon system. When a body at these points is perturbed, it moves away from the point, but the factor opposite of that which is increased or decreased by the perturbation (either gravity or angular momentum-induced speed) will also increase or decrease, bending the object's path into a stable, kidney bean-shaped orbit around the point (as seen in the corotating frame of reference).

In contrast to and , where stable equilibrium exists, the points , , and are positions of unstable equilibrium. Any object orbiting at , , or will tend to fall out of orbit; it is therefore rare to find natural objects there, and spacecraft inhabiting these areas must employ station keeping in order to maintain their position.

It is common to find objects at or orbiting the and points of natural orbital systems. These are commonly called "trojans". In the 20th century, asteroids discovered orbiting at the Sun–Jupiter and points were named after characters from Homer's "Iliad". Asteroids at the point, which leads Jupiter, are referred to as the "Greek camp", whereas those at the point are referred to as the "Trojan camp". 

Other examples of natural objects orbiting at Lagrange points:

Lagrangian points are the constant-pattern solutions of the restricted three-body problem. For example, given two massive bodies in orbits around their common barycenter, there are five positions in space where a third body, of comparatively negligible mass, could be placed so as to maintain its position relative to the two massive bodies. As seen in a rotating reference frame that matches the angular velocity of the two co-orbiting bodies, the gravitational fields of two massive bodies combined providing the centripetal force at the Lagrangian points, allowing the smaller third body to be relatively stationary with respect to the first two.

The location of L is the solution to the following equation, gravitation providing the centripetal force:

where "r" is the distance of the L point from the smaller object, "R" is the distance between the two main objects, and "M" and "M" are the masses of the large and small object, respectively. Solving this for "r" involves solving a quintic function, but if the mass of the smaller object ("M") is much smaller than the mass of the larger object ("M") then and are at approximately equal distances "r" from the smaller object, equal to the radius of the Hill sphere, given by:

This distance can be described as being such that the orbital period, corresponding to a circular orbit with this distance as radius around "M" in the absence of "M", is that of "M" around "M", divided by ≈ 1.73:

The location of L is the solution to the following equation, gravitation providing the centripetal force:

with parameters defined as for the L case. Again, if the mass of the smaller object ("M") is much smaller than the mass of the larger object ("M") then L is at approximately the radius of the Hill sphere, given by:

The location of L is the solution to the following equation, gravitation providing the centripetal force:

with parameters "M" and "R" defined as for the L and L cases, and "r" now indicates the distance of L from the position of the smaller object, if it were rotated 180 degrees about the larger object. If the mass of the smaller object ("M") is much smaller than the mass of the larger object ("M") then:

The reason these points are in balance is that, at and , the distances to the two masses are equal. Accordingly, the gravitational forces from the two massive bodies are in the same ratio as the masses of the two bodies, and so the resultant force acts through the barycenter of the system; additionally, the geometry of the triangle ensures that the resultant acceleration is to the distance from the barycenter in the same ratio as for the two massive bodies. The barycenter being both the center of mass and center of rotation of the three-body system, this resultant force is exactly that required to keep the smaller body at the Lagrange point in orbital equilibrium with the other two larger bodies of system. (Indeed, the third body need not have negligible mass.) The general triangular configuration was discovered by Lagrange in work on the three-body problem.

The radial acceleration "a" of an object in orbit at a point along the line passing through both bodies is given by:

where "r" is the distance from the large body "M" and sgn("x") is the sign function of "x". The terms in this function represent respectively: force from "M"; force from "M"; and centrifugal force. The points L, L, L occur where the acceleration is zero — see chart at right.

Although the , , and points are nominally unstable, there are (unstable) periodic orbits called "halo" orbits around these points in a three-body system. A full "n"-body dynamical system such as the Solar System does not contain these periodic orbits, but does contain quasi-periodic (i.e. bounded but not precisely repeating) orbits following Lissajous-curve trajectories. These quasi-periodic Lissajous orbits are what most of Lagrangian-point space missions have used until now. Although they are not perfectly stable, a modest effort of station keeping keeps a spacecraft in a desired Lissajous orbit for a long time. Also, for Sun–Earth- missions, it is preferable for the spacecraft to be in a large-amplitude () Lissajous orbit around than to stay at , because the line between Sun and Earth has increased solar interference on Earth–spacecraft communications. Similarly, a large-amplitude Lissajous orbit around keeps a probe out of Earth's shadow and therefore ensures continuous illumination of its solar panels.

The and points are stable provided that the mass of the primary body (e.g. the Earth) is at least 25 times the mass of the secondary body (e.g. the Moon). The Earth is over 81 times the mass of the Moon (the Moon is 1.23% of the mass of the Earth). Although the and points are found at the top of a "hill", as in the effective potential contour plot above, they are nonetheless stable. The reason for the stability is a second-order effect: as a body moves away from the exact Lagrange position, Coriolis acceleration (which depends on the velocity of an orbiting object and cannot be modeled as a contour map) curves the trajectory into a path around (rather than away from) the point.

This table lists sample values of L, L, and L within the solar system. Calculations assume the two bodies orbit in a perfect circle with separation equal to the semimajor axis and no other bodies are nearby. Distances are measured from the larger body's center of mass with L showing a negative location. The percentage columns show how the distances compare to the semimajor axis. E.g. for the Moon, L is located from Earth's center, which is 84.9% of the Earth–Moon distance or 15.1% in front of the Moon; L is located from Earth's center, which is 116.8% of the Earth–Moon distance or 16.8% beyond the Moon; and L is located from Earth's center, which is 99.3% of the Earth–Moon distance or 0.7084% in front of the Moon's 'negative' position. 

Sun–Earth is suited for making observations of the Sun–Earth system. Objects here are never shadowed by Earth or the Moon and, if observing Earth, always view the sunlit hemisphere. The first mission of this type was the 1978 International Sun Earth Explorer 3 (ISEE-3) mission used as an interplanetary early warning storm monitor for solar disturbances. Since June 2015, DSCOVR has orbited the L point. Conversely it is also useful for space-based solar telescopes, because it provides an uninterrupted view of the Sun and any space weather (including the solar wind and coronal mass ejections) reaches L a few hours before Earth. Solar telescopes currently located around L include the Solar and Heliospheric Observatory and Advanced Composition Explorer.

Sun–Earth is a good spot for space-based observatories. Because an object around will maintain the same relative position with respect to the Sun and Earth, shielding and calibration are much simpler. It is, however, slightly beyond the reach of Earth's umbra, so solar radiation is not completely blocked at L. Spacecraft generally orbit around L, avoiding partial eclipses of the Sun to maintain a constant temperature. From locations near L, the Sun, Earth and Moon are relatively close together in the sky; this means that a large sunshade with the telescope on the dark-side can allow the telescope to cool passively to around 50 K – this is especially helpful for infrared astronomy and observations of the cosmic microwave background. The James Webb Space Telescope is due to be positioned at L.

Sun–Earth was a popular place to put a "Counter-Earth" in pulp science fiction and comic books. Once space-based observation became possible via satellites and probes, it was shown to hold no such object. The Sun–Earth is unstable and could not contain a natural object, large or small, for very long. This is because the gravitational forces of the other planets are stronger than that of Earth (Venus, for example, comes within 0.3 AU of this every 20 months).

A spacecraft orbiting near Sun–Earth would be able to closely monitor the evolution of active sunspot regions before they rotate into a geoeffective position, so that a 7-day early warning could be issued by the NOAA Space Weather Prediction Center. Moreover, a satellite near Sun–Earth would provide very important observations not only for Earth forecasts, but also for deep space support (Mars predictions and for manned mission to near-Earth asteroids). In 2010, spacecraft transfer trajectories to Sun–Earth were studied and several designs were considered.

Missions to Lagrangian points generally orbit the points rather than occupy them directly.

Another interesting and useful property of the collinear Lagrangian points and their associated Lissajous orbits is that they serve as "gateways" to control the chaotic trajectories of the Interplanetary Transport Network.

Earth–Moon allows comparatively easy access to Lunar and Earth orbits with minimal change in velocity and this has as an advantage to position a half-way manned space station intended to help transport cargo and personnel to the Moon and back.

Earth–Moon has been used for a communications satellite covering the Moon's far side, for example, Queqiao, launched in 2018, and would be "an ideal location" for a propellant depot as part of the proposed depot-based space transportation architecture.

Scientists at the B612 Foundation were planning to use Venus's L point to position their planned Sentinel telescope, which aimed to look back towards Earth's orbit and compile a catalogue of near-Earth asteroids.

In 2017, Nasa proposed the idea of positioning a magnetic dipole shield at the Sun–Mars point for use as an artificial magnetosphere for Mars. The idea is that this would protect the planet's atmosphere from the Sun's radiation and solar winds.

International Sun Earth Explorer 3 (ISEE-3) began its mission at the Sun–Earth L before leaving to intercept a comet in 1982. The Sun–Earth L is also the point to which the Reboot ISEE-3 mission was attempting to return the craft as the first phase of a recovery mission (as of September 25, 2014 all efforts have failed and contact was lost).

Solar and Heliospheric Observatory (SOHO) is stationed in a halo orbit at , and the Advanced Composition Explorer (ACE) in a Lissajous orbit. WIND is also at .

Deep Space Climate Observatory (DSCOVR), launched on 11 February 2015, began orbiting L on 8 June 2015 to study the solar wind and its effects on Earth. DSCOVR is unofficially known as GORESAT, because it carries a camera always oriented to Earth and capturing full-frame photos of the planet similar to the Blue Marble. This concept was proposed by then-Vice President of the United States Al Gore in 1998 and was a centerpiece in his film "An Inconvenient Truth".

LISA Pathfinder (LPF) was launched on 3 December 2015, and arrived at on 22 January 2016, where, among other experiments, it tested the technology needed by (e)LISA to detect gravitational waves. LISA Pathfinder used an instrument consisting of two small gold alloy cubes.

Spacecraft at the Sun–Earth L point are in a Lissajous orbit until decommissioned, when they are sent into a heliocentric graveyard orbit.






</doc>
<doc id="18286" url="https://en.wikipedia.org/wiki?curid=18286" title="Lucid dream">
Lucid dream

A lucid dream is a dream during which the dreamer is aware that they are dreaming. During a lucid dream, the dreamer may gain some amount of control over the dream characters, narrative, and environment; however, this is not actually necessary for a dream to be described as lucid. Lucid dreaming has been studied and reported for many years. Prominent figures from ancient to modern times have been fascinated by lucid dreams and have sought ways to better understand their causes and purpose. Many different theories have emerged as a result of scientific research on the subject and have even been shown in pop culture. Further developments in psychological research have pointed to ways in which this form of dreaming may be utilized as a form of sleep therapy. 

The term 'lucid dream' was coined by Dutch author and psychiatrist Frederik van Eeden in his 1913 article "A Study of Dreams", though descriptions of dreamers being aware that they are dreaming predates the actual term. Eeden studied his personal dreams since 1896. He wrote down the dreams that seemed most important to him, and out of all these dreams, 352 were what is now known as “lucid dreams”. He created different names for the different types of dreams he experienced; each name being created from the data he had collected. He named seven different types of dreams: initial dreams, pathological, ordinary dreaming, vivid dreaming, demoniacal, general dream-sensations, and lucid dreaming. Frederick Van Eeden said the seventh type of dreaming, lucid dreaming, was the most interesting and worthy of the most careful observation of studies. Eeden studied lucid dreaming between January 20, 1898, and December 26, 1912. While describing this state of dreaming, Eeden said, 'you are completely aware of your surroundings and are able to direct your actions freely, yet the sleep is stimulating and uninterrupted.'

Early references to the phenomenon are found in ancient Greek writing. For example, the philosopher Aristotle wrote: 'often when one is asleep, there is something in consciousness which declares that what then presents itself is but a dream'. Meanwhile, the physician Galen of Pergamon used lucid dreams as a form of therapy. In addition, a letter written by Saint Augustine of Hippo in 415 AD tells the story of a dreamer, Doctor Gennadius, and refers to lucid dreaming.

In Eastern thought, cultivating the dreamer's ability to be aware that he or she is dreaming is central to both the Tibetan Buddhist practice of dream Yoga, and the ancient Indian Hindu practice of Yoga nidra. The cultivation of such awareness was common practice among early Buddhists.

Philosopher and physician Sir Thomas Browne (1605–1682) was fascinated by dreams and described his own ability to lucid dream in his "Religio Medici", stating: '...yet in one dream I can compose a whole Comedy, behold the action, apprehend the jests and laugh my self awake at the conceits thereof'.

Samuel Pepys in his diary entry for 15 August 1665 records a dream, stating: "I had my Lady Castlemayne in my arms and was admitted to use all the dalliance I desired with her, and then dreamt that this could not be awake, but that it was only a dream".

In 1867, the French sinologist Marie-Jean-Léon, Marquis d'Hervey de Saint Denys anonymously published "Les Rêves et Les Moyens de Les Diriger; Observations Pratiques" ('Dreams and the ways to direct them; practical observations'), in which he describes his own experiences of lucid dreaming, and proposes that it is possible for anyone to learn to dream consciously.

In 1913, Dutch psychiatrist and writer Frederik (Willem) van Eeden (1860–1932) coined the term 'lucid dream' in an article entitled ""A Study of Dreams"".

Some have suggested that the term is a misnomer because van Eeden was referring to a phenomenon more specific than a lucid dream. Van Eeden intended the term lucid to denote "having insight", as in the phrase "a lucid interval" applied to someone in temporary remission from a psychosis, rather than as a reference to the perceptual quality of the experience, which may or may not be clear and vivid.

In 1968, Celia Green analyzed the main characteristics of such dreams, reviewing previously published literature on the subject and incorporating new data from participants of her own. She concluded that lucid dreams were a category of experience quite distinct from ordinary dreams and said they were associated with rapid eye movement sleep (REM sleep). Green was also the first to link lucid dreams to the phenomenon of false awakenings.

Lucid dreaming was subsequently researched by asking dreamers to perform pre-determined physical responses while experiencing a dream, including eye movement signals.

In 1980, Stephen LaBerge at Stanford University developed such techniques as part of his doctoral dissertation. In 1985, LaBerge performed a pilot study that showed that time perception while counting during a lucid dream is about the same as during waking life. Lucid dreamers counted out ten seconds while dreaming, signaling the start and the end of the count with a pre-arranged eye signal measured with electrooculogram recording. LaBerge's results were confirmed by German researchers D. Erlacher and M. Schredl in 2004.

In a further study by Stephen LaBerge, four subjects were compared either singing while dreaming or counting while dreaming. LaBerge found that the right hemisphere was more active during singing and the left hemisphere was more active during counting.

Neuroscientist J. Allan Hobson has hypothesized what might be occurring in the brain while lucid. The first step to lucid dreaming is recognizing one is dreaming. This recognition might occur in the dorsolateral prefrontal cortex, which is one of the few areas deactivated during REM sleep and where working memory occurs. Once this area is activated and the recognition of dreaming occurs, the dreamer must be cautious to let the dream continue but be conscious enough to remember that it is a dream. While maintaining this balance, the amygdala and parahippocampal cortex might be less intensely activated. To continue the intensity of the dream hallucinations, it is expected the pons and the parieto-occipital junction stay active.

Using electroencephalography (EEG) and other polysomnographical measurements, LaBerge and others have shown that lucid dreams begin in the Rapid Eye Movement (REM) stage of sleep. LaBerge also proposes that there are higher amounts of beta-1 frequency band (13–19 Hz) brain wave activity experienced by lucid dreamers, hence there is an increased amount of activity in the parietal lobes making lucid dreaming a conscious process.

Paul Tholey, a German Gestalt psychologist and a professor of psychology and sports science, originally studied dreams in order to answer the question if one dreams in colour or black and white. In his phenomenological research, he outlined an epistemological frame using critical realism. Tholey instructed his probands to continuously suspect waking life to be a dream, in order that such a habit would manifest itself during dreams. He called this technique for inducing lucid dreams the "Reflexionstechnik" (reflection technique). Probands learned to have such lucid dreams; they observed their dream content and reported it soon after awakening. Tholey could examine the cognitive abilities of dream figures. Nine trained lucid dreamers were directed to set other dream figures arithmetic and verbal tasks during lucid dreaming. Dream figures who agreed to perform the tasks proved more successful in verbal than in arithmetic tasks. Tholey discussed his scientific results with Stephen LaBerge, who has a similar approach.

A study was conducted to see if it were possible to attain the ability to lucid dream through a drug. In 2018, galantamine was given to 121 patients in a double-blind, placebo-controlled trial, the only one of its kind. Some participants found as much as a 42 percent increase in their ability to lucid dream, compared to self-reports from the past six months, and ten people experienced a lucid dream for the first time. It is theorized that galantamine allows ACh to build up, leading to greater recollection and awareness during dreaming.

Other researchers suggest that lucid dreaming is not a state of sleep, but of brief wakefulness, or "micro-awakening". Experiments by Stephen LaBerge used "perception of the outside world" as a criterion for wakefulness while studying lucid dreamers, and their sleep state was corroborated with physiological measurements. LaBerge's subjects experienced their lucid dream while in a state of REM, which critics felt may mean that the subjects are fully awake. J Allen Hobson responded that lucid dreaming must be a state of both waking and dreaming.

Philosopher Norman Malcolm has argued against the possibility of checking the accuracy of dream reports, pointing out that "the only criterion of the truth of a statement that someone has had a certain dream is, essentially, his saying so."

Paul Tholey laid the epistemological basis for the research of lucid dreams, proposing seven different conditions of clarity that a dream must fulfill in order to be defined as a lucid dream:

Later, in 1992, a study by Deirdre Barrett examined whether lucid dreams contained four "corollaries" of lucidity:
Barrett found less than a quarter of lucidity accounts exhibited all four.

Subsequently, Stephen LaBerge studied the prevalence of being able to control the dream scenario among lucid dreams, and found that while dream control and dream awareness are correlated, neither requires the other. LaBerge found dreams that exhibit one clearly without the capacity for the other; also, in some dreams where the dreamer is lucid and aware they could exercise control, they choose simply to observe.

In 2016, a meta-analytic study by David Saunders and colleagues on 34 lucid dreaming studies, taken from a period of 50 years, demonstrated that 55% of a pooled sample of 24,282 people claimed to have experienced lucid dreams at least once or more in their lifetime. Furthermore, for those that stated they did experience lucid dreams, approximately 23% reported to experience them on a regular basis, as often as once a month or more. In a 2004 study on lucid dream frequency and personality, a moderate correlation between nightmare frequency and frequency of lucid dreaming was demonstrated. Some lucid dreamers also reported that nightmares are a trigger for dream lucidity. Previous studies have reported that lucid dreaming is more common among adolescents than adults.

A 2015 study showed that people who had practiced meditation for a long time tended to have more lucid dreams. Julian Mutz and Amir-Homayoun Javadi claimed that “Lucid dreaming is a hybrid state of consciousness with features of both waking and dreaming” in a review they published in Neuroscience of Consciousness in 2017.

Mutz and Javadi found that during lucid dreaming, there is an increase in activity of the dorsolateral prefrontal cortex, the bilateral frontopolar prefrontal cortex, the precuneus, the inferior parietal lobules, and the supramarginal gyrus. All are brain functions related to higher cognitive functions including working memory, planning, and self-consciousness. The researchers also found that during a lucid dream, “levels of self-determination" were similar to those that people experienced during states of wakefulness.  

They also found that lucid dreamers can only control limited aspects of their dream at once. However, it is still a mystery as to why lucid dreaming can sometimes turn ominous. According to Stumburys, about 7 percent of lucid dreams are lucid nightmares.

Mutz and Javadi also have stated that by studying lucid dreaming further, scientists could learn more about various types of consciousness, which happen to be less easy to separate and research at other times.

It has been suggested that those who suffer from nightmares could benefit from the ability to be aware they are indeed dreaming. A pilot study performed in 2006 showed that lucid dreaming therapy treatment was successful in reducing nightmare frequency. This treatment consisted of exposure to the idea, mastery of the technique, and lucidity exercises. It was not clear what aspects of the treatment were responsible for the success of overcoming nightmares, though the treatment as a whole was said to be successful.

Australian psychologist Milan Colic has explored the application of principles from narrative therapy to clients' lucid dreams, to reduce the impact not only of nightmares during sleep but also depression, self-mutilation, and other problems in waking life. Colic found that therapeutic conversations could reduce the distressing content of dreams, while understandings about life—and even characters—from lucid dreams could be applied to their lives with marked therapeutic benefits.

Psychotherapists have applied lucid dreaming as a part of therapy. Studies have shown that, by inducing a lucid dream, recurrent nightmares can be alleviated. It is unclear whether this alleviation is due to lucidity or the ability to alter the dream itself. A 2006 study performed by Victor Spoormaker and Van den Bout evaluated the validity of lucid dreaming treatment (LDT) in chronic nightmare sufferers. LDT is composed of exposure, mastery and lucidity exercises. Results of lucid dreaming treatment revealed that the nightmare frequency of the treatment groups had decreased. In another study, Spoormaker, Van den Bout, and Meijer (2003) investigated lucid dreaming treatment for nightmares by testing eight subjects who received a one-hour individual session, which consisted of lucid dreaming exercises. The results of the study revealed that the nightmare frequency had decreased and the sleep quality had slightly increased.

Holzinger, Klösch, and Saletu managed a psychotherapy study under the working name of ‘Cognition during dreaming – a therapeutic intervention in nightmares’, which included 40 subjects, men and women, 18–50 years old, whose life quality was significantly altered by nightmares. The test subjects were administered Gestalt group therapy and 24 of them were also taught to enter the state of lucid dreaming by Holzinger. This was purposefully taught in order to change the course of their nightmares. The subjects then reported the diminishment of their nightmare prevalence from 2–3 times a week to 2–3 times per month.

In her book "The Committee of Sleep", Deirdre Barrett describes how some experienced lucid dreamers have learned to remember specific practical goals such as artists looking for inspiration seeking a show of their own work once they become lucid or computer programmers looking for a screen with their desired code. However, most of these dreamers had many experiences of failing to recall waking objectives before gaining this level of control.

"Exploring the World of Lucid Dreaming" by Stephen LaBerge and Howard Rheingold (1990) discusses creativity within dreams and lucid dreams, including testimonials from a number of people who claim they have used the practice of lucid dreaming to help them solve a number of creative issues, from an aspiring parent thinking of potential baby names to a surgeon practicing surgical techniques. The authors discuss how creativity in dreams could stem from "conscious access to the contents of our unconscious minds"; access to "tacit knowledge" - the things we know but can't explain, or things we know but are unaware that we know.

Films like "Waking Life" (2001), "Paprika" (2006), "Inception" (2010), "Lucid Dream" (2017) and "118" (2019) refer to lucid dreaming.

Though lucid dreaming can be beneficial to a number of aspects of life, some risks have been suggested. Those who have never had a lucid dream may not understand what is happening when they experience it for the first time. Individuals who experience lucid dreams could begin to feel isolated from others due to feeling different. It could become more difficult over time to wake up from a lucid dream. Someone struggling with certain mental illnesses could find it hard to be able to tell the difference between reality and the actual dream.

Long term risks with lucid dreaming have not been extensively studied.

Some people experience something like sleep paralysis, which is a state in between dreaming and waking. One experiencing sleep paralysis from sleep can't move, is aware that they are awake, and yet still may be experiencing hallucinations from their dream. A report in the journal "Consciousness and Cognition" identifies three common types of hallucinations: an intruder in the room with you, a crushing feeling on your chest or back, and a feeling of flying or levitating. Sleep paralysis is uncommon, affecting anywhere between seven and 40 percent of people.


Notes


</doc>
<doc id="18288" url="https://en.wikipedia.org/wiki?curid=18288" title="Lyric">
Lyric

Lyric may refer to:




</doc>
<doc id="18290" url="https://en.wikipedia.org/wiki?curid=18290" title="Light-emitting diode">
Light-emitting diode

A light-emitting diode (LED) is a semiconductor light source that emits light when current flows through it. Electrons in the semiconductor recombine with electron holes, releasing energy in the form of photons. The color of the light (corresponding to the energy of the photons) is determined by the energy required for electrons to cross the band gap of the semiconductor. White light is obtained by using multiple semiconductors or a layer of light-emitting phosphor on the semiconductor device.

Appearing as practical electronic components in 1962, the earliest LEDs emitted low-intensity infrared light. Infrared LEDs are used in remote-control circuits, such as those used with a wide variety of consumer electronics. The first visible-light LEDs were of low intensity and limited to red. Modern LEDs are available across the visible, ultraviolet, and infrared wavelengths, with high light output.

Early LEDs were often used as indicator lamps, replacing small incandescent bulbs, and in seven-segment displays. Recent developments have produced high-output white light LEDs suitable for room and outdoor area lighting. LEDs have led to new displays and sensors, while their high switching rates are useful in advanced communications technology.

LEDs have many advantages over incandescent light sources, including lower energy consumption, longer lifetime, improved physical robustness, smaller size, and faster switching. LEDs are used in applications as diverse as aviation lighting, automotive headlamps, advertising, general lighting, traffic signals, camera flashes, lighted wallpaper, horticultural grow lights, and medical devices.

Unlike a laser, the light emitted from an LED is neither spectrally coherent nor even highly monochromatic. However, its spectrum is sufficiently narrow that it appears to the human eye as a pure (saturated) color. Nor, unlike most lasers, is its radiation spatially coherent, so that it cannot approach the very high brightnesses characteristic of lasers.

Electroluminescence as a phenomenon was discovered in 1907 by the British experimenter H. J. Round of Marconi Labs, using a crystal of silicon carbide and a cat's-whisker detector. Russian inventor Oleg Losev reported creation of the first LED in 1927. His research was distributed in Soviet, German and British scientific journals, but no practical use was made of the discovery for several decades.
In 1936, Georges Destriau observed that electroluminescence could be produced when zinc sulphide (ZnS) powder is suspended in an insulator and an alternating electrical field is applied to it. In his publications, Destriau often referred to luminescence as Losev-Light. Destriau worked in the laboratories of Madame Marie Curie, also an early pioneer in the field of luminescence with research on radium.

Hungarian Zoltán Bay together with György Szigeti pre-empted LED lighting in Hungary in 1939 by patenting a lighting device based on SiC, with an option on boron carbide, that emitted white, yellowish white, or greenish white depending on impurities present.

Kurt Lehovec, Carl Accardo, and Edward Jamgochian explained these first LEDs in 1951 using an apparatus employing SiC crystals with a current source of a battery or a pulse generator and with a comparison to a variant, pure, crystal in 1953.

Rubin Braunstein of the Radio Corporation of America reported on infrared emission from gallium arsenide (GaAs) and other semiconductor alloys in 1955. Braunstein observed infrared emission generated by simple diode structures using gallium antimonide (GaSb), GaAs, indium phosphide (InP), and silicon-germanium (SiGe) alloys at room temperature and at 77 kelvins.

In 1957, Braunstein further demonstrated that the rudimentary devices could be used for non-radio communication across a short distance. As noted by Kroemer Braunstein "…had set up a simple optical communications link: Music emerging from a record player was used via suitable electronics to modulate the forward current of a GaAs diode. The emitted light was detected by a PbS diode some distance away. This signal was fed into an audio amplifier and played back by a loudspeaker. Intercepting the beam stopped the music. We had a great deal of fun playing with this setup." This setup presaged the use of LEDs for optical communication applications.

In September 1961, while working at Texas Instruments in Dallas, Texas, James R. Biard and Gary Pittman discovered near-infrared (900 nm) light emission from a tunnel diode they had constructed on a GaAs substrate. By October 1961, they had demonstrated efficient light emission and signal coupling between a GaAs p-n junction light emitter and an electrically isolated semiconductor photodetector. On August 8, 1962, Biard and Pittman filed a patent titled "Semiconductor Radiant Diode" based on their findings, which described a zinc-diffused p–n junction LED with a spaced cathode contact to allow for efficient emission of infrared light under forward bias. After establishing the priority of their work based on engineering notebooks predating submissions from G.E. Labs, RCA Research Labs, IBM Research Labs, Bell Labs, and Lincoln Lab at MIT, the U.S. patent office issued the two inventors the patent for the GaAs infrared (IR) light-emitting diode (U.S. Patent US3293513), the first practical LED. Immediately after filing the patent, Texas Instruments (TI) began a project to manufacture infrared diodes. In October 1962, TI announced the first commercial LED product (the SNX-100), which employed a pure GaAs crystal to emit an 890 nm light output. In October 1963, TI announced the first commercial hemispherical LED, the SNX-110.

The first visible-spectrum (red) LED was developed in 1962 by Nick Holonyak, Jr. while working at General Electric. Holonyak first reported his LED in the journal "Applied Physics Letters" on December 1, 1962. M. George Craford, a former graduate student of Holonyak, invented the first yellow LED and improved the brightness of red and red-orange LEDs by a factor of ten in 1972. In 1976, T. P. Pearsall designed the first high-brightness, high-efficiency LEDs for optical fiber telecommunications by inventing new semiconductor materials specifically adapted to optical fiber transmission wavelengths.

The first commercial visible-wavelength LEDs were commonly used as replacements for incandescent and neon indicator lamps, and in seven-segment displays, first in expensive equipment such as laboratory and electronics test equipment, then later in such appliances as calculators, TVs, radios, telephones, as well as watches (see list of signal uses).
Until 1968, visible and infrared LEDs were extremely costly, in the order of US$200 per unit, and so had little practical use.

Hewlett-Packard (HP) was engaged in research and development (R&D) on practical LEDs between 1962 and 1968, by a research team under Howard C. Borden, Gerald P. Pighini and Mohamed M. Atalla at HP Associates and HP Labs. During this time, Atalla launched a material science investigation program on gallium arsenide (GaAs), gallium arsenide phosphide (GaAsP) and indium arsenide (InAs) devices at HP, and they collaborated with Monsanto Company on developing the first usable LED products. The first usable LED products were HP's LED display and Monsanto's LED indicator lamp, both launched in 1968. Monsanto was the first organization to mass-produce visible LEDs, using GaAsP in 1968 to produce red LEDs suitable for indicators. Monsanto had previously offered to supply HP with GaAsP, but HP decided to grow its own GaAsP. In February 1969, Hewlett-Packard introduced the HP Model 5082-7000 Numeric Indicator, the first LED device to use integrated circuit (integrated LED circuit) technology. It was the first intelligent LED display, and was a revolution in digital display technology, replacing the Nixie tube and becoming the basis for later LED displays.

Atalla left HP and joined Fairchild Semiconductor in 1969. He was the vice president and general manager of the Microwave & Optoelectronics division, from its inception in May 1969 up until November 1971. He continued his work on LEDs, proposing they could be used for indicator lights and optical readers in 1971. In the 1970s, commercially successful LED devices at less than five cents each were produced by Fairchild Optoelectronics. These devices employed compound semiconductor chips fabricated with the planar process (developed by Jean Hoerni, based on Atalla's surface passivation method). The combination of planar processing for chip fabrication and innovative packaging methods enabled the team at Fairchild led by optoelectronics pioneer Thomas Brandt to achieve the needed cost reductions. LED producers continue to use these methods.

The early red LEDs were bright enough only for use as indicators, as the light output was not enough to illuminate an area. Readouts in calculators were so small that plastic lenses were built over each digit to make them legible. Later, other colors became widely available and appeared in appliances and equipment.

Early LEDs were packaged in metal cases similar to those of transistors, with a glass window or lens to let the light out. Modern indicator LEDs are packed in transparent molded plastic cases, tubular or rectangular in shape, and often tinted to match the device color. Infrared devices may be dyed, to block visible light. More complex packages have been adapted for efficient heat dissipation in high-power LEDs. Surface-mounted LEDs further reduce the package size. LEDs intended for use with fiber optics cables may be provided with an optical connector.

The first blue-violet LED using magnesium-doped gallium nitride was made at Stanford University in 1972 by Herb Maruska and Wally Rhines, doctoral students in materials science and engineering. At the time Maruska was on leave from RCA Laboratories, where he collaborated with Jacques Pankove on related work. In 1971, the year after Maruska left for Stanford, his RCA colleagues Pankove and Ed Miller demonstrated the first blue electroluminescence from zinc-doped gallium nitride, though the subsequent device Pankove and Miller built, the first actual gallium nitride light-emitting diode, emitted green light. In 1974 the U.S. Patent Office awarded Maruska, Rhines and Stanford professor David Stevenson a patent for their work in 1972 (U.S. Patent US3819974 A). Today, magnesium-doping of gallium nitride remains the basis for all commercial blue LEDs and laser diodes. In the early 1970s, these devices were too dim for practical use, and research into gallium nitride devices slowed.

In August 1989, Cree introduced the first commercially available blue LED based on the indirect bandgap semiconductor, silicon carbide (SiC). SiC LEDs had very low efficiency, no more than about 0.03%, but did emit in the blue portion of the visible light spectrum.

In the late 1980s, key breakthroughs in GaN epitaxial growth and p-type doping ushered in the modern era of GaN-based optoelectronic devices. Building upon this foundation, Theodore Moustakas at Boston University patented a method for producing high-brightness blue LEDs using a new two-step process in 1991.

Two years later, in 1993, high-brightness blue LEDs were demonstrated by Shuji Nakamura of Nichia Corporation using a gallium nitride growth process. In parallel, Isamu Akasaki and Hiroshi Amano in Nagoya were working on developing the important GaN deposition on sapphire substrates and the demonstration of p-type doping of GaN. This new development revolutionized LED lighting, making high-power blue light sources practical, leading to the development of technologies like Blu-ray.

Nakamura was awarded the 2006 Millennium Technology Prize for his invention.
Nakamura, Hiroshi Amano and Isamu Akasaki were awarded the Nobel Prize in Physics in 2014 for the invention of the blue LED. In 2015, a US court ruled that three companies had infringed Moustakas's prior patent, and ordered them to pay licensing fees of not less than US$13 million.

In 1995, Alberto Barbieri at the Cardiff University Laboratory (GB) investigated the efficiency and reliability of high-brightness LEDs and demonstrated a "transparent contact" LED using indium tin oxide (ITO) on (AlGaInP/GaAs).

In 2001 and 2002, processes for growing gallium nitride (GaN) LEDs on silicon were successfully demonstrated. In January 2012, Osram demonstrated high-power InGaN LEDs grown on silicon substrates commercially, and GaN-on-silicon LEDs are in production at Plessey Semiconductors. As of 2017, some manufacturers are using SiC as the substrate for LED production, but sapphire is more common, as it has the most similar properties to that of gallium nitride, reducing the need for patterning the sapphire wafer (patterned wafers are known as epi wafers). Samsung, the University of Cambridge, and Toshiba are performing research into GaN on Si LEDs. Toshiba has stopped research, possibly due to low yields. Some opt towards epitaxy, which is difficult on silicon, while others, like the University of Cambridge, opt towards a multi-layer structure, in order to reduce (crystal) lattice mismatch and different thermal expansion ratios, in order to avoid cracking of the LED chip at high temperatures (e.g. during manufacturing), reduce heat generation and increase luminous efficiency. Epitaxy (or patterned sapphire) can be carried out with nanoimprint lithography. GaN is often deposited using Metalorganic vapour-phase epitaxy (MOCVD).

Even though white light can be created using individual red, green and blue LEDs, this results in poor color rendering, since only three narrow bands of wavelengths of light are being emitted. The attainment of high efficiency blue LEDs was quickly followed by the development of the first white LED. In this device a :Ce (known as "YAG" or Ce:YAG phosphor) cerium doped phosphor coating produces yellow light through fluorescence. The combination of that yellow with remaining blue light appears white to the eye. Using different phosphors produces green and red light through fluorescence. The resulting mixture of red, green and blue is perceived as white light, with improved color rendering compared to wavelengths from the blue LED/YAG phosphor combination.

The first white LEDs were expensive and inefficient. However, the light output of LEDs has increased exponentially. The latest research and development has been propagated by Japanese manufacturers such as Panasonic, and Nichia, and by Korean and Chinese manufacturers such as Samsung, Kingsun, and others. This trend in increased output has been called Haitz's law after Dr. Roland Haitz.

Light output and efficiency of blue and near-ultraviolet LEDs rose and the cost of reliable devices fell. This led to relatively high-power white-light LEDs for illumination, which are replacing incandescent and fluorescent lighting.

Experimental white LEDs have been demonstrated to produce 303 lumens per watt of electricity (lm/w); some can last up to 100,000 hours. However, commercially available LEDs have an efficiency of up to 223 lm/w. Compared to incandescent bulbs, this is not only a huge increase in electrical efficiency, and even though LEDs are more expensive to purchase, overall cost is significantly cheaper than that of incandescent bulbs.

The LED chip is encapsulated inside a small, plastic, white mold. It can be encapsulated using resin (polyurethane-based), silicone, or epoxy containing (powdered) Cerium doped YAG phosphor. After allowing the solvents to evaporate, the LEDs are often tested, and placed on tapes for SMT placement equipment for use in LED light bulb production. Encapsulation is performed after probing, dicing, die transfer from wafer to package, and wire bonding or flip chip mounting, perhaps using Indium tin oxide, a transparent electrical conductor. In this case, the bond wire(s) are attached to the ITO film that has been deposited in the LEDs.
Some "remote phosphor" LED light bulbs use a single plastic cover with YAG phosphor for several blue LEDs, instead of using phosphor coatings on single chip white LEDs.

In a light emitting diode, the recombination of electrons and electron holes in a semiconductor produces light (be it infrared, visible or UV), a process called "electroluminescence". The wavelength of the light depends on the energy band gap of the semiconductors used. Since these materials have a high index of refraction, design features of the devices such as special optical coatings and die shape are required to efficiently emit light.

By selection of different semiconductor materials, single-color LEDs can be made that emit light in a narrow band of wavelengths from near-infrared through the visible spectrum and into the ultraviolet range. As the wavelengths become shorter, because of the larger band gap of these semiconductors, the operating voltage of the LED increases. 

Blue LEDs have an active region consisting of one or more InGaN quantum wells sandwiched between thicker layers of GaN, called cladding layers. By varying the relative In/Ga fraction in the InGaN quantum wells, the light emission can in theory be varied from violet to amber.

Aluminium gallium nitride (AlGaN) of varying Al/Ga fraction can be used to manufacture the cladding and quantum well layers for ultraviolet LEDs, but these devices have not yet reached the level of efficiency and technological maturity of InGaN/GaN blue/green devices. If un-alloyed GaN is used in this case to form the active quantum well layers, the device emits near-ultraviolet light with a peak wavelength centred around 365 nm. Green LEDs manufactured from the InGaN/GaN system are far more efficient and brighter than green LEDs produced with non-nitride material systems, but practical devices still exhibit efficiency too low for high-brightness applications.

With AlGaN and AlGaInN, even shorter wavelengths are achievable. Near-UV emitters at wavelengths around 360–395 nm are already cheap and often encountered, for example, as black light lamp replacements for inspection of anti-counterfeiting UV watermarks in documents and bank notes, and for UV curing. While substantially more expensive, shorter-wavelength diodes are commercially available for wavelengths down to 240 nm. As the photosensitivity of microorganisms approximately matches the absorption spectrum of DNA, with a peak at about 260 nm, UV LED emitting at 250–270 nm are expected in prospective disinfection and sterilization devices. Recent research has shown that commercially available UVA LEDs (365 nm) are already effective disinfection and sterilization devices.
UV-C wavelengths were obtained in laboratories using aluminium nitride (210 nm), boron nitride (215 nm) and diamond (235 nm).

There are two primary ways of producing white light-emitting diodes. One is to use individual LEDs that emit three primary colors—red, green and blue—and then mix all the colors to form white light. The other is to use a phosphor material to convert monochromatic light from a blue or UV LED to broad-spectrum white light, similar to a fluorescent lamp. The yellow phosphor is cerium-doped YAG crystals suspended in the package or coated on the LED. This YAG phosphor causes white LEDs to look yellow when off.

The 'whiteness' of the light produced is engineered to suit the human eye. Because of metamerism, it is possible to have quite different spectra that appear white. However, the appearance of objects illuminated by that light may vary as the spectrum varies. This is the issue of color rendition, quite separate from color temperature. An orange or cyan object could appear with the wrong color and much darker as the LED or phosphor does not emit the wavelength it reflects. The best color rendition LEDs use a mix of phosphors, resulting in less efficiency but better color rendering.

Mixing red, green, and blue sources to produce white light needs electronic circuits to control the blending of the colors. Since LEDs have slightly different emission patterns, the color balance may change depending on the angle of view, even if the RGB sources are in a single package, so RGB diodes are seldom used to produce white lighting. Nonetheless, this method has many applications because of the flexibility of mixing different colors, and in principle, this mechanism also has higher quantum efficiency in producing white light.

There are several types of multicolor white LEDs: di-, tri-, and tetrachromatic white LEDs. Several key factors that play among these different methods include color stability, color rendering capability, and luminous efficacy. Often, higher efficiency means lower color rendering, presenting a trade-off between the luminous efficacy and color rendering. For example, the dichromatic white LEDs have the best luminous efficacy (120 lm/W), but the lowest color rendering capability. However, although tetrachromatic white LEDs have excellent color rendering capability, they often have poor luminous efficacy. Trichromatic white LEDs are in between, having both good luminous efficacy (>70 lm/W) and fair color rendering capability.

One of the challenges is the development of more efficient green LEDs. The theoretical maximum for green LEDs is 683 lumens per watt but as of 2010 few green LEDs exceed even 100 lumens per watt. The blue and red LEDs approach their theoretical limits.

Multicolor LEDs also offer a new means to form light of different colors. Most perceivable colors can be formed by mixing different amounts of three primary colors. This allows precise dynamic color control. However, this type of LED's emission power decays exponentially with rising temperature,
resulting in a substantial change in color stability. Such problems inhibit industrial use. Multicolor LEDs without phosphors cannot provide good color rendering because each LED is a narrowband source. LEDs without phosphor, while a poorer solution for general lighting, are the best solution for displays, either backlight of LCD, or direct LED based pixels.

Dimming a multicolor LED source to match the characteristics of incandescent lamps is difficult because manufacturing variations, age, and temperature change the actual color value output. To emulate the appearance of dimming incandescent lamps may require a feedback system with color sensor to actively monitor and control the color.

This method involves coating LEDs of one color (mostly blue LEDs made of InGaN) with phosphors of different colors to form white light; the resultant LEDs are called phosphor-based or phosphor-converted white LEDs (pcLEDs). A fraction of the blue light undergoes the Stokes shift, which transforms it from shorter wavelengths to longer. Depending on the original LED's color, various color phosphors are used. Using several phosphor layers of distinct colors broadens the emitted spectrum, effectively raising the color rendering index (CRI).

Phosphor-based LEDs have efficiency losses due to heat loss from the Stokes shift and also other phosphor-related issues. Their luminous efficacies compared to normal LEDs depend on the spectral distribution of the resultant light output and the original wavelength of the LED itself. For example, the luminous efficacy of a typical YAG yellow phosphor based white LED ranges from 3 to 5 times the luminous efficacy of the original blue LED because of the human eye's greater sensitivity to yellow than to blue (as modeled in the luminosity function). Due to the simplicity of manufacturing, the phosphor method is still the most popular method for making high-intensity white LEDs. The design and production of a light source or light fixture using a monochrome emitter with phosphor conversion is simpler and cheaper than a complex RGB system, and the majority of high-intensity white LEDs presently on the market are manufactured using phosphor light conversion.

Among the challenges being faced to improve the efficiency of LED-based white light sources is the development of more efficient phosphors. As of 2010, the most efficient yellow phosphor is still the YAG phosphor, with less than 10% Stokes shift loss. Losses attributable to internal optical losses due to re-absorption in the LED chip and in the LED packaging itself account typically for another 10% to 30% of efficiency loss. Currently, in the area of phosphor LED development, much effort is being spent on optimizing these devices to higher light output and higher operation temperatures. For instance, the efficiency can be raised by adapting better package design or by using a more suitable type of phosphor. Conformal coating process is frequently used to address the issue of varying phosphor thickness.

Some phosphor-based white LEDs encapsulate InGaN blue LEDs inside phosphor-coated epoxy. Alternatively, the LED might be paired with a remote phosphor, a preformed polycarbonate piece coated with the phosphor material. Remote phosphors provide more diffuse light, which is desirable for many applications. Remote phosphor designs are also more tolerant of variations in the LED emissions spectrum. A common yellow phosphor material is cerium-doped yttrium aluminium garnet (Ce:YAG).

White LEDs can also be made by coating near-ultraviolet (NUV) LEDs with a mixture of high-efficiency europium-based phosphors that emit red and blue, plus copper and aluminium-doped zinc sulfide (ZnS:Cu, Al) that emits green. This is a method analogous to the way fluorescent lamps work. This method is less efficient than blue LEDs with YAG:Ce phosphor, as the Stokes shift is larger, so more energy is converted to heat, but yields light with better spectral characteristics, which render color better. Due to the higher radiative output of the ultraviolet LEDs than of the blue ones, both methods offer comparable brightness. A concern is that UV light may leak from a malfunctioning light source and cause harm to human eyes or skin.

Another method used to produce experimental white light LEDs used no phosphors at all and was based on homoepitaxially grown zinc selenide (ZnSe) on a ZnSe substrate that simultaneously emitted blue light from its active region and yellow light from the substrate.

A new style of wafers composed of gallium-nitride-on-silicon (GaN-on-Si) is being used to produce white LEDs using 200-mm silicon wafers. This avoids the typical costly sapphire substrate in relatively small 100- or 150-mm wafer sizes. The sapphire apparatus must be coupled with a mirror-like collector to reflect light that would otherwise be wasted. It was predicted that since 2020, 40% of all GaN LEDs are made with GaN-on-Si. Manufacturing large sapphire material is difficult, while large silicon material is cheaper and more abundant. LED companies shifting from using sapphire to silicon should be a minimal investment.

In an organic light-emitting diode (OLED), the electroluminescent material composing the emissive layer of the diode is an organic compound. The organic material is electrically conductive due to the delocalization of pi electrons caused by conjugation over all or part of the molecule, and the material therefore functions as an organic semiconductor. The organic materials can be small organic molecules in a crystalline phase, or polymers.

The potential advantages of OLEDs include thin, low-cost displays with a low driving voltage, wide viewing angle, and high contrast and color gamut. Polymer LEDs have the added benefit of printable and flexible displays. OLEDs have been used to make visual displays for portable electronic devices such as cellphones, digital cameras, and MP3 players while possible future uses include lighting and televisions.

LEDs are made in different packages for different applications. A single or a few LED junctions may be packed in one miniature device for use as an indicator or pilot lamp. An LED array may include controlling circuits within the same package, which may range from a simple resistor, blinking or color changing control, or an addressable controller for RGB devices. Higher-powered white-emitting devices will be mounted on heat sinks and will be used for illumination. Alphanumeric displays in dot matrix or bar formats are widely available. Special packages permit connection of LEDs to optical fibers for high-speed data communication links.

These are mostly single-die LEDs used as indicators, and they come in various sizes from 2 mm to 8 mm, through-hole and surface mount packages. Typical current ratings range from around 1 mA to above 20 mA. Multiple LED dies attached to a flexible backing tape form an LED strip light.

Common package shapes include round, with a domed or flat top, rectangular with a flat top (as used in bar-graph displays), and triangular or square with a flat top. The encapsulation may also be clear or tinted to improve contrast and viewing angle. Infrared devices may have a black tint to block visible light while passing infrared radiation.

Ultra-high-output LEDs are designed for viewing in direct sunlight

5 V and 12 V LEDs are ordinary miniature LEDs that have a series resistor for direct connection to a 5 V or 12 V supply.

High-power LEDs (HP-LEDs) or high-output LEDs (HO-LEDs) can be driven at currents from hundreds of mA to more than an ampere, compared with the tens of mA for other LEDs. Some can emit over a thousand lumens. LED power densities up to 300 W/cm have been achieved. Since overheating is destructive, the HP-LEDs must be mounted on a heat sink to allow for heat dissipation. If the heat from an HP-LED is not removed, the device fails in seconds. One HP-LED can often replace an incandescent bulb in a flashlight, or be set in an array to form a powerful LED lamp.

Some well-known HP-LEDs in this category are the Nichia 19 series, Lumileds Rebel Led, Osram Opto Semiconductors Golden Dragon, and Cree X-lamp. As of September 2009, some HP-LEDs manufactured by Cree now exceed 105 lm/W.

Examples for Haitz's law—which predicts an exponential rise in light output and efficacy of LEDs over time—are the CREE XP-G series LED, which achieved 105 lm/W in 2009 and the Nichia 19 series with a typical efficacy of 140 lm/W, released in 2010.

LEDs developed by Seoul Semiconductor can operate on AC power without a DC converter. For each half-cycle, part of the LED emits light and part is dark, and this is reversed during the next half-cycle. The efficacy of this type of HP-LED is typically 40 lm/W. A large number of LED elements in series may be able to operate directly from line voltage. In 2009, Seoul Semiconductor released a high DC voltage LED, named as 'Acrich MJT', capable of being driven from AC power with a simple controlling circuit. The low-power dissipation of these LEDs affords them more flexibility than the original AC LED design.

Flashing LEDs are used as attention seeking indicators without requiring external electronics. Flashing LEDs resemble standard LEDs but they contain an integrated multivibrator circuit that causes the LED to flash with a typical period of one second. In diffused lens LEDs, this circuit is visible as a small black dot. Most flashing LEDs emit light of one color, but more sophisticated devices can flash between multiple colors and even fade through a color sequence using RGB color mixing.

Bi-color LEDs contain two different LED emitters in one case. There are two types of these. One type consists of two dies connected to the same two leads antiparallel to each other. Current flow in one direction emits one color, and current in the opposite direction emits the other color. The other type consists of two dies with separate leads for both dies and another lead for common anode or cathode so that they can be controlled independently. The most common bi-color combination is red/traditional green, however, other available combinations include amber/traditional green, red/pure green, red/blue, and blue/pure green.

Tri-color LEDs contain three different LED emitters in one case. Each emitter is connected to a separate lead so they can be controlled independently. A four-lead arrangement is typical with one common lead (anode or cathode) and an additional lead for each color. Others, however, have only two leads (positive and negative) and have a built-in electronic controller. 
RGB LEDs consist of one red, one green, and one blue LED. By independently adjusting each of the three, RGB LEDs are capable of producing a wide color gamut. Unlike dedicated-color LEDs, however, these do not produce pure wavelengths. Modules may not be optimized for smooth color mixing.

Decorative-multicolor LEDs incorporate several emitters of different colors supplied by only two lead-out wires. Colors are switched internally by varying the supply voltage.

Alphanumeric LEDs are available in seven-segment, starburst, and dot-matrix format. Seven-segment displays handle all numbers and a limited set of letters. Starburst displays can display all letters. Dot-matrix displays typically use 5x7 pixels per character. Seven-segment LED displays were in widespread use in the 1970s and 1980s, but rising use of liquid crystal displays, with their lower power needs and greater display flexibility, has reduced the popularity of numeric and alphanumeric LED displays.

Digital RGB addressable LEDs contain their own "smart" control electronics. In addition to power and ground, these provide connections for data-in, data-out, and sometimes a clock or strobe signal. These are connected in a daisy chain. Data sent to the first LED of the chain can control the brightness and color of each LED independently of the others. They are used where a combination of maximum control and minimum visible electronics are needed such as strings for Christmas and LED matrices. Some even have refresh rates in the kHz range, allowing for basic video applications. These devices are known by their part number (WS2812 being common) or a brand name such as NeoPixel.

An LED filament consists of multiple LED chips connected in series on a common longitudinal substrate that forms a thin rod reminiscent of a traditional incandescent filament. These are being used as a low-cost decorative alternative for traditional light bulbs that are being phased out in many countries. The filaments use a rather high voltage, allowing them to work efficiently with mains voltages. Often a simple rectifier and capacitive current limiting are employed to create a low-cost replacement for a traditional light bulb without the complexity of the low voltage, high current converter that single die LEDs need. Usually, they are packaged in bulb similar to the lamps they were designed to replace, and filled with inert gas to remove heat efficiently.

Surface-mounted LEDs are frequently produced in chip on board (COB) arrays, allowing better heat dissipation than with a single LED of comparable luminous output. The LEDs can be arranged around a cylinder, and are called "corn cob lights" because of the rows of yellow LEDs.

The current in an LED or other diodes rises exponentially with the applied voltage (see Shockley diode equation), so a small change in voltage can cause a large change in current. Current through the LED must be regulated by an external circuit such as a constant current source to prevent damage. Since most common power supplies are (nearly) constant-voltage sources, LED fixtures must include a power converter, or at least a current-limiting resistor. In some applications, the internal resistance of small batteries is sufficient to keep current within the LED rating.

An LED will light only when voltage is applied in the forward direction of the diode. No current flows and no light is emitted if voltage is applied in the reverse direction. If the reverse voltage exceeds the breakdown voltage, a large current flows and the LED will be damaged. If the reverse current is sufficiently limited to avoid damage, the reverse-conducting LED is a useful noise diode.

Certain blue LEDs and cool-white LEDs can exceed safe limits of the so-called blue-light hazard as defined in eye safety specifications such as "ANSI/IESNA RP-27.1–05: Recommended Practice for Photobiological Safety for Lamp and Lamp Systems". One study showed no evidence of a risk in normal use at domestic illuminance, and that caution is only needed for particular occupational situations or for specific populations. In 2006, the International Electrotechnical Commission published "IEC 62471 Photobiological safety of lamps and lamp systems", replacing the application of early laser-oriented standards for classification of LED sources.

While LEDs have the advantage over fluorescent lamps, in that they do not contain mercury, they may contain other hazardous metals such as lead and arsenic.

In 2016 the American Medical Association (AMA) issued a statement concerning the possible adverse influence of blueish street lighting on the sleep-wake cycle of city-dwellers. Industry critics claim exposure levels are not high enough to have a noticeable effect.



LED uses fall into four major categories:


The low energy consumption, low maintenance and small size of LEDs has led to uses as status indicators and displays on a variety of equipment and installations. Large-area LED displays are used as stadium displays, dynamic decorative displays, and dynamic message signs on freeways. Thin, lightweight message displays are used at airports and railway stations, and as destination displays for trains, buses, trams, and ferries.

One-color light is well suited for traffic lights and signals, exit signs, emergency vehicle lighting, ships' navigation lights, and LED-based Christmas lights

Because of their long life, fast switching times, and visibility in broad daylight due to their high output and focus, LEDs have been used in automotive brake lights and turn signals. The use in brakes improves safety, due to a great reduction in the time needed to light fully, or faster rise time, about 0.1 second faster than an incandescent bulb. This gives drivers behind more time to react. In a dual intensity circuit (rear markers and brakes) if the LEDs are not pulsed at a fast enough frequency, they can create a phantom array, where ghost images of the LED appear if the eyes quickly scan across the array. White LED headlamps are beginning to appear. Using LEDs has styling advantages because LEDs can form much thinner lights than incandescent lamps with parabolic reflectors.

Due to the relative cheapness of low output LEDs, they are also used in many temporary uses such as glowsticks, throwies, and the photonic textile Lumalive. Artists have also used LEDs for LED art.

With the development of high-efficiency and high-power LEDs, it has become possible to use LEDs in lighting and illumination. To encourage the shift to LED lamps and other high-efficiency lighting,in 2008 the US Department of Energy created the L Prize competition. The Philips Lighting North America LED bulb won the first competition on August 3, 2011, after successfully completing 18 months of intensive field, lab, and product testing.

Efficient lighting is needed for sustainable architecture. As of 2011, some LED bulbs provide up to 150 lm/W and even inexpensive low-end models typically exceed 50 lm/W, so that a 6-watt LED could achieve the same results as a standard 40-watt incandescent bulb. The lower heat output of LEDs also reduces demand on air conditioning systems. Worldwide, LEDs are rapidly adopted to displace less effective sources such as incandescent lamps and CFLs and reduce electrical energy consumption and its associated emissions. Solar powered LEDs are used as street lights and in architectural lighting.

The mechanical robustness and long lifetime are used in automotive lighting on cars, motorcycles, and bicycle lights. LED street lights are employed on poles and in parking garages. In 2007, the Italian village of Torraca was the first place to convert its street lighting to LEDs.

Cabin lighting on recent Airbus and Boeing jetliners uses LED lighting. LEDs are also being used in airport and heliport lighting. LED airport fixtures currently include medium-intensity runway lights, runway centerline lights, taxiway centerline and edge lights, guidance signs, and obstruction lighting.

LEDs are also used as a light source for DLP projectors, and to backlight LCD televisions (referred to as LED TVs) and laptop displays. RGB LEDs raise the color gamut by as much as 45%. Screens for TV and computer displays can be made thinner using LEDs for backlighting.

LEDs are small, durable and need little power, so they are used in handheld devices such as flashlights. LED strobe lights or camera flashes operate at a safe, low voltage, instead of the 250+ volts commonly found in xenon flashlamp-based lighting. This is especially useful in cameras on mobile phones, where space is at a premium and bulky voltage-raising circuitry is undesirable.

LEDs are used for infrared illumination in night vision uses including security cameras. A ring of LEDs around a video camera, aimed forward into a retroreflective background, allows chroma keying in video productions.

LEDs are used in mining operations, as cap lamps to provide light for miners. Research has been done to improve LEDs for mining, to reduce glare and to increase illumination, reducing risk of injury to the miners.

LEDs are increasingly finding uses in medical and educational applications, for example as mood enhancement. NASA has even sponsored research for the use of LEDs to promote health for astronauts.

Light can be used to transmit data and analog signals. For example, lighting white LEDs can be used in systems assisting people to navigate in closed spaces while searching necessary rooms or objects.

Assistive listening devices in many theaters and similar spaces use arrays of infrared LEDs to send sound to listeners' receivers. Light-emitting diodes (as well as semiconductor lasers) are used to send data over many types of fiber optic cable, from digital audio over TOSLINK cables to the very high bandwidth fiber links that form the Internet backbone. For some time, computers were commonly equipped with IrDA interfaces, which allowed them to send and receive data to nearby machines via infrared.

Because LEDs can cycle on and off millions of times per second, very high data bandwidth can be achieved.

Machine vision systems often require bright and homogeneous illumination, so features of interest are easier to process. LEDs are often used.

Barcode scanners are the most common example of machine vision applications, and many of those scanners use red LEDs instead of lasers. Optical computer mice use LEDs as a light source for the miniature camera within the mouse.

LEDs are useful for machine vision because they provide a compact, reliable source of light. LED lamps can be turned on and off to suit the needs of the vision system, and the shape of the beam produced can be tailored to match the systems's requirements.

The discovery of radiative recombination in Aluminum Gallium Nitride (AlGaN) alloys by U.S. Army Research Laboratory (ARL) led to the conceptualization of Ultra Violet (UV) light emitting diodes (LEDs) to be incorporated in light induced fluorescence sensors used for biological agent detection. In 2004, the Edgewood Chemical Biological Center (ECBC) initiated the effort to create a biological detector named TAC-BIO. The program capitalized on Semiconductor UV Optical Sources (SUVOS) developed by the Defense Advanced Research Projects Agency (DARPA).

UV induced fluorescence is one of the most robust techniques used for rapid real time detection of biological aerosols. The first UV sensors were lasers lacking in-field-use practicality. In order to address this, DARPA incorporated SUVOS technology to create a low cost, small, lightweight, low power device. The TAC-BIO detector's response time was one minute from when it sensed a biological agent. It was also demonstrated that the detector could be operated unattended indoors and outdoors for weeks at a time.

Aerosolized biological particles will fluoresce and scatter light under a UV light beam. Observed fluorescence is dependent on the applied wavelength and the biochemical fluorophores within the biological agent. UV induced fluorescence offers a rapid, accurate, efficient and logistically practical way for biological agent detection. This is because the use of UV fluorescence is reagent less, or a process that does not require an added chemical to produce a reaction, with no consumables, or produces no chemical byproducts.

Additionally, TAC-BIO can reliably discriminate between threat and non-threat aerosols. It was claimed to be sensitive enough to detect low concentrations, but not so sensitive that it would cause false positives. The particle counting algorithm used in the device converted raw data into information by counting the photon pulses per unit of time from the fluorescence and scattering detectors, and comparing the value to a set threshold.

The original TAC-BIO was introduced in 2010, while the second generation TAC-BIO GEN II, was designed in 2015 to be more cost efficient as plastic parts were used. It's small, light-weight design allows it to be mounted to vehicles, robots, and unmanned aerial vehicles. The second generation device could also be utilized as an environmental detector to monitor air quality in hospitals, airplanes, or even in households to detect fungus and mold.

The light from LEDs can be modulated very quickly so they are used extensively in optical fiber and free space optics communications. This includes remote controls, such as for television sets, where infrared LEDs are often used. Opto-isolators use an LED combined with a photodiode or phototransistor to provide a signal path with electrical isolation between two circuits. This is especially useful in medical equipment where the signals from a low-voltage sensor circuit (usually battery-powered) in contact with a living organism must be electrically isolated from any possible electrical failure in a recording or monitoring device operating at potentially dangerous voltages. An optoisolator also lets information be transferred between circuits that don't share a common ground potential.

Many sensor systems rely on light as the signal source. LEDs are often ideal as a light source due to the requirements of the sensors. The Nintendo Wii's sensor bar uses infrared LEDs. Pulse oximeters use them for measuring oxygen saturation. Some flatbed scanners use arrays of RGB LEDs rather than the typical cold-cathode fluorescent lamp as the light source. Having independent control of three illuminated colors allows the scanner to calibrate itself for more accurate color balance, and there is no need for warm-up. Further, its sensors only need be monochromatic, since at any one time the page being scanned is only lit by one color of light.

Since LEDs can also be used as photodiodes, they can be used for both photo emission and detection. This could be used, for example, in a touchscreen that registers reflected light from a finger or stylus. Many materials and biological systems are sensitive to, or dependent on, light. Grow lights use LEDs to increase photosynthesis in plants, and bacteria and viruses can be removed from water and other substances using UV LEDs for sterilization.

Deep UV LEDs, with a spectra range 247 nm to 386 nm, have other applications, such as water/air purification, surface disinfection, epoxy curing, free-space nonline-of-sight communication, high performance liquid chromatography, UV curing and printing, phototherapy, medical/ analytical instrumentation, and DNA absorption.

LEDs have also been used as a medium-quality voltage reference in electronic circuits. The forward voltage drop (about 1.7 V for a red LED or 1.2V for an infrared) can be used instead of a Zener diode in low-voltage regulators. Red LEDs have the flattest I/V curve above the knee. Nitride-based LEDs have a fairly steep I/V curve and are useless for this purpose. Although LED forward voltage is far more current-dependent than a Zener diode, Zener diodes with breakdown voltages below 3 V are not widely available.

The progressive miniaturization of low-voltage lighting technology, such as LEDs and OLEDs, suitable to incorporate into low-thickness materials has fostered experimentation in combining light sources and wall covering surfaces for interior walls in the form of LED wallpaper.

LEDs require optimized efficiency to hinge on ongoing improvements such as phosphor materials and quantum dots.

The process of down-conversion (the method by which materials convert more-energetic photons to different, less energetic colors) also needs improvement. For example, the red phosphors that are used today are thermally sensitive and need to be improved in that aspect so that they do not color shift and experience efficiency drop-off with temperature. Red phosphors could also benefit from a narrower spectral width to emit more lumens and becoming more efficient at converting photons.

In addition, work remains to be done in the realms of current efficiency droop, color shift, system reliability, light distribution, dimming, thermal management, and power supply performance.

A new family of LEDs are based on the semiconductors called perovskites. In 2018, less than four years after their discovery, the ability of perovskite LEDs (PLEDs) to produce light from electrons already rivaled those of the best performing OLEDs. They have a potential for cost-effectiveness as they can be processed from solution, a low-cost and low-tech method, which might allow perovskite-based devices that have large areas to be made with extremely low cost. Their efficiency is superior by eliminating non-radiative losses, in other words, elimination of recombination pathways that do not produce photons; or by solving outcoupling problem (prevalent for thin-film LEDs) or balancing charge carrier injection to increase the EQE (external quantum efficiency). The most up-to-date PLED devices have broken the performance barrier by shooting the EQE above 20%.

In 2018, Cao et al. and Lin et al. independently published two papers on developing perovskite LEDs with EQE greater than 20%, which made these two papers a mile-stone in PLED development. Their device have similar planar structure, i.e. the active layer (perovskite) is sandwiched between two electrodes. To achieve a high EQE, they not only reduced non-radiative recombination, but also utilized their own, subtly different methods to improve the EQE.

In Cao and his colleagues' work, they targeted to solve the outcoupling problem, which is that the optical physics of thin-film LEDs causes the majority of light generated by the semiconductor to be trapped in the device. To achieve this goal, they demonstrated that solution-processed perovskites can spontaneously form submicrometre-scale crystal platelets, which can efficiently extract light from the device. These perovskites are formed simply by introducing amino-acif additives into the perovskite precursor solutions. In addition, their method is able to passivate perovskite surface defects and reduce nonradiative recombination. Therefore, by improving the light outcoupling and reducing nonradiative losses, Cao and his colleagues successfully achieved PLED with EQE up to 20.7%. 

In Lin and his colleague's work, however, they used a different approach to generate high EQE. Instead of modifying the microstructure of perovskite layer, they chose to adopt a new strategy for managing the compositional distribution in the device——an approach that simultaneously provides high luminescence and balanced charge injection. In other words, they still used flat emissive layer, but tried to optimize the balance of electrons and holes injected into the perovskite, so as to make the most efficient use of the charge carriers. Moreover, in the perovskite layer, the crystals are perfectly enclosed by MABr additive (where MA is CHNH). The MABr shell passivates the nonradiative defects that would otherwise be present perovskite crystals, resulting in reduction of the nonradiative recombination. Therefore, by balancing charge injection and decreasing nonradiative losses, Lin and his colleagues developed PLED with EQE up to 20.3%. 

Devices called "nanorods" are a form of LEDs that can also detect and absorb light. They consist of a quantum dot directly contacting two semiconductor materials (instead of just one as in a traditional LED). One semiconductor allows movement of positive charge and one allows movement of negative charge. They can emit light, sense light, and collect energy. The nanorod gathers electrons while the quantum dot shell gathers positive charges so the dot emits light. When the voltage is switched the opposite process occurs and the dot absorbs light. By 2017 the only color developed was red.



</doc>
<doc id="18291" url="https://en.wikipedia.org/wiki?curid=18291" title="Luxembourgish">
Luxembourgish

Luxembourgish, Luxemburgish ( ), Letzeburgesch ( or ) (Luxembourgish: ), or Luxembourgian is a West Germanic language that is spoken mainly in Luxembourg. About 390,000 people speak Luxembourgish worldwide.

As a standard form of the Moselle Franconian language, Luxembourgish has similarities with other varieties of High German and the wider group of West Germanic languages. The status of Luxembourgish as an official language in Luxembourg and the existence there of a regulatory body, has removed Luxembourgish, at least in part, from the domain of Standard German, its traditional .

Luxembourgish belongs to the West Central German group of High German languages and is the primary example of a Moselle Franconian language.

Luxembourgish is the national language of Luxembourg and one of three administrative languages, alongside French and German.

In Luxembourg, 50.9% of citizens can speak Luxembourgish. Luxembourgish is also spoken in the Arelerland region of Belgium (part of the Province of Luxembourg) and in small parts of Lorraine in France. 

In the German Eifel and Hunsrück regions, similar local Moselle Franconian dialects of German are spoken. The language is also spoken by a few descendants of Luxembourg immigrants in the United States and Canada.

Other Moselle Franconian dialects are spoken by ethnic Germans long settled in Transylvania, Romania (Siebenbürgen).

Moselle Franconian dialects outside the Luxembourg state border tend to have far fewer French loan words, and these mostly remain from the French Revolution.

There are several distinct dialect forms of Luxembourgish including Areler (from Arlon), Eechternoacher (Echternach), Kliärrwer (Clervaux), Miseler (Moselle), Stater (Luxembourg), Veiner (Vianden), Minetter (Southern Luxembourg) and Weelzer (Wiltz). Further small vocabulary differences may be seen even between small villages.

Increasing mobility of the population and the dissemination of the language through mass media such as radio and television are leading to a gradual standardisation towards a "Standard Luxembourgish" through the process of koineization.

There is no distinct geographic boundary between the use of Luxembourgish and the use of other closely related High German dialects (for example Lorraine Franconian); it instead forms a dialect continuum of gradual change.

Spoken Luxembourgish is relatively hard to understand for speakers of German who are generally not familiar with Moselle Franconian dialects (or at least other West Central German dialects). However, they can usually read the language to some degree. For those Germans familiar with Moselle Franconian dialects, it is relatively easy to understand and speak Luxembourgish as far as the everyday vocabulary is concerned. However, the large number of French loanwords in Luxembourgish may hamper communication about certain topics, or with certain speakers (who use many French loanwords).

There is no intelligibility between Luxembourgish and French or any of the Romance dialects spoken in the adjacent parts of Belgium and France.

Erna Hennicot-Schoepges, President of the Christian Social People's Party of Luxembourg 1995–2003, was active in promoting the language beyond Luxembourg's borders.

A number of proposals for standardising the orthography of Luxembourgish can be documented, going back to the middle of the 19th century. There was no officially recognised system, however, until the adoption of the "OLO" ("ofizjel lezebuurjer ortografi") on 5 June 1946. This orthography provided a system for speakers of all varieties of Luxembourgish to transcribe words the way they pronounced them, rather than imposing a single, standard spelling for the words of the language. The rules explicitly rejected certain elements of German orthography (e.g., the use of "ä" and "ö", the capitalisation of nouns). Similarly, new principles were adopted for the spelling of French loanwords.
This proposed orthography, so different from existing "foreign" standards that people were already familiar with, did not enjoy widespread approval.

A more successful standard eventually emerged from the work of the committee of specialists charged with the task of creating the "Luxemburger Wörterbuch", published in 5 volumes between 1950 and 1977. The orthographic conventions adopted in this decades-long project, set out in Bruch (1955), provided the basis of the standard orthography that became official on 10 October 1975. Modifications to this standard were proposed by the "Permanent Council of the Luxembourguish language" and adopted officially in the spelling reform of 30 July 1999. A detailed explanation of current practice for Luxembourgish can be found in Schanen & Lulling (2003).

The Luxembourgish alphabet consists of the 26 Latin letters plus three letters with diacritics: "é", "ä", and "ë". In loanwords from French and Standard German, other diacritics are usually preserved:

Like many other varieties of Western High German, Luxembourgish has a rule of final "n"-deletion in certain contexts. The effects of this rule (known as the "Eifel Rule") are indicated in writing, and therefore must be taken into account when spelling words and morphemes ending in or . For example:

The consonant inventory of Luxembourgish is quite similar to that of Standard German.




Luxembourgish has three genders (masculine, feminine, and neuter), and has three cases (nominative, accusative, and dative). These are marked morphologically on determiners and pronouns. As in German, there is no morphological gender distinction in the plural.
The forms of the articles and of some selected determiners are given below:
As seen above, Luxembourgish has plural forms of "en" ("a, an"), namely "eng" in the nominative/accusative and "engen" in the dative. They are not used as indefinite articles, which—as in German and English—do not exist in the plural, but they do occur in the compound pronouns "wéi en" ("what, which") and "sou en" ("such"). For example: "wéi eng Saachen" ("what things"); "sou eng Saachen" ("such things"). Moreover, they are used before numbers to express an estimation: "eng 30.000 Spectateuren" ("some 30,000 spectators").

Distinct nominative forms survive in a few nominal phrases such as "der Däiwel" ("the devil") and "eiser Herrgott" ("our Lord"). Rare examples of the genitive are also found: "Enn des Mounts" ("end of the month"), "Ufanks der Woch" ("at the beginning of the week"). The functions of the genitive are normally expressed using a combination of the dative and a possessive determiner: e.g. "dem Mann säi Buch" (lit. "to the man his book", i.e. "the man's book"). This is known as a periphrastic genitive, and is a phenomenon also commonly seen in dialectal and colloquial German, and in Dutch.

The forms of the personal pronouns are given in the following table (unstressed forms appear in parentheses):

The 2pl form is also used as a polite singular (like French "vous", see T-V distinction); the forms are capitalised in writing:

Like most varieties of colloquial German, but even more invariably, Luxembourgish uses definite articles with personal names. They are obligatory and not to be translated:

A feature Luxembourgish shares with only some western dialects of German is that women and girls are most often referred to with forms of the "neuter" pronoun "hatt":

Luxembourgish morphology distinguishes two types of adjective: attributive and predicative. Predicative adjectives appear with verbs like "sinn" ("to be"), and receive no extra ending:

Attributive adjectives are placed before the noun they describe, and change their ending according to the grammatical gender, number, and case:

Curiously, the definite article changes with the use of an attributive adjective: feminine "d<nowiki>'</nowiki>" goes to "déi" (or "di"), neuter "d<nowiki>'</nowiki>" goes to "dat", and plural "d<nowiki>'</nowiki>" changes to "déi".

The comparative in Luxembourgish is formed analytically, i.e. the adjective itself is not altered (compare the use of -"er" in German and English; "tall" → "taller", "klein" → "kleiner"). Instead it is formed using the adverb "méi": e.g. "schéin" → "méi schéin"

The superlative involves a synthetic form consisting of the adjective and the suffix "-st": e.g. "schéin" → "schéinst " (compare German "schönst", English "prettiest"). Attributive modification requires the emphatic definite article and the inflected superlative adjective:

Predicative modification uses either the same adjectival structure or the adverbial structure "am"+ -"sten": e.g. "schéin" → "am schéinsten":

Some common adjectives have exceptional comparative and superlative forms:

Several other adjectives also have comparative forms. However, these are not commonly used as normal comparatives, but in special senses:

Luxembourgish exhibits "verb second" word order in clauses. More specifically, Luxembourgish is a V2-SOV language, like German and Dutch. In other words, we find the following finite clausal structures:

Non-finite verbs (infinitives and participles) generally appear in final position:

These rules interact so that in subordinate clauses, the finite verb and any non-finite verbs must all cluster at the end. Luxembourgish allows different word orders in these cases:
This is also the case when two non-finite verb forms occur together:

Luxembourgish (like Dutch and German) allows prepositional phrases to appear after the verb cluster in subordinate clauses:

Luxembourgish has borrowed many French words. For example, the name for a bus driver is "Buschauffeur" (also Dutch and Swiss German), which would be "Busfahrer" in German and "chauffeur de bus" in French.

Some words are different from Standard German but have equivalents in German dialects. An example is "Gromperen" (potatoes – German: "Kartoffeln"). Other words are exclusive to Luxembourgish.

"Note: Words spoken in sound clip do not reflect all words on this list."
Neologisms in Luxembourgish include both entirely new words, and the attachment of new meanings to old words in everyday speech. The most recent neologisms come from the English language in the fields of telecommunications, computer science, and the Internet.

Recent neologisms in Luxembourgish include:

Between 2000 and 2002, Luxembourgish linguist Jérôme Lulling compiled a lexical database of 125,000 word forms as the basis for the very first Luxembourgish spellchecker (Projet C.ORT.IN.A).

The LaF ("Lëtzebuergesch als Friemsprooch" – Luxembourgish as a Foreign Language) is a set of four language proficiency certifications for Luxembourgish and follows the ALTE framework of language examination standards. The tests are administered by the Institut National des Langues Luxembourg.

The "Centre for Luxembourg Studies" at the University of Sheffield was founded in 1995 on the initiative of Professor Gerald Newton. It is supported by the government of Luxembourg which funds an endowed chair in Luxembourg Studies at the university.
The first class of students to study the language outside of the country as undergraduate students began their studies at the 'Centre for Luxembourg Studies' at Sheffield in the academic year 2011–2012.


In English

In French

In Luxembourgish

In German




</doc>
<doc id="18292" url="https://en.wikipedia.org/wiki?curid=18292" title="Lev Kuleshov">
Lev Kuleshov

Lev Vladimirovich Kuleshov (; – 29 March 1970) was a Russian and Soviet filmmaker and film theorist, one of the founders of the world's first film school, the Moscow Film School. He was given the title People's Artist of the RSFSR in 1969. He was intimately involved in development of the style of film making known as Soviet montage, especially its psychological underpinning, including the use of editing and the cut to emotionally influence the audience, a principle known as the Kuleshov effect. He also developed the theory of creative geography, which is the use of the action around a cut to connect otherwise disparate settings into a cohesive narrative.

Lev Kuleshov was born in 1899 into an intellectual Russian family. His father Vladimir Sergeevich Kuleshov was of noble heritage; he studied art in the Moscow School of Painting, Sculpture and Architecture, despite his own father's disapproval. He then married a village schoolteacher Pelagia Alexandrovna Shubina who was raised in an orphanage, which only led to more confrontation. They gave birth to two sons: Boris and Lev.

At the time Lev Kuleshov was born, the family became financially broke, lost their estate and moved to Tambov, living a modest life. In 1911 Vladimir Kuleshov died; three years later Lev and his mother moved to Moscow where his elder brother was studying and working as an engineer. Lev Kuleshov decided to follow the steps of his father and entered the Moscow School of Painting, although he didn't finish it. In 1916 he applied to work at the film company led by Aleksandr Khanzhonkov. He produced scenery for Yevgeni Bauer's pictures, such as "The King of Paris", "For Happiness" and others. With time Kuleshov became more interested in film theory. He co-directed his first movie "Twilight" in 1917. His next film was released under the Soviet patronage.

During 1918–1920 he covered the Russian Civil War with a documentary crew. In 1919 he headed the first Soviet film courses at the National Film School. Kuleshov may well be the very first film theorist as he was a leader in the Soviet montage theory – developing his theories of editing before those of Sergei Eisenstein (briefly a student of Kuleshov). He contributed the article "Kinematogafichekij naturshchik" to the first issue of "Zrelishcha" in 1922. Among his other notable students were Vsevolod Pudovkin, Boris Barnet, Mikhail Romm, Sergey Komarov, Porfiri Podobed, Vladimir Fogel and Aleksandra Khokhlova who became his wife. For Kuleshov, the essence of the cinema was editing, the juxtaposition of one shot with another. To illustrate this principle, he created what has come to be known as the Kuleshov Effect. In this now-famous editing exercise, shots of an actor were intercut with various meaningful images (a casket, a bowl of soup, etc.) in order to show how editing changes viewers' interpretations of images. Another one of his famous inventions was creative geography, also known as artificial landscape. Those techniques were described in his book "The Basics of Film Direction" (1941) which was later translated into many languages.

In addition to his theoretical and teaching work, Kuleshov directed a number of feature-length films. Among his most notable works are an action-comedy "The Extraordinary Adventures of Mr. West in the Land of the Bolsheviks" (1924), a psychological drama "By the Law" (1926) adapted from the short story by Jack London and a biographical drama "The Great Consoler" (1933) based on O. Henry's life and works. In 1934 and 1935 Kuleshov went to Tajikistan to direct there "Dokhunda", a movie based on the novel by Tajik national poet Sadriddin Ayni, but the project was regarded with suspicion by the authorities as possibly exciting Tajik nationalism, and stopped. No footage survives.

After directing his last film in 1943, Kuleshov served as an artistic director and an academic rector at VGIK where he worked for the next 25 years. He was a member of the jury at the 27th Venice International Film Festival, as well as a special guest during other international film festivals.

Lev Kuleshov died in Moscow in 1970. He was buried at the Novodevichy Cemetery. He was survived by his wife Aleksandra Khokhlova (1897–1985) – an actress, film director and educator, granddaughter of Pavel Tretyakov and Sergey Botkin – and Aleksandra's son from the first marriage.





</doc>
<doc id="18295" url="https://en.wikipedia.org/wiki?curid=18295" title="Legacy system">
Legacy system

In computing, a legacy system is an old method, technology, computer system, or application program, "of, relating to, or being a previous or outdated computer system," yet still in use. Often referencing a system as "legacy" means that it paved the way for the standards that would follow it. This can also imply that the system is out of date or in need of replacement.

The first use of the term "legacy" to describe computer systems probably occurred in the 1970s. By the 1980s it was commonly used to refer to existing computer systems to distinguish them from the design and implementation of new systems. Legacy was often heard during a conversion process, for example, when moving data from the legacy system to a new database.

While this term may indicate that some engineers may feel that a system is out of date, a legacy system can continue to be used for a variety of reasons. It may simply be that the system still provides for the users' needs. In addition, the decision to keep an old system may be influenced by economic reasons such as return on investment challenges or vendor lock-in, the inherent challenges of change management, or a variety of other reasons other than functionality. Backward compatibility (such as the ability of newer systems to handle legacy file formats and character encodings) is a goal that software developers often include in their work.

Even if it is no longer used, a legacy system may continue to impact the organization due to its historical role. Historic data may not have been converted into the new system format and may exist within the new system with the use of a customized schema crosswalk, or may exist only in a data warehouse. In either case, the effect on business intelligence and operational reporting can be significant. A legacy system may include procedures or terminology which are no longer relevant in the current context, and may hinder or confuse understanding of the methods or technologies used.

Organizations can have compelling reasons for keeping a legacy system, such as:

Legacy systems are considered to be potentially problematic by some software engineers for several reasons.

Where it is impossible to replace legacy systems through the practice of application retirement, it is still possible to enhance (or "re-face") them. Most development often goes into adding new interfaces to a legacy system. The most prominent technique is to provide a Web-based interface to a terminal-based mainframe application. This may reduce staff productivity due to slower response times and slower mouse-based operator actions, yet it is often seen as an "upgrade", because the interface style is familiar to unskilled users and is easy for them to use. John McCormick discusses such strategies that involve middleware.

Printing improvements are problematic because legacy software systems often add no formatting instructions, or they use protocols that are not usable in modern PC/Windows printers. A print server can be used to intercept the data and translate it to a more modern code. Rich Text Format (RTF) or PostScript documents may be created in the legacy application and then interpreted at a PC before being printed.

Biometric security measures are difficult to implement on legacy systems. A workable solution is to use a telnet or http proxy server to sit between users and the mainframe to implement secure access to the legacy application.

The change being undertaken in some organizations is to switch to automated business process (ABP) software which generates complete systems. These systems can then interface to the organizations' legacy systems and use them as data repositories. This approach can provide a number of significant benefits: the users are insulated from the inefficiencies of their legacy systems, and the changes can be incorporated quickly and easily in the ABP software.

Model-driven reverse and forward engineering approaches can be also used for the improvement of legacy software.

Andreas Hein, from the Technical University of Munich, researched the use of legacy systems in space exploration. According to Hein, legacy systems are attractive for reuse if an organization has the capabilities for verification, validation, testing, and operational history. These capabilities must be integrated into various software life cycle phases such as development, implementation, usage, or maintenance. For software systems, the capability to use and maintain the system are crucial. Otherwise the system will become less and less understandable and maintainable.

According to Hein, verification, validation, testing, and operational history increases the confidence in a system's reliability and quality. However, accumulating this history is often expensive. NASA's now retired Space Shuttle program used a large amount of 1970s-era technology. Replacement was cost-prohibitive because of the expensive requirement for flight certification. The original hardware completed the expensive integration and certification requirement for flight, but any new equipment would have had to go through that entire process again. This long and detailed process required extensive tests of the new components in their new configurations before a single unit could be used in the Space Shuttle program. Thus any new system that started the certification process becomes a "de facto" legacy system by the time it is approved for flight.

Additionally, the entire Space Shuttle system, including ground and launch vehicle assets, was designed to work together as a closed system. Since the specifications did not change, all of the certified systems and components performed well in the roles for which they were designed. Even before the Shuttle was scheduled to be retired in 2010, NASA found it advantageous to keep using many pieces of 1970s technology rather than to upgrade those systems and recertify the new components.

The term "legacy support" is often used in conjunction with legacy systems. The term may refer to a feature of modern software. For example, Operating systems with "legacy support" can detect and use older hardware. The term may also be used to refer to a business function; e.g. A software or hardware vendor that is supporting, or providing software maintenance, for older products.

A "legacy" product may be a product that is no longer sold, has lost substantial market share, or is a version of a product that is not current. A legacy product may have some advantage over a modern product making it appealing for customers to keep it around. A product is only truly "obsolete" if it has an advantage to nobody – if no person making a rational decision would choose to acquire it new.

The term "legacy mode" often refers specifically to backward compatibility. A software product that is capable of performing as though it were a previous version of itself, is said to be "running in legacy mode." This kind of feature is common in operating systems and internet browsers, where many applications depend on these underlying components.

The computer mainframe era saw many applications running in legacy mode. In the modern business computing environment, n-tier, or 3-tier architectures are more difficult to place into legacy mode as they include many components making up a single system.

Virtualization technology is a recent innovation allowing legacy systems to continue to operate on modern hardware by running older operating systems and browsers on a software system that emulates legacy hardware.

Programmers have borrowed the term "brownfield" from the construction industry, where previously developed land (often polluted and abandoned) is described as "brownfield".


There is an alternate favorable opinion — growing since the end of the Dotcom bubble in 1999 — that legacy systems are simply computer systems in working use:

IT analysts estimate that the cost of replacing business logic is about five times that of reuse, even discounting the risk of system failures and security breaches. Ideally, businesses would never have to rewrite most core business logic: "debits = credits" is a perennial requirement.

The IT industry is responding with "legacy modernization" and "legacy transformation": refurbishing existing business logic with new user interfaces, sometimes using screen scraping and service-enabled access through web services. These techniques allow organizations to understand their existing code assets (using discovery tools), provide new user and application interfaces to existing code, improve workflow, contain costs, minimize risk, and enjoy classic qualities of service (near 100% uptime, security, scalability, etc.).

This trend also invites reflection on what makes legacy systems so durable. Technologists are relearning the importance of sound architecture from the start, to avoid costly and risky rewrites. The most common legacy systems tend to be those which embraced well-known IT architectural principles, with careful planning and strict methodology during implementation. Poorly designed systems often don't last, both because they wear out and because their inherent faults invite replacement. Thus, many organizations are rediscovering the value of both their legacy systems and the theoretical underpinnings of those systems.



</doc>
<doc id="18297" url="https://en.wikipedia.org/wiki?curid=18297" title="Lamentations (disambiguation)">
Lamentations (disambiguation)

The Book of Lamentations is part of the Old Testament or Pentateuch.

Lamentations may also refer to:



</doc>
<doc id="18298" url="https://en.wikipedia.org/wiki?curid=18298" title="Lunar eclipse">
Lunar eclipse

A lunar eclipse occurs when the Moon passes directly behind Earth and into its shadow. This can occur only when the Sun, Earth, and Moon are exactly or very closely aligned (in syzygy), with Earth between the other two. A lunar eclipse can occur only on the night of a full moon. The type and length of a lunar eclipse depend on the Moon's proximity to either node of its orbit.

During a total lunar eclipse, Earth completely blocks direct sunlight from reaching the Moon. The only light reflected from the lunar surface has been refracted by Earth's atmosphere. This light appears reddish for the same reason that a sunset or sunrise does: the Rayleigh scattering of bluer light. Due to this reddish color, a totally eclipsed Moon is sometimes called a blood moon.

Unlike a solar eclipse, which can only be viewed from a relatively small area of the world, a lunar eclipse may be viewed from anywhere on the night side of Earth. A total lunar eclipse can last up to nearly 2 hours, while a total solar eclipse lasts only up to a few minutes at any given place, due to the smaller size of the Moon's shadow. Also unlike solar eclipses, lunar eclipses are safe to view without any eye protection or special precautions, as they are dimmer than the full Moon.

For the date of the next eclipse, see the section "Recent and forthcoming lunar eclipses".

Earth's shadow can be divided into two distinctive parts: the umbra and penumbra. Earth totally occludes direct solar radiation within the umbra, the central region of the shadow. However, since the Sun's diameter appears about one-quarter of Earth's in the lunar sky, the planet only partially blocks direct sunlight within the penumbra, the outer portion of the shadow.

A penumbral lunar eclipse occurs when the Moon passes through Earth's penumbra. The penumbra causes a subtle dimming of the lunar surface, which is only visible to the naked eye when aboout 70% of the Moon's diameter has immersed into Earth's penumbra. A special type of penumbral eclipse is a total penumbral lunar eclipse, during which the Moon lies exclusively within Earth's penumbra. Total penumbral eclipses are rare, and when these occur, the portion of the Moon closest to the umbra may appear slightly darker than the rest of the lunar disk.

A partial lunar eclipse occurs when only a portion of the Moon enters Earth's umbra, while a total lunar eclipse occurs when the entire Moon enters the planet's umbra. The Moon's average orbital speed is about , or a little more than its diameter per hour, so totality may last up to nearly 107 minutes. Nevertheless, the total time between the first and the last contacts of the Moon's limb with Earth's shadow is much longer and could last up to four hours.

The relative distance of the Moon from Earth at the time of an eclipse can affect the eclipse's duration. In particular, when the Moon is near apogee, the farthest point from Earth in its orbit, its orbital speed is the slowest. The diameter of Earth's umbra does not decrease appreciably within the changes in the Moon's orbital distance. Thus, the concurrence of a totally eclipsed Moon near apogee will lengthen the duration of totality.

A central lunar eclipse is a total lunar eclipse during which the Moon passes through the centre of Earth's shadow, contacting the antisolar point. This type of lunar eclipse is relatively rare.
A selenelion or selenehelion occurs when both the Sun and an eclipsed Moon can be observed at the same time. This can occur only just before sunset or just after sunrise, when both bodies will appear just above the horizon at nearly opposite points in the sky. This arrangement has led to the phenomenon being also called a horizontal eclipse.

Typically, a number of high ridges undergoing sunrise or sunset can view it. Although the Moon is in Earth's umbra, both the Sun and an eclipsed Moon can be simultaneously seen because atmospheric refraction causes each body to appear higher in the sky than their true geometric positions.

The following scale (the Danjon scale) was devised by André Danjon for rating the overall darkness of lunar eclipses:

There is often confusion between a solar eclipse and a lunar eclipse. While both involve interactions between the Sun, Earth, and the Moon, they are very different in their interactions.

The Moon does not completely darken as it passes through the umbra because of the refraction of sunlight by Earth's atmosphere into the shadow cone; if Earth had no atmosphere, the Moon would be completely dark during the eclipse. The reddish coloration arises because sunlight reaching the Moon must pass through a long and dense layer of Earth's atmosphere, where it is scattered. Shorter wavelengths are more likely to be scattered by the air molecules and small particles; thus, the longer wavelengths predominate by the time the light rays have penetrated the atmosphere. Human vision perceives this resulting light as red. This is the same effect that causes sunsets and sunrises to turn the sky a reddish color. An alternative way of conceiving this scenario is to realize that, as viewed from the Moon, the Sun would appear to be setting (or rising) behind Earth.

The amount of refracted light depends on the amount of dust or clouds in the atmosphere; this also controls how much light is scattered. In general, the dustier the atmosphere, the more that other wavelengths of light will be removed (compared to red light), leaving the resulting light a deeper red color. This causes the resulting coppery-red hue of the Moon to vary from one eclipse to the next. Volcanoes are notable for expelling large quantities of dust into the atmosphere, and a large eruption shortly before an eclipse can have a large effect on the resulting color.

Several cultures have myths related to lunar eclipses or allude to the lunar eclipse as being a good or bad omen. The Egyptians saw the eclipse as a sow swallowing the Moon for a short time; other cultures view the eclipse as the Moon being swallowed by other animals, such as a jaguar in Mayan tradition, or a three legged toad in China. Some societies thought it was a demon swallowing the Moon, and that they could chase it away by throwing stones and curses at it. The Greeks were ahead of their time when they said the Earth was round and used the shadow from the lunar eclipse as evidence. Some Hindus believe in the importance of bathing in the Ganges River following an eclipse because it will help to achieve salvation.

Similarly to the Mayans, the Incans believed that lunar eclipses occurred when a jaguar would eat the Moon, which is why a blood moon looks red. The Incans also believed that once the jaguar finished eating the Moon, it could come down and devour all the animals on Earth, so they would take spears and shout at the Moon to keep it away.

The ancient Mesopotamians believed that a lunar eclipse was when the Moon was being attacked by seven demons. This attack was more than just one on the Moon, however, for the Mesopotamians linked what happened in the sky with what happened on the land, and because the king of Mesopotamia represented the land, the seven demons were thought to be also attacking the king. In order to prevent this attack on the king, the Mesopotamians made someone pretend to be the king so they would be attacked instead of the true king. After the lunar eclipse was over, the substitute king was made to disappear (possibly by poisoning).

In some Chinese cultures, people would ring bells to prevent a dragon or other wild animals from biting the Moon. In the nineteenth century, during a lunar eclipse, the Chinese navy fired its artillery because of this belief. During the Zhou Dynasty in the Book of Songs, the sight of a red Moon engulfed in darkness was believed to foreshadow famine or disease.

Certain lunar eclipses have been referred to as "blood moons" in popular articles but this is not a scientifically-recognized term. This term has been given two separate, but overlapping, meanings.

The first, and simpler, meaning relates to the reddish color a totally eclipsed Moon takes on to observers on Earth. As sunlight penetrates the atmosphere of Earth, the gaseous layer filters and refracts the rays in such a way that the green to violet wavelengths on the visible spectrum scatter more strongly than the red, thus giving the Moon a reddish cast.

The second meaning of "blood moon" has been derived from this apparent coloration by two fundamentalist Christian pastors, Mark Blitz and John Hagee. They claimed that the 2014–15 "lunar tetrad" of four lunar eclipses coinciding with the feasts of Passover and Tabernacles matched the "moon turning to blood" described in the Book of Joel of the Hebrew Bible. This tetrad was claimed to herald the Second Coming of Christ and the Rapture as described in the Book of Revelation on the date of the first of the eclipses in this sequence on April 15, 2014.

At least two lunar eclipses and as many as five occur every year, although total lunar eclipses are significantly less common. If the date and time of an eclipse is known, the occurrences of upcoming eclipses are predictable using an eclipse cycle, like the saros.

Eclipses occur only during an eclipse season, when the Sun appears to pass near either node of the Moon's orbit.




</doc>
<doc id="18303" url="https://en.wikipedia.org/wiki?curid=18303" title="Liber Pontificalis">
Liber Pontificalis

The Liber Pontificalis (Latin for 'pontifical book' or "Book of the Popes") is a book of biographies of popes from Saint Peter until the 15th century. The original publication of the "Liber Pontificalis" stopped with Pope Adrian II (867–872) or Pope Stephen V (885–891), but it was later supplemented in a different style until Pope Eugene IV (1431–1447) and then Pope Pius II (1458–1464). Although quoted virtually uncritically from the 8th to 18th centuries, the "Liber Pontificalis" has undergone intense modern scholarly scrutiny. The work of the French priest Louis Duchesne (who compiled the major scholarly edition), and of others has highlighted some of the underlying redactional motivations of different sections, though such interests are so disparate and varied as to render improbable one popularizer's claim that it is an "unofficial instrument of pontifical propaganda."

The title "Liber Pontificalis" goes back to the 12th century, although it only became current in the 15th century, and the canonical title of the work since the edition of Duchesne in the 19th century. In the earliest extant manuscripts it is referred to as Liber episcopalis in quo continentur acta beatorum pontificum Urbis Romae ('episcopal book in which are contained the acts of the blessed pontiffs of the city of Rome') and later the Gesta or Chronica pontificum.

During the Middle Ages, Saint Jerome was considered the author of all the biographies up until those of Pope Damasus I (366–383), based on an apocryphal letter between Saint Jerome and Pope Damasus published as a preface to the Medieval manuscripts. The attribution originated with Rabanus Maurus and is repeated by Martin of Opava, who extended the work into the 13th century. Other sources attribute the early work to Hegesippus and Irenaeus, having been continued by Eusebius of Caesarea.

In the 16th century, Onofrio Panvinio attributed the biographies after Damasus until Pope Nicholas I (858–867) to Anastasius Bibliothecarius; Anastasius continued to be cited as the author into the 17th century, although this attribution was disputed by the scholarship of Caesar Baronius, Ciampini, Schelstrate and others.

The modern interpretation, following that of Louis Duchesne, is that the "Liber Pontificalis" was gradually and unsystematically compiled, and that the authorship is impossible to determine, with a few exceptions (e.g. the biography of Pope Stephen II (752–757) to papal "Primicerius" Christopher; the biographies of Pope Nicholas I and Pope Adrian II (867–872) to Anastasius). Duchesne and others have viewed the beginning of the "Liber Pontificalis" up until the biographies of Pope Felix III (483–492) as the work of a single author, who was a contemporary of Pope Anastasius II (496-498), relying on "Catalogus Liberianus", which in turn draws from the papal catalogue of Hippolytus of Rome, and the "Leonine Catalogue", which is no longer extant. Most scholars believe the "Liber Pontificalis" was first compiled in the 5th or 6th century.

Because of the use of the "vestiarium", the records of the papal treasury, some have hypothesized that the author of the early "Liber Pontificalis" was a clerk of the papal treasury. Edward Gibbon's "Decline and Fall of the Roman Empire" (1788) summarised the scholarly consensus as being that the "Liber Pontificalis" was composed by "apostolic librarians and notaries of the viii and ix centuries" with only the most recent portion being composed by Anastasius.

Duchesne and others believe that the author of the first addition to the "Liber Pontificalis" was a contemporary of Pope Silverius (536–537), and that the author of another (not necessarily the second) addition was a contemporary of Pope Conon (686–687), with later popes being added individually and during their reigns or shortly after their deaths.

The "Liber Pontificalis" originally only contained the names of the bishops of Rome and the durations of their pontificates. As enlarged in the 6th century, each biography consists of: the birth name of the pope and that of his father, place of birth, profession before elevation, length of pontificate, historical notes of varying thoroughness, major theological pronouncements and decrees, administrative milestones (including building campaigns, especially of Roman churches), ordinations, date of death, place of burial, and the duration of the ensuing "sede vacante".

Pope Adrian II (867–872) is the last pope for which there are extant manuscripts of the original "Liber Pontificalis": the biographies of Pope John VIII, Pope Marinus I, and Pope Adrian III are missing and the biography of Pope Stephen V (885–891) is incomplete. From Stephen V through the 10th and 11th centuries, the historical notes are extremely abbreviated, usually with only the pope's origin and reign duration.

It was only in the 12th century that the "Liber Pontificalis" was systematically continued, although papal biographies exist in the interim period in other sources.

Duchesne refers to the 12th century work by Petrus Guillermi in 1142 at the monastery of St. Gilles (Diocese of Reims) as the "Liber Pontificalis of Petrus Guillermi (son of William)". Guillermi's version is mostly copied from other works with small additions or excisions from the papal biographies of Pandulf, nephew of Hugo of Alatri, which in turn was copied almost verbatim from the original "Liber Pontificalis" (with the notable exception of the biography of Pope Leo IX), then from other sources until Pope Honorius II (1124–1130), and with contemporary information from Pope Paschal II (1099–1118) to Pope Urban II (1088–1099).

Duchesne attributes all biographies from Pope Gregory VII to Urban II to Pandulf, while earlier historians like Giesebrecht and Watterich attributed the biographies of Gregory VII, Victor III, and Urban II to Petrus Pisanus, and the subsequent biographies to Pandulf. These biographies until those of Pope Martin IV (1281–1285) are extant only as revised by Petrus Guillermi in the manuscripts of the monastery of St. Gilles having been taken from the Chronicle of Martin of Opava.

Early in the 14th century, an unknown author built upon the continuation of Petrus Guillermi, adding the biographies of popes Martin IV (d. 1285) through John XXII (1316–1334), with information taken from the "Chronicon Pontificum" of Bernardus Guidonis, stopping abruptly in 1328.

Independently, the cardinal-nephew of Pope Adrian IV, Cardinal Boso intended to extend the "Liber Pontificalis" from where it left off with Stephen V, although his work was only published posthumously as the "Gesta Romanorum Pontificum" alongside the "Liber Censuum" of Pope Honorius III. Boso drew on Bonizo of Sutri for popes from John XII to Gregory VII, and wrote from his own experiences about the popes from Gelasius II (1118–1119) to Alexander III (1179–1181).

An independent continuation appeared in the reign of Pope Eugene IV (1431–1447), appending biographies from Pope Urban V (1362–1370) to Pope Martin V (1417–1431), encompassing the period of the Western Schism. A later recension of this continuation was expanded under Pope Eugene IV.

The two collections of papal biographies of the 15th century remain independent, although they may have been intended to be continuations of the "Liber Pontificalis". The first extends from popes Benedict XII (1334–1342) to Martin V (1417–1431), or in one manuscript to Eugene IV (1431–1447). The second extends from Pope Urban VI (1378–1389) to Pope Pius II (1458–1464).

The "Liber Pontificalis" was first edited by Joannes Busaeus under the title "Anastasii bibliothecarii Vitæ seu Gesta. Romanorum Pontificum" (Mainz, 1602). A new edition, including the "Historia ecclesiastica" of Anastasius, was edited by Fabrotti (Paris, 1647). Another edition, editing the older "Liber Pontificalis" up to Pope Adrian II and adding Pope Stephen VI, was compiled by Fr. Bianchini (4 vols., Rome, 1718–35; a projected fifth volume did not appear). Muratori reprinted Bianchini's edition, adding the remaining popes through John XXII (Scriptores rerum Italicarum, III). Migne also republished Bianchini's edition, adding several appendixes (P. L., CXXVII-VIII).

Modern editions include those of Louis Duchesne ("Liber Pontificalis. Texte, introduction et commentaire", 2 vols., Paris, 1886–92) and Theodor Mommsen ("Gestorum Pontificum Romanorum pars I: Liber Pontificalis", Mon. Germ. hist., Berlin, 1898). Duchesne incorporates the "Annales Romani" (1044–1187) into his edition of the "Liber Pontificalis", which otherwise relies on the two earliest known recensions of the work (530 and 687). Mommsen's edition is incomplete, extending only until 715. Translations and further commentaries appeared throughout the 20th century.





</doc>
<doc id="18306" url="https://en.wikipedia.org/wiki?curid=18306" title="Latin alphabet">
Latin alphabet

The Latin or Roman alphabet is the writing system originally used by the ancient Romans to write the Latin language.

The term "Latin alphabet" may refer to either the alphabet used to write Latin (as described in this article) or other alphabets based on the Latin script, which is the basic set of letters common to the various alphabets descended from the classical Latin alphabet, such as the English alphabet. These Latin-script alphabets may discard letters, like the Rotokas alphabet or add new letters, like the Danish and Norwegian alphabets. Letter shapes have evolved over the centuries, including the development in Medieval Latin of lower-case, forms which did not exist in the Classical period alphabet.

Due to its use in writing Germanic, Romance and other languages first in Europe and then in other parts of the world and due to its use in Romanizing writing of other languages, it has become widespread (see Latin script). It is also used officially in China (separate from its ideographic writing) and has been adopted by Baltic and some Slavic states. 

The Latin alphabet evolved from the visually similar Etruscan alphabet, which evolved from the Cumaean Greek version of the Greek alphabet, which was itself descended from the Phoenician alphabet, which in turn derived from Egyptian hieroglyphics. The Etruscans ruled early Rome; their alphabet evolved in Rome over successive centuries to produce the Latin alphabet.

During the Middle Ages, the Latin alphabet was used (sometimes with modifications) for writing Romance languages, which are direct descendants of Latin, as well as Celtic, Germanic, Baltic and some Slavic languages. With the age of colonialism and Christian evangelism, the Latin script spread beyond Europe, coming into use for writing indigenous American, Australian, Austronesian, Austroasiatic and African languages. More recently, linguists have also tended to prefer the Latin script or the International Phonetic Alphabet (itself largely based on the Latin script) when transcribing or creating written standards for non-European languages, such as the African reference alphabet.

Although it does not seem that classical Latin used diacritics (accents etc), modern English is the only major modern European language that does not have any for native words.

It is generally believed that the
Latin alphabet used by the Romans
was derived from the
Old Italic alphabet used by the Etruscans.
That alphabet was derived from the Euboean alphabet used by the Cumae, which in turn was derived from the Phoenician alphabet.

Latin included 21 different characters. The letter was the western form of the Greek gamma, but it was used for the sounds and alike, possibly under the influence of Etruscan, which might have lacked any voiced plosives. Later, probably during the 3rd century BC, the letter – unneeded to write Latin properly – was replaced with the new letter , a modified with a small vertical stroke, which took its place in the alphabet. From then on, represented the voiced plosive , while was generally reserved for the voiceless plosive . The letter was used only rarely, in a small number of words such as "Kalendae", often interchangeably with .

After the Roman conquest of Greece in the 1st century BC, Latin adopted the Greek letters and (or readopted, in the latter case) to write Greek loanwords, placing them at the end of the alphabet. An attempt by the emperor Claudius to introduce three additional letters did not last. Thus it was during the classical Latin period that the Latin alphabet contained 23 letters:

The Latin names of some of these letters are disputed; for example, may have been called or . In general the Romans did not use the traditional (Semitic-derived) names as in Greek: the names of the plosives were formed by adding to their sound (except for and , which needed different vowels to be distinguished from ) and the names of the continuants consisted either of the bare sound, or the sound preceded by .

The letter when introduced was probably called "hy" as in Greek, the name upsilon not being in use yet, but this was changed to "i Graeca" (Greek i) as Latin speakers had difficulty distinguishing its foreign sound from . was given its Greek name, zeta. This scheme has continued to be used by most modern European languages that have adopted the Latin alphabet. For the Latin sounds represented by the various letters see Latin spelling and pronunciation; for the names of the letters in English see English alphabet.

Diacritics were not regularly used, but they did occur sometimes, the most common being the apex used to mark long vowels, which had previously sometimes been written doubled. However, in place of taking an apex, the letter i was written taller: . For example, what is today transcribed "Lūciī a fīliī" was written in the inscription depicted.

The primary mark of punctuation was the interpunct, which was used as a word divider, though it fell out of use after 200 AD.

Old Roman cursive script, also called majuscule cursive and capitalis cursive, was the everyday form of handwriting used for writing letters, by merchants writing business accounts, by schoolchildren learning the Latin alphabet, and even emperors issuing commands. A more formal style of writing was based on Roman square capitals, but cursive was used for quicker, informal writing. It was most commonly used from about the 1st century BC to the 3rd century, but it probably existed earlier than that. It led to Uncial, a majuscule script commonly used from the 3rd to 8th centuries AD by Latin and Greek scribes.

New Roman cursive script, also known as minuscule cursive, was in use from the 3rd century to the 7th century, and uses letter forms that are more recognizable to modern eyes; , , , and had taken a more familiar shape, and the other letters were proportionate to each other. This script evolved into the medieval scripts known as Merovingian and Carolingian minuscule.

It was not until the Middle Ages that the letter (originally a ligature of two s) was added to the Latin alphabet, to represent sounds from the Germanic languages which did not exist in medieval Latin, and only after the Renaissance did the convention of treating and as vowels, and and as consonants, become established. Prior to that, the former had been merely allographs of the latter.

With the fragmentation of political power, the style of writing changed and varied greatly throughout the Middle Ages, even after the invention of the printing press. Early deviations from the classical forms were the uncial script, a development of the Old Roman cursive, and various so-called minuscule scripts that developed from New Roman cursive, of which the Carolingian minuscule was the most influential, introducing the lower case forms of the letters, as well as other writing conventions that have since become standard.

The languages that use the Latin script generally use capital letters to begin paragraphs and sentences and proper nouns. The rules for capitalization have changed over time, and different languages have varied in their rules for capitalization. Old English, for example, was rarely written with even proper nouns capitalized, whereas Modern English writers and printers of the 17th and 18th century frequently capitalized most and sometimes all nouns, which is still systematically done in Modern German, e.g. in the preamble and all of the United States Constitution: "We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America."

The Latin alphabet spread, along with the Latin language, from the Italian Peninsula to the lands surrounding the Mediterranean Sea with the expansion of the Roman Empire. The eastern half of the Empire, including Greece, Anatolia, the Levant, and Egypt, continued to use Greek as a lingua franca, but Latin was widely spoken in the western half, and as the western Romance languages evolved out of Latin, they continued to use and adapt the Latin alphabet.

With the spread of Western Christianity during the Middle Ages, the script was gradually adopted by the peoples of northern Europe who spoke Celtic languages (displacing the Ogham alphabet) or Germanic languages (displacing earlier Runic alphabets), Baltic languages, as well as by the speakers of several Uralic languages, most notably Hungarian, Finnish and Estonian. The Latin alphabet came into use for writing the West Slavic languages and several South Slavic languages, as the people who spoke them adopted Roman Catholicism.

Later, it was adopted by non-Catholic countries. Romanian, most of whose speakers are Orthodox, was the first major language to switch from Cyrillic to Latin script, doing so in the 19th century, although Moldova only did so after the Soviet collapse.

It has also been increasingly adopted by Turkic-speaking countries, beginning with Turkey in the 1920s. After the Soviet collapse, Azerbaijan, Turkmenistan, and Uzbekistan all switched from Cyrillic to Latin. The government of Kazakhstan announced in 2015 that the Latin alphabet would replace Cyrillic as the writing system for the Kazakh language by 2025.

The spread of the Latin alphabet among previously illiterate peoples has inspired the creation of new writing systems, such as the Avoiuli alphabet in Vanuatu, which replaces the letters of the Latin alphabet with alternative symbols.





</doc>
<doc id="18307" url="https://en.wikipedia.org/wiki?curid=18307" title="Lugh">
Lugh

Lugh or Lug (Old ; Modern Irish: "Lú" ) is one of the most prominent gods in Irish mythology. A member of the Tuatha Dé Danann, Lugh is portrayed as a warrior, a king, a master craftsman and a saviour. He is associated with skill and mastery in multiple disciplines, including the arts. He is also associated with oaths, truth and the law, and therefore with rightful kingship. Lugh is linked with the harvest festival of Lughnasadh, which bears his name. His most common epithets are "Lámfada" (, "of the long arm," possibly for his skill with a spear or his ability as a ruler) and "Samildánach" ("equally skilled in many arts").

In mythology, Lugh is the son of Cian and Ethniu (or Ethliu). He is the maternal grandson of the Fomorian tyrant Balor, whom Lugh kills in the "Battle of Mag Tuired". His foster-father is the sea god Manannán. Lugh's son is the hero Cú Chulainn, who is believed to be an incarnation of Lugh. 

Lugh has several magical possessions. He wields an unstoppable fiery spear, a sling stone, and owns a hound named "Failinis". He is said to have invented "fidchell" (a Gaelic equivalent of chess), ball games, and horse racing.

He corresponds to the pan-Celtic god Lugus, and his Welsh counterpart is Lleu Llaw Gyffes. He has also been equated with Mercury.

The meaning of Lugh's name is still a matter of debate. Some scholars propose it derives from the Proto-Indo-European root "*(h2)lewgh-" meaning "to bind by oath" (compare Old Irish "luige" and Welsh "llw", both meaning "oath, vow, act of swearing" and derived from a suffixed Proto-Celtic form, "*lugiyo-", "oath"), suggesting he was originally a god of oaths and sworn contracts. When Balor meets Lugh in the Second Battle of Moytura, he calls Lugh a "babbler." In the past, his name was generally believed to come from the Proto-Indo-European root *"leuk-", "flashing light", so from Victorian times he has often been considered a sun god, similar to the Greco-Roman Apollo. However, the figure of Lugh from Irish literature seems to be a better match with the Celtic Mercury as described by Julius Caesar in his "De Bello Gallico". There are serious phonological issues with deriving the name from Proto-Indo-European "*leuk-", notably that Proto-Indo-European ' never produced Proto-Celtic '; for this reason, modern specialists in Celtic languages no longer accept this etymology.


Lugh is typically described as a youthful warrior. In the brief narrative "Baile in Scáil" Lugh is described as being very large and very beautiful and also as a spear-wielding horseman.

When he appears before the wounded Cú Chulainn in the Táin Bó Cúalnge, he is described as follows:
"A man fair and tall, with a great head of curly yellow hair. He has a green mantle wrapped about him and a brooch of white silver in the mantle over his breast. Next to his white skin, he wears a tunic of royal satin with red-gold insertion reaching to his knees. He carries a black shield with a hard boss of white-bronze. In his hand a five-pointed spear and next to it a forked javelin. Wonderful is the play and sport and diversion that he makes (with these weapons). But none accosts him and he accosts none as if no one could see him."

Elsewhere Lugh is described as a young, tall man with bright red cheeks, white sides, a bronze-coloured face, and blood-coloured hair. 

Finally, in "The Fate of the Children of Turenn", Lugh is described by Bres as follows:
It is a wonder to me the sun to be rising in the west today, and it rising in the east every other day." "It would be better for us it to be the sun," said the Druids. "What else is it?" said he. "It is the shining of the face of Lugh, son of Ethlinn," said they.

Lugh's father is Cian of the Tuatha Dé Danann, and his mother is Ethniu: daughter of Balor, of the Fomorians. In "Cath Maige Tuired" their union is a dynastic marriage following an alliance between the Tuatha Dé and the Fomorians. In the "Lebor Gabála Érenn," Cian gives the boy to Tailtiu, queen of the Fir Bolg, in fosterage. In the Dindsenchas, Lugh, the foster-son of Tailtiu, is described as the "son of the Dumb Champion". In the poem Baile Suthain Sith Eamhna Lugh is called "descendant of the poet."

A folktale told to John O'Donovan by Shane O'Dugan of Tory Island in 1835 recounts the birth of a grandson of Balor who grows up to kill his grandfather. The grandson is unnamed, his father is called Mac Cinnfhaelaidh and the manner of his killing of Balor is different, but it has been taken as a version of the birth of Lugh, and was adapted as such by Lady Gregory. In this tale, Balor hears a druid's prophecy that he will be killed by his own grandson. To prevent this he imprisons his only daughter in the Tór Mór (great tower) of Tory Island. She is cared for by twelve women, who are to prevent her ever meeting or even learning of the existence of men. On the mainland, Mac Cinnfhaelaidh owns a magic cow who gives such abundant milk that everyone, including Balor, wants to possess her. While the cow is in the care of Mac Cinnfhaelaidh's brother Mac Samthainn, Balor appears in the form of a little red-haired boy and tricks him into giving him the cow. Looking for revenge, Mac Cinnfhaelaidh calls on a "leanan sídhe" (fairy woman) called Biróg, who transports him by magic to the top of Balor's tower, where he seduces Eithne. In time she gives birth to triplets, which Balor gathers up in a sheet and sends to be drowned in a whirlpool. The messenger drowns two of the babies but unwittingly drops one child into the harbour, where he is rescued by Biróg. She takes him to his father, who gives him to his brother, Gavida the smith, in fosterage.

There may be further triplism associated with his birth. His father in the folktale is one of a triad of brothers, Mac Cinnfhaelaidh, Gavida, and Mac Samthainn, and his father in the medieval texts, Cian, is often mentioned together with his brothers Cú and Cethen. "Lebor Gabála Érenn" Two characters called Lugaid, a popular medieval Irish name thought to derive from Lugh, have three fathers: Lugaid Riab nDerg (Lugaid of the Red Stripes) was the son of the three "Findemna" or fair triplets, and Lugaid mac Con Roí was also known as "mac Trí Con", "son of three hounds". In Ireland's other great "sequestered maiden" story, the tragedy of Deirdre, the king's intended is carried off by three brothers, who are hunters with hounds. The canine imagery continues with Cian's brother Cú ("hound"), another Lugaid, Lugaid Mac Con (son of a hound), and Lugh's son Cúchulainn ("Culann's Hound"). A fourth Lugaid was Lugaid Loígde, a legendary King of Tara and ancestor of (or inspiration for) Lugaid Mac Con.

As a young man Lugh travels to Tara to join the court of King Nuada of the Tuatha Dé Danann. The doorkeeper will not let him in unless he has a skill he can use to serve the king. He offers his services as a wright, a smith, a champion, a swordsman, a harpist, a hero, a poet, historian, a sorcerer, and a craftsman, but each time is rejected as the Tuatha Dé Danann already have someone with that skill. When Lugh asks if they have anyone with all those skills simultaneously, the doorkeeper has to admit defeat, and Lugh joins the court and is appointed Chief Ollam of Ireland. He wins a flagstone-throwing contest against Ogma, the champion, and entertains the court with his harp. The Tuatha Dé Danann are, at that time, oppressed by the Fomorians, and Lugh is amazed how meekly they accept their oppression. Nuada wonders if this young man could lead them to freedom. Lugh is given command over the Tuatha Dé Danann, and he begins making preparations for war.

Tuireann and Cian, Lugh's father, are old enemies, and one day his sons, Brian, Iuchar, and Iucharba spot Cian in the distance and decide to kill him. They find him hiding in the form of a pig, but Cian tricked the brothers into allowing him to transform back to a man before they killed him, giving Lugh the legal right to claim compensation for a father rather than just a pig. When they try to bury him, the ground spits his body back twice before keeping him down, and eventually confesses that it is a grave to Lugh. Lugh holds a feast and invites the brothers, and during it he asks them what they would demand as compensation for the murder of their father. They reply that death would be the only just demand, and Lugh agrees. He then accuses them of the murder of his father, Cian, and sets them a series of seemingly impossible quests. The brothers go on an adventure and achieve them all except the last one, which will surely kill them. Despite Tuireann's pleas, Lugh demands that they proceed and, when they are all fatally wounded, he denies them the use of one of the items they have retrieved, a magic pigskin which heals all wounds. They die of their wounds and Tuireann dies of grief over their bodies.

Using the magic artefacts the sons of Tuireann have gathered, Lugh leads the Tuatha Dé Danann in the Second Battle of Mag Tuireadh against the Fomorians. Prior to the battle Lugh asks each man and woman in his army what art he or she will bring to the fray; he then addressed his army in speech, which elevated each warrior's spirit to that of a king or lord. Nuada is killed in the battle by Balor. Lugh faces Balor, who opens his terrible, poisonous eye that kills all it looks upon, but Lugh shoots a sling-stone that drives his eye out the back of his head, killing Balor and wreaking havoc on the Fomorian army behind. After the victory Lugh finds Bres, the half-Fomorian former king of the Tuatha Dé Danann, alone and unprotected on the battlefield, and Bres begs for his life. If he is spared, he promises, he will ensure that the cows of Ireland always give milk. The Tuatha Dé Danann refuse the offer. He then promises four harvests a year, but the Tuatha Dé Danann say one harvest a year suits them. But Lugh spares his life on the condition that he teach the Tuatha Dé Danann how and when to plough, sow, and reap.

Lugh instituted an event similar to the Olympic games called the Assembly of Talti which finished on Lughnasadh (1 August) in memory of his foster-mother, Tailtiu, at the town that bears her name (now Teltown, County Meath). He likewise instituted Lughnasadh fairs in the areas of Carman and Naas in honour of Carman and Nás, the eponymous tutelary goddess of these two regions. Horse races and displays of martial arts were important activities at all three fairs. However, Lughnasadh itself is a celebration of Lugh's triumph over the spirits of the Otherworld who had tried to keep the harvest for themselves. It survived long into Christian times and is still celebrated under a variety of names. "Lúnasa" is now the Irish name for the month of August.

According to a poem of the "dindsenchas", Lugh was responsible for the death of Bres. He made 300 wooden cows and filled them with a bitter, poisonous red liquid which was then "milked" into pails and offered to Bres to drink. Bres, who was under an obligation not to refuse hospitality, drank it down without flinching, and it killed him.

Lugh is said to have invented the board game fidchell.

One of his wives, Buach, had an affair with Cermait, son of the Dagda. Lugh killed him in revenge, but Cermait's sons, Mac Cuill, Mac Cecht, and Mac Gréine, killed Lugh in return, spearing him through the foot then drowning him in Loch Lugborta in County Westmeath. He had ruled for forty years. Cermait was later revived by his father, the Dagda, who used the smooth or healing end of his staff to bring Cermait back to life.


Lugh is given the matriname "mac Ethlenn" or "mac Ethnenn" ("son of Ethliu or Ethniu", his mother) and the patriname "mac Cein" ("son of Cian", his father). He is the maternal grandson of the Fomorian tyrant Balor, whom Lugh kills in the "Battle of Mag Tuired". His foster-father is the sea god Manannán. Lugh's son is the hero Cú Chulainn, who is believed to be an incarnation of Lugh.

He had several wives, including Buí (AKA Buach or Bua "Victory") and Nás, daughters of Ruadri Ruad, king of Britain. Buí lived and was buried at Knowth (Cnogba). Nás was buried at Naas, County Kildare, which is named after her. Lugh had a son, Ibic "of the horses", by Nás. It is said that Nás dies with the noise of combat, therefore it is difficult to know where she dies. Lugh's daughter or sister was Ebliu, who married Fintan. By the mortal Deichtine, Lugh was father to the hero Cú Chulainn.

Lug possessed a number of magical items, retrieved by the sons of Tuirill Piccreo in Middle Irish redactions of the Lebor Gabála. Not all the items are listed here. The late narrative "Fate of the Children of Tuireann" not only gives a list of items gathered for Lugh, but also endows him with such gifts from the sea god Manannán as the sword Fragarach, the horse Enbarr (Aonbarr), the boat / ("Wave-Sweeper"), his armour and helmet.

Lugh's spear (), according to the text of The Four Jewels of the Tuatha Dé Danann, was said to be impossible to overcome, taken to Ireland from Gorias (or Findias).

Lugh obtained the Spear of Assal () as fine () imposed on the children of Tuirill Piccreo (or Biccreo), according to the short account in (Poem LXV, 319), which adds that the incantation "Ibar (Yew)" made the cast always hit its mark, and "Athibar (Re-Yew)" caused the spear to return.

In a full narrative version called (The Fate of the Children of Tuireann), from copies no earlier than the 18th century, Lugh demands the spear named "Ar-éadbair" or "Areadbhair" (Early Modern Irish: ) which belonged to Pisear, king of Persia, that its tip had to be kept immersed in a pot of water to keep it from igniting, a property similar to the Lúin of Celtchar. This spear is also called "Slaughterer" in translation.

There is yet another name that Lugh's spear goes by: "A [yew] tree, the finest of the wood" (Early Modern Irish: ), occurring in an inserted verse within "The Fate of the Children of Tuireann". "The famous yew of the wood" () is also the name that Lugh's spear is given in a tract which alleges that it, the Lúin of Celtchar and the spear Crimall that blinded Cormac Mac Airt were one and the same weapon (tract in TCD MS 1336 (olim H 3. 17), col. 723, discussed in the Lúin page).

Lugh's projectile weapon, whether a dart or missile, was envisioned by symbolic of lightning-weapon. Lugh's sling rod, named "Lugh's Chain", was the rainbow and the Milky Way. Unlike the rod-sling, Lugh had no need to wield the spear himself. It was alive and thirsted so for blood that only by steeping its head in a sleeping-draught of pounded fresh poppy seeds could it be kept at rest. When battle was near, it was drawn out; then it roared and struggled against its thongs, fire flashed from it, and it tore through the ranks of the enemy once slipped from the leash, never tired of slaying.

According to the brief accounts in the Lebor Gabála Érenn, Lugh used the "sling-stone" ("cloich tabaill") to slay his grandfather, Balor the Strong-Smiter in the Battle of Magh Tuired. The narrative , preserved in a unique 16th century copy, words it slightly different saying that Lugh used the sling-stone (here § 133, i.e. "stone" of the ' "sling") to destroy the evil eye of Balor of the Piercing Eye (Bolur Birugderc).

A certain poem recorded by O'Curry in English translation says that the missile fired by Lugh was a tathlum ( "(slingstone made of) cement").

Lugh is also seen girt with the Freagarthach (better known as Fragarach), the sword of Manannán, in the assembly of the Tuatha Dé Danann in the "Fate of the Children of Tuireann".

Lugh had a horse named Aenbharr which could fare over both land and sea. Like much of his equipment, it was furnished to him by the sea god Manannán mac Lir. When the Children of Tuireann asked to borrow this horse, Lugh begrudged them, saying it would not be proper to make a loan of a loan. Consequently, Lugh was unable to refuse their request to use Lugh's currach (coracle) or boat, the "Wave-Sweeper" ().

In the Lebor Gabála, Gainne and Rea were the names of the pair of horses belonging to the king of the isle of Sicily [on the (Tyrrhene sea)], which Lug demanded as éric from the sons of Tuirill Briccreo.

Failinis was the name of the whelp of the King of Ioruaidhe that Lugh demanded as éiric (a forfeit) in the "Oidhead Chloinne Tuireann". This concurs with the name of the hound mentioned in an "Ossianic Ballad", sometimes referred to by its opening line " (They came here as a band of three)". In the ballad, the hound is called Ṡalinnis (Shalinnis) or Failinis (in the Lismore text), and belonged to a threesome from Iruaide whom the Fianna encounter. It is described as "the ancient grayhound... that had been with Lugh of the Mantles, / Given him by the sons of Tuireann Bicreann;..."

O'Curry's excerpt ends here, but the subsequent verse runs "The three full-fledged heroes are called Sél, Donait and Domhnán. The dog of the fairest figure, Failinis was brought to Finn". This threesome also appears in though in that work the wonder-dog is called Fer Mac.

Lugh corresponds to the pan-Celtic god Lugus, and his Welsh counterpart is Lleu Llaw Gyffes. He has also been equated with Mercury. Sometimes he is interpreted as a storm god and, less often today, as a sun god. Others have noted a similarity in Lugh's slaying of Balor a Celtic analog to the slaying of Baldr by Loki. Lugh's mastery of all arts has led many to link him with the unnamed Gaulish god Julius Caesar identifies with Mercury, whom he describes as the "inventor of all the arts". Caesar describes the Gaulish Mercury as the most revered deity in Gaul, overseeing journeys and business transactions. 

St. Mologa has been theorized to be a Christian continuation of the god Lugh.

The County of Louth in Ireland is named after the village of Louth, which is named after the God Lugh. Historically, the place name has had various spellings; "Lugmad", "Lughmhaigh", and "Lughmhadh" (see Historic Names List, for full listing). "Lú" is the modern simplified spelling. Other places named for Lugh include the cairn at Seelewey (Suidhe Lughaidh, or Lug's Seat), Dunlewey, and Rath-Lugaidh in Carney, Sligo. Seelewey was located in Moyturra Chonlainn and, according to local folklore, was a place where giants used to gather in olden days.





</doc>
<doc id="18308" url="https://en.wikipedia.org/wiki?curid=18308" title="Lanthanide">
Lanthanide

The lanthanide () or lanthanoid () series of chemical elements comprises the 15 metallic chemical elements with atomic numbers 57–71, from lanthanum through lutetium. These elements, along with the chemically similar elements scandium and yttrium, are often collectively known as the rare earth elements.

The informal chemical symbol Ln is used in general discussions of lanthanide chemistry to refer to any lanthanide. All but one of the lanthanides are f-block elements, corresponding to the filling of the 4f electron shell; depending on the source, either lanthanum or lutetium is considered a d-block element, but is included due to its chemical similarities with the other 14. All lanthanide elements form trivalent cations, Ln, whose chemistry is largely determined by the ionic radius, which decreases steadily from lanthanum to lutetium.

They are called lanthanides because the elements in the series are chemically similar to lanthanum. Both lanthanum and lutetium have been labeled as group 3 elements, because they have a single valence electron in the 5d shell. However, both elements are often included in discussions of the chemistry of lanthanide elements. Lanthanum is the more often omitted of the two, because its placement as a group 3 element is somewhat more common in texts and for semantic reasons: since "lanthanide" means "like lanthanum", it has been argued that lanthanum cannot logically be a lanthanide, but IUPAC acknowledges its inclusion based on common usage.

In presentations of the periodic table, the lanthanides and the actinides are customarily shown as two additional rows below the main body of the table, with placeholders or else a selected single element of each series (either lanthanum and actinium, or lutetium and lawrencium) shown in a single cell of the main table, between barium and hafnium, and radium and rutherfordium, respectively. This convention is entirely a matter of aesthetics and formatting practicality; a rarely used wide-formatted periodic table inserts the lanthanide and actinide series in their proper places, as parts of the table's sixth and seventh rows (periods).

The 1985 International Union of Pure and Applied Chemistry “Red Book” (p. 45) recommends that ""lanthanoid"" is used rather than ""lanthanide"". The ending “-ide” normally indicates a negative ion. However, owing to wide current use, “lanthanide” is still allowed.
Together with the two elements at the top of group 3, scandium and yttrium, the trivial name "rare earths" is sometimes used to describe all the lanthanides; a definition of rare earths including the group 3, lanthanide, and actinide elements is also occasionally seen, and rarely Sc + Y + lanthanides + thorium. The "earth" in the name "rare earths" arises from the minerals from which they were isolated, which were uncommon oxide-type minerals. However, the use of the name is deprecated by IUPAC, as the elements are neither rare in abundance nor "earths" (an obsolete term for water-insoluble strongly basic oxides of electropositive metals incapable of being smelted into metal using late 18th century technology). Group 2 is known as the alkaline earth elements for much the same reason.

The "rare" in the "rare earths" name has much more to do with the difficulty of separating out each of the individual lanthanide elements than scarcity of any of them. By way of the Greek "dysprositos" for "hard to get at," element 66, dysprosium was similarly named; lanthanum itself is named after a word for "hidden." The elements 57 (La) to 71 (Lu) are very similar chemically to one another and frequently occur together in nature, often anywhere from three to all 15 of the lanthanides (along with yttrium as a 16th) occur in minerals such as samarskite, monazite and many others which can also contain the other two group 3 elements as well as thorium and occasionally other actinides as well. A majority of the rare earths were discovered at the same mine in Ytterby, Sweden and four of them are named (yttrium, ytterbium, erbium, terbium) after the city and a fifth *(holmium) after Stockholm; scandium is named after Scandinavia, thulium after the old name Thule, and the immediately-following group 4 element (number 72) hafnium is named for the Latin name of the city of Copenhagen.

Samarskite (a mineral which is the source of the name of the element samarium) and other similar minerals in particular also have these elements in association with the nearby metals tantalum, niobium, hafnium, zirconium, vanadium, and titanium, from group 4 and group 5 often in similar oxidation states. Monazite is a phosphate of numerous group 3 + lanthanide + actinide metals and mined especially for the thorium content and specific rare earths especially lanthanum, yttrium and cerium. Cerium and lanthanum as well as other members of the rare earth series are often produced as a metal called mischmetal containing a variable mixture of these elements with cerium and lanthanum predominating; it has direct uses such as lighter flints and other spark sources which do not require extensive purification of one of these metals. There are also rare earth-bearing minerals based on group 2 elements such as yttrocalcite, yttrocerite, yttrofluorite which vary in content of yttrium, cerium, and lanthanum in a particular as well as varying amounts of the others. Other lanthanide/rare earth minerals include bastnäsite, florencite, chernovite, perovskite, xenotime, cerite, gadolinite, lanthanite, fergusonite, polycrase, blomstrandine, håleniusite, miserite, loparite, lepersonnite, euxenite, all of which have a range of relative element concentration and may have the symbol of a predominating one such as monazite-ce; group 3 elements do not occur as native element minerals in the fashion of gold, silver, tantalum and many others on earth but may in lunar regolith. Very rare cerium, lanthanum, and presumably other lanthanide/group 3 halides, feldspars and garnets are also known to exist.

All of this is the result of the order in which the electron shells of these elements are filled—the outermost has the same configuration for all of them, and a deeper shell is progressively filled with electrons as the atomic number increases from 57 towards 71. For many years, mixtures of more than one rare earth were considered to be single elements, such as neodymium and praseodymium being thought to be the single element didymium and so on. Very small differences in solubility are used in solvent and ion-exchange purification methods for these elements which require a great deal of repeating to get a purified metal. The refined metals and their compounds have subtle and stark differences amongst themselves in electronic, electrical, optical, and magnetic properties which account for their many niche uses.

By way of examples of the term meaning the above considerations rather than their scarcity, cerium is the 26th most abundant element in the Earth's crust and more abundant than copper, neodymium is more abundant than gold; thulium (the second least common naturally occurring lanthanide) is more abundant than iodine, which is itself common enough for biology to have evolved critical usages thereof, and even the lone radioactive element in the series, promethium, is more common than the two rarest naturally occurring elements, francium and astatine, combined. Despite their abundance, even the technical term "lanthanides" could be interpreted to reflect a sense of elusiveness on the part of these elements, as it comes from the Greek λανθανειν ("lanthanein"), "to lie hidden". However, if not referring to their natural abundance, but rather to their property of "hiding" behind each other in minerals, this interpretation is in fact appropriate. The etymology of the term must be sought in the first discovery of lanthanum, at that time a so-called new rare earth element "lying hidden" in a cerium mineral, and it is an irony that lanthanum was later identified as the first in an entire series of chemically similar elements and could give name to the whole series. The term "lanthanide" was introduced by Victor Goldschmidt in 1925.

<nowiki>*</nowiki> Between initial Xe and final 6s electronic shells

<nowiki>**</nowiki> Sm has a close packed structure like the other lanthanides but has an unusual 9 layer repeat

Gschneider and Daane (1988) attribute the trend in melting point which increases across the series, (lanthanum (920 °C) – lutetium (1622 °C)) to the extent of hybridization of the 6s, 5d, and 4f orbitals. The hybridization is believed to be at its greatest for cerium, which has the lowest melting point of all, 795 °C.
The lanthanide metals are soft; their hardness increases across the series. Europium stands out, as it has the lowest density in the series at 5.24 g/cm and the largest metallic radius in the series at 208.4 pm. It can be compared to barium, which has a metallic radius of 222 pm. It is believed that the metal contains the larger Eu ion and that there are only two electrons in the conduction band. Ytterbium also has a large metallic radius, and a similar explanation is suggested.
The resistivities of the lanthanide metals are relatively high, ranging from 29 to 134 μΩ·cm. These values can be compared to a good conductor such as aluminium, which has a resistivity of 2.655 μΩ·cm.
With the exceptions of La, Yb, and Lu (which have no unpaired f electrons), the lanthanides are strongly paramagnetic, and this is reflected in their magnetic susceptibilities. Gadolinium becomes ferromagnetic at below 16 °C (Curie point). The other heavier lanthanides – terbium, dysprosium, holmium, erbium, thulium, and ytterbium – become ferromagnetic at much lower temperatures.

<nowiki>*</nowiki> Not including initial [Xe] core

The colors of lanthanide complexes originate almost entirely from charge transfer interactions between the metal and the ligand. f → f transitions are symmetry forbidden (or Laporte-forbidden), which is also true of transition metals. However, transition metals are able to use vibronic coupling to break this rule. The valence orbitals in lanthanides are almost entirely non-bonding and as such little effective vibronic coupling takes, hence the spectra from f → f transitions are much weaker and narrower than those from d → d transitions. In general this makes the colors of lanthanide complexes far fainter than those of transition metal complexes. f → f transitions are not possible for the f and f configurations of Ce and Yb and thus these ions are colorless in aqueous solution.

Going across the lanthanides in the periodic table, the 4f orbitals are usually being filled. The effect of the 4f orbitals on the chemistry of the lanthanides is profound and is the factor that distinguishes them from the transition metals. There are seven 4f orbitals, and there are two different ways in which they are depicted: as a "cubic set" or as a general set. The cubic set is "f", "f", "f", "f", "f", "f" and "f". The 4f orbitals penetrate the [Xe] core and are isolated, and thus they do not participate in bonding. This explains why crystal field effects are small and why they do not form π bonds. As there are seven 4f orbitals, the number of unpaired electrons can be as high as 7, which gives rise to the large magnetic moments observed for lanthanide compounds. Measuring the magnetic moment can be used to investigate the 4f electron configuration, and this is a useful tool in providing an insight into the chemical bonding. The lanthanide contraction, i.e. the reduction in size of the Ln ion from La (103 pm) to Lu (86.1 pm), is often explained by the poor shielding of the 5s and 5p electrons by the 4f electrons.

The electronic structure of the lanthanide elements, with minor exceptions, is [Xe]6s4f. The chemistry of the lanthanides is dominated by the +3 oxidation state, and in Ln compounds the 6s electrons and (usually) one 4f electron are lost and the ions have the configuration [Xe]4f. All the lanthanide elements exhibit the oxidation state +3. In addition, Ce can lose its single f electron to form Ce with the stable electronic configuration of xenon. Also, Eu can gain an electron to form Eu with the f configuration that has the extra stability of a half-filled shell. Other than Ce(IV) and Eu(II), none of the lanthanides are stable in oxidation states other than +3 in aqueous solution. Promethium is effectively a man-made element, as all its isotopes are radioactive with half-lives shorter than 20 years.

In terms of reduction potentials, the Ln couples are nearly the same for all lanthanides, ranging from −1.99 (for Eu) to −2.35 V (for Pr). Thus these metals are highly reducing, with reducing power similar to alkaline earth metals such as Mg (−2.36 V).

The ionization energies for the lanthanides can be compared with aluminium. In aluminium the sum of the first three ionization energies is 5139 kJ·mol, whereas the lanthanides fall in the range 3455 – 4186 kJ·mol. This correlates with the highly reactive nature of the lanthanides.

The sum of the first two ionization energies for europium, 1632 kJ·mol can be compared with that of barium 1468.1 kJ·mol and europium's third ionization energy is the highest of the lanthanides. The sum of the first two ionization energies for ytterbium are the second lowest in the series and its third ionization energy is the second highest. The high third ionization energy for Eu and Yb correlate with the half filling 4f and complete filling 4f of the 4f subshell, and the stability afforded by such configurations due to exchange energy. Europium and ytterbium form salt like compounds with Eu and Yb, for example the salt like dihydrides. Both europium and ytterbium dissolve in liquid ammonia forming solutions of Ln(NH) again demonstrating their similarities to the alkaline earth metals.

The relative ease with which the 4th electron can be removed in cerium and (to a lesser extent praseodymium) indicates why Ce(IV) and Pr(IV) compounds can be formed, for example CeO is formed rather than CeO when cerium reacts with oxygen.

The similarity in ionic radius between adjacent lanthanide elements makes it difficult to separate them from each other in naturally occurring ores and other mixtures. Historically, the very laborious processes of cascading and fractional crystallization were used. Because the lanthanide ions have slightly different radii, the lattice energy of their salts and hydration energies of the ions will be slightly different, leading to a small difference in solubility. Salts of the formula Ln(NO)·2NHNO·4HO can be used. Industrially, the elements are separated from each other by solvent extraction. Typically an aqueous solution of nitrates is extracted into kerosene containing tri-"n"-butylphosphate. The strength of the complexes formed increases as the ionic radius decreases, so solubility in the organic phase increases. Complete separation can be achieved continuously by use of countercurrent exchange methods. The elements can also be separated by ion-exchange chromatography, making use of the fact that the stability constant for formation of EDTA complexes increases for log K ≈ 15.5 for [La(EDTA)] to log K ≈ 19.8 for [Lu(EDTA)].

When in the form of coordination complexes, lanthanides exist overwhelmingly in their +3 oxidation state, although particularly stable 4f configurations can also give +4 (Ce, Tb) or +2 (Eu, Yb) ions. All of these forms are strongly electropositive and thus lanthanide ions are hard Lewis acids. The oxidation states are also very stable; with the exceptions of SmI and cerium(IV) salts, lanthanides are not used for redox chemistry. 4f electrons have a high probability of being found close to the nucleus and are thus strongly affected as the nuclear charge increases across the series; this results in a corresponding decrease in ionic radii referred to as the lanthanide contraction.

The low probability of the 4f electrons existing at the outer region of the atom or ion permits little effective overlap between the orbitals of a lanthanide ion and any binding ligand. Thus lanthanide complexes typically have little or no covalent character and are not influenced by orbital geometries. The lack of orbital interaction also means that varying the metal typically has little effect on the complex (other than size), especially when compared to transition metals. Complexes are held together by weaker electrostatic forces which are omni-directional and thus the ligands alone dictate the symmetry and coordination of complexes. Steric factors therefore dominate, with coordinative saturation of the metal being balanced against inter-ligand repulsion. This results in a diverse range of coordination geometries, many of which are irregular, and also manifests itself in the highly fluxional nature of the complexes. As there is no energetic reason to be locked into a single geometry, rapid intramolecular and intermolecular ligand exchange will take place. This typically results in complexes that rapidly fluctuate between all possible configurations.

Many of these features make lanthanide complexes effective catalysts. Hard Lewis acids are able to polarise bonds upon coordination and thus alter the electrophilicity of compounds, with a classic example being the Luche reduction. The large size of the ions coupled with their labile ionic bonding allows even bulky coordinating species to bind and dissociate rapidly, resulting in very high turnover rates; thus excellent yields can often be achieved with loadings of only a few mol%. The lack of orbital interactions combined with the lanthanide contraction means that the lanthanides change in size across the series but that their chemistry remains much the same. This allows for easy tuning of the steric environments and examples exist where this has been used to improve the catalytic activity of the complex and change the nuclearity of metal clusters.

Despite this, the use of lanthanide coordination complexes as homogeneous catalysts is largely restricted to the laboratory and there are currently few examples them being used on an industrial scale. It should be noted however, that lanthanides exist in many forms other that coordination complexes and many of these are industrially useful. In particular lanthanide metal oxides are used as heterogeneous catalysts in various industrial processes.

The trivalent lanthanides mostly form ionic salts. The trivalent ions are hard acceptors and form more stable complexes with oxygen-donor ligands than with nitrogen-donor ligands. The larger ions are 9-coordinate in aqueous solution, [Ln(HO)] but the smaller ions are 8-coordinate, [Ln(HO)]. There is some evidence that the later lanthanides have more water molecules in the second coordination sphere. Complexation with monodentate ligands is generally weak because it is difficult to displace water molecules from the first coordination sphere. Stronger complexes are formed with chelating ligands because of the chelate effect, such as the tetra-anion derived from 1,4,7,10-tetraazacyclododecane-1,4,7,10-tetraacetic acid (DOTA).

The most common divalent derivatives of the lanthanides are for Eu(II), which achieves a favorable f configuration. Divalent halide derivatives are known for all of the lanthanides. They are either conventional salts or are Ln(III) "electride"-like salts. The simple salts include YbI, EuI, and SmI. The electride-like salts, described as Ln, 2I, e, include LaI, CeI and GdI. Many of the iodides form soluble complexes with ethers, e.g. TmI(dimethoxyethane). Samarium(II) iodide is a useful reducing agent. Ln(II) complexes can be synthesized by transmetalation reactions. The normal range of oxidation states can be expanded via the use of sterically bulky cyclopentadienyl ligands, in this way many lanthanides can be isolated as Ln(II) compounds.

Ce(IV) in ceric ammonium nitrate is a useful oxidizing agent. Otherwise tetravalent lanthanides are rare. The Ce(IV) is the exception owing to the tendency to form an unfilled f shell.

Lanthanide metals react exothermically with hydrogen to form LnH, dihydrides. With the exception of Eu and Yb which resemble the Ba and Ca hydrides (non conducting, transparent salt like compounds) they form black pyrophoric, conducting compounds where the metal sub-lattice is face centred cubic and the H atoms occupy tetrahedral sites. Further hydrogenation produces a trihydride which is non-stoichiometric, non-conducting, more salt like. The formation of trihydride is associated with and increase in 8–10% volume and this is linked to greater localization of charge on the hydrogen atoms which become more anionic (H hydride anion) in character.

The only tetrahalides known are the tetrafluorides of cerium, praseodymium, terbium, neodymium and dysprosium, the last two known only under matrix isolation conditions.
All of the lanthanides form trihalides with fluorine, chlorine, bromine and iodine. They are all high melting and predominantly ionic in nature. The fluorides are only slightly soluble in water and are not sensitive to air, and this contrasts with the other halides which are air sensitive, readily soluble in water and react at high temperature to form oxohalides.
The trihalides were important as pure metal can be prepared from them. In the gas phase the trihalides are planar or approximately planar, the lighter lanthanides have a lower % of dimers, the heavier lanthanides a higher proportion. The dimers have a similar structure to AlCl.

Some of the dihalides are conducting while the rest are insulators. The conducting forms can be considered as Ln electride compounds where the electron is delocalised into a conduction band, Ln (X)(e). All of the diodides have relatively short metal-metal separations. The CuTi structure of the lanthanum, cerium and praseodymium diodides along with HP-NdI contain 4 nets of metal and iodine atoms with short metal-metal bonds (393-386 La-Pr). these compounds should be considered to be two-dimensional metals (two-dimensional in the same way that graphite is). The salt-like dihalides include those of Eu, Dy, Tm, and Yb. The formation of a relatively stable +2 oxidation state for Eu and Yb is usually explained by the stability (exchange energy) of half filled (f) and fully filled f. GdI possesses the layered MoS structure, is ferromagnetic and exhibits colossal magnetoresistance
The sesquihalides LnX and the LnI compounds listed in the table contain metal clusters, discrete LnI clusters in LnI and condensed clusters forming chains in the sesquihalides. Scandium forms a similar cluster compound with chlorine, ScCl Unlike many transition metal clusters these lanthanide clusters do not have strong metal-metal interactions and this is due to the low number of valence electrons involved, but instead are stabilised by the surrounding halogen atoms.

LaI is the only known monohalide. Prepared from the reaction of LaI and La metal, it has a NiAs type structure and can be formulated La (I)(e).

All of the lanthanides form sesquioxides, LnO. The lighter/larger lanthanides adopt a hexagonal 7-coordinate structure while the heavier/smaller ones adopt a cubic 6-coordinate "C-MO" structure. All of the sesquioxides are basic, and absorb water and carbon dioxide from air to form carbonates, hydroxides and hydroxycarbonates. They dissolve in acids to form salts.

Cerium forms a stoichiometric dioxide, CeO, where cerium has an oxidation state of +4. CeO is basic and dissolves with difficulty in acid to form Ce solutions, from which Ce salts can be isolated, for example the hydrated nitrate Ce(NO).5HO. CeO is used as an oxidation catalyst in catalytic converters. Praseodymium and terbium form non-stoichiometric oxides containing Ln, although more extreme reaction conditions can produce stoichiometric (or near stoichiometric) PrO and TbO.

Europium and ytterbium form salt-like monoxides, EuO and YbO, which have a rock salt structure. EuO is ferromagnetic at low temperatures, and is a semiconductor with possible applications in spintronics. A mixed Eu/Eu oxide EuO can be produced by reducing EuO in a stream of hydrogen. Neodymium and samarium also form monoxides, but these are shiny conducting solids, although the existence of samarium monoxide is considered dubious.

All of the lanthanides form hydroxides, Ln(OH). With the exception of lutetium hydroxide, which has a cubic structure, they have the hexagonal UCl structure. The hydroxides can be precipitated from solutions of Ln. They can also be formed by the reaction of the sesquioxide, LnO, with water, but although this reaction is thermodynamically favorable it is kinetically slow for the heavier members of the series. Fajans' rules indicate that the smaller Ln ions will be more polarizing and their salts correspondingly less ionic. The hydroxides of the heavier lanthanides become less basic, for example Yb(OH) and Lu(OH) are still basic hydroxides but will dissolve in hot concentrated NaOH.

All of the lanthanides form LnQ (Q= S, Se, Te). The sesquisulfides can be produced by reaction of the elements or (with the exception of EuS) sulfidizing the oxide (LnO) with HS. The sesquisulfides, LnS generally lose sulfur when heated and can form a range of compositions between LnS and LnS. The sesquisulfides are insulators but some of the LnS are metallic conductors (e.g. CeS) formulated (Ln) (S) (e), while others (e.g. EuS and SmS) are semiconductors. Structurally the sesquisulfides adopt structures that vary according to the size of the Ln metal. The lighter and larger lanthanides favoring 7-coordinate metal atoms, the heaviest and smallest lanthanides (Yb and Lu) favoring 6 coordination and the rest structures with a mixture of 6 and 7 coordination. Polymorphism is common amongst the sesquisulfides. The colors of the sesquisulfides vary metal to metal and depend on the polymorphic form. The colors of the γ-sesquisulfides are LaS, white/yellow; CeS, dark red; PrS, green; NdS, light green; GdS, sand; TbS, light yellow and DyS, orange. The shade of γ-CeS can be varied by doping with Na or Ca with hues ranging from dark red to yellow, and CeS based pigments are used commercially and are seen as low toxicity substitutes for cadmium based pigments.

All of the lanthanides form monochalcogenides, LnQ, (Q= S, Se, Te). The majority of the monochalcogenides are conducting, indicating a formulation LnQ(e-) where the electron is in conduction bands. The exceptions are SmQ, EuQ and YbQ which are semiconductors or insulators but exhibit a pressure induced transition to a conducting state.
Compounds LnQ are known but these do not contain Ln but are Ln compounds containing polychalcogenide anions.

Oxysulfides LnOS are well known, they all have the same structure with 7-coordinate Ln atoms, and 3 sulfur and 4 oxygen atoms as near neighbours.
Doping these with other lanthanide elements produces phosphors. As an example, gadolinium oxysulfide, GdOS doped with Tb produces visible photons when irradiated with high energy X-rays and is used as a scintillator in flat panel detectors.
When mischmetal, an alloy of lanthanide metals, is added to molten steel to remove oxygen and sulfur, stable oxysulfides are produced that form an immiscible solid.

All of the lanthanides form a mononitride, LnN, with the rock salt structure. The mononitrides have attracted interest because of their unusual physical properties. SmN and EuN are reported as being "half metals". NdN, GdN, TbN and DyN are ferromagnetic, SmN is antiferromagnetic. Applications in the field of spintronics are being investigated.
CeN is unusual as it is a metallic conductor, contrasting with the other nitrides also with the other cerium pnictides. A simple description is CeN (e–) but the interatomic distances are a better match for the trivalent state rather than for the tetravalent state. A number of different explanations have been offered.
The nitrides can be prepared by the reaction of lanthanum metals with nitrogen. Some nitride is produced along with the oxide, when lanthanum metals are ignited in air. Alternative methods of synthesis are a high temperature reaction of lanthanide metals with ammonia or the decomposition of lanthanide amides, Ln(NH). Achieving pure stoichiometric compounds, and crystals with low defect density has proved difficult. The lanthanide nitrides are sensitive to air and hydrolyse producing ammonia.

The other pnictides phosphorus, arsenic, antimony and bismuth also react with the lanthanide metals to form monopnictides, LnQ. Additionally a range of other compounds can be produced with varying stoichiometries, such as LnP, LnP, LnP, LnAs, LnAs and LnAs.

Carbides of varying stoichiometries are known for the lanthanides. Non-stoichiometry is common. All of the lanthanides form LnC and LnC which both contain C units. The dicarbides with exception of EuC, are metallic conductors with the calcium carbide structure and can be formulated as LnC(e–). The C-C bond length is longer than that in CaC, which contains the C anion, indicating that the antibonding orbitals of the C anion are involved in the conduction band. These dicarbides hydrolyse to form hydrogen and a mixture of hydrocarbons. EuC and to a lesser extent YbC hydrolyse differently producing a higher percentage of acetylene (ethyne). The sesquicarbides, LnC can be formulated as Ln(C). These compounds adopt the PuC structure which has been described as having C anions in bisphenoid holes formed by eight near Ln neighbours. The lengthening of the C-C bond is less marked in the sesquicarbides than in the dicarbides, with the exception of CeC.
Other carbon rich stoichiometries are known for some lanthanides. LnC (Ho-Lu) containing C, C and C units; LnC (Ho-Lu) contain C atoms and C units and LnC (Gd-Ho) containing C and C units.
Metal rich carbides contain interstitial C atoms and no C or C units. These are LnC (Tb and Lu); LnC (Dy, Ho, Tm) and LnC (Sm-Lu).

All of the lanthanides form a number of borides. The "higher" borides (LnB where x > 12) are insulators/semiconductors whereas the lower borides are typically conducting. The lower borides have stoichiometries of LnB, LnB, LnB and LnB. Applications in the field of spintronics are being investigated. The range of borides formed by the lanthanides can be compared to those formed by the transition metals. The boron rich borides are typical of the lanthanides (and groups 1–3) whereas for the transition metals tend to form metal rich, "lower" borides. The lanthanide borides are typically grouped together with the group 3 metals with which they share many similarities of reactivity, stoichiometry and structure. Collectively these are then termed the rare earth borides.

Many methods of producing lanthanide borides have been used, amongst them are direct reaction of the elements; the reduction of LnO with boron; reduction of boron oxide, BO, and LnO together with carbon; reduction of metal oxide with boron carbide, BC. Producing high purity samples has proved to be difficult. Single crystals of the higher borides have been grown in a low melting metal (e.g. Sn, Cu, Al).

Diborides, LnB, have been reported for Sm, Gd, Tb, Dy, Ho, Er, Tm, Yb and Lu. All have the same, AlB, structure containing a graphitic layer of boron atoms. Low temperature ferromagnetic transitions for Tb, Dy, Ho and Er. TmB is ferromagnetic at 7.2 K.

Tetraborides, LnB have been reported for all of the lanthanides except EuB, all have the same UB structure. The structure has a boron sub-lattice consists of chains of octahedral B clusters linked by boron atoms. The unit cell decreases in size successively from LaB to LuB. The tetraborides of the lighter lanthanides melt with decomposition to LnB. Attempts to make EuB have failed. The LnB are good conductors and typically antiferromagnetic.

Hexaborides, LnB have been reported for all of the lanthanides. They all have the CaB structure, containing B clusters. They are non-stoichiometric due to cation defects. The hexaborides of the lighter lanthanides (La – Sm) melt without decomposition, EuB decomposes to boron and metal and the heavier lanthanides decompose to LnB with exception of YbB which decomposes forming YbB. The stability has in part been correlated to differences in volatility between the lanthanide metals. In EuB and YbB the metals have an oxidation state of +2 whereas in the rest of the lanthanide hexaborides it is +3. This rationalises the differences in conductivity, the extra electrons in the Ln hexaborides entering conduction bands. EuB is a semiconductor and the rest are good conductors. LaB and CeB are thermionic emitters, used, for example, in scanning electron microscopes.

Dodecaborides, LnB, are formed by the heavier smaller lanthanides, but not by the lighter larger metals, La – Eu. With the exception YbB (where Yb takes an intermediate valence and is a Kondo insulator), the dodecaborides are all metallic compounds. They all have the UB structure containing a 3 dimensional framework of cubooctahedral B clusters.

The higher boride LnB is known for all lanthanide metals. The composition is approximate as the compounds are non-stoichiometric. They all have similar complex structure with over 1600 atoms in the unit cell. The boron cubic sub lattice contains super icosahedra made up of a central B icosahedra surrounded by 12 others, B(B). Other complex higher borides LnB (Tb, Dy, Ho Er Tm Lu) and LnB are known (Gd, Tb, Dy, Ho, Er) and these contain boron icosahedra in the boron framework.

Lanthanide-carbon σ bonds are well known; however as the 4f electrons have a low probability of existing at the outer region of the atom there is little effective orbital overlap, resulting in bonds with significant ionic character. As such organo-lanthanide compounds exhibit carbanion-like behavior, unlike the behavior in transition metal organometallic compounds. Because of their large size, lanthanides tend to form more stable organometallic derivatives with bulky ligands to give compounds such as Ln[CH(SiMe)]. Analogues of uranocene are derived from dilithiocyclooctatetraene, LiCH. Organic lanthanide(II) compounds are also known, such as Cp*Eu.

All the trivalent lanthanide ions, except lanthanum and lutetium, have unpaired f electrons. However, the magnetic moments deviate considerably from the spin-only values because of strong spin-orbit coupling. The maximum number of unpaired electrons is 7, in Gd, with a magnetic moment of 7.94 B.M., but the largest magnetic moments, at 10.4–10.7 B.M., are exhibited by Dy and Ho. However, in Gd all the electrons have parallel spin and this property is important for the use of gadolinium complexes as contrast reagent in MRI scans.
Crystal field splitting is rather small for the lanthanide ions and is less important than spin-orbit coupling in regard to energy levels. Transitions of electrons between f orbitals are forbidden by the Laporte rule. Furthermore, because of the "buried" nature of the f orbitals, coupling with molecular vibrations is weak. Consequently, the spectra of lanthanide ions are rather weak and the absorption bands are similarly narrow. Glass containing holmium oxide and holmium oxide solutions (usually in perchloric acid) have sharp optical absorption peaks in the spectral range 200–900 nm and can be used as a wavelength calibration standard for optical spectrophotometers, and are available commercially.

As f-f transitions are Laporte-forbidden, once an electron has been excited, decay to the ground state will be slow. This makes them suitable for use in lasers as it makes the population inversion easy to achieve. The is one that is widely used. Europium-doped yttrium vanadate was the first red phosphor to enable the development of color television screens. Lanthanide ions have notable luminescent properties due to their unique 4f orbitals. Laporte forbidden f-f transitions can be activated by excitation of a bound "antenna" ligand. This leads to sharp emission bands throughout the visible, NIR, and IR and relatively long luminescence lifetimes.

The lanthanide contraction is responsible for the great geochemical divide that splits the lanthanides into light and heavy-lanthanide enriched minerals, the latter being almost inevitably associated with and dominated by yttrium. This divide is reflected in the first two "rare earths" that were discovered: yttria (1794) and ceria (1803). The geochemical divide has put more of the light lanthanides in the Earth's crust, but more of the heavy members in the Earth's mantle. The result is that although large rich ore-bodies are found that are enriched in the light lanthanides, correspondingly large ore-bodies for the heavy members are few. The principal ores are monazite and bastnäsite. Monazite sands usually contain all the lanthanide elements, but the heavier elements are lacking in bastnäsite. The lanthanides obey the Oddo-Harkins rule – odd-numbered elements are less abundant than their even-numbered neighbors.

Three of the lanthanide elements have radioactive isotopes with long half-lives (La, Sm and Lu) that can be used to date minerals and rocks from Earth, the Moon and meteorites.

Lanthanide elements and their compounds have many uses but the quantities consumed are relatively small in comparison to other elements. About 15000 ton/year of the lanthanides are consumed as catalysts and in the production of glasses. This 15000 tons corresponds to about 85% of the lanthanide production. From the perspective of value, however, applications in phosphors and magnets are more important.

The devices lanthanide elements are used in include superconductors, samarium-cobalt and neodymium-iron-boron high-flux rare-earth magnets, magnesium alloys, electronic polishers, refining catalysts and hybrid car components (primarily batteries and magnets). Lanthanide ions are used as the active ions in luminescent materials used in optoelectronics applications, most notably the laser. Erbium-doped fiber amplifiers are significant devices in optical-fiber communication systems. Phosphors with lanthanide dopants are also widely used in cathode ray tube technology such as television sets. The earliest color television CRTs had a poor-quality red; europium as a phosphor dopant made good red phosphors possible. Yttrium iron garnet (YIG) spheres can act as tunable microwave resonators. Lanthanide oxides are mixed with tungsten to improve their high temperature properties for TIG welding, replacing thorium, which was mildly hazardous to work with. Many defense-related products also use lanthanide elements such as night vision goggles and rangefinders. The SPY-1 radar used in some Aegis equipped warships, and the hybrid propulsion system of s all use rare earth magnets in critical capacities.
The price for lanthanum oxide used in fluid catalytic cracking has risen from $5 per kilogram in early 2010 to $140 per kilogram in June 2011.

Most lanthanides are widely used in lasers, and as (co-)dopants in doped-fiber optical amplifiers; for example, in Er-doped fiber amplifiers, which are used as repeaters in the terrestrial and submarine fiber-optic transmission links that carry internet traffic. These elements deflect ultraviolet and infrared radiation and are commonly used in the production of sunglass lenses. Other applications are summarized in the following table:
The complex Gd(DOTA) is used in magnetic resonance imaging.

As mentioned in the industrial applications section above, lanthanide metals are particularly useful in technologies that take advantage of their reactivity to specific wavelengths of light. Certain life science applications take advantage of the unique luminescence properties of lanthanide ion complexes (Ln(III) chelates or cryptates). These are well-suited for this application due to their large Stokes shifts and extremely long emission lifetimes (from microseconds to milliseconds) compared to more traditional fluorophores (e.g., fluorescein, allophycocyanin, phycoerythrin, and rhodamine). The biological fluids or serum commonly used in these research applications contain many compounds and proteins which are naturally fluorescent. Therefore, the use of conventional, steady-state fluorescence measurement presents serious limitations in assay sensitivity. Long-lived fluorophores, such as lanthanides, combined with time-resolved detection (a delay between excitation and emission detection) minimizes prompt fluorescence interference.

Time-resolved fluorometry (TRF) combined with fluorescence resonance energy transfer (FRET) offers a powerful tool for drug discovery researchers: Time-Resolved Fluorescence Resonance Energy Transfer or TR-FRET. TR-FRET combines the low background aspect of TRF with the homogeneous assay format of FRET. The resulting assay provides an increase in flexibility, reliability and sensitivity in addition to higher throughput and fewer false positive/false negative results.

This method involves two fluorophores: a donor and an acceptor. Excitation of the donor fluorophore (in this case, the lanthanide ion complex) by an energy source (e.g. flash lamp or laser) produces an energy transfer to the acceptor fluorophore if they are within a given proximity to each other (known as the Förster's radius). The acceptor fluorophore in turn emits light at its characteristic wavelength.

The two most commonly used lanthanides in life science assays are shown below along with their corresponding acceptor dye as well as their excitation and emission wavelengths and resultant Stokes shift (separation of excitation and emission wavelengths).
Currently there is research showing that lanthanide elements can be used as anticancer agents. The main role of the lanthanides in these studies is to inhibit proliferation of the cancer cells. Specifically cerium and lanthanum have been studied for their role as anti-cancer agents.

One of the specific elements from the lanthanide group that has been tested and used is cerium (Ce). There have been studies that use a protein-cerium complex to observe the effect of cerium on the cancer cells. The hope was to inhibit cell proliferation and promote cytotoxicity. Transferrin receptors in cancer cells, such as those in breast cancer cells and epithelial cervical cells, promote the cell proliferation and malignancy of the cancer. Transferrin is a protein used to transport iron into the cells and is needed to aid the cancer cells in DNA replication. Transferrin acts as a growth factor for the cancerous cells and is dependent on iron. Cancer cells have much higher levels of transferrin receptors than normal cells and are very dependent on iron for their proliferation. Cerium has shown results as an anti-cancer agent due to its similarities in structure and biochemistry to iron. Cerium may bind in the place of iron on to the transferrin and then be brought into the cancer cells by transferrin-receptor mediated endocytosis. The cerium binding to the transferrin in place of the iron inhibits the transferrin activity in the cell. This creates a toxic environment for the cancer cells and causes a decrease in cell growth. This is the proposed mechanism for cerium's effect on cancer cells, though the real mechanism may be more complex in how cerium inhibits cancer cell proliferation. Specifically in HeLa cancer cells studied in vitro, cell viability was decreased after 48 to 72 hours of cerium treatments. Cells treated with just cerium had decreases in cell viability, but cells treated with both cerium and transferrin had more significant inhibition for cellular activity.

Another specific element that has been tested and used as an anti-cancer agent is lanthanum, more specifically lanthanum chloride (LaCl). The lanthanum ion is used to affect the levels of let-7a and microRNAs miR-34a in a cell throughout the cell cycle. When the lanthanum ion was introduced to the cell in vivo or in vitro, it inhibited the rapid growth and induced apoptosis of the cancer cells (specifically cervical cancer cells). This effect was caused by the regulation of the let-7a and microRNAs by the lanthanum ions. The mechanism for this effect is still unclear but it is possible that the lanthanum is acting in a similar way as the cerium and binding to a ligand necessary for cancer cell proliferation.

Due to their sparse distribution in the earth's crust and low aqueous solubility, the lanthanides have a low availability in the biosphere, and for a long time were not known to naturally form part of any biological molecules. In 2007 a novel methanol dehydrogenase that strictly uses lanthanides as enzymatic cofactors was discovered in a bacterium from the phylum Verrucomicrobia, "Methylacidiphilum fumariolicum". This bacterium was found to survive only if there are lanthanides present in the environment. Compared to most other nondietary elements, non-radioactive lanthanides are classified as having low toxicity.




</doc>
<doc id="18309" url="https://en.wikipedia.org/wiki?curid=18309" title="Lucifer">
Lucifer

Lucifer ( ; ; 'light-bringer', corresponding to the Greek name, Ἑωσφόρος. 'dawn-bringer', for the same planet) is a Latin name for the planet Venus in its morning appearances, and is often used for mythological and religious figures associated with the planet. Due to the unique movements and discontinuous appearances of Venus in the sky, mythology surrounding these figures often involved a fall from the heavens to earth or the underworld. Interpretations of a similar term in the Hebrew Bible, translated in the King James Version as "Lucifer", led to a Christian tradition of applying the name Lucifer, and its associated stories of a fall from heaven, to Satan. Most modern scholarship regards these interpretations as questionable, and translates the term in the relevant Bible passage (Isaiah 14:12) as "morning star" or "shining one" rather than as a proper name, "Lucifer".

As a name for the Devil, the more common meaning in English, "Lucifer" is the rendering of the Hebrew word (transliteration: "hêylêl"; pronunciation: "hay-lale") in Isaiah () given in the King James Version of the Bible. The translators of this version took the word from the Latin Vulgate, which translated הֵילֵל by the Latin word "lucifer" (uncapitalized), meaning "the morning star, the planet Venus", or, as an adjective, "light-bringing".

As a name for the planet in its morning aspect, "Lucifer" (Light-Bringer) is a proper name and is capitalized in English. In Greco-Roman civilization, it was often personified and considered a god and in some versions considered a son of Aurora (the Dawn). A similar name used by the Roman poet Catullus for the planet in its evening aspect is "Noctifer" (Night-Bringer).

The motif of a heavenly being striving for the highest seat of heaven only to be cast down to the underworld has its origins in the motions of the planet Venus, known as the morning star.

The Sumerian goddess Inanna (Babylonian Ishtar) is associated with the planet Venus, and Inanna's actions in several of her myths, including "Inanna and Shukaletuda" and "Inanna's Descent into the Underworld" appear to parallel the motion of Venus as it progresses through its synodic cycle.

A similar theme is present in the Babylonian myth of Etana. The "Jewish Encyclopedia" comments:

The fall from heaven motif also has a parallel in Canaanite mythology. In ancient Canaanite religion, the morning star is personified as the god Attar, who attempted to occupy the throne of Ba'al and, finding he was unable to do so, descended and ruled the underworld. The original myth may have been about a lesser god Helel trying to dethrone the Canaanite high god El who lived on a mountain to the north. Hermann Gunkel's reconstruction of the myth told of a mighty warrior called Hêlal, whose ambition was to ascend higher than all the other stellar divinities, but who had to descend to the depths; it thus portrayed as a battle the process by which the bright morning star fails to reach the highest point in the sky before being faded out by the rising sun. However, the Eerdmans Commentary on the Bible argues that no evidence has been found of any Canaanite myth or imagery of a god being forcibly thrown from heaven, as in the "Book of Isaiah" (see below). It argues that the closest parallels with "Isaiah"'s description of the king of Babylon as a fallen morning star cast down from heaven are to be found not in Canaanite myths but in traditional ideas of the Jewish people, echoed in the Biblical account of the fall of Adam and Eve, cast out of God's presence for wishing to be as God, and the picture in Psalm 82 of the "gods" and "sons of the Most High" destined to die and fall. This Jewish tradition has echoes also in Jewish pseudepigrapha such as 2 Enoch and the "Life of Adam and Eve". The "Life of Adam and Eve", in turn, shaped the idea of Iblis in the Quran.

The Greek myth of Phaethon, a personification of the planet Jupiter, follows a similar pattern.

In classical mythology, Lucifer ("light-bringer" in Latin) was the name of the planet Venus, though it was often personified as a male figure bearing a torch. The Greek name for this planet was variously Phosphoros (also meaning "light-bringer") or Heosphoros (meaning "dawn-bringer"). Lucifer was said to be "the fabled son of Aurora and Cephalus, and father of Ceyx". He was often presented in poetry as heralding the dawn.

The Latin word corresponding to Greek "Phosphoros" is "Lucifer". It is used in its astronomical sense both in prose and poetry. Poets sometimes personify the star, placing it in a mythological context.

Lucifer's mother Aurora is cognate to the Vedic goddess "Ushas", Lithuanian goddess "Aušrinė", and Greek Eos, all three of whom are also goddesses of the dawn. All four are considered derivatives of the Proto-Indo-European stem "*h₂ewsṓs" (later *"Ausṓs"), "dawn", a stem that also gave rise to Proto-Germanic "*Austrō", Old Germanic "*Ōstara" and Old English "Ēostre / Ēastre". This agreement leads to the reconstruction of a Proto-Indo-European dawn goddess.

The second century Roman mythographer Pseudo-Hyginus said of the planet: 

Ovid, in his first-century epic "Metamorphoses", describes Lucifer as ordering the heavens:

The Latin poet Ovid, speaking of Phosphorus and Hesperus (the Evening Star, the evening appearance of the planet Venus) as identical, makes him the father of Daedalion. Ovid also makes him the father of Ceyx, while the Latin grammarian Servius makes him the father of the Hesperides or of Hesperis.

In the classical Roman period, Lucifer was not typically regarded as a deity and had few, if any, myths, though the planet was associated with various deities and often poetically personified. Cicero pointed out that "You say that Sol the Sun and Luna the Moon are deities, and the Greeks identify the former with Apollo and the latter with Diana. But if Luna (the Moon) is a goddess, then Lucifer (the Morning-Star) also and the rest of the Wandering Stars (Stellae Errantes) will have to be counted gods; and if so, then the Fixed Stars (Stellae Inerrantes) as well."

In the Book of Isaiah, chapter 14, the king of Babylon is condemned in a prophetic vision by the prophet Isaiah and is called (, Hebrew for "shining one, son of the morning"). who is addressed as הילל בן שחר ("Hêlêl ben Šāḥar"), The title ""Helel ben Shahar"" refers to the planet Venus as the morning star, and that is how the Hebrew word is usually interpreted. The Hebrew word transliterated as "Hêlêl" or "Heylel" (pron. as "Hay-LALE"), occurs only once in the Hebrew Bible. The Septuagint renders הֵילֵל in Greek as Ἑωσφόρος ("heōsphoros"), "bringer of dawn", the Ancient Greek name for the morning star. Similarly the Vulgate renders הֵילֵל in Latin as "Lucifer", the name in that language for the morning star. According to the King James Bible-based Strong's Concordance, the original Hebrew word means "shining one, light-bearer", and the English translation given in the King James text is the Latin name for the planet Venus, "Lucifer", as it was already in the Wycliffe Bible.

However, the translation of הֵילֵל as "Lucifer" has been abandoned in modern English translations of Isaiah 14:12. Present-day translations render הֵילֵל as "morning star" (New International Version, New Century Version, New American Standard Bible, Good News Translation, Holman Christian Standard Bible, Contemporary English Version, Common English Bible, Complete Jewish Bible), "daystar" (New Jerusalem Bible, The Message), "Day Star" (New Revised Standard Version, English Standard Version), "shining one" (New Life Version, New World Translation, JPS Tanakh), or "shining star" (New Living Translation).

In a modern translation from the original Hebrew, the passage in which the phrase "Lucifer" or "morning star" occurs begins with the statement: "On the day the Lord gives you relief from your suffering and turmoil and from the harsh labour forced on you, you will take up this taunt against the king of Babylon: How the oppressor has come to an end! How his fury has ended!" After describing the death of the king, the taunt continues:

J. Carl Laney has pointed out that in the final verses here quoted, the king of Babylon is described not as a god or an angel but as a man, and that man may have been not Nebuchadnezzar II, but rather his son, Belshazzar. Nebuchadnezzar was gripped by a spiritual fervor to build a temple to the moon god Sin, and his son ruled as regent. The Abrahamic scriptural texts could be interpreted as a weak usurping of true kingly power, and a taunt at the failed regency of Belshazzar.

For the unnamed "king of Babylon" a wide range of identifications have been proposed. They include a Babylonian ruler of the prophet Isaiah's own time the later Nebuchadnezzar II, under whom the Babylonian captivity of the Jews began, or Nabonidus, and the Assyrian kings Tiglath-Pileser, Sargon II and Sennacherib. Verse 20 says that this king of Babylon will not be "joined with them [all the kings of the nations] in burial, because thou hast destroyed thy land, thou hast slain thy people; the seed of evil-doers shall not be named for ever", but rather be cast out of the grave, while "All the kings of the nations, all of them, sleep in glory, every one in his own house". Herbert Wolf held that the "king of Babylon" was not a specific ruler but a generic representation of the whole line of rulers.

Isaiah 14:12 became a source for the popular conception of the fallen angel motif seen later in 1 Enoch 86–90 and 2 Enoch 29:3–4. Rabbinical Judaism has rejected any belief in rebel or fallen angels. In the 11th century, the "Pirkei De-Rabbi Eliezer" illustrates the origin of the "fallen angel myth" by giving two accounts, one relates to the angel in the Garden of Eden who seduces Eve, and the other relates to the angels, the "benei elohim" who cohabit with the daughters of man (Genesis 6:1–4). An association of Isaiah 14:12–18 with a personification of evil, called the devil developed outside of mainstream Rabbinic Judaism in pseudepigrapha and Christian writings, particularly with the apocalypses.

Some Christian writers have applied the name "Lucifer" as used in the Book of Isaiah, and the motif of a heavenly being cast down to the earth, to Satan. Sigve K Tonstad argues that the New Testament War in Heaven theme of Revelation 12 (), in which the dragon "who is called the devil and Satan … was thrown down to the earth", was derived from the passage about the Babylonian king in Isaiah 14. Origen (184/185 – 253/254) interpreted such Old Testament passages as being about manifestations of the devil; but writing in Greek, not Latin, he did not identify the devil with the name "Lucifer". Origen was not the first to interpret the Isaiah 14 passage as referring to the devil: he was preceded by at least Tertullian (c. 160 – c. 225), who in his "Adversus Marcionem" (book 5, chapters 11 and 27) twice presents as spoken by the devil the words of : "I will ascend above the tops of the clouds; I will make myself like the Most High". Though Tertullian was a speaker of the language in which the word "lucifer" was created, "Lucifer" is not among the numerous names and phrases he used to describe the devil. Even at the time of the Latin writer Augustine of Hippo (354–430), a contemporary of the composition of the Vulgate, "Lucifer" had not yet become a common name for the devil.

Some time later, the metaphor of the morning star that Isaiah 14:12 applied to a king of Babylon gave rise to the general use of the Latin word for "morning star", capitalized, as the original name of the devil before his fall from grace, linking Isaiah 14:12 with Luke 10 () ("I saw Satan fall like lightning from heaven") and interpreting the passage in Isaiah as an allegory of Satan's fall from heaven.

As a result, "Lucifer has become a byword for Satan or the devil in the church and in popular literature", as in Dante Alighieri's "Inferno", Joost van den Vondel's "Lucifer", and John Milton's "Paradise Lost". However, unlike the English word, the Latin word was not used exclusively in this way and was applied to others also, including Jesus: the Latin (Vulgate) text of Revelation 22:16 (where English translations refer to Jesus as "the bright morning star") has "stella matutina", not "lucifer", but the term "lucifer" is applied to Jesus in the Easter "Exultet" and in a hymn by Hilary of Poitiers that contains the phrase: ""Tu verus mundi lucifer"" (You are the true light bringer of the world).

Adherents of the King James Only movement and others who hold that Isaiah 14:12 does indeed refer to the devil have decried the modern translations. An opposing view attributes to Origen the first identification of the "Lucifer" of Isaiah 14:12 with the devil and to Tertullian and Augustine of Hippo the spread of the story of Lucifer as fallen through pride, envy of God and jealousy of humans.

However, the understanding of the morning star in Isaiah 14:12 as a metaphor referring to a king of Babylon continued also to exist among Christians. Theodoret of Cyrus (c. 393 – c. 457) wrote that Isaiah calls the king "morning star", not as being the star, but as having had the illusion of being it. The same understanding is shown in Christian translations of the passage, which in English generally use "morning star" rather than treating the word as a proper name, "Lucifer". So too in other languages, such as French, German, Portuguese, and Spanish. Even the Vulgate text in Latin is printed with lower-case "lucifer" (morning star), not upper-case "Lucifer" (proper name).

John Calvin said: "The exposition of this passage, which some have given, as if it referred to Satan, has arisen from ignorance: for the context plainly shows these statements must be understood in reference to the king of the Babylonians." Martin Luther also considered it a gross error to refer this verse to the devil.
In the Bogomil and Cathar text "Gospel of the secret supper", Lucifer is a glorified angel and the older brother of Jesus, but fell from heaven to establish his own kingdom and became the Demiurge. Therefore, he created the material world and trapped souls from heaven inside matter. Jesus descended to earth to free the captured souls. In contrast to mainstream Christianity, the cross was denounced as a symbol of Lucifer and his instrument in an attempt to kill Jesus.

Lucifer is regarded within The Church of Jesus Christ of Latter-day Saints as the pre-mortal name of the devil. Mormon theology teaches that in a heavenly council, Lucifer rebelled against the plan of God the Father and was subsequently cast out. The Church's scripture reads:"And this we saw also, and bear record, that an angel of God who was in authority in the presence of God, who rebelled against the Only Begotten Son whom the Father loved and who was in the bosom of the Father, was thrust down from the presence of God and the Son, and was called Perdition, for the heavens wept over him—he was Lucifer, a son of the morning. And we beheld, and lo, he is fallen! is fallen, even a son of the morning! And while we were yet in the Spirit, the Lord commanded us that we should write the vision; for we beheld Satan, that old serpent, even the devil, who rebelled against God, and sought to take the kingdom of our God and his Christ—Wherefore, he maketh war with the saints of God, and encompasseth them round about."After becoming Satan by his fall, Lucifer "goeth up and down, to and fro in the earth, seeking to destroy the souls of men". Members of the Church of Jesus Christ of Latter-Day Saints consider Isaiah 14:12 to be referring to both the king of the Babylonians and the devil.

Other instances of "lucifer" in the Old Testament pseudepigrapha are related to the "star" Venus, in the Sibylline Oracles battle of the constellations (line 517) "Lucifer fought mounted on the back of Leo", or the entirely rewritten Christian version of the Greek Apocalypse of Ezra 4:32 which has a reference to Lucifer as Antichrist.

Indications that in Christian tradition the Latin word "lucifer", unlike the English word, did not necessarily call a fallen angel to mind exist also outside the text of the Vulgate. Two bishops bore that name: Saint Lucifer of Cagliari, and Lucifer of Siena.

In Latin, the word is applied to John the Baptist and is used as a title of Jesus himself in several early Christian hymns. The morning hymn "Lucis largitor splendide" of Hilary contains the line: ""Tu verus mundi lucifer"" (you are the true light bringer of the world). Some interpreted the mention of the morning star ("lucifer") in Ambrose's hymn "Aeterne rerum conditor" as referring allegorically to Jesus and the mention of the cock, the herald of the day ("praeco") in the same hymn as referring to John the Baptist. Likewise, in the medieval hymn "Christe qui lux es et dies", some manuscripts have the line "Lucifer lucem proferens".

The Latin word "lucifer" is also used of Jesus in the Easter Proclamation prayer to God regarding the paschal candle: "Flammas eius lucifer matutinus inveniat: ille, inquam, lucifer, qui nescit occasum. Christus Filius tuus, qui, regressus ab inferis, humano generi serenus illuxit, et vivit et regnat in saecula saeculorum" ("May this flame be found still burning by the Morning Star: the one Morning Star who never sets, Christ your Son, who, coming back from death's domain, has shed his peaceful light on humanity, and lives and reigns for ever and ever"). In the works of Latin grammarians, Lucifer, like Daniel, was discussed as an example of a personal name.

Rudolf Steiner's writings, which formed the basis for Anthroposophy, characterised Lucifer as a spiritual opposite to Ahriman, with Christ between the two forces, mediating a balanced path for humanity. Lucifer represents an intellectual, imaginative, delusional, otherworldly force which might be associated with visions, subjectivity, psychosis and fantasy. He associated Lucifer with the religious/philosophical cultures of Egypt, Rome and Greece. Steiner believed that Lucifer, as a supersensible Being, had incarnated in China about 3000 years before the birth of Christ.

Luciferianism is a belief structure that venerates the fundamental traits that are attributed to Lucifer. The custom, inspired by the teachings of Gnosticism, usually reveres Lucifer not as the devil, but as a savior, a guardian or instructing spirit or even the true god as opposed to Jehovah.

In Anton LaVey's "The Satanic Bible", Lucifer is one of the four crown princes of hell, particularly that of the East, the 'lord of the air', and is called the bringer of light, the morning star, intellectualism, and enlightenment. The title 'lord of the air' is based upon Ephesians 2:2, which uses the phrase 'prince of the power of the air' to refer to the pagan god Zeus, but that phrase later became conflated with Satan.

Author Michael W. Ford has written on Lucifer as a "mask" of the adversary, a motivator and illuminating force of the mind and subconscious.

Léo Taxil (1854–1907) claimed that Freemasonry is associated with worshipping Lucifer. In what is known as the Taxil hoax, he alleged that leading Freemason Albert Pike had addressed "The 23 Supreme Confederated Councils of the world" (an invention of Taxil), instructing them that Lucifer was God, and was in opposition to the evil god Adonai. Taxil promoted a book by Diana Vaughan (actually written by himself, as he later confessed publicly) that purported to reveal a highly secret ruling body called the Palladium, which controlled the organization and had a satanic agenda. As described by "Freemasonry Disclosed" in 1897:
Supporters of Freemasonry assert that, when Albert Pike and other Masonic scholars spoke about the "Luciferian path," or the "energies of Lucifer," they were referring to the Morning Star, the light bearer, the search for light; the very antithesis of dark. Pike says in Morals and Dogma, "Lucifer, the Son of the Morning! Is it "he" who bears the Light, and with its splendors intolerable blinds feeble, sensual, or selfish Souls? Doubt it not!" Much has been made of this quote.

Taxil's work and Pike's address continue to be quoted by anti-masonic groups.

In "Devil-Worship in France", Arthur Edward Waite compared Taxil's work to today's tabloid journalism, replete with logical and factual inconsistencies.

In a collection of folklore and magical practices supposedly collected in Italy by Charles Godfrey Leland and published in his "Aradia, or the Gospel of the Witches", the figure of Lucifer is featured prominently as both the brother and consort of the goddess Diana, and father of Aradia, at the center of an alleged Italian witch-cult. In Leland's mythology, Diana pursued her brother Lucifer across the sky as a cat pursues a mouse. According to Leland, after dividing herself into light and darkness:

Here, the motions of Diana and Lucifer once again mirror the celestial motions of the moon and Venus, respectively. Though Leland's Lucifer is based on the classical personification of the planet Venus, he also incorporates elements from Christian tradition, as in the following passage: 

In the several modern Wiccan traditions based in part on Leland's work, the figure of Lucifer is usually either omitted or replaced as Diana's consort with either the Etruscan god Tagni, or Dianus (Janus, following the work of folklorist James Frazer in "The Golden Bough").




</doc>
<doc id="18310" url="https://en.wikipedia.org/wiki?curid=18310" title="Lambda phage">
Lambda phage

Enterobacteria phage λ (lambda phage, coliphage λ, officially Escherichia virus Lambda) is a bacterial virus, or bacteriophage, that infects the bacterial species "Escherichia coli" ("E. coli"). It was discovered by Esther Lederberg in 1950. The wild type of this virus has a temperate life cycle that allows it to either reside within the genome of its host through lysogeny or enter into a lytic phase, during which it kills and lyses the cell to produce offspring. Lambda strains, mutated at specific sites, are unable to lysogenize cells; instead, they grow and enter the lytic cycle after superinfecting an already lysogenized cell.

The phage particle consists of a head (also known as a capsid), a tail, and tail fibers (see image of virus below). The head contains the phage's double-strand linear DNA genome. During infection, the phage particle recognizes and binds to its host, "E. coli", causing DNA in the head of the phage to be ejected through the tail into the cytoplasm of the bacterial cell. Usually, a "lytic cycle" ensues, where the lambda DNA is replicated and new phage particles are produced within the cell. This is followed by cell lysis, releasing the cell contents, including virions that have been assembled, into the environment. However, under certain conditions, the phage DNA may integrate itself into the host cell chromosome in the lysogenic pathway. In this state, the λ DNA is called a prophage and stays resident within the host's genome without apparent harm to the host. The host is termed a lysogen when a prophage is present. This prophage may enter the lytic cycle when the lysogen enters a stressed condition.

The virus particle consists of a head and a tail that can have tail fibers. The whole particle consists of 12–14 different proteins with more than 1000 protein molecules total and one DNA molecule located in the phage head. However, it is still not entirely clear whether the L and M proteins are part of the virion.

The genome contains 48,490 base pairs of double-stranded, linear DNA, with 12-base single-strand segments at both 5' ends. These two single-stranded segments are the "sticky ends" of what is called the "cos" site. The "cos" site circularizes the DNA in the host cytoplasm. In its circular form, the phage genome, therefore, is 48,502 base pairs in length. The lambda genome can be inserted into the " E. coli" chromosome and is then called a prophage. See section below for details.

Lambda phage is a non-contractile tailed phage, meaning during an infection event it cannot 'force' its DNA through a bacterial cell membrane. It must instead use an existing pathway to invade the host cell, having evolved the tip of its tail to interact with a specific pore to allow entry of its DNA to the hosts.



On initial infection, the stability of cII determines the lifestyle of the phage; stable cII will lead to the lysogenic pathway, whereas if cII is degraded the phage will go into the lytic pathway. Low temperature, starvation of the cells and high multiplicity of infection (MOI) are known to favor lysogeny (see later discussion).

This occurs without the N protein interacting with the DNA; the protein instead binds to the freshly transcribed mRNA. Nut sites contain 3 conserved "boxes," of which only BoxB is essential.

This is the lifecycle that the phage follows following most infections, where the cII protein does not reach a high enough concentration due to degradation, so does not activate its promoters.

Rightward transcription expresses the O, P and Q genes. O and P are responsible for initiating replication, and Q is another antiterminator that allows the expression of head, tail, and lysis genes from "P".


Q is similar to N in its effect: Q binds to RNA polymerase in "Qut" sites and the resulting complex can ignore terminators, however the mechanism is very different; the Q protein first associates with a DNA sequence rather than an mRNA sequence.

Leftward transcription expresses the "gam", "red", "xis", and "int" genes. Gam and red proteins are involved in recombination. Gam is also important in that it inhibits the host RecBCD nuclease from degrading the 3’ ends in rolling circle replication. Int and xis are integration and excision proteins vital to lysogeny.


The lysogenic lifecycle begins once the cI protein reaches a high enough concentration to activate its promoters, after a small number of infections.

The prophage is duplicated with every subsequent cell division of the host. The phage genes expressed in this dormant state code for proteins that repress expression of other phage genes (such as the structural and lysis genes) in order to prevent entry into the lytic cycle. These repressive proteins are broken down when the host cell is under stress, resulting in the expression of the repressed phage genes. Stress can be from starvation, poisons (like antibiotics), or other factors that can damage or destroy the host. In response to stress, the activated prophage is excised from the DNA of the host cell by one of the newly expressed gene products and enters its lytic pathway.

The integration of phage λ takes place at a special attachment site in the bacterial and phage genomes, called "att". The sequence of the bacterial att site is called "attB", between the "gal" and "bio" operons, and consists of the parts B-O-B', whereas the complementary sequence in the circular phage genome is called "attP" and consists of the parts P-O-P'. The integration itself is a sequential exchange (see genetic recombination) via a Holliday junction and requires both the phage protein Int and the bacterial protein IHF ("integration host factor"). Both Int and IHF bind to "attP" and form an intasome, a DNA-protein-complex designed for site-specific recombination of the phage and host DNA. The original B-O-B' sequence is changed by the integration to B-O-P'-phage DNA-P-O-B'. The phage DNA is now part of the host's genome.



The classic induction of a lysogen involved irradiating the infected cells with UV light. Any situation where a lysogen undergoes DNA damage or the SOS response of the host is otherwise stimulated leads to induction.

Multiplicity reactivation (MR) is the process by which multiple viral genomes, each containing inactivating genome damage, interact within an infected cell to form a viable viral genome. MR was originally discovered with phage T4, but was subsequently found in phage λ (as well as in numerous other bacterial and mammalian viruses). MR of phage λ inactivated by UV light depends on the recombination function of either the host or of the infecting phage. Absence of both recombination systems leads to a loss of MR.

Survival of UV-irradiated phage λ is increased when the E. coli host is lysogenic for an homologous prophage, a phenomenon termed prophage reactivation. Prophage reactivation in phage λ appears to occur by a recombinational repair process similar to that of MR.

The repressor found in the phage lambda is a notable example of the level of control possible over gene expression by a very simple system. It forms a 'binary switch' with two genes under mutually exclusive expression, as discovered by Barbara J. Meyer.

The lambda repressor gene system consists of (from left to right on the chromosome):

The lambda repressor is a self assembling dimer also known as the cI protein. It binds DNA in the helix-turn-helix binding motif. It regulates the transcription of the cI protein and the Cro protein.

The life cycle of lambda phages is controlled by cI and Cro proteins. The lambda phage will remain in the lysogenic state if cI proteins predominate, but will be transformed into the lytic cycle if cro proteins predominate.

The cI dimer may bind to any of three operators, O1, O2, and O3, in the order O1 > O2 > O3.
Binding of a cI dimer to O1 enhances binding of a second cI dimer to O2, an effect called cooperativity. Thus, O1 and O2 are almost always simultaneously occupied by cI. However, this does not increase the affinity between cI and O3, which will be occupied only when the cI concentration is high.

At high concentrations of cI, the dimers will also bind to operators O1 and O2 (which are over 2 kb downstream from the R operators). When cI dimers are bound to O1, O2, O1, and O2 a loop is induced in the DNA, allowing these dimers to bind together to form an octamer. This is a phenomenon called "long-range cooperativity". Upon formation of the octamer, cI dimers may cooperatively bind to O3 and O3, repressing transcription of cI. This "autonegative" regulation ensures a stable minimum concentration of the repressor molecule and, should SOS signals arise, allows for more efficient prophage induction.

An important distinction here is that between the two decisions; lysogeny and lysis on infection, and continuing lysogeny or lysis from a prophage. The latter is determined solely by the activation of RecA in the SOS response of the cell, as detailed in the section on induction. The former will also be affected by this; a cell undergoing an SOS response will always be lysed, as no cI protein will be allowed to build up. However, the initial lytic/lysogenic decision on infection is also dependent on the cII and cIII proteins.

In cells with sufficient nutrients, protease activity is high, which breaks down cII. This leads to the lytic lifestyle. In cells with limited nutrients, protease activity is low, making cII stable. This leads to the lysogenic lifestyle. cIII appears to stabilize cII, both directly and by acting as a competitive inhibitor to the relevant proteases. This means that a cell "in trouble", i.e. lacking in nutrients and in a more dormant state, is more likely to lysogenise. This would be selected for because the phage can now lie dormant in the bacterium until it falls on better times, and so the phage can create more copies of itself with the additional resources available and with the more likely proximity of further infectable cells.

A full biophysical model for lambda's lysis-lysogeny decision remains to be developed. Computer modeling and simulation suggest that random processes during infection drive the selection of lysis or lysogeny within individual cells. However, recent experiments suggest that physical differences among cells, that exist prior to infection, predetermine whether a cell will lyse or become a lysogen.

Lambda phage has been used heavily as a model organism, and has been a rich source for useful tools in microbial genetics, and later in molecular genetics. Uses include its application as a vector for the cloning of recombinant DNA; the use of its site-specific recombinase (int) for the shuffling of cloned DNAs by the gateway method; and the application of its Red operon, including the proteins Red alpha (also called 'exo'), beta and gamma in the DNA engineering method called recombineering. The 48 kb DNA fragment of lambda phage is not essential for productive infection and can be replaced by foreign DNA. Lambda phage will enter bacteria more easily than plasmids making it a useful vector that can destroy or can become part of the host's DNA. Lambda phage can be manipulated and used as an anti-cancer vaccine, nanoparticle, targeting human aspartyl (asparaginyl) β-hydroxylase (HAAH). Lambda phage has also been of major importance in the study of specialized transduction.




</doc>
<doc id="18313" url="https://en.wikipedia.org/wiki?curid=18313" title="Louis Armstrong">
Louis Armstrong

Louis Daniel Armstrong (August 4, 1901 – July 6, 1971), nicknamed "Satchmo", "Satch", and "Pops", was an American trumpeter, composer, vocalist, and actor who was among the most influential figures in jazz. His career spanned five decades, from the 1920s to the 1960s, and different eras in the history of jazz. In 2017, he was inducted into the Rhythm & Blues Hall of Fame.

Armstrong was born and raised in New Orleans. Coming to prominence in the 1920s as an inventive trumpet and cornet player, Armstrong was a foundational influence in jazz, shifting the focus of the music from collective improvisation to solo performance. Around 1922, he followed his mentor, Joe "King" Oliver, to Chicago to play in the Creole Jazz Band. In Chicago, he spent time with other popular jazz musicians, reconnecting with his friend Bix Beiderbecke and spending time with Hoagy Carmichael and Lil Hardin. He earned a reputation at "cutting contests", and relocated to New York in order to join Fletcher Henderson's band.

With his instantly recognizable rich, gravelly voice, Armstrong was also an influential singer and skillful improviser, bending the lyrics and melody of a song. He was also skilled at scat singing. Armstrong is renowned for his charismatic stage presence and voice as well as his trumpet playing. By the end of Armstrong's career in the 1960s, his influence had spread to popular music in general. Armstrong was one of the first popular African-American entertainers to "cross over", meaning his music transcended his skin color in a racially divided America. He rarely publicly politicized his race, to the dismay of fellow African Americans, but took a well-publicized stand for desegregation in the Little Rock crisis. He was able to access the upper echelons of American society at a time when this was difficult for black men.

Armstrong often stated that he was born on July 4, 1900. Although he died in 1971, it was not until the mid-1980s that his true birth date, August 4, 1901, was discovered by Tad Jones by researching baptismal records. At least three other biographies treat the July 4th birth date as a myth.

Armstrong was born in New Orleans to Mary Albert and William Armstrong. Albert was from Boutte, Louisiana, and gave birth at home when she was about sixteen. William Armstrong abandoned the family shortly after. About two years later, he had a daughter, Beatrice "Mama Lucy" Armstrong, who was raised by Albert.

Louis Armstrong was raised by his grandmother until the age of five when he was returned to his mother. He spent his youth in poverty in a rough neighborhood known as The Battlefield. At six he attended the Fisk School for Boys, a school that accepted black children in the racially segregated system of New Orleans. He did odd jobs for the Karnoffskys, a family of Lithuanian Jews. While selling coal in Storyville, he heard spasm bands, groups that played music out of household objects. He heard the early sounds of jazz from bands that played in brothels and dance halls such as Pete Lala's, where King Oliver performed.

The Karnoffskys took him in and treated him like family. Knowing he lived without a father, they fed and nurtured him. In his memoir "Louis Armstrong + the Jewish Family in New Orleans, La., the Year of 1907", he described his discovery that this family was also subject to discrimination by "other white folks" who felt that they were better than Jews: "I was only seven years old but I could easily see the ungodly treatment that the white folks were handing the poor Jewish family whom I worked for." He wore a Star of David pendant for the rest of his life and wrote about what he learned from them: "how to live—real life and determination." His first musical performance may have been at the side of the Karnoffsky's junk wagon. To distinguish them from other hawkers, he tried playing a tin horn to attract customers. Morris Karnoffsky gave Armstrong an advance toward the purchase of a cornet from a pawn shop.

When Armstrong was eleven, he dropped out of school. His mother moved into a one-room house on Perdido Street with him, Lucy, and her common-law husband, Tom Lee, next door to her brother Ike and his two sons. Armstrong joined a quartet of boys who sang in the streets for money. He also got into trouble. Cornetist Bunk Johnson said he taught the eleven-year-old to play by ear at Dago Tony's honky tonk. (In his later years Armstrong credited King Oliver.) He said about his youth, "Every time I close my eyes blowing that trumpet of mine—I look right in the heart of good old New Orleans ... It has given me something to live for."

Borrowing his stepfather's gun without permission, he fired a blank into the air and was arrested on December 31, 1912. He spent the night at New Orleans Juvenile Court, then was sentenced the next day to detention at the Colored Waif's Home. Life at the home was spartan. Mattresses were absent. Meals were often little more than bread and molasses. Captain Joseph Jones ran the home like a military camp and used corporal punishment.

Armstrong developed his cornet skills by playing in the band. Peter Davis, who frequently appeared at the home at the request of Captain Jones, became Armstrong's first teacher and chose him as bandleader. With this band, the thirteen year-old Armstrong attracted the attention of Kid Ory.

On June 14, 1914, Armstrong was released into the custody of his father and his new stepmother, Gertrude. He lived in this household with two stepbrothers for several months. After Gertrude gave birth to a daughter, Armstrong's father never welcomed him, so he returned to his mother, Mary Albert. In her small home, he had to share a bed with his mother and sister. His mother still lived in The Battlefield, leaving him open to old temptations, but he sought work as a musician. He found a job at a dance hall owned by Henry Ponce, who had connections to organized crime. He met the six-foot tall drummer Black Benny, who became his guide and bodyguard.

Armstrong played in brass bands and riverboats in New Orleans, first on an excursion boat in September 1918. He traveled with the band of Fate Marable, which toured on the steamboat "Sidney" with the Streckfus Steamers line up and down the Mississippi River. Marable was proud of his musical knowledge, and he insisted that Armstrong and other musicians in his band learn sight reading. Armstrong described his time with Marable as "going to the University", since it gave him a wider experience working with written arrangements. He did return to New Orleans periodically. In 1919, Oliver decided to go north and resigned his position in Kid Ory's band; Armstrong replaced him. He also became second trumpet for the Tuxedo Brass Band.

Throughout his riverboat experience, Armstrong's musicianship began to mature and expand. At twenty, he could read music. He became one of the first jazz musicians to be featured on extended trumpet solos, injecting his own personality and style. He started singing in his performances. In 1922, he moved to Chicago at the invitation of King Oliver. With Oliver's Creole Jazz Band he could make enough money to quit his day jobs. Although race relations were poor, Chicago was booming. The city had jobs for blacks making good wages at factories with some left over for entertainment.

Oliver's band was among the most influential jazz bands in Chicago in the early 1920s. Armstrong lived luxuriously in his own apartment with his first private bath. Excited as he was to be in Chicago, he began his career-long pastime of writing letters to friends in New Orleans. Armstrong could blow two hundred high Cs in a row. As his reputation grew, he was challenged to cutting contests by other musicians.

His first studio recordings were with Oliver for Gennett Records on April 56, 1923. They endured several hours on the train to remote Richmond, Indiana, and the band was paid little. The quality of the performances was affected by lack of rehearsal, crude recording equipment, bad acoustics, and a cramped studio. In addition, Richmond was associated with the Ku Klux Klan.

Lil Hardin Armstrong urged him to seek more prominent billing and develop his style apart from the influence of Oliver. She encouraged him to play classical music in church concerts to broaden his skills. She prodded him into wearing more stylish attire to offset his girth. Her influence eventually undermined Armstrong's relationship with his mentor, especially concerning his salary and additional money that Oliver held back from Armstrong and other band members.

Armstrong and Oliver parted amicably in 1924. Shortly afterward, Armstrong received an invitation to go to New York City to play with the Fletcher Henderson Orchestra, the top African-American band of the time. He switched to the trumpet to blend in better with the other musicians in his section. His influence on Henderson's tenor sax soloist, Coleman Hawkins, can be judged by listening to the records made by the band during this period.

Armstrong adapted to the tightly controlled style of Henderson, playing trumpet and experimenting with the trombone. The other members were affected by Armstrong's emotional style. His act included singing and telling tales of New Orleans characters, especially preachers. The Henderson Orchestra played in prominent venues for patrons only, including the Roseland Ballroom, with arrangements by Don Redman. Duke Ellington's orchestra went to Roseland to catch Armstrong's performances.

During this time, Armstrong recorded with Clarence Williams (a friend from New Orleans), the Williams Blue Five, Sidney Bechet, and blues singers Alberta Hunter, Ma Rainey, and Bessie Smith.

In 1925, Armstrong returned to Chicago largely at the insistence of Lil, who wanted to expand his career and his income. In publicity, much to his chagrin, she billed him as "the World's Greatest Trumpet Player". For a time he was a member of the Lil Hardin Armstrong Band and working for his wife. He formed Louis Armstrong and his Hot Five and recorded the hits "Potato Head Blues" and "Muggles". The word "muggles" was a slang term for marijuana, something he used often during his life.

The Hot Five included Kid Ory (trombone), Johnny Dodds (clarinet), Johnny St. Cyr (banjo), Lil Armstrong on piano, and usually no drummer. Over a twelve-month period starting in November 1925, this quintet produced twenty-four records. Armstrong's band leading style was easygoing, as St. Cyr noted, "One felt so relaxed working with him, and he was very broad-minded ... always did his best to feature each individual." Among the most notable of the Hot Five and Seven records were "Cornet Chop Suey", "Struttin' With Some Barbecue", "Hotter Than that" and "Potato Head Blues", all featuring highly creative solos by Armstrong. His recordings soon after with pianist Earl "Fatha" Hines (most famously their 1928 "Weather Bird" duet) and Armstrong's trumpet introduction to and solo in "West End Blues" remain some of the most famous and influential improvisations in jazz history. Armstrong was now free to develop his personal style as he wished, which included a heavy dose of effervescent jive, such as "Whip That Thing, Miss Lil" and "Mr. Johnny Dodds, Aw, Do That Clarinet, Boy!"

Armstrong also played with Erskine Tate's Little Symphony, which played mostly at the Vendome Theatre. They furnished music for silent movies and live shows, including jazz versions of classical music, such as "Madame Butterfly", which gave Armstrong experience with longer forms of music and with hosting before a large audience. He began to scat sing (improvised vocal jazz using nonsensical words) and was among the first to record it, on the Hot Five recording "Heebie Jeebies" in 1926. The recording was so popular that the group became the most famous jazz band in the United States, even though they had not performed live to any great extent. Young musicians across the country, black or white, were turned on by Armstrong's new type of jazz.

After separating from Lil, Armstrong started to play at the Sunset Café for Al Capone's associate Joe Glaser in the Carroll Dickerson Orchestra, with Earl Hines on piano, which was renamed Louis Armstrong and his Stompers, though Hines was the music director and Glaser managed the orchestra. Hines and Armstrong became fast friends and successful collaborators. It was at the Sunset Café that Armstrong accompanied singer Adelaide Hall. It was during Hall's tenure at the venue that she experimented, developed and expanded her use and art of Scat singing with Armstrong's guidance and encouragement.

In the first half of 1927, Armstrong assembled his Hot Seven group, which added drummer Al "Baby" Dodds and tuba player, Pete Briggs, while preserving most of his original Hot Five lineup. John Thomas replaced Kid Ory on trombone. Later that year he organized a series of new Hot Five sessions which resulted in nine more records. In the last half of 1928, he started recording with a new group: Zutty Singleton (drums), Earl Hines (piano), Jimmy Strong (clarinet), Fred Robinson (trombone), and Mancy Carr (banjo).

Armstrong returned to New York in 1929, where he played in the pit orchestra for the musical "Hot Chocolates", an all-black revue written by Andy Razaf and pianist Fats Waller. He also made a cameo appearance as a vocalist, regularly stealing the show with his rendition of "Ain't Misbehavin'". His version of the song became his biggest selling record to date.

Armstrong started to work at Connie's Inn in Harlem, chief rival to the Cotton Club, a venue for elaborately staged floor shows, and a front for gangster Dutch Schultz. Armstrong also had considerable success with vocal recordings, including versions of famous songs composed by his old friend Hoagy Carmichael. His 1930s recordings took full advantage of the new RCA ribbon microphone, introduced in 1931, which imparted a characteristic warmth to vocals and immediately became an intrinsic part of the 'crooning' sound of artists like Bing Crosby. Armstrong's famous interpretation of Carmichael's "Stardust" became one of the most successful versions of this song ever recorded, showcasing Armstrong's unique vocal sound and style and his innovative approach to singing songs that had already become standards.

Armstrong's radical re-working of Sidney Arodin and Carmichael's "Lazy River" (recorded in 1931) encapsulated many features of his groundbreaking approach to melody and phrasing. The song begins with a brief trumpet solo, then the main melody is introduced by sobbing horns, memorably punctuated by Armstrong's growling interjections at the end of each bar: "Yeah! ..."Uh-huh"..."Sure"..."Way down, way down." In the first verse, he ignores the notated melody entirely and sings as if playing a trumpet solo, pitching most of the first line on a single note and using strongly syncopated phrasing. In the second stanza he breaks into an almost fully improvised melody, which then evolves into a classic passage of Armstrong "scat singing".

As with his trumpet playing, Armstrong's vocal innovations served as a foundation stone for the art of jazz vocal interpretation. The uniquely gravelly coloration of his voice became a musical archetype that was much imitated and endlessly impersonated. His scat singing style was enriched by his matchless experience as a trumpet soloist. His resonant, velvety lower-register tone and bubbling cadences on sides such as "Lazy River" exerted a huge influence on younger white singers such as Bing Crosby.

The Great Depression of the early 1930s was especially hard on the jazz scene. The Cotton Club closed in 1936 after a long downward spiral, and many musicians stopped playing altogether as club dates evaporated. Bix Beiderbecke died and Fletcher Henderson's band broke up. King Oliver made a few records but otherwise struggled. Sidney Bechet became a tailor, later moving to Paris and Kid Ory returned to New Orleans and raised chickens.

Armstrong moved to Los Angeles in 1930 to seek new opportunities. He played at the New Cotton Club in Los Angeles with Lionel Hampton on drums. The band drew the Hollywood crowd, which could still afford a lavish night life, while radio broadcasts from the club connected with younger audiences at home. Bing Crosby and many other celebrities were regulars at the club. In 1931, Armstrong appeared in his first movie, "Ex-Flame" and was also convicted of marijuana possession but received a suspended sentence. He returned to Chicago in late 1931 and played in bands more in the Guy Lombardo vein and he recorded more standards. When the mob insisted that he get out of town, Armstrong visited New Orleans, had a hero's welcome, and saw old friends. He sponsored a local baseball team known as Armstrong's Secret Nine and had a cigar named after him. But soon he was on the road again. After a tour across the country shadowed by the mob, he fled to Europe.

After returning to the United States, he undertook several exhausting tours. His agent Johnny Collins's erratic behavior and his own spending ways left Armstrong short of cash. Breach of contract violations plagued him. He hired Joe Glaser as his new manager, a tough mob-connected wheeler-dealer, who began to straighten out his legal mess, his mob troubles, and his debts. Armstrong also began to experience problems with his fingers and lips, which were aggravated by his unorthodox playing style. As a result, he branched out, developing his vocal style and making his first theatrical appearances. He appeared in movies again, including Crosby's 1936 hit "Pennies from Heaven". In 1937, Armstrong substituted for Rudy Vallee on the CBS radio network and became the first African American to host a sponsored, national broadcast.

During the 1920s, Louis Armstrong brought a huge impact during the Harlem Renaissance within the Jazz world. The music he created was an incredible part of his life during the Harlem Renaissance. His impact touched many, including a well known man during that time named Langston Hughes. The admiration he had for Armstrong and acknowledging him as one of the most recognized musicians during the era. Within Hughes writings, he created many books which held the central idea of jazz and recognition to Armstrong as one of the most important person to be part of the new found love of their culture. The sound of jazz, along with many other musicians such as Armstrong, helped shape Hughes as a writer. Just as the musicians, Hughes wrote his words with jazz.

Armstrong changed the jazz during the Harlem Renaissance. Being known as "the world's greatest trumpet player" during this time he continued his legacy and decided to continue a focus on his own vocal career. The popularity he gained brought together many black and white audiences to watch him perform.

After spending many years on the road, Armstrong settled permanently in Queens, New York in 1943 in contentment with his fourth wife, Lucille. Although subject to the vicissitudes of Tin Pan Alley and the gangster-ridden music business, as well as anti-black prejudice, he continued to develop his playing. He recorded Hoagy Carmichael's "Rockin' Chair" for Okeh Records.

During the next 30 years, Armstrong played more than 300 performances a year. Bookings for big bands tapered off during the 1940s due to changes in public tastes: ballrooms closed, and there was competition from television and from other types of music becoming more popular than big band music. It became impossible under such circumstances to finance a 16-piece touring band.

During the 1940s, a widespread revival of interest in the traditional jazz of the 1920s made it possible for Armstrong to consider a return to the small-group musical style of his youth. Armstrong was featured as a guest artist with Lionel Hampton's band at the famed second Cavalcade of Jazz concert held at Wrigley Field in Los Angeles which was produced by Leon Hefflin Sr. on October 12, 1946. Following a highly successful small-group jazz concert at New York Town Hall on May 17, 1947, featuring Armstrong with trombonist/singer Jack Teagarden, Armstrong's manager, Joe Glaser dissolved the Armstrong big band on August 13, 1947, and established a six-piece traditional jazz group featuring Armstrong with (initially) Teagarden, Earl Hines and other top swing and Dixieland musicians, most of whom were previously leaders of big bands. The new group was announced at the opening of Billy Berg's Supper Club.

This group was called Louis Armstrong and His All Stars and included at various times Earl "Fatha" Hines, Barney Bigard, Edmond Hall, Jack Teagarden, Trummy Young, Arvell Shaw, Billy Kyle, Marty Napoleon, Big Sid Catlett, Cozy Cole, Tyree Glenn, Barrett Deems, Mort Herbert, Joe Darensbourg, Eddie Shu and percussionist Danny Barcelona. During this period, Armstrong made many recordings and appeared in over thirty films. He was the first jazz musician to appear on the cover of "Time" magazine, on February 21, 1949. Louis Armstrong and his All Stars were featured at the ninth Cavalcade of Jazz concert also at Wrigley Field in Los Angeles produced by Leon Hefflin Sr. held on June 7, 1953 along with Shorty Rogers, Roy Brown, Don Tosti and His Mexican Jazzmen, Earl Bostic, and Nat "King" Cole.

By the 1950s, Armstrong was a widely beloved American icon and cultural ambassador who commanded an international fanbase. However, a growing generation gap became apparent between him and the young jazz musicians who emerged in the postwar era such as Charlie Parker, Miles Davis, and Sonny Rollins. The postwar generation regarded their music as abstract art and considered Armstrong's vaudevillian style, half-musician and half-stage entertainer, outmoded and Uncle Tomism, "... he seemed a link to minstrelsy that we were ashamed of." He called bebop "Chinese music". While touring Australia, 1954, he was asked if he could play bebop. "Bebop?" he husked. "I just play music. Guys who invent terms like that are walking the streets with their instruments under their arms."

In June 1950, Suzy Delair performed rehearsals of the song "C'est si bon" with Aimé Barelli and his orchestra at the Monte Carlo casino where Louis Armstrong was finishing the evening. Armstrong enjoyed the song and he recorded the American version in New York City on June 26, 1950. In the 1960s, he toured Ghana and Nigeria.

After finishing his contract with Decca Records, he became a freelance artist and recorded for other labels. He continued an intense international touring schedule, but in 1959 he suffered a heart attack in Italy and had to rest.

In 1964, after over two years without setting foot in a studio, he recorded his biggest-selling record, "Hello, Dolly!", a song by Jerry Herman, originally sung by Carol Channing. Armstrong's version remained on the Hot 100 for 22 weeks, longer than any other record produced that year, and went to No. 1 making him, at 62 years, 9 months and 5 days, the oldest person ever to accomplish that feat. In the process, he dislodged the Beatles from the No. 1 position they had occupied for 14 consecutive weeks with three different songs.

Armstrong kept touring well into his 60s, even visiting part of the communist bloc in 1965. He also toured Africa, Europe, and Asia under the sponsorship of the US State Department with great success, earning the nickname "Ambassador Satch" and inspiring Dave Brubeck to compose his jazz musical "The Real Ambassadors". By 1968, he was approaching 70 and his health began to give out. He suffered heart and kidney ailments that forced him to stop touring. He did not perform publicly at all in 1969 and spent most of the year recuperating at home. Meanwhile, his longtime manager Joe Glaser died. By the summer of 1970, his doctors pronounced him fit enough to resume live performances. He embarked on another world tour, but a heart attack forced him to take a break for two months.

Armstrong made his last recorded trumpet performances on his 1968 album "Disney Songs the Satchmo Way".

The Louis Armstrong House Museum website states:

In a memoir written for Robert Goffin between 1943 and 1944, Armstrong states, "All white folks call me Louie," perhaps suggesting that he himself did not or, on the other hand, that no whites addressed him by one of his nicknames such as Pops. That said, Armstrong was registered as "Lewie" for the 1920 U.S. Census. On various live records he's called "Louie" on stage, such as on the 1952 "Can Anyone Explain?" from the live album "In Scandinavia vol.1". The same applies to his 1952 studio recording of the song "Chloe", where the choir in the background sings "Louie ... Louie", with Armstrong responding "What was that? Somebody called my name?" "Lewie" is the French pronunciation of "Louis" and is commonly used in Louisiana.

Armstrong was performing at the Brick House in Gretna, Louisiana, when he met Daisy Parker, a local prostitute. He started the affair as a client. He returned to Gretna on several occasions to visit her. He found the courage to look for her home to see her away from work. It was on this occasion that he found out that she had a common-law husband. Not long after this fiasco, Parker traveled to Armstrong's home on Perdido Street. They checked into Kid Green's hotel that evening. On the next day, March 19, 1919, Armstrong and Parker married at City Hall. They adopted a three-year-old boy, Clarence, whose mother, Armstrong's cousin Flora, had died soon after giving birth. Clarence Armstrong was mentally disabled as the result of a head injury at an early age, and Armstrong spent the rest of his life taking care of him. His marriage to Parker ended when they separated in 1923.

On February 4, 1924, he married Lil Hardin Armstrong, King Oliver's pianist. She had divorced her first husband a few years earlier. His second wife helped him develop his career, but they separated in 1931 and divorced in 1938. Armstrong then married Alpha Smith. His marriage to his third wife lasted four years, and they divorced in 1942. Louis then married Lucille Wilson in October 1942, a singer at the Cotton Club, to whom he was married until his death in 1971.

Armstrong's marriages never produced any offspring. However, in December 2012, 57-year-old Sharon Preston-Folta claimed to be his daughter from a 1950s affair between Armstrong and Lucille "Sweets" Preston, a dancer at the Cotton Club. In a 1955 letter to his manager, Joe Glaser, Armstrong affirmed his belief that Preston's newborn baby was his daughter, and ordered Glaser to pay a monthly allowance of $400 (US$ in dollars) to mother and child.

Armstrong was noted for his colorful and charismatic personality. His autobiography vexed some biographers and historians, as he had a habit of telling tales, particularly of his early childhood when he was less scrutinized, and his embellishments of his history often lack consistency.

In addition to being an entertainer, Armstrong was a leading personality of the day. He was beloved by an American public that gave even the greatest African American performers little access beyond their public celebrity, and he was able to live a private life of access and privilege afforded to few other African Americans during that era.

He generally remained politically neutral, which at times alienated him from members of the black community who looked to him to use his prominence with white America to become more of an outspoken figure during the civil rights movement. However, he did criticize President Eisenhower for not acting forcefully enough on civil rights.

The trumpet is a notoriously hard instrument on the lips, and Armstrong suffered from lip damage over much of his life due to his aggressive style of playing and preference for narrow mouthpieces that would stay in place easier, but which tended to dig into the soft flesh of his inner lip. During his 1930s European tour, he suffered an ulceration so severe that he had to stop playing entirely for a year. Eventually he took to using salves and creams on his lips and also cutting off scar tissue with a razor blade. By the 1950s, he was an official spokesman for Ansatz-Creme Lip Salve.

During a backstage meeting with trombonist Marshall Brown in 1959, Armstrong received the suggestion that he should go to a doctor and receive proper treatment for his lips instead of relying on home remedies, but he did not get around to doing it until the final years of his life, by which point his health was failing and doctors considered surgery too risky.

The nicknames "Satchmo" and "Satch" are short for "Satchelmouth". The nickname has many possible origins. The most common tale that biographers tell is the story of Armstrong as a young boy in New Orleans dancing for pennies. He scooped the coins off the street and stuck them into his mouth to prevent bigger children from stealing them. Someone dubbed him "satchel mouth" for his mouth acting as a satchel. Another tale is that because of his large mouth, he was nicknamed "satchel mouth" which was shortened to "Satchmo".

Early on he was also known as "Dipper", short for "Dippermouth", a reference to the piece "Dippermouth Blues". and something of a riff on his unusual embouchure.

The nickname "Pops" came from Armstrong's own tendency to forget people's names and simply call them "Pops" instead. The nickname was turned on Armstrong himself. It was used as the title of a 2010 biography of Armstrong by Terry Teachout.

Armstrong was largely accepted into white society, both on stage and off, a rarity for a black person at the time. Some musicians criticized Armstrong for playing in front of segregated audiences, and for not taking a strong enough stand in the American civil rights movement. When he did speak out, it made national news, including his criticism of President Eisenhower, calling him "two-faced" and "gutless" because of his inaction during the conflict over school desegregation in Little Rock, Arkansas, in 1957. As a protest, Armstrong canceled a planned tour of the Soviet Union on behalf of the State Department saying: "The way they're treating my people in the South, the government can go to hell" and that he could not represent his government abroad when it was in conflict with its own people. The FBI kept a file on Armstrong for his outspokenness about integration.

When asked about his religion, Armstrong answered that he was raised a Baptist, always wore a Star of David, and was friends with the pope. He wore the Star of David in honor of the Karnoffsky family, who took him in as a child and lent him money to buy his first cornet. He was baptized a Catholic in the Sacred Heart of Jesus Church in New Orleans, and he met Pope Pius XII and Pope Paul VI.

Armstrong was concerned with his health. He used laxatives to control his weight, a practice he advocated both to acquaintances and in the diet plans he published under the title "Lose Weight the Satchmo Way". Armstrong's laxative of preference in his younger days was Pluto Water, but when he discovered the herbal remedy Swiss Kriss, he became an enthusiastic convert, extolling its virtues to anyone who would listen and passing out packets to everyone he encountered, including members of the British Royal Family. (Armstrong also appeared in humorous, albeit risqué, cards that he had printed to send out to friends; the cards bore a picture of him sitting on a toilet—as viewed through a keyhole—with the slogan ""Satch says, 'Leave it all behind ya!'"") The cards have sometimes been incorrectly described as ads for Swiss Kriss. In a live recording of "Baby, It's Cold Outside" with Velma Middleton, he changes the lyric from "Put another record on while I pour" to "Take some Swiss Kriss while I pour."

Armstrong was a heavy marijuana smoker for much of his life and spent nine days in jail in 1930 after being arrested for drug possession outside a club. He described marijuana as "a thousand times better than whiskey".

The concern with his health and weight was balanced by his love of food, reflected in such songs as "Cheesecake", "Cornet Chop Suey", though "Struttin' with Some Barbecue" was written about a fine-looking companion, not about food. He kept a strong connection throughout his life to the cooking of New Orleans, always signing his letters, "Red beans and ricely yours ..."

A fan of Major League Baseball, he founded a team in New Orleans that was known as Raggedy Nine and transformed the team into his Armstrong's "Secret Nine Baseball".

Armstrong's gregariousness extended to writing. On the road, he wrote constantly, sharing favorite themes of his life with correspondents around the world. He avidly typed or wrote on whatever stationery was at hand, recording instant takes on music, sex, food, childhood memories, his heavy "medicinal" marijuana use—and even his bowel movements, which he gleefully described.

Louis Armstrong was not, as is often claimed, a Freemason. Although he is usually listed as being a member of Montgomery Lodge No. 18 (Prince Hall) in New York, no such lodge has ever existed. However, Armstrong stated in his autobiography that he was a member of the Knights of Pythias, which although real is not a Masonic group.

In his early years, Armstrong was best known for his virtuosity with the cornet and trumpet. Along with his "clarinet-like figurations and high notes in his cornet solos", he was also known for his "intense rhythmic 'swing', a complex conception involving ... accented upbeats, upbeat to downbeat slurring, and complementary relations among rhythmic patterns." The most lauded recordings on which Armstrong plays trumpet include the Hot Five and Hot Seven sessions, as well as those of the Red Onion Jazz Babies. Armstrong's improvisations, while unconventionally sophisticated for that era, were also subtle and highly melodic. The solo that Armstrong plays during the song "Potato Head Blues" has long been considered his best solo of that series.

Prior to Armstrong, most collective ensemble playing in jazz, along with its occasional solos, simply varied the melodies of the songs. Armstrong was virtually the first to create significant variations based on the chord harmonies of the songs instead of merely on the melodies. This opened a rich field for creation and improvisation, and significantly changed the music into a soloist's art form.

Often, Armstrong re-composed pop-tunes he played, simply with variations that made them more compelling to jazz listeners of the era. At the same time, however, his oeuvre includes many original melodies, creative leaps, and relaxed or driving rhythms. Armstrong's playing technique, honed by constant practice, extended the range, tone and capabilities of the trumpet. In his records, Armstrong almost single-handedly created the role of the jazz soloist, taking what had been essentially a collective folk music and turning it into an art form with tremendous possibilities for individual expression.

Armstrong was one of the first artists to use recordings of his performances to improve himself. Armstrong was an avid audiophile. He had a large collection of recordings, including reel-to-reel tapes, which he took on the road with him in a trunk during his later career. He enjoyed listening to his own recordings, and comparing his performances musically. In the den of his home, he had the latest audio equipment and would sometimes rehearse and record along with his older recordings or the radio.

As his music progressed and popularity grew, his singing also became very important. Armstrong was not the first to record scat singing, but he was masterful at it and helped popularize it with the first recording on which he scatted, "Heebie Jeebies". At a recording session for Okeh Records, when the sheet music supposedly fell on the floor and the music began before he could pick up the pages, Armstrong simply started singing nonsense syllables while Okeh president E.A. Fearn, who was at the session, kept telling him to continue. Armstrong did, thinking the track would be discarded, but that was the version that was pressed to disc, sold, and became an unexpected hit. Although the story was thought to be apocryphal, Armstrong himself confirmed it in at least one interview as well as in his memoirs. On a later recording, Armstrong also sang out "I done forgot the words" in the middle of recording "I'm A Ding Dong Daddy From Dumas".

Such records were hits and scat singing became a major part of his performances. Long before this, however, Armstrong was playing around with his vocals, shortening and lengthening phrases, interjecting improvisations, using his voice as creatively as his trumpet. Armstrong once told Cab Calloway that his scat style was derived "from the Jews "rockin"", an Orthodox Jewish style of chanting during prayer.

Armstrong was a gifted composer who wrote more than fifty songs, some of which have become jazz standards (e.g. "Gully Low Blues", "Potato Head Blues" and "Swing That Music").

During his long career he played and sang with some of the most important instrumentalists and vocalists of the time; among them were Bing Crosby, Duke Ellington, Fletcher Henderson, Earl Hines, Jimmie Rodgers, Bessie Smith and perhaps most famously Ella Fitzgerald. His influence upon Crosby is particularly important with regard to the subsequent development of popular music: Crosby admired and copied Armstrong, as is evident on many of his early recordings, notably "Just One More Chance" (1931). The "New Grove Dictionary of Jazz" describes Crosby's debt to Armstrong in precise detail, although it does not acknowledge Armstrong by name:

Armstrong recorded two albums with Ella Fitzgerald: "Ella and Louis", and "Ella and Louis Again" for Verve Records, with the sessions featuring the backing musicianship of the Oscar Peterson Trio and drummers Buddy Rich (on the first album), and Louie Bellson (on the second). Norman Granz then had the vision for Ella and Louis to record "Porgy and Bess".

His recordings for Columbia Records, "Louis Armstrong Plays W.C. Handy" (1954) and "Satch Plays Fats" (all Fats Waller tunes) (1955) were both being considered masterpieces, as well as moderately well selling. In 1961 the All Stars participated in two albums—"The Great Summit" and "The Great Reunion" (now together as a single disc) with Duke Ellington. The albums feature many of Ellington's most famous compositions (as well as two exclusive cuts) with Duke sitting in on piano. His participation in Dave Brubeck's high-concept jazz musical "The Real Ambassadors" (1963) was critically acclaimed, and features "Summer Song", one of Armstrong's most popular vocal efforts.
In 1964, his recording of the song "Hello Dolly" went to number one. An album of the same title was quickly created around the song, and also shot to number one (knocking The Beatles off the top of the chart). The album sold very well for the rest of the year, quickly going "Gold" (500,000). His performance of "Hello Dolly" won for best male pop vocal performance at the 1964 Grammy Awards.

Armstrong had nineteen "Top Ten" records including "Stardust", "What a Wonderful World", "When The Saints Go Marching In", "Dream a Little Dream of Me", "Ain't Misbehavin'", "You Rascal You", and "Stompin' at the Savoy". "We Have All the Time in the World" was featured on the soundtrack of the James Bond film "On Her Majesty's Secret Service", and enjoyed renewed popularity in the UK in 1994 when it featured on a Guinness advertisement. It reached number 3 in the charts on being re-released.

In 1964, Armstrong knocked The Beatles off the top of the "Billboard" Hot 100 chart with "Hello, Dolly!", which gave the 63-year-old performer a U.S. record as the oldest artist to have a number one song. His 1964 song "Bout Time" was later featured in the film "Bewitched".

Armstrong performed in Italy at the 1968 Sanremo Music Festival where he sang "Mi Va di Cantare" alongside his friend, the Eritrean-born Italian singer Lara Saint Paul. In February 1968, he also appeared with Lara Saint Paul on the Italian RAI television channel where he performed "Grassa e Bella", a track he sang in Italian for the Italian market and C.D.I. label.

In 1968, Armstrong scored one last popular hit in the United Kingdom with "What a Wonderful World", which topped the British charts for a month. Armstrong appeared on the October 28, 1970, "Johnny Cash Show", where he sang Nat King Cole's hit "Ramblin' Rose" and joined Cash to re-create his performance backing Jimmie Rodgers on "Blue Yodel No. 9".

Armstrong enjoyed many types of music, from blues to the arrangements of Guy Lombardo, to Latin American folksongs, to classical symphonies and opera. He incorporated influences from all these sources into his performances, sometimes to the bewilderment of fans who wanted him to stay in convenient narrow categories. Armstrong was inducted into the Rock and Roll Hall of Fame as an "early influence". Some of his solos from the 1950s, such as the hard rocking version of "St. Louis Blues" from the "WC Handy" album, show that the influence went in both directions.

Armstrong appeared in more than a dozen Hollywood films, usually playing a bandleader or musician. His most familiar role was as the bandleader "cum" narrator in the 1956 musical "High Society" in which he sang the title song and performed a duet with Bing Crosby on "Now You Has Jazz". In 1947, he played himself in the movie "New Orleans" opposite Billie Holiday, which chronicled the demise of the Storyville district and the ensuing exodus of musicians from New Orleans to Chicago. In the 1959 film "The Five Pennies" he played himself, sang, and played several classic numbers. With Danny Kaye he performed a duet of "When the Saints Go Marching In" during which Kaye impersonated Armstrong. He had a part in the film alongside James Stewart in "The Glenn Miller Story".

Armstrong was the first African American to host a nationally broadcast radio show in the 1930s. In 1969, he had a cameo role in the film version of "Hello, Dolly!" as the bandleader Louis. He sang the title song with actress Barbra Streisand. His solo recording of "Hello, Dolly!" is one of his most recognizable performances.

Argentine writer Julio Cortázar, a self-described Armstrong admirer, asserted that a 1952 Louis Armstrong concert at the Théâtre des Champs-Élysées in Paris played a significant role in inspiring him to create the fictional creatures called Cronopios that are the subject of a number of Cortázar's short stories. Cortázar once called Armstrong himself "Grandísimo Cronopio" (The Great Cronopio).

There is a pivotal scene in "Stardust Memories" (1980) in which Woody Allen is overwhelmed by a recording of Armstrong's "Stardust" and experiences a nostalgic epiphany.

Against his doctor's advice, Armstrong played a two-week engagement in March 1971 at the Waldorf-Astoria's Empire Room. At the end of it, he was hospitalized for a heart attack. He was released from the hospital in May, and quickly resumed practicing his trumpet playing. Still hoping to get back on the road, Armstrong died of a heart attack in his sleep on July 6, 1971, a month before his 70th birthday. He was residing in Corona, Queens, New York City, at the time of his death. He was interred in Flushing Cemetery, Flushing, in Queens, New York City.
His honorary pallbearers included Bing Crosby, Ella Fitzgerald, Dizzy Gillespie, Pearl Bailey, Count Basie, Harry James, Frank Sinatra, Ed Sullivan, Earl Wilson, Alan King, Johnny Carson and David Frost. Peggy Lee sang The Lord's Prayer at the services while Al Hibbler sang "Nobody Knows the Trouble I've Seen" and Fred Robbins, a long-time friend, gave the eulogy.

Armstrong was posthumously awarded the Grammy Lifetime Achievement Award in 1972 by the Academy of Recording Arts and Sciences. This Special Merit Award is presented by vote of the Recording Academy's National Trustees to performers who, during their lifetimes, have made creative contributions of outstanding artistic significance to the field of recording.

Recordings of Armstrong were inducted into the Grammy Hall of Fame, which is a special Grammy award established in 1973 to honor recordings that are at least 25 years old, and that have "qualitative or historical significance".

The Rock and Roll Hall of Fame listed Armstrong's "West End Blues" on the list of 500 songs that shaped Rock and Roll.

In 1995, the U.S. Post Office issued a Louis Armstrong 32 cents commemorative postage stamp.

In 1999 Armstrong was nominated for inclusion in the American Film Institute's 100 Years ... 100 Stars.

The influence of Armstrong on the development of jazz is virtually immeasurable. His irrepressible personality both as a performer and as a public figure was so strong that to some it sometimes overshadowed his contributions as a musician and singer.

As a virtuoso trumpet player, Armstrong had a unique tone and an extraordinary talent for melodic improvisation. Through his playing, the trumpet emerged as a solo instrument in jazz and is used widely today. Additionally, jazz itself was transformed from a collectively improvised folk music to a soloist's serious art form largely through his influence. He was a masterful accompanist and ensemble player in addition to his extraordinary skills as a soloist. With his innovations, he raised the bar musically for all who came after him.

Though Armstrong is widely recognized as a pioneer of scat singing, Ethel Waters precedes his scatting on record in the 1930s according to Gary Giddins and others. Billie Holiday and Frank Sinatra are just two singers who were greatly indebted to him. Holiday said that she always wanted Bessie Smith's 'big' sound and Armstrong's feeling in her singing. Even special musicians like Duke Ellington have praised Armstrong through strong testimonials. Duke Ellington, DownBeat magazine in 1971, said, "If anybody was a master, it was Louis Armstrong. He was and will continue to be the embodiment of jazz." In 1950, Bing Crosby, the most successful vocalist of the first half of the 20th century, said, "He is the beginning and the end of music in America."

In the summer of 2001, in commemoration of the centennial of Armstrong's birth, New Orleans's main airport was renamed Louis Armstrong New Orleans International Airport.

In 2002, the Louis Armstrong's Hot Five and Hot Seven recordings (1925–1928) were preserved in the United States National Recording Registry, a registry of recordings selected yearly by the National Recording Preservation Board for preservation in the National Recording Registry of the Library of Congress.

The US Open tennis tournament's former main stadium was named Louis Armstrong Stadium in honor of Armstrong who had lived a few blocks from the site.

"Congo Square" was a common gathering place for African-Americans in New Orleans for dancing and performing music. The park where Congo Square is located was later renamed Louis Armstrong Park. Dedicated in April 1980, the park includes a 12-foot statue of Armstrong, trumpet in hand.

The house where Armstrong lived for almost 28 years was declared a National Historic Landmark in 1977 and is now a museum. The Louis Armstrong House Museum, at 34-56 107th Street between 34th and 37th avenues in Corona, Queens, presents concerts and educational programs, operates as a historic house museum and makes materials in its archives of writings, books, recordings and memorabilia available to the public for research. The museum is operated by the Queens College, City University of New York, following the dictates of Lucille Armstrong's will. The museum opened to the public on October 15, 2003. A new visitors center is planned.

Armstrong appeared at many New York area venues, including several extended engagements at Freedomland U.S.A. in The Bronx. His performances there are featured in the book, "Freedomland U.S.A.: The Definitive History" (Theme Park Press, 2019). 

According to literary critic Harold Bloom, "The two great American contributions to the world's art, in the end, are Walt Whitman and, after him, Armstrong and jazz ... If I had to choose between the two, ultimately, I wouldn't. I would say that the genius of this nation at its best is indeed Walt Whitman and Louis Armstrong." 

On June 25, 2019, "The New York Times Magazine" listed Louis Armstrong among hundreds of artists whose material was reportedly destroyed in the 2008 Universal fire.





</doc>
